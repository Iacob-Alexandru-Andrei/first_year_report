The Academic Phrasebank is a
general resource for academic
writers. It makes explicit the more
common phraseological ‘nuts and
bolts’ of academic writing.

Academic
Phrasebank
A compendium of commonly
used phrasal elements in
academic English in PDF format
2021 enhanced edition
Personal Copy

Dr John Morley

Navigable PDF version

3rd Edition

©2021 The University of Manchester

The enhanced PDF version of Academic Phrasebank is for the sole use of the individual who has downloaded it from
www.phrasebankresearch.net. Distribution of the enhanced PDF version of Academic Phrasebank by electronic (e.g. via
email, web download) or any other means is strictly prohibited and constitutes copyright infringement.
The enhanced version of Academic Phrasebank is only available on this website: http://www.phrasebankresearch.net as a
PDF file or on the Kindle store (search “Academic Phrasebank” in your regional Kindle store). If you see this enhanced
version of Academic Phrasebank made available anywhere else, please contact john.morley@manchester.ac.uk
immediately.

Preface
The Academic Phrasebank is a general resource for academic writers. It aims to provide the
phraseological ‘nuts and bolts’ of academic writing organised according to the main sections of a
research paper or dissertation. Other phrases are listed under the more general communicative
functions of academic writing.
The resource was designed primarily for academic and scientific writers who are non-native speakers
of English. However, native writers may still find much of the material helpful. In fact, recent data
suggest that the majority of users are native speakers of English.
The phrases, and the headings under which they are listed, can be used simply to assist you in
thinking about the content and organisation of your own writing, or the phrases can be incorporated
into your writing where this is appropriate. In most cases, a certain amount of creativity and
adaptation will be necessary when a phrase is used.
The Academic Phrasebank is not discipline specific. Nevertheless, it should be particularly useful for
writers who need to report their empirical studies. The phrases are content neutral and generic in
nature; in using them, therefore, you are not stealing other people's ideas and this does not
constitute plagiarism.
Most of the phrases in this compendium have been organised according to the main sections of a
research report. However, it is an over-simplification to associate the phrases only with the section in
which they have been placed here. In reality, for example, many of phrases used for referring to
other studies may be found throughout a research report.
In the current PDF version, additional material, which is not phraseological, has been included at the
end of the document. These additional sections should be helpful to you as a writer.
Dr John Morley, 2021

2|Page

Contents
About Academic Phrasebank

Major Sections

Introducing Work
Reviewing the Literature
Describing Methods
Reporting Results
Discussing Findings
Writing Conclusions

General Functions

Being Cautious
Being Critical
Classifying and Listing
Comparing and Contrasting
Defining Terms
Describing Trends
Describing Quantities
Explaining Causality
Giving Examples as Support
Signalling Transition
Indicating Shared Knowledge
Writing about the Past
Writing Abstracts
Writing Acknowledgements

Notes on Academic Writing
Academic Style
Style in Presentations
British and US Spelling
Punctuation
Using Articles
Sentence Structure
Paragraph Structure
Tips on the Writing Process

Useful Lists

Connecting Words
Commonly Confused Words
Commonly Used Verbs

……………………………………………..……..…..................

4

……………………………………………..………....................
……………………………………………..………….................
……………………………………………..………....................
……………………………………………..………....................
……………………………………………..………....................
……………………………………………..………....................

7
32
47
57
65
73

……………………………………………..………....................
……………………………………………..………....................
……………………………………………..………....................
……………………………………………..………....................
……………………………………..………..………..................
………………………………………..……..………..................
…………………………………………..…..………..................
……………………………………………....………..................
……………………………………………….………..................
……………………………………………..…..……..................
……………………………………………..……..…..................
……………………………………………..……..…..................
……………………………………………..………....................
……………………………………………..………....................

84
88
99
102
106
111
113
115
119
121
125
127
129
132

……………………………………..………..………..................
………………………………………..……..………..................
…………………………………………..…..………..................
……………………………………………....………..................
……………………………………………….………..................
……………………………………………..…..……..................
……………………………………………..……..…..................
……………………………………………..………....................

135
138
141
142
143
145
147
148

……………………………………………..………....................
……………………………………………..………....................
……………………………………………..………....................

151
152
154

3|Page

About Academic Phrasebank
Theoretical Influences
The Academic Phrasebank largely draws on an approach to analysing academic texts originally
pioneered by John Swales in the 1980s. Utilising a genre analysis approach to identify rhetorical
patterns in the introductions to research articles, Swales defined a ‘move’ as a section of text that
serves a specific communicative function (Swales, 1981,1990). This unit of rhetorical analysis is used
as one of the main organising sub-categories of the Academic Phrasebank. Swales not only identified
commonly used moves in article introductions, but he was interested in showing the kind of language
which was used to achieve the communicative purpose of each move. Much of this language was
phraseological in nature.
The resource also draws upon psycholinguistic insights into how language is learnt and produced. It is
now accepted that much of the language we use is phraseological; that it is acquired, stored and
retrieved as pre-formulated constructions (Bolinger, 1976; Pawley and Syder, 1983). These insights
began to be supported empirically in the 1990s as computer technology permitted the identification
of recurrent phraseological patterns in very large corpora of spoken and written English using
specialised software (e.g. Sinclair, 1991). Phrasebank recognises that there is an important
phraseological dimension to academic language and attempts to make examples of this explicit.
Sources of the phrases
The vast majority of phrases in this resource have been taken from authentic academic sources. The
original corpus from which the phrases were ‘harvested’ consisted of 100 postgraduate dissertations
completed at the University of Manchester. However, phrases from academic articles drawn from a
broad spectrum of disciplines have also been, and continue to be, incorporated. In most cases, the
phrases have been simplified and where necessary they have been ‘sifted’ from their particularised
academic content. Where content words have been included for exemplificatory purposes, these are
substitutions of the original words. In selecting a phrase for inclusion into the Academic Phrasebank,
the following questions are asked:
•
•
•
•

does it serve a useful communicative purpose in academic text?
does it contain collocational and/or formulaic elements?
are the content words (nouns, verbs, adjectives) generic in nature?
does the combination ‘sound natural' to a native speaker or writer of English?

When is it acceptable to reuse phrases in academic writing?
In a recent study (Davis and Morley, 2015), 45 academics from two British universities were surveyed
to determine whether reusing phrases was a legitimate activity for academic writers, and if so, what
kind of phrases could be reused. From the survey and later from in-depth interviews, the following
characteristics for acceptability emerged. A reused phrase:
•
•
•
•

should not have a unique or original construction;
should not express a clear point of view of another writer;
depending on the phrase, may be up to nine words in length; beyond this 'acceptability'
declines;
may contain up to four generic content words (nouns, verbs or adjectives which are not
bound to a specific topic).

Some of the entries in the Academic Phrasebank, contain specific content words which have been
included for illustrative purposes. These words should be substituted when the phrases are used. In
the phrases below, for example, the content words in bold should be substituted:
4|Page

•
•

X is a major public health problem, and the cause of ...
X is the leading cause of death in western-industrialised countries.

The many thousands of disciplinary-specific phrases which can be found in academic communication
comprise a separate category of phrases. These tend to be shorter than the generic phrases listed in
Academic Phrasebank, and typically consist of noun phrases or combinations of these. Acceptability
for reusing these is determined by the extent to which they are commonly used and understood by
members of a particular academic community.
Further work
Development of the website content is ongoing. In addition, research is currently being carried out
on the ways in which experienced and less-experienced writers make use of the Academic
Phrasebank. Another project is seeking to find out more about ways in which teachers of English for
academic purposes make use of this resource.
References and related reading
•
•
•

•

•

•
•

•
•
•
•
•

Bolinger, D. (1976) ‘Meaning and memory’. Forum Linguisticum, 1, pp. 1–14.
Cowie, A. (1992) ‘Multiword lexical units and communicative language teaching’ in
Vocabulary and applied linguistics, Arnaud, P. and Béjoint, H. (eds). London: MacMillan.
Davis, M., and Morley, J. (2015) ‘Phrasal intertextuality: The responses of academics from
different disciplines to students’ re-use of phrases’. Journal Second Language Writing 28 (2),
pp. 20-35.
Davis, M. and Morley, J. (2018) in. ‘Writing with sources: how much can be copied?’ in
Student Plagiarism in Higher Education, edited by Diane Pecorari and Philip Shaw. Oxford:
Routledge.
Davis, M. and Morley, J. (2018) ‘Facilitating learning about academic phraseology: teaching
activities for student writers’, Journal of Learning Development in Higher Education. Special
Edition, pp 1- 17. ISSN: 1759-667X
Hopkins, A. and Dudley-Evans, A. (1988). ‘A genre-based investigations of the discussions
sections in articles and dissertation’. English for Specific Purposes, 7(2), pp.113-122.
Pawley, A., and Syder, F.H. (1983). ‘Two puzzles for linguistic theory: nativelike selection and
nativelike fluency’. In: Richards, J.C. and Schmidt, R.W. (Eds.), Language and communication,
pp. 191-226. Longman: New York.
Sinclair, J. (1991) Corpus, concordance, collocation. Oxford: Oxford University Press.
Swales, J. (1981). Aspects of article introductions (Aston ESP Research Report No. 1).
Birmingham: Language Studies Unit: University of Aston.
Swales, J. (1990). Genre analysis: English in academic and research settings. Cambridge:
Cambridge University Press.
Wood, D. (2015) The fundamentals of formulaic language. London: Bloomsbury.
Wray, A., and Perkins, M. (2000). ‘The functions of formulaic language: an integrated model’.
Language and Communication, 20, pp.1-28.

5|Page

Major Sections

6|Page

Introducing Work
There are many ways to introduce an academic essay or short paper. Most academic writers,
however, appear to do one or more of the following in their introductions:
•
•
•
•
•

establish the context, background and/or importance of the topic
indicate an issue, problem, or controversy in the field of study
define the topic or key terms
state the purpose of the essay or piece of writing
provide an overview of the coverage and/or structure of the writing

Slightly less complex introductions may simply inform the reader: what the topic is, why it is
important, and how the writing is organised. In very short assignments, it is not uncommon for a
writer to commence simply by stating the purpose of their writing and by indicating how it is
organised.
Introductions to research dissertations and theses tend to be relatively short compared to the
other sections of the text but quite complex in terms of their functional elements. Some of the
more common elements include:
•
•
•
•
•
•
•
•

establishing the context, background and/or importance of the topic
giving a brief review of the relevant academic literature
identifying a problem, controversy or a knowledge gap in the field of study
stating the aim(s) of the research and the research questions or hypotheses
providing a synopsis of the research design and method(s)
explaining the significance or value of the study
defining certain key terms
providing an overview of the dissertation or report structure

Examples of phrases which are commonly employed to realise these and other functions are
listed under the headings on the following pages of this section. Note that there may be a certain
amount of overlap between some of the categories under which the phrases are listed. Also, the
order in which the different categories of phrases are shown reflects a typical order but this is far
from fixed or rigid, and not all the elements are present in all introductions.
A number of analysts have identified common patterns in the introductions of research articles.
One of the best known is the CARS model (create a research space) first described by John Swales
(1990) 1. This model, which utilises an ecological metaphor, has, in its simplest form, three
elements or moves:
•
•
•

1

Establishing the territory (establishing importance of the topic, reviewing previous work)
Identifying a niche (indicating a gap in knowledge)
Occupying the niche (listing purpose of new research, listing questions, stating value,
indicating structure of writing)

Swales, J. (1990) Genre Analysis. Cambridge: Cambridge University Press.

7|Page

Establishing the importance of the topic for the discipline
A key aspect of X is …
X is of interest because …
X is a classic problem in …
X is a central concept in …
A primary concern of X is …
X is a dominant feature of …
X is a fundamental property of …
Xs are the most widely investigated …
Studies on X represent a growing field.
X is an increasingly important area in...
The concepts of X and Y are central to …
X is at the heart of our understanding of …
X is attracting considerable critical attention.
Central to the theory of X is the Y hypothesis.
X has been shown to occur in many different …
Investigating X is a continuing concern within …
X is a major area of interest within the field of …
X has been studied by many researchers using …
X has been the subject of many classic studies in …
X has been instrumental in our understanding of …
The theory of X provides a useful account of how …
X has been an important concept in the study of the …
Central to the entire discipline of X is the concept of …
One of the most significant current discussions in X is …
X has been the subject of much systematic investigation.
The issue of X has received considerable critical attention.
Understanding the complexity of X is vitally important if …
X has long been a question of great interest in a wide range of fields.
The role of X in Y has received increased attention across a number of disciplines in recent years.
Establishing the importance of the topic for the discipline: time frame given
X was one of the most popular Ys during …
Recent years have seen renewed interest in …
Traditionally, Xs have subscribed to the belief that …
Recent trends in X have led to a proliferation of studies that ...
Recent years have witnessed a growing academic interest in …
The nature of X has been the subject of several recent papers.
Over the past century, there has been a dramatic increase in …
X proved an important literary genre in the early Y community.
X has received considerable scholarly attention in recent years …
In recent years, researchers have shown an increased interest in ...
Recently, considerable literature has grown up around the theme of …
Recent developments in the field of X have led to a renewed interest in …
The past thirty years have seen increasingly rapid advances in the field of …
In the last few decades, there has been a surge of interest in the effects of …
For more than a century, scientists have been interested in the existence of …
The most significant recent developments in this direction have been those of …
The discovery of X in 2016 has triggered a huge amount of innovative scientific inquiry.
During the last decade, the link between X and Y has been at the centre of much attention.
8|Page

growing interest in …
renewed interest in …
a surge of interest in …
increasing interest in …
extensive research on …
increased emphasis on …
growing recognition of the vital links between …
a growing number of publications focusing on …
a greater focus placed upon X within the Y literature.
world-wide recognition of the problems associated with …

Recently,
More recently,
In recent years,

there has been

X

studied widely
studied extensively
an object of research
studied using light-microscopy
attracting considerable interest

has been

since

the 1960s.
it was discovered in 1998.
the early years of this century.

Establishing the importance of the topic for the world or society
X is widespread in …
X is fundamental to …
X is the primary means of …
X is a major contributor to …
X is an important aspect of …
X is frequently prescribed for …
The importance of X is indisputable.
X is one of the key components of Y.
Xs are among the most widely used …
X is fast becoming a key instrument in ...
X is the most widely distributed species of …
Xs have emerged as powerful platforms for …
Xs are one of the most widely used groups of …
Xs are essential for a wide range of technologies.
Xs are the most potent anti-inflammatory agents known.
There is evidence that X plays a crucial role in regulating …
In the history of X, Y has been thought of as a key factor in …
X is a common condition which has considerable impact on …
In the new global economy, X has become a central issue for ...
Determining the impacts of X on Y is important for the future of …
Evidence suggests that X is among the most important factors for …
X is important for a wide range of scientific and industrial processes.
X is an important component in the X system, and plays a key role in ...
There is a growing body of literature that recognises the importance of …
Xs were the most serious and widespread popular disturbances to occur in …
9|Page

X

X

plays a
can play a
may play a

is a key

key
vital
major
crucial
pivotal
central
essential
important
significant
fundamental

role in

ensuring …
reducing …
fostering …
combating …
preventing …
determining …
protecting against …
addressing the issue of …
the repair of …
the life cycle of …
the treatment of …
the regulation of …
the transmission of …
the maintenance of …
the development of …
the pathogenesis of …

part of …
issue in …
driver of …
factor in …
aspect of …
feature of …
element of …
strategy for …
indicator of …
ingredient in …
component of …
mechanism for …
determinant of …
characteristic of …

Establishing the importance of the topic for the world or society: time frame given
X has been an established practice since …
One of the most important events of the 1970s was …
Recent developments in X have heightened the need for …
The last two decades have seen a growing trend towards …
Recent trends in X have led to a proliferation of studies that ...
Over the past century, there has been a dramatic increase in …
The past decade has seen the rapid development of X in many …
X has experienced unprecedented growth over the past 100 years.
10 | P a g e

Establishing the importance of the topic as a problem to be addressed
X is a key issue in …
X is a leading cause of …
X is a major problem in …
Of particular concern is …
One of the main obstacles …
One of the greatest challenges …
X is the leading cause of death in …
A key issue is the safe disposal of …
The main disadvantage of X is that …
X is associated with increased risk of …
X impacts negatively upon a range of …
X is a common disorder characterised by …
It is now well established that X can impair …
X has led to the decline in the population of …
X is a growing public health concern worldwide.
The main challenge faced by many researchers is the …
X is one of the most frequently stated problems with …
Lack of X has existed as a health problem for many years.
X is a major environmental problem, and the main cause of …
Xs are one of the most rapidly declining groups of insects in ...
Exposure to X has been shown to be related to adverse effects in …
There is increasing concern that some Xs are being disadvantaged …
There is an urgent need to address the safety problems caused by …
The prevalence of X is increasing at an alarming rate in all age groups.
Questions have been raised about the safety of the prolonged use of …
Despite its safety and efficacy, X suffers from several major drawbacks:
Along with this growth in X, however, there is increasing concern over …
X is increasingly recognised as a serious, worldwide public health concern.
Despite its long clinical success, X is associated with a number of problems.
X and its consequences are an important, but understudied, cause for concern.

(However,)

X may cause …
X is limited by …
X suffers from …
X is too expensive to be used for …
X has accentuated the problem of …
the performance of X is limited by …
X could be a contributing factor to …
the synthesis of X remains a major challenge.
X can be extremely harmful to human beings.
research has consistently shown that X lacks …
the determination of X is technically challenging.
a major problem with this kind of application is …
current methods of X have proven to be unreliable.
these rapid changes are having a serious effect on …
X can be adversely affected under certain conditions.
accounting for these varying experiences is problematic .
observations have indicated a serious decline in the population of …

11 | P a g e

Referring to previous work to establish what is already known
Recent evidence suggests that …
Extensive research has shown that …
Research in this area has shown that …
Studies of X show the importance of …
It has previously been observed that …
Several attempts have been made to …
Data from several studies suggest that …
Previous research has established that …
Recent work by historians has established that …
Previous research comparing X and Y has found …
The existing body of research on X suggests that …
There is a growing body of literature that recognises …
Several theories on the origin of X have been proposed.
Existing research recognises the critical role played by …
It is now well established from a variety of studies, that …
A growing body of published work provides evidence of …
Recently investigators have examined the effects of X on Y.
Surveys such as that conducted by Smith (1988) have shown that …
Evidence from a number of experimental studies has established that …
Factors found to be influencing X have been explored in several studies.
A number of cross-sectional studies suggest an association between X and Y…
Studies over the past two decades have provided important information on …
A considerable amount of literature has been published on X. These studies …
In the past two decades, a number of researchers have sought to determine …
In previous studies of X, different variables have been found to be related to ...
The first serious discussions and analyses of X emerged during the 1970s with …
There have been a number of longitudinal studies involving X that have reported …
Xs were reported in the first studies of Y (e.g., Smith, 1977; Smith and Jones, 1977).
What we know about X is largely based upon empirical studies that investigate how …
Smith (1984: 217) shows how, in the past, research into X was mainly concerned with …
Results from earlier studies demonstrate a strong and consistent association between …
There are a large number of published studies (e.g., Smith, 2001; Jones, 2005) that describe …

It has been

noted that …
found that …
shown that …
argued that …
reported that …
assumed that …
observed that …
proposed that …
estimated that …
suggested that …
established that …
demonstrated that ….
conclusively shown that …

12 | P a g e

Recent
Previous

studies have
research has

Several
A number of

What

studies
researchers

we know about X
is known about X

found …
linked …
reported …
shown that …
documented …
demonstrated …
established that …

have

found …
reported …
identified ….
shown that …
attempted to …
demonstrated that …
investigated whether …
found an association between …
explored risk factors associated with …

comes from
is (largely) based on
is (largely) derived from

accounts by …
observations of …
laboratory studies.
outdated studies …
historical data from …
epidemiological studies.
brief biographical details.
cross-sectional studies of …
studies of people living in ...
case studies undertaken in …
contemporary textual sources.
small-scale experiments with …
research using laboratory animals.
research undertaken in major cities.
a few primary sources from the time.
studies conducted in populations of X.
observations using various animal models.

13 | P a g e

Identifying a controversy within the field of study
A much-debated question is whether …
Debate has long prevailed as to whether …
The precise effect of X is a much-debated topic.
One major issue in early X research concerned ...
To date there has been little agreement on what ...
The issue has grown in importance in light of recent ...
There has been disagreement on the criteria for defining X.
One observer has already drawn attention to the paradox in ...
Questions have been raised about the use of animal subjects in ...
In the literature on X, the importance of Y has been hotly debated ...
In many Xs, a debate is taking place between Ys and Zs concerning ...
Debate continues about the best strategies for the management of ...
This concept has recently been challenged by X studies demonstrating ...
There has been much disagreement between historians on the subject of …
The debate about X has gained fresh prominence with many arguing that ...
Scholars have long debated the impact of X on the creation and diffusion of …
More recently, literature has emerged that offers contradictory findings about ...
One of the most significant current discussions in legal and moral philosophy is ...
The relationship between X and Y has attracted conflicting interpretations from …
One major theoretical issue that has dominated the field for many years concerns ...
The controversy about scientific evidence for X has raged unabated for over a century.
The issue of X has been a controversial and much disputed subject within the field of ...
Several divergent accounts of X have been proposed, creating numerous controversies.
The causes of X have been the subject of intense debate within the scientific community.
In the literature on X, the relative importance of Y has been subject to considerable discussion.

So far
To date

there has been little agreement

on
about

why …
what …
how to …
whether …
how much …
the role of …
the origin of …
the nature of …
the definition of …
what constitutes ...
the characteristics of …
the precise nature of …
how best to measure …
how to conduct research on …
the important question of why …

14 | P a g e

Noting the lack of or paucity of previous research
No previous study has investigated X.
The use of X has not been investigated.
There is little published information on …
The role of X remains largely unexamined.
There is very little published research on …
There has been no detailed investigation of …
There has been little quantitative analysis of ...
Data about the efficacy and safety of X are limited.
Up to now, far too little attention has been paid to ...
A search of the literature revealed few studies which …
The impact of X on Y is understudied, particularly for …
So far, however, there has been little discussion about ...
In addition, no research has been found that surveyed ...
Surprisingly, the effects of X have not been closely examined.
Surprisingly, X is seldom studied, and it is unclear to what extent …
In contrast to X, there is much less information about effects of …
X has hitherto received scant attention by scholars of the Y period.
A systematic understanding of how X contributes to Y is still lacking.
While X is a growing field (Smith, 2015), publications on Y remain few.
Relatively little research has been carried out on X, and even less on Y.
Despite the importance of X, there remains a paucity of evidence on …
There have been no controlled studies which compare differences in ...
The issue of X has attracted very little attention from the scholarly community.
To date, the problem of X has received scant attention in the research literature.
To date, no large-scale studies have been performed to investigate the prevalence of ….
Although studies have recognised X, research has yet to systematically investigate the effect of …

To date,
Surprisingly,

There is a

X

has (still) not (yet) been

current
relative
lack
general
paucity
notable
surprising

closely
formally
empirically
extensively
scientifically
systematically
comprehensively

studied.
examined.
investigated.

of studies
of well-controlled studies

investigating …
describing how …
that seek to identify …

of empirical research
of high-quality research

in the field of …
focusing specifically on …
on the current prevalence of …

of scientific literature
of evidence-based literature

specifically relating to …
on the experiences of …
describing the impact of …
15 | P a g e

No previous study has
(Very) few studies have
Few (published) studies have

So far,
To date,
Up to now,

explored …
focused on …
investigated …
controlled for …
examined how …
compared trends in …
attempted to define …
examined the role of …
measured X in humans.
quantified the levels of …
systematically investigated …
assessed the implications of …
evaluated the effects of X on …
examined the consequences of …
actually examined the impact of …
provided quantitative evidence of …
systematically evaluated the use of …
attempted to quantify the impact of …
adequately tested the effectiveness of …
addressed the long term psychological effects of …
been large enough to provide reliable estimates of …
been conducted to determine the possible effects of …

there

has been no systematic analysis of …
have been no attempts to examine …
has been very little research directly investigating X.
have been very few empirically published accounts of X.

(very) little

research has been carried out on …
has been published on the subject of …
attention has been paid to the role of …
research has addressed the question of …

(very) few

studies have assessed the role of …
studies have examined the association between …
studies have investigated x in any systematic way …
randomised clinical trials have specifically investigated X in …

16 | P a g e

Relatively
Surprisingly
Remarkably
Comparatively

few

studies have

little

research has

some research has been
carried out on X,
While
Whilst
Although

several studies have
shown that …,

analysed …
assessed …
examined …
measured …
investigated …

no single study exists which ...
no studies have been found which ...
no controlled studies have been reported.
there is very little scientific understanding of ...
only two studies have attempted to investigate ...
there have been few empirical investigations into ...
the mechanism by which ... has not been established.
no studies of the effects of X on Y have been published.
little if any empirical work has been done to investigate …

Highlighting inadequacies or weaknesses of previous studies (also refer to Being Critical)
Previous studies of X have not dealt with ...
Researchers have not treated X in much detail.
Such expositions are unsatisfactory because they ...
Such approaches, however, have failed to address …
Most studies in the field of X have only focused on ...
Previous published studies are limited to local surveys.
Half of the studies evaluated failed to specify whether ...
The research to date has tended to focus on X rather than Y.
Previously published studies on the effect of X are not consistent.
Smith’s analysis does not take account of ..., nor does she examine ...
The existing accounts fail to resolve the contradiction between X and Y.
Most studies of X have only been carried out in a small number of areas.
However, much of the research up to now has been descriptive in nature ...
The generalisability of much published research on this issue is problematic.
Research on the subject has been mostly restricted to limited comparisons of ...
However, few writers have been able to draw on any systematic research into ...
Short-term studies such as these do not necessarily show subtle changes over time …
Although extensive research has been carried out on X, no single study exists which ...
However, these results were based upon data from over 30 years ago and it is unclear if ...
Recent attempts to understand X (e.g. Smith 1989; Jones 1992) pay too little attention to …
The experimental data are rather controversial, and there is no general agreement about ...
However, all the previous X research was cross-sectional in design. Therefore, it is unclear if …
Although there are many reports in the literature on the outcome of X, most are restricted to ...
Some evidence suggests that ..., although further work using X is required to confirm this finding.

17 | P a g e

The existing literature on X
Most of the work carried out on X

Previous studies

have failed to

Previous studies (of X)
Most of these studies

have

fails to …
suffers from …
lacks clarity regarding …
ignores the possibility that …
has not distinguished between X and Y in a systematic way.

explore
consider
take account of

mostly
mainly
largely
typically
generally
predominantly

the impact of …
the reasons for …
the evidence for …
the ways in which …
the contexts in which …
several key aspects of …
the variable nature of …
other explanations for …
the complex nature of …
the potential impact of …
the social dimension of …
the dynamic aspects of ...
the underlying causes of …
all the possible effects of …
demographic factors that ...
the ethical implications of ...
the important role played by …
the broader implications of how ...
the unique complexities faced by ...
the contextual factors that influence …

ignored …
examined …
focused on …
concentrated on …
been concerned with …

18 | P a g e

Previous studies (of X)
Most of these studies

Previous studies (of X)
Most of these studies

have suffered from

small sample sizes.
low response rates.
confounding factors.
multiple design flaws.
an overemphasis on …
inconsistent definitions.
inadequate sample sizes.
poorly developed theory.
serious sampling problems.
experimental design errors.
poor case control matching.
inadequate research design.
a lack of clarity in defining …
a high degree of sampling bias.
lack of instrumental sensitivity.
considerable design limitations.
the use of poorly matched controls.
a paucity of standardised measures.
fundamental flaws in research design.
lack of a strong theoretical framework.
an over-reliance on self-report methodology.
a restricted range of methodological approaches.
shortcomings in the methods used to select cases.
a lack of well-grounded theoretical considerations.

have suffered from

certain
several
serious
various
notable

methodological

flaws.
limitations.
drawbacks.
weaknesses.
shortcomings.

only involved …
only been carried out in …
only been undertaken using …
only provided weak evidence for …
Previous studies (of X)
Most of these studies

have

been of poor quality.
been limited in a number of ways.
been limited to convenience samples.
been limited to a small number of cases.
generally been restricted to the analysis of …
mainly been restricted to epidemiological observations.

19 | P a g e

No previous study has

controlled for …
been large enough to …
completely eliminated …
distinguished between …
provided information on …
addressed the question of …
assessed the occurrence of ...
used a dynamic measure of …
given sufficient consideration to …
employed time-series techniques for …
utilised verbal reports to examine the problem of …
used a method for analysing multiple factors related to …

General reference to previous research or scholarship: highlighting negative outcomes

Previous studies have failed to

Recent studies have
The research to date has

find
show
demonstrate

a link between …
any treatment effect.
a correlation between …
a connection between …
significant differences in …
any convincing evidence of …
a causal relationship between …
any support for the X hypothesis.
any significant advantages of using …
significant changes in health outcomes.
reliable, repeatable therapeutic effects of …

not been able to

establish …
confirm earlier …
determine whether …
show a link between …
duplicate these results.
reproduce these findings.
replicate these associations.
rule out the possibility that …
provide robust evidence for …
detect an increase in the risk of …
confirm earlier findings showing …

20 | P a g e

Indicating missing, weak, or contradictory evidence
Evidence for X has been mixed.
The evidence for X is in fact ambiguous.
There is contradictory evidence as to whether …
To date, there has been no reliable evidence that ...
To date, studies investigating X have produced equivocal results.
There is conflicting evidence on the relationship between X and Y.
The evidence that X and Y are associated with Z is weak and inconclusive.
Whilst evidence is increasing that …, a consistent empirical picture is missing.
Studies undertaken so far provide conflicting evidence concerning the impact of …
However, conflicting results from studies suggest the need for new investigations that …
Previous research findings into X have been inconsistent and contradictory (Smith, 1996; ...).
Some studies have shown the beneficial effects of X, but others have shown a deterioration in …

To date, (however), there has been

no
little

clear
solid
reliable
clear-cut
scientific
definitive
empirical
convincing
conclusive
experimental

evidence that …

Identifying a knowledge gap in the field of study
Much less is known about X.
It is still not known whether …
The nature of X remains unclear.
Currently, there are no data on …
What is less clear is the nature of …
Very little is currently known about X in ...
Research to date has not yet determined …
What is not yet clear is the impact of X on ...
There is still uncertainty, however, whether …
The response of X to Y is not fully understood.
Causal factors leading to X remain speculative.
The neurobiological basis of X is poorly understood.
Little is known about X and it is not clear what factors ...
To date, only a limited number of Xs have been identified.
The mechanisms that underpin X are not fully understood.
Much uncertainty still exists about the relationship between ...
Our understanding of how X influences Y is notably underdeveloped.
The potential impacts of X have not previously been analysed and quantified.
This indicates a need to understand the various perceptions of X that exist among …
It is now well established that … However, the influence of X on Y has remained unclear.
21 | P a g e

However,

what is not yet

What remains

unclear
unknown

clear
known
understood

(, however,)

is whether …
is the role of …
is the effect of …
is the nature of …
is the importance of …
is the extent to which …
is the degree to which …
is the actual proportion of …
are the different stages of …
are the circumstances that …
is the actual relationship between …
is the relative importance of the factors that ...

is why …
is how …
is precisely how …
is to what degree there exists …
is how different species are distributed in …
is how such policies and practices affect the …
is whether these two systems interact.
is whether the two conditions are related.
is whether this finding is a true representation.
is whether these two factors operate independently.

However,

(exactly) how

X affects Y
X inhibits Y
X develops
X is formed
X acquires Y
X damages Y
X produces Y
X increases Y
X influences Y
X benefits from Y
X contributes to Y

remains unclear.
remains poorly understood.
is (still) not yet fully understood.

22 | P a g e

The extent to which

However,

X affects Y
X inhibits Y
X applies to Y
X influences Y
X moderates Y
X determines Y
X is related to Y
X plays a role in Y
X benefits from Y
X contributes to Y
X changes during …
X presents a risk to Y
X corresponds with Y
X may be attributed to Y
X has been successful in …
X can be extrapolated to …
the problem of X is facilitated by Y
these findings have wider relevance
lack of X is causally associated with Y

several
a number of

key
further
critical
essential
additional
important
interesting
unresolved
unanswered
fundamental

is (still)
remains

unclear.
unknown.
unexplored.
poorly understood.

questions remain about

the role of …
the nature of …
the effects of …
the aftermath of …
the treatment for …
the development of …

Stating the focus, aim, or argument of a short paper
In this paper, I argue that ...
This paper has four key aims. Firstly, …
The central thesis of this paper is that ...
In the pages that follow, it will be argued that ...
In this essay, I attempt to defend the view that ...
Specifically, the following issues will be addressed:
Secondly, the study aims to assess the extent to which …
In the pages that follow, the following questions will be addressed:

23 | P a g e

This paper

argues that …
gives an account of …
discusses the case of …
analyses the impact of …
attempts to show that …
contests the claim that …
provides an overview of …
reviews the evidence for …
reports on a study which …
addresses the question of …
presents new evidence for …
traces the development of …
explores the ways in which …
assesses the significance of …
highlights the importance of …
considers the implications of …
evaluates the effectiveness of …
critically examines the view that …
proposes a new methodology for …
surveys recent empirical studies on …
examines the relationship between …
compares the different ways in which …
offers a new model for understanding …
investigates the factors that determine …
describes the design and implementation of …
seeks to remedy these problems by analysing the literature of ...

The (primary) aim of this paper is to

The aim of this paper is to

critically

explore the …
trace the history of …
assess the claim that …
review recent research into the ...
explore the relationship between …
contribute to the understanding of …
provide empirical evidence for the claim that …
propose a conceptual theoretical framework based on …

analyse the effects of …
examine the claim that …
review the evidence for …
examine the ways in which …
review the different approaches used to …
evaluate the rationale behind X’s theory of …
discuss the some of the prominent ideas which …

24 | P a g e

Stating the purpose of the current research
The specific objective of this study was to …
This thesis examines the way in which the ...
An objective of this study was to investigate ...
This study set out to investigate the usefulness of ...
This dissertation seeks to explain the development of ...
This case study seeks to examine the changing nature of ...
The objectives of this research are to determine whether ...
The overall aim of this thesis is to review the evidence for …
This prospective study was designed to investigate the use of …
The aim of this study was to develop a better understanding of …
This research examines the emerging role of X in the context of ...
This study systematically reviews the data for..., aiming to provide ...
Drawing upon two strands of research into X, this study attempts to ...
This thesis intends to determine the extent to which ... and whether ...
This dissertation aims to unravel some of the mysteries surrounding ...
This study therefore set out to assess the effect of X ..., and the effect of ...
The main aim of this study is to investigate the differences between X and Y.
Part of the aim of this project is to develop software that is compatible with ...
There are two primary aims of this study: 1. To investigate ... 2. To ascertain ...
This study seeks to obtain data which will help to address these research gaps.
One purpose of this study was to assess the extent to which these factors were ...
The purpose of this investigation was to explore the relationship between X and Y.
The aim of this research project has therefore been to assess the doses and risks associated with ...

This study set out to

explore …
determine whether …
try and establish what ...
better understand the …
find a new method for …
evaluate how effective …
assess the feasibility of …
test the hypothesis that …
explore the influence of …
clarify several aspects of ...
investigate the impact of …
identify the predictors for …
develop an understanding of ...
gain further understanding of …
compare the two ways of treating …
examine the relationship between …
evaluate a new method of measuring …
determine the predictive validity of the…
understand the views and experiences of …
review in detail the available information on …
describe some of the more recent developments in …
shine new light on these debates through an examination of ...

25 | P a g e

The aim of
The purpose of

this study was to
this investigation has been to

predict which …
establish whether …
determine whether …
develop a model for …
examine the effects of …
assess the extent to which …
identify and describe factors that …
compare the clinical performance of …
evaluate behavioural interventions in …
explore the relationship between X and Y.
better understand the relationship between …
identify the most important factors influencing ...

Stating purpose of the current study with reference to gaps or issues in the literature

The current study aimed to address these

questions using …
limitations in two ways.
problems through the use of …
gaps in the existing literature by …
discrepancies and investigate the …
concerns through the development of …
challenges by identifying methods applicable to …
issues by reviewing the scientific and technical data …

Setting out the research questions or hypotheses
The hypothesis that will be tested is that ...
The research questions in this study focused on …
The central question in this dissertation asks how ...
Specifically, the following issues will be addressed: …
The specific questions which drive the research are: …
This research seeks to address the following questions:
The key research question of this study was whether or not ...
This study aimed to address the following research questions: …
The study sought to answer the following specific research questions: …
In particular, this dissertation will examine six main research questions: …

26 | P a g e

Describing the research design and the methods used
Data for this study were collected using...
Five works will be examined, all of which …
A mixed-method approach was employed using …
This investigation takes the form of a case-study...
This study draws on two theoretical frameworks …
Qualitative content analysis was used to examine …
This study utilised clustering techniques to identify …
Contemporary source material was used to examine …
This study was exploratory and interpretative in nature.
This study uses a qualitative case study approach to investigate …
The research data in this thesis are drawn from four main sources: ...
This study employed survey methodology to investigate the impact of …
The approach to empirical research adopted for this study was one of ...
This dissertation follows a case-study design, with in-depth analysis of ...
By employing qualitative modes of enquiry, I attempt to illuminate the ...
Qualitative and quantitative research designs were adopted to provide ...
This study makes use of oral history interviews as well as archival sources.
Both qualitative and quantitative methods were used in this investigation.
A holistic approach is utilised, integrating X, Y and Z material to establish ...
The study was conducted in the form of a survey, with data being gathered via ...
This project uses interviews and participant-observation to produce an account of …
The methodological approach taken in this study is a mixed methodology based on ...
A combination of quantitative and qualitative approaches was used in the data analysis.

This study
This investigation

uses
used
utilised

recent
survey
existing
archival
historical
empirical
interview
secondary
qualitative
time-series
quantitative
longitudinal
retrospective
observational
cross-sectional

data (from X) to

assess …
explore …
analyse …
examine …
estimate …
determine …
investigate …

27 | P a g e

Explaining the significance of the current study
This is the first study to …
This work will generate fresh insight into …
The study offers some important insights into ...
Understanding the link between X and Y will help …
This is the first study to undertake a longitudinal analysis of ...
Investigating X is critically important in our understanding of …
The importance and originality of this study is that it explores …
The present research explores, for the first time, the effects of …
The findings should make an important contribution to the field of ....
It is hoped that this research will contribute to a deeper understanding of …
This study aims to contribute to this growing area of research by exploring ...
This project provided an important opportunity to advance the understanding of ...
Therefore, this study makes a major contribution to research on X by demonstrating ...
There are several important areas where this study makes an original contribution to ...
The experimental work presented here provides one of the first investigations into how …

This

sheds new light on …
provides new insights into …
fills a gap in the research on …
gives us new information on …
study
offers a fresh perspective on …
research
enhances our understanding of …
investigation
contributes to our knowledge of …
study fills a gap in the literature by …
makes an important contribution by …
provides the first extensive examination of …

The study presented

here
in this thesis
in this report

is one of the first investigations to

use …
utilise …
survey …
include …
explore …
employ …
compare …
undertake an …
examine in detail …
test the effects of …
focus specifically on …
assess the impact of …

28 | P a g e

Giving reasons for personal interest in the research*
I became interested in Xs after reading ...
My interest in this area developed while I was …
I have worked closely with X for many years and ...
This research complements an earlier study which …
My personal experience of X has prompted this research.
My main reason for choosing this topic is personal interest.
The genesis of this thesis can be traced back to the time I spent …
It is my experience of working with X that has driven this research.
This project was conceived during my time working for X. As a medical advisor, I witnessed …
* sometimes found in the humanities, and the applied human sciences

Describing the limitations of the current study
The thesis does not engage with ...
It is not the task of this paper to examine …
This study is unable to encompass the entire …
Establishing X is beyond the scope of this study.
It is beyond the scope of this study to examine the ...
A full discussion of X lies beyond the scope of this study.
The reader should bear in mind that the study is based on ...
Another potential problem is that the scope of my thesis may be too broad.
Due to practical constraints, this paper cannot provide a comprehensive review of...

Outlining the structure of a short paper
The first section of this paper will examine ...
This paper begins by ... It will then go on to ...
The essay has been organised in the following way: ...
The remaining part of the paper proceeds as follows: ...
The main issues addressed in this paper are: a), b) and c).
This paper first gives a brief overview of the recent history of X.
This paper has been divided into four parts. The first part deals with ...

Outlining the structure of a thesis or dissertation
This thesis is composed of four themed chapters.
The overall structure of the study takes the form of six chapters.
The thesis is divided into three distinct sections. The first section …
The third chapter is concerned with the methodology employed for this study.
Chapter 2 will consider both the sources and methods of study which will include …
The purpose of the final chapter is to reflect on the extent to which this study has …
Chapter 4 analyses the data gathered and addresses each of the research questions in turn.
Chapter 5 analyses the results of interviews and focus group discussions undertaken during ...
The fifth section presents the findings of the research, focusing on the three key themes that ...
Chapter Two begins by laying out the theoretical dimensions of the research, and looks at how ...

29 | P a g e

The second part
The final chapter
The final section

examines …
gives a brief review of …
contextualises the research by …
discusses the significant findings.
draws upon the entire thesis to …
identifies areas for further research.
ties together the common themes and …
explains the emergent themes influencing …
draws together these various findings, and …
draws together the key findings, making the ...
draws together the various strands of the thesis.
gives a brief summary and critique of the findings.
summarises the main findings of this project and ...
summarises the principal findings of these experiments and …
brings together the lessons from these case studies, and then ...
describes the experimental approach and instrumentation utilised in …
ties together the various theoretical and empirical strands in order to ...
includes a discussion of the implication of the findings to future research …

Previewing a chapter
The aim of the chapter is to introduce …
This chapter seeks to assess the impact of …
This chapter is subdivided into three sections
The first section will attempt to assess whether …
The second part highlights the key theoretical concepts which …
This chapter contextualises the research by providing background information on …
This chapter discusses the specific methods by which the research and analyses were conducted.

The main

topics
issues
themes
periods
developments

covered in this chapter are …

30 | P a g e

Explaining keywords (also refer to Defining Terms)
Throughout this paper, the term ‘X’ will refer to ...
The term ‘X’ will be used in this thesis to refer to …
Historically, the term ‘X’ has been used to describe …
This study utilises the concept of ‘X’ first proposed by …
It is necessary here to clarify exactly what is meant by ...
The phrase ‘X’ will be used in this study to describe the …
According to Smith (2002), X can be defined as follows: ‘ ... ’
In this article, the abbreviation XYZ will be used to refer to ...
Throughout this dissertation, the term ‘X’ will be used to refer to ...
The term ‘X’ is a relatively new name for ..., commonly referred to as ...
In this essay, the term ‘X’ will be used in its broadest sense to refer to all ...
In this dissertation, the terms ‘X’ and ‘Y’ are used interchangeably to mean ...
While a variety of definitions of the term ‘X’ have been suggested, this paper will use the definition
first suggested by Smith (1968) who saw it as …

31 | P a g e

Reviewing the Literature
One of the distinguishing features of academic writing is that it is informed by what is already
known, what work has been done before, and/or what ideas and models have already been
developed. Thus, in academic texts, writers frequently make reference to other studies and to the
work of other authors. It is important that writers guide their readers through this literature. This
section of Academic Phrasebank lists some of the phrases that writers may use for this purpose.
A note on the literature review: It is the purpose of the literature review section of a paper or
dissertation to show the reader, in a systematic way, what is already known about the research
topic as a whole, and to outline the key ideas and theories that help us to understand this. As well
as being systematic, the review should be evaluative and critical of the studies or ideas which are
relevant to the current work. For example, you may think a particular study did not investigate
some important aspect of the area you are researching, that the author(s) failed to notice a
weakness in their methods, or that their conclusion is not well-supported (refer to Being Critical).
A note on referencing style: The way a writer refers to other sources varies somewhat across
different disciplines. In some cases, where the individual author is important, the author’s name
will be the main subject of the sentence; in other cases, the author’s name may only be mentioned
in brackets ( ... ) or via a number notation system (e.g. footnotes and endnotes). The ‘author as
subject’ style is less common in the empirical disciplines (sciences) and more commonly used in the
humanities. Different referencing systems are used in different disciplines. In the majority of the
examples given here, the Harvard in-text referencing system has been used.
A note on verb tenses: For general reference to the literature, the present perfect tense (have/has
+ verb participle) tends to be used. For reference to specific studies carried out in the past, the
simple past tense is most commonly used. This is normally the case where a specific date or point
in time in the past forms a part of the sentence. When referring to the words or ideas of writers,
the present tense is often used if the ideas are still relevant, even if the author is no longer alive.
The examples given below reflect these general patterns, but these are by no means rigid.

General comments on the relevant literature
The literature on X has highlighted several …
Much of the literature concerns X rather than Y.
Different theories exist in the literature regarding …
More recent attention has focused on the provision of ...
There are relatively few historical studies in the area of …
A great deal of previous research into X has focused on ...
A large and growing body of literature has investigated ...
Much of the literature since the mid-1990s emphasises the …
Much of the current literature on X pays particular attention to ...
There is a large volume of published studies describing the role of ...
There is a relatively small body of literature that is concerned with …
The existing literature on X is extensive and focuses particularly on …
The generalisability of much published research on this issue is problematic.
A considerable amount of literature has been published on X. These studies ...
What we know about X is largely based upon empirical studies that investigate how ...
The academic literature on X has revealed the emergence of several contrasting themes.
32 | P a g e

Much of
The greater part of

the literature on X

ignores …
is descriptive.
focusses on …
comes from …
acknowledges …
takes as its focus …
is concerned with …
is exploratory in nature.
lacks clarity regarding …
pays particular attention to ...
seems to have been based on …
has emphasised the importance of …
perpetuates out-of-date notions of …
is extensive and focuses particularly on …

Previous research: a historical perspective
Research into X has a long history.
For many years, this phenomenon was surprisingly neglected by …
Only in the past ten years have studies of X directly addressed how …
Prior to the work of Smith (1983), the role of X was largely unknown.
Early examples of research into X include … (Smith, 1962; Jones, 1974).
Over the past decade, most research in X has emphasised the use of ...
In recent years, there has been an increasing amount of literature on ...
During the past 30 years, much more information has become available on ...
The first serious discussions and analyses of X emerged during the 1970s with ...
Over the past two decades, major advances in molecular biology have allowed …
Historically, research investigating the factors associated with X has focused on …
It is only since the work of Smith (2001) that the study of X has gained momentum.
An extensive series of randomised, controlled trials in the late 1970s demonstrated …
The construct of X was first articulated by Smith (1977) and popularised in his book: …
It was not until the late 1960s that historians considered X worthy of scholarly attention.
Awareness of X is not recent, having possibly first been described in the 5th century BCE by …
Around the early 1960s, small-scale research and case studies began to emerge linking the use of …

Previous research: area investigated as the sentence object
To date, several studies have investigated …
A number of studies have begun to examine …
Various studies have assessed the efficacy of …
Researchers attempted to evaluate the impact of …
A great deal of previous research into X has focused on …
Several studies have used longitudinal data to examine …
Previous studies have explored the relationships between X and Y.
Twenty cohort study analyses have examined the relationship between …
A number of authors have considered the effects of … (Smith, 2003; Jones, 2004).
At least 120 case-control studies worldwide have examined the relationship between …
Numerous studies have attempted to explain … (for example, Smith, 1996; Jones, 1998; …).
33 | P a g e

To date,
Thus far,
Up to now,

several studies
previous studies
a number of studies

have

tested the efficacy of …
assessed the impact of …
investigated the effects of…
begun to examine the use of …
used longitudinal data to examine …
examined the association between …
attempted to evaluate the impact of …
analysed the accuracy and precision of …
explored the relationships between X and Y.

Previous research: area investigated as the sentence subject
X has been proposed to explain how …
The X problem has been extensively studied.
Xs have been studied extensively in vitro, using …
X has been intensively investigated recently due to its …
Markers for the prediction of X have been widely investigated.
X has also been shown to reverse the anti-inflammatory effects of Y in …
These effects have been shown in X (e.g., Smith et al., 1981; Jones, 1996).
Factors thought to be influencing X have been explored in several studies.
X appears to be positively related to both Y and Z (Smith, 2010; Jones, 2011).
The geology of X has been addressed in several small-scale investigations and ...
X has been identified as a major contributing factor to the decline of many species of …
The roles of X have been studied extensively (Jones, 1989; Johnson, 1994; Smith, 1998).
The causes of X have been widely investigated (Jones, 1987; Johnson, 1990; Smith, 1994).
The relationship between X and Y has been widely investigated (Smith, 1985; Jones, 1987, ...

Previous research: approaches taken
Most research on X has been carried out in …
Two different approaches have been used to …
Most researchers investigating X have utilised …
The majority of previous studies on X are based on …
Using this approach, researchers have been able to …
Several systematic reviews of X have been undertaken.
Historians have attempted to interpret X in the light of …
The vast majority of studies on X have been quantitative.
What we know about X is largely based on observational studies.
Much of the previous research on X has been exploratory in nature.
There are a number of large cross-sectional studies which suggest …
Much of the X research has focused on identifying and evaluating the …
Existing comparative studies are largely observational in nature, mostly relying on …
Publications that concentrate on X more frequently adopt a historical or chronological approach …

34 | P a g e

What we know about X is largely based upon

Recent studies have
The research to date has

been

case
clinical
empirical
qualitative
simulation
laboratory
longitudinal
comparative
experimental
observational
epidemiological

studies that investigate how ...

conducted using …
carried out using …
largely exploratory.
qualitative in nature.
designed to determine whether …
based on relatively small sample sizes.
undertaken in a variety of healthcare settings.

Previous research: what has been established or proposed
Several lines of evidence suggest that …
Previous research has established that …
Data from several studies suggest that …
Recent evidence suggests that ... (Smith, 2019; …).
It is now well established from a variety of studies that …
New findings amongst X provides further evidence that …
A number of studies have postulated a convergence between …
Recently, considerable evidence has accumulated to show that …
Surveys such as that conducted by Smith (1998) have shown that ...
Many recent studies (e.g. Smith, 2014; Jones, 2015) have shown that …
Traditionally, it has been argued that ... (e.g. Smith, 1960; Jones, 1972).
Several biographies of Brown have been published. Smith (2016) presents ...
In previous studies on X, different variables have been found to be related to ...
Many historians have argued that ... (e.g. Jones, 1997; Brown, 1999; Smith, 2019).
There is a consensus among social scientists that ... (e.g. Smith, 2019; Jones, 2020; ...
Data from several sources have identified the increased X and Y associated with obesity.
Recently, in vitro studies have shown that X can ... (Smith et al., 1997; Jones et al., 1998).
It has been demonstrated that a high intake of X results in damage to ... (Smith, 1998; ...).
A series of papers on X (Jones, 1997; Brown, 1999; Smith, 2018) agree in suggesting that …
Some cross-sectional studies suggest an association between X and Y (Smith, 2004; Jones, 2019).
There is a large number of published studies (e.g., Smith, 2011; …) that describe the link between …
35 | P a g e

It has been

To date,
Thus far,
Up to now,

Previous
Several

noted that …
argued that …
shown that …
thought that …
assumed that …
reported that …
observed that …
suggested that …
established that …
demonstrated that ….
conclusively shown that …

several studies
previous studies
a number of studies

studies of X
surveys of X
investigations of X

have

found …
reported …
shown that…
linked X with Y.
indicated that …
suggested that …
demonstrated that …
identified a link between …
confirmed the effectiveness of …
revealed a correlation between X and Y.
highlighted factors that are associated with …

have

found …
shown …
revealed …
reported …
identified …
established …
demonstrated …
shown significant increases in …

36 | P a g e

Stating what is currently known about the topic
X increases when … (Smith, 2015)
X is able to affect Y (Smith, 2015; Jones, 2020).
X is positively related to Y (Smith, 2015; Jones, 2020).
X is proportional to Y as expressed by the… (Smith, 2015).
X is one of the most important … (Smith, 2015; Jones, 2020).
X is one of the most intense reactions following Y (Jones, 2020).
A relationship exists between X and Y (Smith, 2015; Jones, 2020).
X is a principal determining factor of Y (Smith, 2015; Jones, 2020).
There is an unambiguous relationship between X and Y (Smith, 2015).
X is significantly reduced during the first months of … (Smith, 2015; Jones, 2020).
X has been found to oppose the anti-inflammatory actions of Y on Z (Smith, 2019).

Previous research: highlighting negative outcomes

Previous studies have failed to

Prior studies have
Recent studies have
The research to date has

find
show
demonstrate

not been able to

a (any) benefit in …
a (any) link between …
a (any) treatment effect.
a (any) protective effect of …
a (any) correlation between …
a (any) connection between …
a (any) causal relationship between …
a (any) consistent association between …
a (any) statistically significant difference …
(any) convincing evidence of …
(any) benefits associated with …
(any) significant differences in …
(any) support for the X hypothesis.
(any) significant advantages of using …
(any) significant changes in health outcomes ...
(any) reliable, repeatable therapeutic effects of …

find …
detect …
confirm …
establish …
determine whether …
adequately control for …
convincingly show that …
reproduce these findings.
account for all aspects of …
replicate these associations.
confirm earlier findings showing …

37 | P a g e

Reference to previous research: important studies
The first detailed study of X was …
Smith (1960) was one of the first to examine …
The first systematic study of X was reported by …
Before Smith (1961), it was generally believed that …
One of the most cited studies is that of Smith who sees …
Smith (1952) helped to establish an explanatory model for …
X is most commonly associated with the work of Jones (1960).
In one of the earliest studies in this field, Smith (1961) found …
The first major fieldwork project that was undertaken in X was …
The reaction between X and Y was first reported by Smith in 1872.
In their ground-breaking work in 1958, Smith and Jones established …
A good summary of the classification of X has been provided in the work of …
In a comprehensive literature review of X, Smith identified three significant …
The electronic spectroscopy of X was first studied by Smith and Jones in 1970.
In 1985, Smith and Jones were the first of many investigators to demonstrate …
X was first demonstrated experimentally by Pavlov (1927). In his seminal study ...
X formed the central focus of a study by Smith (2002) in which the author found ...
Perhaps the best-known study using this approach was carried out by Smith (1988).
One well-known study that is often cited in research on X is that of Smith (1972), who found …
The way in which X is regulated was studied extensively by Smith and colleagues (Smith et al. 1995).
The innovative and seminal work of Smith pioneered a new approach to examining X and provided …

By far
Perhaps

the most

detailed
thorough
complete
influential
important
well-known
comprehensive
widely accepted

account of X is to be found in the work of …

Referring to a single investigation in the past: time prominent
In 1959, a seminal article was published entitled …
In 1889, Smith performed a bilateral ablation of the …
In 1965, Smith published his major historic survey of …
In 1975, Smith et al. published a paper in which they described …
In 1984, Smith et al. made several amino acid esters of X and evaluated them as …
In 1981, Smith and co-workers demonstrated that X induced in vitro resistance to …
In 1990, Smith et al. demonstrated that replacement of H2O with heavy water led to …
In 1990, Smith et al. reported a new and convenient synthetic procedure to obtain …
In the 1950s, Smith pointed to some of the ways in which …
Thirty years later, Smith (1974) reported three cases of X which …
Following this period, Smith actively searched for anti-bacterial agents.
Almost 20 years ago, Jones (1995) formulated his X theory, centred around …

38 | P a g e

Referring to a single investigation in the past: investigation prominent
One longitudinal study found that …
A seminal study in this area is the work of ...
One study by Smith (2014) examined the trend in ...
A recent study by Smith and Jones (2012) involved ...
A qualitative study by Smith (2003) described how …
A recent systematic literature review concluded that …
Preliminary work on X was undertaken by Jones (1992).
A longitudinal study of X by Smith (2012) reports that ...
A key study comparing X and Y is that of Smith (2010), in which ...
The first systematic study of X was reported by Smith et al. in 1986.
Detailed examination of X by Smith and Jones (1961) showed that ...
Analysis of the genes involved in X was first carried out by Smith et al. (1983).
A significant analysis and discussion on the subject was presented by Smith (1988).
The study of the structural behaviour of X was first carried out by Jones et al. (1986).
A small-scale study by Smith (2012) reached different conclusions, finding no increase in ...
The study by Jones (1990) offers probably the most comprehensive empirical analysis of …
In an analysis of X, Smith et al. (2015) found ...
In a follow-up study, Smith et al. (2009) found that …
In an investigation into X, Smith et al. (2012) found ...
In a study investigating X, Smith (2004) reported that …
In a comprehensive study of X, Jones (2001) found that …
In a study conducted by Smith (1998), it was shown that …
In studies of rats given X, Smith and colleagues found that …
In a study which set out to determine X, Smith (2012) found that ...
In a randomised controlled study of X, Smith (2012) reported that ...
In another major study, Smith (1974) found that just over half of the ...
In a recent cross-sectional study, Smith (2006b) investigated whether …
In a large longitudinal study, Smith et al. (2012) investigated the incidence of X in Y.
In one well-known recent experiment, limits on X were found to be ... (Smith, 2019).
To examine this issue …
To better understand X,
To compare the X with Y, …
To determine whether the …
To further examine the role of …
To further investigate the role of …

Using
Taking

historical
integrated
theoretical
longitudinal
a(n)
evidence-based
cross-sectional
interdisciplinary
intergenerational

Smith et al. (1984) carried out a series of experiments.

approach, Smith (1993)

showed that …
demonstrated that …
was able to show that …

39 | P a g e

Referring to a single investigation in the past: researcher prominent
Smith’s comparative study (2012) found that ...
Jones’s comprehensive review concluded that …
Brown’s (1992) model of X assumes three main ...
Smith’s cross-country analysis (2012) showed that ...
Jones’s (1994) review of the literature concluded that …
Brown’s (1999) recent analysis of X provides a strong critique of …

Smith et al. (2015)

reported …
identified …
found that …
showed that …
demonstrated that …

Jones (2015)

compared the rate of …
investigated whether …
calculated the average ...
labelled these subsets as ...
studied the effects of X on …
estimated the prevalence of …
measured both components of the ...
used a survey to assess the various ...
undertook a series of interviews with …
investigated the differential impact of...
identified parents of disabled children as ...
set up a series of virtual experiments using …
examined the flow of international students ...
carried out a number of investigations into the ...
analysed the data from 72 countries and concluded that ...
interviewed 250 undergraduate students using semi-structured ...
performed a similar series of experiments in the 1960s to show that ...
reviewed the literature from the period and found little evidence for this ...
conducted a series of trials in which he mixed X with different quantities of ...

Referring to important texts in the area of interest
With its publication in 1876, Smith’s XXXXX established …
In 1859, the publication of XXXXX had a major impact on …
In his seminal text, XXXXX, Smith devoted some attention to ….
One of the most influential accounts of X comes from Smith (1986).
In Smith’s landmark paper, XXXXX (1956), he adopted a Y approach to …
One well-known early study that is often cited in research on X is that of …
In her seminal paper entitled XXXXX, Smith (1981) identified problems with …
Smith, in his comprehensive biography of X, devoted a substantial section to …
Among the historiography of X, perhaps the most well-known work is that of …
Herodotus, writing in the fifth century BC, provides the earliest description of …
A more substantial approach to the longer-term significance of X can be found in …
Smith et al., in their book XXXXX (2006), give some reliable methods for calculating …
40 | P a g e

Describing what other writers do in their published work
On the basis of these findings, Smith proposes that …
In Chapter 2, Smith provides us with a number of important ...
In the subsequent chapter, Smith examines the extent to which ...
By drawing on the concept of X, Smith has been able to show that ...
Some analysts (e.g. Jones, 2015) have attempted to draw fine distinctions between ...
In their recent review of X, Smith and Jones (2015) shed light on the new challenges in …
Drawing on an extensive range of sources, the authors set out the different ways in which ...
Other authors (see Smith, 2013; Jones, 2015) question the usefulness of such an approach.
distinguishes …
cautions against …
calls our attention to …
stresses the role played by …
draws a distinction between …
emphasises the importance of …
challenges the misconception that …
pinpoints a number of similarities between …
identifies X, Y, and Z as the major causes of ...
draws on an extensive range of sources to assess ...
traces the development of X during the 19th century.
Smith (2018)
offers what may be the most complete treatment of …
highlights the need to break the link between X and Y.
uses examples of these various techniques as evidence that ...
mentions the special situation of Singapore as an example of ...
lists three reasons why X has become so dominant. These are: ...
draws our attention to distinctive categories of X often observed in ...
discusses the challenges and strategies for facilitating and promoting ...
questions whether mainstream schools are the best environment for ...
considers whether countries work well on cross-border issues such as ...
provides in-depth analysis of the work of Aristotle showing its relevance to ...
defines evidence-based practice as the conscious, explicit and judicious use of ...

In her review of ...,
In her major study,
In her seminal article,
In her case study of …,
In her introduction to ...,
In her classic critique of ...,
In her historical account of …,
In her interesting analysis of …,

Smith (2012) identifies five characteristics of ...

41 | P a g e

Referring to another writer’s idea(s) or position
As argued by Smith (2003), X is far more cost effective, and therefore ...
According to Smith (2003), preventative medicine is far more cost effective, and therefore ...

Smith (2013)

claims
argues
suggests
maintains
concludes
points out

Jones (2013)

offers
suggests
proposes
argues for
makes the case for …

that

preventative medicine is far more cost effective than …

an explanatory theory for …

Synthesising sources: supporting evidence or ideas
Similarly, Jones (2015) found that X ...
This is consistent with the data obtained by …
Smith (1995) makes a similar point in his study of X …
In the same vein, Smith (1995) in his book XYZ notes ...
This view is supported by Jones (2015) who writes that ...
Along the same lines, Smith (1995) subsequently argued that …
Smith argues that her data support Jones’s (1995) view that ...
Jones’s (1986) work on X is complemented by Smith’s (2009) study of ...
Almost every paper that has been written on X includes a section relating to ...
A broadly similar point has also recently been made by Johnson (2019), who …
Jones (2016), like Smith, maintains that …
Like Smith, Jones (2016) maintains that ...
Similarly, Jones (2016) makes the case for …
Smith (2015)

sees X as …
argues that …

Likewise, Jones (2016) holds the view that ...
Supporting this view, Jones (2016) writes that …
Adopting a similar position, Jones (2016) argues that …
In the same vein, Jones (2016), in his book XXXXX, notes ...

42 | P a g e

Synthesising sources: contrasting evidence or ideas
Other writers have argued that …
Other studies have concluded that …
Unlike Smith, Jones (2013) argues that ...
In contrast to Smith, Jones (2013) argues that ...
Smith (2010) presents an X account, whilst Jones (2011) ...
While Smith (2008) focuses on X, Jones (2009) is more concerned with ...
A broader perspective has been adopted by Smith (213) who argues that ...
Contrary to previously published studies, Johnson et al. demonstrated the efficacy of…
This result conflicts with Smith’s (1965) previously mentioned study which found that …
Conversely, Smith (2010) reported no significant difference in mortality between X and Y.
Some writers (e.g. Smith, 2002) have
attempted to draw distinctions between ...

Others (see Jones, 2003; Brown, 2004) question
the usefulness of ...

Some authors have mainly been interested in
questions concerning X (Smith, 2001; Jones ...)

Others have highlighted the relevance of …

Whilst Smith identifies X as the principal
dimension of Y,

Jones (2000) has taken a different approach by
focusing on …

Contrasting sources with ‘however’ for emphasis
Much of the available literature on X deals
with the question of ...

However, Smith (2008) is much more concerned
with ...

According to some studies, X is represented as
… (Smith, 2012; Davis, 2014)

However, others propose … (Jones, 2014; Brown,
2015)

Smith (2013) found that X accounted for
approximately 30% of Y.

Other researchers, however, who have looked at
X, have found ... Jones (2010), for example, ...

Smith (2002) reports that ...

Jones’ (2010) study of Y, however, found little
evidence of ...

43 | P a g e

Unlike Smith,

(however),

Jones

accepts …
holds that …
thinks that …
insists that …
argues that …
suggests that …
sees great value in …
does not believe that …
embraces the idea that …
refuses to acknowledge …
provides a positive account of …
makes no distinction between …
acknowledges the role played by …

Referring to secondary sources
Smith (1973, cited in Jones, 2002) points out that …
Smith draws on the work of Jones (1959) who suggested that …
Building on the work of Jones (2000), Smith (2005) argues that …
Smith (2003) revisits and updates the Jones (1996) model of X by …
Smith (2000, citing Jones, 1998) points out, X has been shown to result in …
The view that … is supported by Smith (2003) who draws on Jones’s (1996) comparison of …
Drawing on the work of a wide range of philosophers, Smith (2015) advances the notion that …

Some ways of introducing quotations
Commenting on X, Smith (2003) argues: ‘... ...’
As Jones (2014: 215) states: ‘there are many good reasons to be sceptical’.
As Smith argues: ‘In the past, the purpose of education was to ...’ (Smith, 2000:150).
In the final part of the Theses on Feuerbach, Marx writes: ‘Philosophers have hitherto only …’
Sachs concludes: ‘The idea of development stands today like a ruin in …’ (Sachs, 1992a: 156).

As Smith

notes: ‘... ... ... ... ...’
writes: ‘... ... ... ... ...’
argues: ‘... ... ... ... ...’
observes: ‘... ... ... ... ...’
points out: ‘... ... ... ... ...’
reminds us: ‘... ... ... ... ...’

(Smith 2013: 23).

44 | P a g e

Summarising the studies reviewed
Together, these studies indicate that ...
Overall, these studies highlight the need for ...
Considering all of this evidence, it seems that ...
Collectively, these studies outline a critical role for…
In all the studies reviewed here, X is recognised as …
The evidence presented in this section suggests that ...
The studies presented thus far provide evidence that ...
Taken together, these studies support the notion that …
Overall, there seems to be some evidence to indicate that ...
Together these studies provide important insights into the ...
All of the studies reviewed here support the hypothesis that …
Two important themes emerge from the studies discussed so far:
However, such studies remain narrow in focus dealing only with …
These research findings reported here consistently point towards …
The evidence reviewed here seems to suggest a pertinent role for …
These studies clearly indicate that there is a relationship between …
In view of all that has been mentioned so far, one may suppose that ...
There remain several aspects of X about which relatively little is known.

suggest that …
suggest the efficacy of …
suggest an inverse association between …
suggest that the self-report method possesses ...
suggest that both X and Y play a role in the development of …
illustrate how …
illustrate the role of …
illustrate the flexibility of …
illustrate the heterogeneity of …
illustrate just how important X is in …
Overall, these studies
highlight the need for ...
highlight the complexity of …
highlight the positive aspects of …
highlight the beneficial effects of …
highlight the unique relationship between …
indicate a link between …
consistently indicate that …
clearly indicate the importance of …
indicate that Xs are often important predictors of …
indicate that the X has only a slight impact, if any, on …

45 | P a g e

provide mixed evidence for …
provide converging evidence for …
provide strong evidence for the efficacy of ...
provide clear evidence for the usefulness of …
provide reasonably consistent evidence of an association between ...
Overall, these studies
show weak evidence of ...
show that Xs may serve as important ...
show a modest correlation between X and Y.
show that X is caused by a complex system of …
show that a change from X to Y is usually associated with …

Summarising the literature review
The previous section has shown that …
In conclusion, these studies show that …
The evidence reviewed here seems to suggest …
To conclude this section, the literature identifies …
From the studies reviewed here, it is evident that …
This review has demonstrated the shortcomings of …
In summary, it has been shown from this review that …
Taken together, these studies support the notion that …
In summary, little is known about the interrelationships between …
This literature review points to the following general conclusions regarding …
This section has attempted to provide a brief summary of the literature relating to …

46 | P a g e

Describing Methods
In the Methods section of a dissertation or research article, writers give an account of how they
carried out their research. The Methods section should be clear and detailed enough for another
experienced person to repeat the research and reproduce the results. Where the methods chosen
are new, unfamiliar or perhaps even controversial, or where the intended audience is from many
disciplines, the Methods section will tend to be much more extensive. Typical stretches of text
found in this section of a research article or dissertation along with examples of the kind of language
used for these are listed below. Note that for many of the functional categories listed later in this
section, the verbs are written in the simple past tense and are in the passive voice.
Describing previously used methods
Many researchers have utilised X to measure …
One of the most well-known tools for assessing …
Traditionally, X has been assessed by measuring ...
A number of techniques have been developed to …
Different methods have been proposed to classify …
X is the main non-invasive method used to determine ...
Different authors have measured X in a variety of ways.
Several methods currently exist for the measurement of X.
Previous studies have based their criteria for selection on ...
X is one of the most common procedures for determining …
There are three main types of study design used to identify …
The use of life story data has a relatively long tradition within X.
Recent advances in X methods have facilitated investigation of …
There are a number of instruments available for measuring the …
Recently, simpler and more rapid tests of X have been developed.
X and Y are currently the most popular methods for investigating …
In most recent studies, X has been measured in four different ways.
The use of qualitative case studies is a well-established approach in ...
Xs have been used in the past to investigate the mechanical properties of …
Case studies have been long established in X to present detailed analysis of ...
To date, various methods have been developed and introduced to measure X.
Since the 1950s, researchers have used a multitude of scientific methods to …
This test is widely available and has been used in many investigational studies.
The methods for measuring X have varied somewhat across this research area.
In recent years, two different approaches have attempted to account for the …
In recent years, molecular methods have been utilised for the quantification of …
A variety of methods are used to assess X. Each has its advantages and drawbacks.
More recent examples of narrative studies within X can be found in the work of Smith (2010).
Two of the most common methods for estimating X are the use of Y and the measurement of Z.

X studies
Studies of X

have traditionally

employed …
based their approaches on …
used model systems to predict …
adopted functionalist perspectives
utilised a population-based approach.
relied upon participant observation as …
47 | P a g e

Various
Different

methods have been

utilised to
proposed to
employed to

assess …
test for…
identify …
capture …
quantify …
measure …
determine …
investigate …

Indicating the methodology for the current research
The present study utilises X to analyse …
The current study adopts a case study approach.
A qualitative methodology is employed in this study.
A mixed methods approach is employed in this research.
This investigation utilises energy analysis and statistical methods to …
A participatory qualitative research approach is employed in this study.
The current investigation utilises an array of assessment techniques to …
The current study uses qualitative analysis in order to gain insights into ...
It was decided that the best method to adopt for this investigation was to ...
This study employs qualitative analysis and natural language processing to …

This study
The current study

uses
utilises
employs

the X technique to …
archival research to …
an X methodology to …
the conceptual tools of …
a quasi-experimental design to …
experimental modal analysis to …
a descriptive research design to …
an ethnographic approach including …
a multi-method approach combining …
a qualitative research approach in which …
a randomised, double-blind trial involving …
critical discourse analysis (CDA) to examine …
interpretative phenomenological analysis to …
a qualitative methodology to critically evaluate how …
a mixture of quantitative and qualitative research methods to …
a cluster randomization design to examine the effectiveness of …

48 | P a g e

Giving reasons why a particular method was adopted
A major advantage of X is that …
The benefit of this approach is that …
The decision to use X was based on …
X based methods provide a means of …
X was selected for its reliability and validity.
A case study approach was used to allow a ...
This method is particularly useful in studying ...
A quantitative approach was employed since ...
Qualitative methods offer an effective way of ...
The design of the questionnaires was based on ...
The X method is one of the more practical ways of ...
The semi-structured approach was chosen because ...
The X approach has a number of attractive features: ...
The second advantage of using the multivariate method is ...
One advantage of the X analysis is that it avoids the problem of ...
Another advantage of using computer simulations is that it allows …
Continuous sampling methods have a number of advantages over …
The collaborative nature of the focus group offers another advantage …
Qualitative methods can be more useful for identifying and characterising …
The advantage of this particular method is that it allows us to make predictions about …
Many of the distributions were not normal so non-parametric signed rank tests were run.
It was considered that quantitative measures would usefully supplement and extend the ...

A case-study approach was

X is one of the most

used
chosen
adopted

successful
widely used
commonly used

to ensure that …
to help understand how …
to allow a deeper insight into …
to conduct this exploratory study.
to evaluate the effectiveness of …
to gain a detailed understanding of …
to determine the factors that affect ...
to assess the management practices of …
to obtain further in-depth information on the ...
to capture the complexities of the phenomenon.
to provide rounded, detailed illustrations of the …

methods
techniques

for
(used for)

dating …
assessing …
gathering …
collecting …
evaluating …
estimating …
measuring …
identifying …
determining …

49 | P a g e

A(n)
The
One

key
major
distinct
obvious
practical
potential
additional
important
significant

advantage

of using

Z-scores
focus groups
a rating scale
secondary data
self-report data
longitudinal data
retrospective data
regression analysis
natural speech data
semi-structured interviews

is that …

a convenience sample
a case study approach
a comparative approach
a mixed method approach
a multidimensional approach

Referring to the literature to justify a method or approach
In a recent article, Smith (2009) argues that case studies offer …
Smith et al. (1994) identify several advantages of the case study ...
Jones (2012) argues that case studies are useful when the conditions of the research …
According to Smith (2011), semi-structured interviews have a wide-spread popularity in …
The sensitivity of the X technique has been demonstrated in a report by Smith et al. (2011).
Jones (2006) points out that there is a role for both qualitative and quantitative approaches in …
Indicating the use of an established method
The solution was then assayed for X using the Y method.
X was prepared according to the procedure used by Jones et al. (1957).
The synthesis of X was done according to the procedure of Smith (1973).
X was synthesised using the same method that was detailed for Y, using ...
Samples were analysed for X as previously reported by Smith et al. (2012).
Analysis was based on the conceptual framework proposed by Smith et al. (2002).
This compound was prepared by adapting the procedure used by Jones et al. (1990).
Giving reasons why a particular method was rejected
The limitation of this approach is that …
A disadvantage of many cohort studies is that …
A major problem with the experimental method is that ...
The main disadvantage of the experimental method is that ...
The principal limitation of the experimental approach is that …
However, there are certain drawbacks associated with the use of ...
The disadvantage of this method is its reliance on the availability of …
However, this method clearly is not valid for analysing long-term trends in …
There are obvious difficulties in accepting the reliability of self-report information.
There are certain problems with the use of focus groups. One of these is that there is less ...
50 | P a g e

Explaining the provenance of the participants
A random sample of patients with X was recruited from ...
Forty-seven students studying X were recruited for this study.
The 5,880 study participants were recruited from four urban communities …
The project used a convenience sample of 32 first year students studying at ….
The participants for this cohort were identified from a census questionnaire that …
Participants were recruited from 15 clinics across X, covering urban and rural areas ...
Participants from X, Y, and Z were invited to complete a survey when they enrolled in …
Potential participants who lived within the radius of the centre were invited to take part in…
A comparison group of 12 male subjects without any history of X was drawn from a pool of ...
Describing the characteristics of the participants
The cohort was divided into two groups according to ...
The sample was representative with respect to gender and …
Just over half the sample (53%) was female, of whom 69% were ...
Of the initial cohort of 123 students, 66 were female and 57 male.
Eligible women who matched the selection criteria were identified by …
Only children aged between 10 and 15 years were included in the study.
The participants were divided into two groups based on their performance on ...
Two groups of subjects were interviewed, namely X and Y. The first group were ...
All of the participants were aged between 18 and 19 at the beginning of the study...
The initial sample consisted of 200 students, 75 of whom belonged to minority groups.
All were between 18 and 30 years old (mean age = 24.27 years, s. d. = 2.05), and comprised …
Semi-structured interviews were conducted with 17 male participants with a mean age of 38 years.
Explaining the provenance of articles for review
Literature was identified by searching …
X was searched to uncover studies relating to …
Additional searches were performed using the Index of …
The small corpus of texts for this study was drawn from …
Articles were searched from January 1965 to April 2014.
A systematic literature review was conducted of studies that ...
Electronic literature searches of X and Y were performed to identify …
The literature was searched using electronic databases covering the period 2000–2008.
Indicating criteria for selection or inclusion in the study
Publications were only included in the analysis if…
To identify X, the following parameters were used: …
Criteria for selecting the participants were as follows:
The area of study was chosen for its relatively small ...
Primary inclusion criteria for the X participants were …
A number of criteria were considered when selecting …
Eligibility criteria required individuals to have received ...
Five individuals were excluded from the study on the basis of ...
The inclusion/exclusion criteria for all participants were as follows:
The subjects were selected on the basis of the degree of homogeneity of their ...
All studies described as using some sort of X procedure were included in the analysis.
Articles were included if they reported a randomised, double-blind, placebo-controlled trials
51 | P a g e

Describing the process: typical verbs in the passive form
All participants were sent …
The data were normalised using ...
Ethical approval was obtained from ...
The drug was administered by ICV injection …
Descriptive data were generated for all variables.
The procedures of this study were approved by ...
Prompts were used as an aid to question two so that ...
Data were collected using semi-structured interviews in …
Participants were thanked for their time and effort and for …
The experiments were run using custom software written in...
Two sets of anonymised questionnaires were completed by ...
A total of 256 samples were taken from 52 boreholes (Figure 11).
The solution was washed three times with deionized water and ...
Significance levels were set at the 1% level using the student t-test.
Data management and analysis were performed using SPSS 26.0 (2019).
Published studies were identified using a search strategy developed in ...
Data were gathered from multiple sources at various time points during ...
Injection solutions were coded by a colleague to reduce experimenter bias.
The pilot interviews were conducted informally by the trained interviewer ...
Article references were searched further for additional relevant publications.
The experiments were conducted over the course of the growing period from ...
Blood samples were obtained with consent, from 256 Caucasian male patients ...
The participants were asked to pay close attention to the characters whenever ...
Independent tests were carried out on the X and Y scores for the four years from ...
This experiment was repeated under conditions in which the poor signal/noise ratio was improved.
The mean score for the two trials was subjected to multivariate analysis of variance to determine ...

The participants were asked

to rate …
to recall …
to attend …
to record …
to indicate …
to say whether …
to comment on …
to complete two tasks.
to answer a series of …
whether they believed …
to provide feedback on …
a variety of questions about …
to describe an instance when …
to explain what happened during …
to press the key corresponding to …
a series of open-ended questions that …
to describe what had happened when …
to complete a 20 question survey about …

52 | P a g e

Describing the process: sequence words
To begin this process, ...
The first step in this process was to ...
The second method used to identify X involved ...

Prior to

(Immediately)
After

commencing the study, ethical clearance was sought from ...
analysing the interview data, the transcripts were checked for …
undertaking the investigation, ethical clearance was obtained from ...
data collection, the participants received an explanation of the project.
‘training’, the participants were told that ...
collection, the samples were shipped back to X in ...
testing for the presence of antibodies, the blood was …
the appliance was fitted, the patients attended X every four weeks.

On

arrival at the clinic, patients were asked to ...
completion of X, the process of parameter estimation was carried out.
obtaining written informed consent from the patients, a questionnaire was …

Once

the samples were extracted, it was first necessary to …
the Xs were located and marked, a thin clear plastic ruler ...
the positions had been decided upon, the Xs were removed from each Y and …
the exposures were completed, the X was removed from the Y and placed in …

Following

correction for ..., X was reduced to ...
conformational analysis of X, it was necessary to ...
administration of X to patients, we assessed the effects on …
this treatment, the samples were recovered and stored overnight at ...

The participants were then shown a film individually and were asked to ...
The soil was then weighed again, and this weight was recorded as ...
These ratings were then made for the ten stimuli to which the subject had been exposed ...
The preparation was then placed in a custom-built microfluidics chamber, covered with …

When

dividing X, care was taken to ...
removing X, it was important to ...
inviting the participants, the purpose of the research was clearly explained.

Finally, questions were asked as to the role of ...
In the follow-up phase of the study, participants were asked ...
The final stage of the study comprised a semi-structured interview with participants who …

53 | P a g e

Describing the process: using + instrument
All the work on the computer was carried out using ...
Data were collected using two high spectral resolution Xs.
Semi-automated genotyping was carried out using X software and ...
Qualitative data were collected using a semi-structured questionnaire.
Using the X-ray and looking at the actual X, it was possible to identify ...
Comparisons between the two groups were made using unrelated t-tests
The data were recorded on a digital audio recorder and transcribed using a ...
Statistical significance was analysed using analysis of variance and t-tests as appropriate..
15 subjects were recruited using email advertisements requesting healthy students from ...
The relationship between X and Y was examined using the Pearson correlation coefficient and …
Describing the process: adverbs of manner
The resulting solution was gently mixed at room temperature for …
A sample of the concentrate was then carefully injected into ...
The soil was then placed in a furnace and gradually heated up to ...
The vials were shaken manually to allow the soil to mix well with the water.
The medium was then aseptically transferred to a conical flask.
The tubes were accurately reweighed to six decimal places using ...

Describing the process: infinitive of purpose
In order to investigate the effects of …
In order to identify …, the participants were asked to ...
In order to help familiarise participants with …, they were asked to …
In order to address these ethical concerns, the following steps were taken: …
In order to understand how X regulates Y, a series of transfections was performed.
To avoid …
To test whether …
To establish whether ...,
To better understand how …
To address the possibility of …
To measure X, a question asking ... was used.
To determine whether …, the cells were incubated for ...
To rule out the possibility that … , the participants were ...
To control for bias, measurements were carried out by another person.
To assess whether and how Xs are produced and received, we measured ...
To see if the two methods gave the same measurement, the data were plotted and ...
To compare the scores three weeks after initial screening, a global ANOVA F-test was used.
To enable the subjects to see the computer screen clearly, the laptop was configured with ...
To increase the reliability of measures, each X was tested twice with a 4-minute break between ...
The vials were capped with X to prevent ...
The process was repeated several times in order to remove ...
In an attempt to make each interviewee feel as comfortable as possible, the interviewer ...
The interview schedule comprised structured and open questions to identify and explore …
54 | P a g e

Describing the process: expressing purpose with for
For the next two questions, a Likert scale was used.
For the purpose of analysis, two segments were extracted from each ...
For the purpose of height measurement, participants were asked to stand ...
For the estimation of protein concentration, 100 µL of protein sample was mixed with ...
Describing questionnaire design
The first question elicited information on …
Seven questions, adapted from X, assessed …
All survey questions utilised a 5-point Likert scale.
Using a 5-point Likert scale, participants were asked …
A short questionnaire was designed to ascertain the participants' …
The questionnaire was designed to measure the following constructs:
Participants were asked to respond using a 5-point Likert scale ranging from …
The questions asked participants to rate how strongly they agreed with each statement.
The study began with two open-ended survey questions that asked participants to indicate …
The questionnaire asked participants to complete three open-ended questions that asked about …

The first question

was designed to

find out …
gauge how much…
ascertain whether …
identify the types of …
test participants’ knowledge of …
measure the students' ability to explain …
elicit a simple answer to a complex question about …

asked participants

to list …
to rank …
to provide …
to describe …
to reflect on …
to choose between …
to indicate whether …
to rate how much they liked …

Question 2 asked participants to indicate

whether …
which of three …
where and when …
the extent to which they …
what they liked best about …
how often they think about …
what their preferred X is for …
what percentage of the time …

Question 2
The third question
The final question

55 | P a g e

Q2 asked participants to rate

themselves as …
the intensity of …
their interest in …
the importance of …
their perception of …
the extent to which …
how frequently they …
their level of agreement with …
how strongly they agreed with the statement …

on a 5-point
Likert scale.

Describing the process: statistical procedures
The data were normalised using ...
A p value <0.05 was considered significant.
Descriptive data were generated for all variables.
Reliability was calculated using Cronbach’s alpha.
All analyses were carried out using SPSS, version 26.
Non-parametric tests were used to compare the number of …
Independent sample t-tests were carried out to assess whether …
Statistical analysis was performed using SPSS software (version 26).
Significance levels were set at the 1% level using the student t-test.
Data management and analysis were performed using SPSS 26.0 (2019).
A Pearson correlation analysis was conducted in order to assess the strength of …
An independent t-test was carried out on each of the variables to determine whether …
The mean score for the two trials was subjected to multivariate analysis of variance to determine ...
assess whether …
run
test the hypothesis that …
used
compare the mean scores of…
An independent t-test was conducted to
determine whether there was a difference …
performed
test for differences between the two groups.
carried out
test whether any differences existed between …

Indicating methodological problems or limitations
In particular, the analysis of X was problematic.
In observational studies, there is a potential for bias from …
The small size of the dataset meant that it was not possible to ...
Further data collection is required to determine exactly how X affects Y.
Another major source of uncertainty is in the method used to calculate X.
In this investigation there are several sources for error. The main error is ...
It was not possible to investigate the significant relationships of X and Y further because…
The responses relating to X were subjective and were therefore susceptible to recall bias.

56 | P a g e

Reporting Results
The standard approach to this section of a research article or dissertation is to present and describe
the results in a systematic and detailed way. When reporting qualitative results, the researcher will
highlight and comment on the themes that emerge from the analysis. These comments will often
be illustrated with excerpts from the raw data. In text based studies, this may comprise quotations
from the primary sources. In quantitative studies, the results section is likely to consist of tables and
figures, and writers comment on the significant data shown in these. This often takes the form of
the location or summary statement, which identifies the table or figure and indicates its content,
and a highlighting statement or statements, which point out and describe the relevant or significant
data. All figures and tables should be numbered and given a title.
More elaborate commentary on the results is normally restricted to the Discussion section. In
research articles, however, authors may comment extensively on their results as they are presented,
and it is not uncommon for the Results section to be combined with the Discussion section under
the heading: Results and Discussion.

Referring back to the research aims or procedures
The first set of questions aimed to …
To compare the difference between …
The purpose of Experiment 3 was to …
Simple statistical analysis was used to ...
The next question asked the informants …
To assess X, the Y questionnaire was used.
Changes in X and Y were compared using ...
The third research question was whether …
Regression analysis was used to predict the ...
To distinguish between these two possibilities, ...
The first set of analyses examined the impact of ...
The correlation between X and Y was tested using …
T-tests were used to analyse the relationship between ...
The average scores of X and Y were compared in order to ...
In order to assess Z, repeated-measures ANOVAs were used.
Nine items on the questionnaire measured the extent to which ...
To compare the scores three weeks after initial screening, a global ANOVA F-test was used.
The Pearson product moment correlation coefficient was used to determine the relationship …
Transition: moving to the next result
If we now turn to ...
Further analysis shows that ...
Further statistical tests revealed ...
Further analysis of the data reveals …
A comparison of the two results reveals ...
Turning now to the experimental evidence on ...
Comparing the two results, it can be seen that ...
The next section of the survey was concerned with ...
In the final part of the survey, respondents were asked ...

57 | P a g e

Referring to data in a table or chart

Table 1
Figure 1

shows
displays
presents
provides
compares

an overview of ...
the experimental data on X.
the summary statistics for ...
the breakdown of X according to ...
the median and range of scores for each group.
the intercorrelations among the nine measures of X.
the results obtained from the preliminary analysis of X.
the scatter diagram of the relationship between X and Y.

As shown in Figure 1,
As can be seen from the table (above),
Looking at Figure 3, it is apparent that …
From the graph above we can see that …
It can be seen from the data in Table 1 that …

The table below illustrates
The pie chart above shows
The top half of the table shows
The bottom half of the table shows

the X group reported significantly more Y than …

the proportion of different categories of ...

Means and standard deviations of X
The results of the correlational analysis
The themes identified in these responses
The results obtained from the preliminary analysis of X

are shown
are set out
are displayed
are presented
are summarised

in Table 1.
in Figure 1.

can be seen
can be compared

58 | P a g e

Highlighting significant data in a table or chart
What stands out in the table is …
Closer inspection of the table shows …
The X in Figure 2 is interesting because …
It is apparent from this table that very few ...
The most interesting aspect of this graph is …
In Fig.10 there is a clear trend of decreasing …
What is striking about the figures in this table is …
An inspection of the data in Table 1.5 reveals that …
What is interesting about the data in this table is that ...
The differences between X and Y are highlighted in Table 4.
From the chart, it can be seen that by far the greatest demand is for ...
From this data, we can see that Study 2 resulted in the lowest value of ...
This table is quite revealing in several ways. First, unlike the other tables ...
From the data in Figure 9, it is apparent that the length of time left between ...
Data from this table can be compared with the data in Table 4.6 which shows ...
As Table III shows, there is a significant difference (t = -2.15, p = 0.03) between the two groups.

What stands out in this

table
chart
figure

is the growth of …
is the high rate of …
is the dominance of …
is the wide range of …
is the rapid decrease in …
is the general pattern of …
is the difference between …
is the wide disparity between …
is the markedly lower rates of …

Stating a positive result
The mean score for X was ...
An increase in X was detected.
A two-way ANOVA revealed that ...
Participants’ ratings of X indicated …
On average, Xs were shown to have ...
Strong evidence of X was found when ...
This result is significant at the p = 0.05 level.
The results, as shown in Table 1, indicate that ...
A positive correlation was found between X and Y.
There was a significant positive correlation between ...
The difference between the X and Y groups was significant.
There was a significant difference between the two conditions ...
There were small but significant negative correlations between …
A significant difference was found between X1 and X2, t(11) = 2.906, p<0.01.
Respondents who reported low levels of X also reported significantly lower levels of Y.
There is a moderate correlation (r2 = 0.60, significant at less than 1% probability) between …

59 | P a g e

Stating a negative result
No increase in X was detected.
No difference greater than X was observed.
No significant differences were found between ...
None of these differences were statistically significant.
No significant difference between the two groups was evident.
No significant reduction in X was found compared with placebo.
No evidence was found for non-linear associations between X and Y.
No significant correlation was found between X scores and the Y scores (p = .274)
X appeared to be unaffected by Y.
Only trace amounts of X were detected in ...
There was no evidence that X has an influence on …
The results of this experiment show no clear-cut pattern of …
The Chi-square test did not show any significant differences between ...
There was no significant difference between the groups with respect to ...
Overall, X did not affect males and females differently in these measures.
A clear benefit of X in the prevention of Y could not be identified in this analysis.
T-tests found no significant differences in mean scores on the X and Y subscales.

There was no

increase of X associated with ...
significant difference between ...
evidence that X has an influence on …
observed difference in the number of …

No statistically significant

difference
correlation

between the means was found.
between the two groups was evident.
was observed between X and Y groups.
was found between X score and the Y scores.
between the mean scores of these groups was evident.

Reporting positive and negative reactions
X occurred with successive increases in Y.
With successive increases in intensity of the X, the Y moved further to ...
Following the addition of X, a significant increase (p<0.05) in the Y was recorded.
Combining X with Y did not produce …
Stimulation of X with Y did not increase the ...
When X cells were stimulated with Y, no significant difference in Z was detected.

60 | P a g e

Highlighting interesting or surprising results
Interestingly, the X was observed to ...
This result is somewhat counterintuitive.
Interestingly, this correlation is related to ...
The more surprising correlation is with the ...
Surprisingly, only a minority of respondents …
The most surprising aspect of the data is in the ...
The correlation between X and Y is interesting because ...
The most striking result to emerge from the data is that ...
Interestingly, there were also differences in the ratios of ...
Interestingly, a significant interaction of X and Y was also observed.
The single most striking observation to emerge from the data comparison was ...

This is a/an (rather)

One
A further
An important

surprising
significant
interesting
remarkable
unexpected
disappointing

issue
theme
factor
that emerged
problem
concept
category

result.
outcome.

from the data was …
from the interviews was …
during the pilot interviews was …
at the initial stages of the analytic process was …

Surveys and interviews: Reporting response rates
The overall response to the survey was poor.
Thirty-two individuals returned the questionnaires.
The response rate was 60% at six months and 56% at 12 months.
Of the study population, 90 subjects completed and returned the questionnaire.
Of 150 potential participants who were sent invitations, 80 agreed to take part in …
By the end of the survey period, data had been collected from 64 individuals, 23 of whom were …
There were 53 responses to the question: ‘...?’
Respondents were asked to indicate whether ...
The total number of responses for this question was ...
The overall response to this question was very positive.
Respondents were asked to suggest other reasons for ...
In response to the question: ‘...?’, a range of responses was elicited.
This section of the questionnaire required respondents to give information on ...

61 | P a g e

Surveys and interviews: Reporting proportions
Over half of those surveyed reported that ...
A minority of participants (17%) indicated that ...
70% of those who were interviewed indicated that ....
Almost two-thirds of the participants (64%) said that ....
The majority of those who responded to this item felt that ...
When asked whether ..., 90% of the respondents reported that ...
Just over half of those who answered this question reported that ...
In response to Question 1, most of those surveyed indicated that ...
When the participants were asked ……, the majority commented that ...
Of the 148 patients who completed the questionnaire, just over half indicated that ...
Surveys and interviews: Reporting themes
Another reported problem was …
Opinions differed as to whether …
Concerns were expressed about …
A number of issues were identified …
A variety of perspectives were expressed …
These views surfaced mainly in relation to …
Concerns regarding X were more widespread.
There was a sense of X amongst interviewees.
Five broad themes emerged from the analysis.
A common view amongst interviewees was that …
One concern expressed regarding X was whether …
This theme came up for example in discussions of …
The themes of X and Y recurred throughout the dataset.
Particularly revealing is how the participants described …
Two discrete reasons emerged from this. First ... Second …
Two divergent and often conflicting discourses emerged …
Of the five themes, ‘X’ was the most frequently coded theme in the data.
Issues related to X were not particularly prominent in the interview data.
The responses to Question 1 could be grouped into the following themes:
A recurrent theme in the interviews was a sense amongst interviewees that …
Surveys and interviews: Introducing excerpts from interview data
As one interviewee said: ‘...’
As one interviewee put it: ‘...’
One informant reported that ...
The comment below illustrates ...
One participant commented: ‘...’
For example, one interviewee said: ‘...’
In one case, the participant thought that …
Another interviewee, when asked …, said: ‘...’
Other responses to this question included: ‘...’
Another interviewee alluded to the notion of ...
Talking about this issue an interviewee said: ‘...’
Commenting on X, one of the interviewees said …
One individual stated that ‘...’ And another commented ‘...’

62 | P a g e

Surveys and interviews: Reporting participants’ views
It was suggested that ...
One interviewee argued that …
There were some suggestions that ...
In all cases, the informants reported that …
In their accounts of the events surrounding ...
There were some negative comments about ...
The participants on the whole demonstrated ...
Some felt that …, while others considered that …
Some interviewees argued that …, while others …
This view was echoed by another informant who ...
Whilst a minority mentioned that…, all agreed that…
Only a small number of respondents indicated that ...
A small number of those interviewed suggested that ....
For a small number of participants X was the reason for …
The majority of participants agreed with the statement that …
When asked about X, the participants were unanimous in the view that …

One
Some
A few
A number of
The majority of
A small number of
The overwhelming majority of

informant(s)
participant(s)
interviewee(s)

felt that …
said that …
stated that …
argued that …
reported that …
indicated that …
proposed that …
remarked that …
suggested that …
commented that …
referred to …
emphasised …
attributed X to …
explicitly referred to …
questioned whether …
expressed a desire for …
were reluctant to discuss …
offered an explanation for …
expressed concerns about …
were particularly critical of …
agreed with the statement that …
welcomed the opportunity to focus on …

63 | P a g e

Summarising the results section
These results suggest that ...
The results also indicate that …
Overall, these results indicate that ...
In summary, these results show that ...
In summary, for the informants in this study, ...
What emerges from the results reported here is that …
Together these results provide important insights into ...
Taken together, these results suggest that there is an association between ...
The results in this chapter indicate that ... The next chapter, therefore, moves on to discuss the ...

64 | P a g e

Discussing Findings
The term ‘discussion’ has a variety of meanings in English. In academic writing, however, it usually
refers to two types of activity: a) considering both sides of an issue, or question before reaching a
conclusion; b) considering the results of research and the implications of these. Discussion sections
in dissertations and research articles are probably the most complex sections in terms of their
elements. They normally centre around a 'statement of result' or an important 'finding'. As there is
usually more than one result, discussion sections are often structured into a series of discussion
cycles. The most common elements in these cycles, and some of the language that is typically
associated with them, are listed below. Note that when offering explanations and suggesting
implications the language used is very tentative or cautious (refer to the section entitled Expressing
Caution).

Providing background information: reference to the literature
A number of recent studies …
Several reports have shown that …
As mentioned in the literature review, ...
Prior studies that have noted the importance of ...
Very little was found in the literature on the question of ...
Previous studies evaluating X observed inconsistent results on whether …
A strong relationship between X and Y has been reported in the literature.
In reviewing the literature, no data was found on the association between X and Y.

Providing background information: reference to the purpose of the study
One of the aims of this study was to …
The third question in this research was ...
An initial objective of the project was to identify ...
This study set out to assess the importance of X in ...
The first question in this study sought to determine ...
It was hypothesised that participants with a history of ...
The present study was designed to determine the effect of ...
With respect to the first research question, it was found that …

Restating the result or one of several results
This study found that …
One interesting finding is ...
The current study found that ...
Another important finding is that ...
The most important result was that ...
In this study, Xs were found to cause ...
The results of this study show/indicate that ...
On the question of X, this study found that ...
This experiment did not detect any evidence for ...
The most obvious finding to emerge from the analysis is that ...
65 | P a g e

(Perhaps) the most

striking
important
disturbing
significant
interesting
compelling
unexpected
clinically relevant

finding is …

Indicating an unexpected outcome
What is surprising is that ...
Surprisingly, X was found to ...
One unanticipated result was that ...
What is curious about this result is that …
Surprisingly, no differences were found in ...
This finding was unexpected and suggests that ...
One unexpected finding was the extent to which …
It is somewhat surprising that no X was noted in this condition ...
The weak association of X with Y is interesting, but not surprising.
It is interesting to compare Figure 4 with Figure 2 in Smith (2019) that shows …
One surprising variable that was found to be significantly associated with X was …
These findings are somewhat surprising given the fact that other research shows …
Contrary to expectations, this study did not find a significant difference between ...
However, the observed difference between X and Y in this study was not significant.
However, the ANOVA (one way) showed that these results were not statistically significant.
It was surprising that the X group scores did not differ significantly from those of the Y group.

Comparing the result: supporting previous findings
This study confirms that X is associated with ...
This finding was also reported by Smith et al. (1989).
This finding is consistent with that of Smith (2000) who …
Comparison of the findings with those of other studies confirms …
This also accords with our earlier observations, which showed that ...
These results reflect those of Smith et al. (1992) who also found that …
Increased activation in the X in this study corroborates these earlier findings.
These results corroborate the findings of a great deal of the previous work in ...
This finding broadly supports the work of other studies in this area linking X with Y.
In accordance with the present results, previous studies have demonstrated that ...
It is encouraging to compare this figure with that found by Jones (1993) who found that ...
Consistent with the literature, this research found that participants who reported using X also …
There are similarities between the attitudes expressed by X in this study and those described by …
This study supports evidence from clinical observations (e.g. Smith, 1997; Jones et al., 1994) that …

66 | P a g e

These results

further support the idea of ...
confirm the association between ...
are consistent with data obtained in …
match those observed in earlier studies.
are in line with those of previous studies.
are in agreement with those obtained by …
are in accord with recent studies indicating that …
agree with the findings of other studies, in which ...
seem to be consistent with other research which found ...
mirror those of the previous studies that have examined ...
are consistent with those of Smith and Jones (2015) who ...
are in keeping with previous observational studies, which ...
support previous research into this area which links X and Y.
are in agreement with Smith’s (1999) findings which showed ...
corroborate the ideas of Smith and Jones (2008), who suggested that ...

Comparing the result: contradicting previous findings
This study has been unable to demonstrate that ...
However, this result has not previously been described.
This outcome is contrary to that of Smith et al. (2001) who found …
This finding is contrary to previous studies which have suggested that …
In contrast to earlier findings, however, no evidence of X was detected.
The yields in this investigation were higher compared to those of other studies.
However, the findings of the current study do not support the previous research.
Smith et al. (1999) showed that …. This differs from the findings presented here …
The overall level was found to be 15%, lower than that of previously reported levels.
It has been suggested that … (Smith et al., 2002). This does not appear to be the case.
The levels observed in this investigation are far below those observed by Smith et al. (2007).
These results differ from X’s 2003 estimate of Y, but they are broadly consistent with earlier ...
Although, these results differ from some published studies (Smith, 1992; Jones, 1996), they are
consistent with those of ...
Offering an explanation for the findings
A possible explanation for this might be that ...
Another possible explanation for this is that ...
This result may be explained by the fact that ...
There are, however, other possible explanations.
These relationships may partly be explained by …
There are several possible explanations for this result.
Several factors could explain this observation. Firstly, …
These differences can be explained in part by the proximity of X and Y.
A possible explanation for these results may be the lack of adequate ...
These factors may explain the relatively good correlation between X and Y.

67 | P a g e

This inconsistency may be due to ...
These results are likely to be related to …
This discrepancy could be attributed to ...
It seems possible that these results are due to ...
This rather contradictory result may be due to ...
The observed increase in X could be attributed to …
It is difficult to explain this result, but it might be related to ...
This finding could have been generated by misclassification bias since …
Another possible alternative explanation of our findings is that they are due to …
The possible interference of X cannot be ruled out.
It may be that these participants benefitted from ...
Differences between X and Y may have influenced ...
These possible sources of error could have affected …
There are two likely causes for the differences between ...
This result may reflect differences in the size, quality and …
The reason for this is not clear but it may have something to do with ...
The observed correlation between X and Y might be explained in this way: ...
Since this difference has not been found elsewhere it is probably not due to ...
These conflicting experimental results could be associated with the nature of the …
It is possible that these unmeasured variables could account for some aspects of the results.

This (rather)

intriguing
interesting
surprising
unexpected
disappointing

result
finding

could be due to …
may be related to …
might be a result of …
could be attributed to …
can be explained by X.
might be explained by the fact that …

Advising cautious interpretation of the findings
Another source of uncertainty is …
Additional uncertainty arises from …
A note of caution is due here since …
We cannot exclude the possibility that …
There are several possible sources of error.
These findings cannot be extrapolated to all …
These findings may be somewhat limited by …
The possible interference of X cannot be ruled out.
These data must be interpreted with caution because ...
It could be argued that the positive results were due to …
Several sources of error may have influenced these results.
These results therefore need to be interpreted with caution.
It is important to bear in mind the possible bias in these responses.
This limitation means that study findings need to be interpreted cautiously.
Although exclusion of X did not ..., these results should be interpreted with caution.
However, with a small sample size, caution must be applied, as the findings might not be …
68 | P a g e

It is possible that these results

are due to …
are limited to …
are only valid for …
do not represent the …
have been confounded by ...
may have been skewed by …
might be biased because of …
could be a statistical anomaly.
were influenced by the lack of …
merely reflect a selection effect.
may underestimate the role of …
are not a true representation of …
underestimate the true prevalence of …
might not be applicable to other groups …
are an artefact of our experimental design.
are biased, given the self-reported nature of …
will not be reproducible on a wide scale across …
may not be generalisable to a broader range of ...

Suggesting general hypotheses
These findings suggest that ...
It is possible, therefore, that ...
It can thus be suggested that ...
In general, therefore, it seems that ...
The findings reported here suggest that …
According to these data, we can infer that …
It is possible/likely/probable therefore that ...
The present study raises the possibility that ...
Hence, it could conceivably be hypothesised that ...
This observation may support the hypothesis that …
It may be the case therefore that these variations ...
It is therefore likely that such connections exist between ...
The value of X suggests that a weak link may exist between ...
These results provide further support for the hypothesis that ...
Therefore, X could be a major factor, if not the only one, causing ...
It is possible to hypothesise that these conditions are less likely to occur in ...

69 | P a g e

Commenting on the findings
These findings are rather disappointing.
However, these results were not very encouraging.
The test was successful as it was able to identify students who ...
The present results are significant in at least two major respects.
Unfortunately, these findings are rather difficult to interpret because …

This is a/an
These are

This is a
These are

key
useful
positive
valuable
troubling
surprising
important
significant
reassuring
interesting
remarkable
encouraging
disappointing

rather
somewhat
particularly

result(s).
finding(s).

useful
troubling
surprising
reassuring
remarkable
encouraging
disappointing

result(s).
finding(s).

70 | P a g e

Noting implications of the findings
These findings suggest that ...
It can therefore be assumed that the ...
This provides some explanation as to why …
An implication of this is the possibility that ...
One of the issues that emerges from these findings is ...
These initial results are suggestive of a link between X and Y.
Some of the issues emerging from this finding relate specifically to ...
This combination of findings provides some support for the conceptual premise that ...

These

results
findings

These findings

suggest that …
provide support for …
cast some doubt on …
have implications for …
support the idea that …
challenge the notion that …
might further indicate that …
may help us to understand ...
may be taken to indicate that …
reveal something about the nature of …
are representative of an emerging trend in …
provide some tentative initial evidence that …
have important implications for developing ...
may reflect differences in the size, quality and …
add to a growing body of evidence that suggests …
draw our attention to the importance of considering …
raise intriguing questions regarding the nature and extent of ...
suggest that the lowering of X may reduce hospital admissions for …

may
will
might
should

help us to
help others to

shape …
design…
predict …
develop …
prioritise …
explain why …
find new ways of …
better understand …

71 | P a g e

Suggestions for future work
This is an important issue for future research.
Research questions that could be asked include ...
Several questions remain unanswered at present.
Despite these promising results, questions remain.
There are still many unanswered questions about …
Further work is required to establish the viability of...
These results warrant further investigation with a larger …
Another potentially fruitful avenue for future research is …
Further research should be undertaken to investigate the ...
A further study with more focus on X is therefore suggested.
There is abundant room for further progress in determining …
Future studies on the current topic are therefore recommended.
In further research, the use of these data as X could be a means of ...
To develop a full picture of X additional studies will be needed that ...
In future investigations, it might be possible to use a different X in which ...
A comprehensive review based on more reliable study designs is recommended.
Further studies, which take these variables into account, will need to be undertaken.
However, more research on this topic needs to be undertaken before the association between X and
Y is more clearly understood.

Further

work is
research is
studies are
investigations are

needed to
required to

identify the …
establish how …
confirm whether …
assess the risks of …
ascertain whether …
determine whether …
examine the effects of …
evaluate the impact of …
address the following questions:
explore the mechanisms behind …
assess the longer-term impact of …
confirm and validate these findings.
identify or develop drugs that can …
assess the competing therapies for …
develop reliable analytical methods for ...
shed light on the mechanism underlying ...
provide greater insight into the effects of …
gain a better understanding of the possible …
establish the effectiveness of treatment with …
better understand the mechanisms underlying …

72 | P a g e

Writing Conclusions
Conclusions are shorter sections of academic texts which usually serve two functions. The first is to
summarise and bring together the main areas covered in the writing, which might be called ‘looking
back’; and the second is to give a final comment or judgement on this. The final comment may also
include making suggestions for improvement and speculating on future directions.
In dissertations and research papers, conclusions tend to be more complex and will also include
sections on the significance of the findings and on recommendations for future work. In some
research papers, the conclusion is not presented separately from the discussion section; the two
sections may be combined. However, separate conclusions are nearly always expected for
dissertations and essays.

Referring back to the purpose of the paper or study
This study set out to …
This paper has argued that ...
This essay has discussed the reasons for ...
In this investigation, the aim was to assess ...
The aim of the present research was to examine …
The purpose of the current study was to determine ...
The main goal of the current study was to determine ...
This project was undertaken to design ... and evaluate ...
The present study was designed to determine the effect of ...
The second aim of this study was to investigate the effects of …
Returning to the question posed at the beginning of this study, it is now possible to state that ...

This study set out to

predict which …
establish whether …
determine whether …
develop a model for …
assess the effects of …
investigate impact of …
better understand the …
find a new method for …
evaluate how effective …
assess the feasibility of …
test the hypothesis that …
explore the influence of …
gain a better understanding of …
objectively measure and assess …
examine the relationship between …
compare the two ways of treating …
critically examine the ways in which …
evaluate a new method of measuring …
provide the first systematic account of …
understand the views and experiences of …
review in detail the available information on …

73 | P a g e

This study has

examined

the role of …
the impact of …
the nature of …
the concept of …
the differences between …
the relationship between …
the peer reviewed literature on …
the factors which are thought to contribute to …

Summarising the main research findings
This study has identified …
This study has shown that ...
The findings clearly indicate that …
The research has also shown that ...
The second major finding was that ...
These experiments confirmed that …
X made no significant difference to …
This study has found that generally ...
The investigation of X has shown that ...
The results of this investigation show that ...
X, Y and Z emerged as reliable predictors of ...
Multiple regression analysis revealed that the ...
The most obvious finding to emerge from this study is that ...
The relevance of X is clearly supported by the current findings.
One of the more significant findings to emerge from this study is that ...
Suggesting implications for what is already known
In general, therefore, it seems that ...
The results of this study indicate that ...
The findings of this study suggest that ...
Taken together, these results suggest that ...
An implication of this is the possibility that ...
The evidence from this study suggests that ...
Overall, this study strengthens the idea that …
The current data highlight the importance of …
The findings of this research provide insights for …
The results of this research support the idea that ...
These data suggest that X can be achieved through ...
The theoretical implications of these findings are unclear.
The principal theoretical implication of this study is that …
This study has raised important questions about the nature of …
The following conclusions can be drawn from the present study ...
Taken together, these findings suggest a role for X in promoting Y.
The findings of this investigation complement those of earlier studies.
These findings have significant implications for the understanding of how …
Although this study focuses on X, the findings may well have a bearing on ...
These findings raised important theoretical issues that have a bearing on the ...
74 | P a g e

Explaining the significance of the findings or contribution of the study
The findings will be of interest to …
This thesis has provided a deeper insight into …
The findings reported here shed new light on …
The understanding gained here should help to …
The study contributes to our understanding of …
These results add to the rapidly expanding field of …
The contribution of this study has been to confirm …
Before this study, evidence of X was purely anecdotal.
This project is the first comprehensive investigation of …
The insights gained from this study may be of assistance to …
This work contributes to existing knowledge of X by providing ...
This is the largest study so far documenting a delayed onset of ...
Prior to this study it was difficult to make predictions about how …
The analysis of X undertaken here, has extended our knowledge of ...
The empirical findings in this study provide a new understanding of ...
This paper contributes to recent historiographical debates concerning …
This approach will prove useful in expanding our understanding of how …
By providing a conceptual model, this work offers a novel understanding of …
This new understanding should help to improve predictions of the impact of …
This is the first report on X from a nationally representative cohort of patients.
The methods used for this X may be applied to other Xs elsewhere in the world.
The X that we have identified therefore assists in our understanding of the role of ...
This is the first study of substantial duration which examines associations between …
The findings from this study make several contributions to the current literature. First,…
These findings contribute in several ways to our understanding of X and provide a basis for …

This study
The present study

lays the groundwork for future research into …
provides the first comprehensive assessment of …
establishes a quantitative framework for detecting …
adds to the growing body of research that indicates …
is the only empirical investigation into the impact of …
has been one of the first attempts to thoroughly examine …
appears to be the first study to compare the experiences of …
has gone some way towards enhancing our understanding of ...
has confirmed the findings of Smith et al. (2001) which found that...

75 | P a g e

These findings

illustrate how …
could be used to help …
are important because …
are particularly relevant for …
provide insights into whether …
enhance our understanding of ...
provide additional evidence for …
will help other researchers design …
highlight the potential usefulness of …
add to a growing body of literature on ...
provide strong empirical confirmation that …
represent a major breakthrough in the way …
provide important insights into the role of …
make several contributions to the current literature.
are relevant to both practitioners and policy-makers.
will be of broad use to the scientific and biomedical communities.

This is the first study

to identify …
to show that …
to investigate …
to test the effects of …
to firmly establish that …
to provide evidence for …
to reveal the presence of ...
to investigate the effect of ...
to use objective measures to …
to report an association between …
to integrate modelling approaches intended to …
that has used …
that has found …
that has revealed …
that has measured …
that has presented evidence for …
that has systematically analysed …
that has investigated the effects of …
that has documented the impact of …
that has evaluated the effectiveness of …
that has shown a clear-cut positive effect of …

76 | P a g e

This research
The present study

Prior to this

extends our knowledge of ...
has demonstrated, for the first time, that ...
will serve as a base for future studies and ...
should prove to be particularly valuable to ...
makes several noteworthy contributions to ...
has offered a framework for the exploration of ...
has provided additional evidence with respect to ...
has several practical applications. Firstly, it points to ...
has shed a contemporary light on the contentious issue of …
is important in furthering our understanding of the role of …
confirms previous findings and contributes additional evidence that ...

study
investigation

X was unknown.
it was difficult to …
there were no data on …
there was uncertainty about whether …
it had not been possible to determine …
no clear evidence of X had been reported.
little was known about the characteristics of …
little evidence existed to support the idea that ...
the influence of X on Y had not been thoroughly investigated.

Commenting on the strengths of the current study
A key strength of the present study was the ...
The main strength of this study is the exclusion of …
One strength of this study is the high rate of follow-up, …
The key strengths of this study are its long duration and ...
The strengths of the study included the in-depth analysis of …
Although the findings should be interpreted with caution, this study has several strengths …
One of the strengths of this study is that it represents a comprehensive examination of the whole …

Introducing the limitations of the current study
A number of limitations need to be noted regarding the present study.
Study limitations make an overall conclusion about X extremely difficult.
The findings in this report are subject to at least three limitations. First, ...
Finally, a number of important weaknesses need to be considered. First, ...
With regard to the research methods, some limitations need to be acknowledged.
The generalisability of these results is subject to certain limitations. For instance, ...
Several limitations to this pilot study need to be acknowledged. The sample size is ...
The present study was subject to a number of potential methodological weaknesses.
The project was limited in several ways. First, the project used a convenience sample that
Although the study has successfully demonstrated that ..., it has certain limitations in terms of ...
77 | P a g e

Detailing specific limitations
A limitation of this study is that …
Being limited to X, this study lacks …
The major limitation of this study is the ...
The interference of X cannot be ruled out.
One issue with the current study was that …
X makes these findings less generalisable to ...
Thirdly, the study did not evaluate the use of ...
The generalisability of these findings is limited …
It is unfortunate that the study did not include ...
The scope of this study was limited in terms of ...
However, these findings are limited by the use of …
The most important limitation lies in the fact that ...
The main weakness of this study was the paucity of ...
Since the study was limited to X, it was not possible to ..
An additional uncontrolled factor is the possibility that ...
A limitation of using this kind of data is that it precludes ...
It was not possible to assess X; therefore, it is unknown if …
An issue that was not addressed in this study was whether...
An arguable weakness is the arbitrariness in our definition of ...
The study did not control for the possible confounding effects of …
The principal limitation of this analysis was the variance in the design of …
A potential source of bias for the study is the influence the researcher had upon …
The responses relating to X were subjective and were therefore susceptible to recall bias.
The sample was nationally representative of X but would tend to miss people who were ...
One source of weakness in this study which could have affected the measurements of X was ...
The lack of X in the sample adds further caution regarding the generalisability of these findings.
With a small sample size, caution must be applied, as the findings might not be transferable to ...

This
The current
The present

The current study

study
research
investigation

is limited by ...
has only examined ...
has not been able to establish …
has only considered the context of …
has not been able to confirm earlier …
was unable to analyse these variables.
was not specifically designed to evaluate factors related to …

is limited by ...

the absence of …
the possible effect of …
the small number of cases.
the relatively small sample.
the fact that it only surveyed …
by the fact that it was restricted to …

78 | P a g e

However, these results may not be applicable to

Another source of
uncertainty

is
has been

all types of …
all situations.
other species.
patients who …
all clinical settings.
The wider population.
other groups within …
organisations which …

the role of …
the estimate for …
the assumption that …
the variation of X over time.
associated with changes in …
the possibility of measurement errors in …

Acknowledging limitation(s) whilst stating a finding or contribution
Notwithstanding these limitations, the study suggests that ...
Whilst this study did not confirm X, it did partially substantiate ...
Despite its exploratory nature, this study offers some insight into ...
In spite of its limitations, the study certainly adds to our understanding of the ...
Notwithstanding the relatively limited sample, this work offers valuable insights into …
Although the current study is based on a small sample of participants, the findings suggest ...
Making recommendations for further research work
The question raised by this study is …
The study should be repeated using ...
This would be a fruitful area for further work.
Several questions still remain to be answered.
A natural progression of this work is to analyse ...
More research using controlled trials is needed to …
More broadly, research is also needed to determine ...
A further study could assess the long-term effects of ...
What is now needed is a cross-national study involving ...
Considerably more work will need to be done to determine ...
The precise mechanism of X in insects remains to be elucidated.
These findings provide the following insights for future research: ...
Large randomised controlled trials could provide more definitive evidence.
This research has thrown up many questions in need of further investigation.
A greater focus on X could produce interesting findings that account more for ...
The issue of X is an intriguing one which could be usefully explored in further research.
If the debate is to be moved forward, a better understanding of X needs to be developed.
I suggest that before X is introduced, a study similar to this one should be carried out on ...
More information on X would help us to establish a greater degree of accuracy on this matter.
79 | P a g e

Further

work needs to be done to establish whether ...
studies need to be carried out in order to validate ...
studies regarding the role of X would be worthwhile.
experimental investigations are needed to estimate ...
work is needed to fully understand the implications of …
research is required to establish the therapeutic efficiency of …
modelling work will have to be conducted in order to determine …
investigation and experimentation into X is strongly recommended.
experiments, using a broader range of Xs, could shed more light on …
research in other Xs is, therefore, an essential next step in confirming …

Further research

More research

might explore …
could usefully explore how …
should focus on determining …
is required to determine whether …
in this field would be of great help in …
should be carried out to establish the …
should be undertaken to explore how …
on these questions would be a useful way of ...
needs to examine more closely the links between X and Y.
could also be conducted to determine the effectiveness of …

is needed
is required

to account for ...
in order to determine which …
to determine the efficacy and safety of ...
to examine the long-term efficacy and safety of …
to better understand when implementation ends and ...
to develop a deeper understanding of the relationships between …

80 | P a g e

Further

research is
studies are

needed to better
required understand

why …
how …
the nature of …
the causes of …
the impact of …
the reasons for …
the influence of …
the extent to which …
the role that X plays in …
how X is associated with …
the risks associated with …
the underlying causes of …
the possible link between ...
the relationship between …
the discrepancies between …
the mechanisms underlying …
the effectiveness and safety of …
the complex linkages between …
the complex interaction between …
the complex association between …

It would be interesting to assess the effects of ...
It is recommended that further research be undertaken in the following areas:
It would be interesting to compare experiences of individuals within the same …
It is suggested that the association of these factors is investigated in future studies.
A future study investigating X would be very interesting.
In terms of directions for future research, further work could ...
In the future, it will be important to explore the potential use of …
Another possible area of future research would be to investigate why ...
A number of possible future studies using the same experimental set up are apparent.
In terms of future work, it would be interesting to repeat the experiments described here using …

Future studies should

include …
focus on …
target specific …
clarify whether …
attempt to identify …
assess the impact of ...
explore the effects of …
seek to minimise bias by …
investigate the degree to which …
concentrate on the investigation of ...
address the questions raised by this research.
81 | P a g e

Implications and/or recommendations for practice or policy
Other types of X could include: a), b) ...
Greater efforts are needed to ensure ...
There is, therefore, a definite need for ...
A second broad recommendation is that …
Provision of X will enhance Y and reduce Z.
Another important practical implication is that ...
Moreover, more X should be made available to ...
The challenge now is to fabricate Xs that contain …
Unless governments adopt X, Y will not be attained.
These findings suggest several courses of action for ...
A reasonable approach to tackle this issue could be to ...
This particular research finding also points to the need for …
Continued efforts are needed to make X more accessible to ...
These findings have implications within the clinical setting for …
The findings of this study have a number of practical implications.
There are a number of important changes which need to be made.
Management to enhance bumble-bee populations might involve ...
This information can be used to develop targeted interventions aimed at ...
This study suggests that X should be avoided by people who are prone to …
A key policy priority should therefore be to plan for the long-term care of ...
Taken together, these findings do not support strong recommendations to ...
Ensuring appropriate systems, services and support for X should be a priority for …
The findings of this study have a number of important implications for future practice.
An implication of these findings is that both X and Y should be taken into account when ...

82 | P a g e

General Functions of Academic Writing

83 | P a g e

Being Cautious
One of the most noticeable stylistic aspects of academic communication is the tendency for writers
to avoid expressing absolute certainty, where there may be a small degree of uncertainty, and to
avoid making over-generalisations, where a small number of exceptions might exist. This means
that there are many instances where the epistemological strength (strength of knowledge) of a
statement or claim is mitigated (weakened) in some way. Writers may also wish to create a degree
of distance between themselves and a statement or claim made by another writer. In the field of
linguistics, devices for lessening the strength of a statement or for creating distance are known as
hedging devices. Analysis of research reports have shown that discussion sections tend to be rich
in hedging devices, particularly where writers are offering explanations for findings.

Devices that distance the writer from a proposition
It is thought that ...
It is believed that ...
It has been reported that ...
It is a widely held view that ...
It has commonly been assumed that ...
According to Smith (2002), ...
According to recent reports, ...
According to many in the field ...
Many scholars hold the view that ...
Smith (2001) is of the opinion that ...
Recent research has suggested that ...
If Smith’s (2001) findings are accurate, ...
There is some evidence to suggest that ...
There is a growing body of evidence to suggest that …
Being cautious when giving explanations

These frequent storms

It may be
It is likely
It could be
It is possible
It is probable
It is almost certain

may be
could be
might be
are almost certainly

that

due to climate change.

these frequent storms

are a result of climate change.

84 | P a g e

A likely explanation
A possible explanation
A probable explanation

is that

these frequent storms

are a result of climate change.

Being cautious when explaining results (Refer to: Discussing Findings)
This inconsistency may be due to ...
It is possible that this result is due to …
This discrepancy could be attributed to ...
A possible explanation for this might be that ...
It seems possible that these results are due to ...
This rather contradictory result may be due to ...
The observed increase in X could be attributed to ...
There are several possible explanations for this result.
There are two likely causes for the differences between ...
A possible explanation for these results may be the lack of adequate ...
Since this difference has not been found elsewhere it is probably not due to ...
Advising cautious interpretation of results (Refer to: Discussing Findings)
We cannot exclude the possibility that …
These findings cannot be extrapolated to all …
These findings may be somewhat limited by …
The possible interference of X cannot be ruled out ...
These data must be interpreted with caution because ...
Several sources of error may have influenced these results.
These results therefore need to be interpreted with caution.
These results do not rule out the influence of other factors in …
This account must be approached with some caution because …
It is important to bear in mind the possible bias in these responses.
Although exclusion of X did not ..., these findings should be interpreted with caution.
However, with a small sample size, caution must be applied, as the findings might not be ...
The lack of a standardised measure makes it difficult to interpret these results with confidence.

It is possible that these results

may not apply to …
do not represent the …
do not accurately reflect …
have been confounded by ...
may have been skewed by …
might be biased because of …
could be a statistical anomaly.
might have been affected by …
were influenced by the lack of …
may underestimate the role of …
are not a true representation of …
underestimate the true prevalence of …
are an artefact of our experimental design.

85 | P a g e

Being cautious when discussing implications or recommendations
The findings of this study suggest that ...
Taken together, these results suggest that ...
The evidence from this study suggests that ...
These results would seem to suggest that the ...
These initial results are suggestive of a link between X and Y.
Initial observations suggest that there may be a link between ...
The findings from these studies suggest that X can have an effect on ...
One possible implication of this is that ...
Strategies to enhance X might involve ...
Other types of response could include: a) …, b) ...
There would therefore seem to be a definite need for ...
A reasonable approach to tackle this issue could be to ...
The data reported here appear to support the assumption that ...
Another possible area of future research would be to investigate why ...
Being cautious when writing about the future

This phenomenon

may
could
might
is likely to
will probably
will almost certainly

It is likely
It is possible
It is almost certain
There is a possibility
There is a small chance
There is a strong possibility

that

become more common in the future.

the situation will improve in the long term.

Devices for avoiding over-generalisation
In general, this requires ...
In general terms, this means ...
X is generally assumed to play a role in ...
Authors generally place an emphasis on …
X uses generally accepted principles to ...
Generally accepted methods for X include: ...
Studies which show no effect are not generally published.
Research articles generally consist of the following components:
Quantitative research is generally associated with the positivist paradigm.

86 | P a g e

Ozone is toxic to

most
almost all
some types of
many types of
the majority of
certain types of

living organisms.

Ozone levels

often
generally
frequently
sometimes
occasionally
nearly always

exceed WHO levels in many cities.

In general, the study found a tendency for …
There is a tendency for ozone to attack cells.
Ozone tends to attack cells and break down tissues.
Smith (2003) found a tendency for X to be associated with …
Smith et al. (1985) found a tendency for survey respondents to over-report ...
The tendency for extreme scores to move toward the mean score over time is known as ...

87 | P a g e

Being Critical
As an academic writer, you are expected to be critical of the sources that you use. This essentially
means questioning what you read and not necessarily agreeing with it just because the information
has been published. Being critical also means looking for reasons why we should not just accept
something as being correct or true. This can require you to identify problems with a writer’s
arguments or methods, or perhaps to refer to other people’s criticisms of these. Constructive
criticism goes beyond this by suggesting ways in which a piece of research or writing could be
improved ... being against is not enough. We also need to develop habits of constructive thinking. 2

Introductory phrases
Much of the criticism that X has attracted relates to …
Critics question the ability of the X theory to provide ...
Many aspects of this interpretation have been questioned.
Non-government agencies are also very critical of the new policies.
Smith’s meta-analysis has been subjected to considerable criticism.
A frequent criticism of much of the research on X concerns a general lack of …
These claims have been strongly contested in recent years by a number of writers.
The X theory has been vigorously challenged in recent years by a number of writers.
More recent arguments against X have been summarised by Smith and Jones (1982).
Many analysts now argue that the strategy of X has not been successful. Jones (2003), for example, …
Highlighting inadequacies of previous studies
Previous studies of X have not dealt with ...
Researchers have not treated X in much detail.
Such expositions are unsatisfactory because they ...
Most studies in the field of X have only focused on ...
Half of the studies evaluated failed to specify whether ...
The research to date has tended to focus on X rather than Y.
Most empirical studies of X have relied upon small sample sizes.
However, these studies used non-validated methods to measure ...
The vast majority of researchers have not considered the effects of …
The existing accounts fail to resolve the contradiction between X and Y.
Most studies of X have only been carried out in a small number of areas.
However, much of the research up to now has been descriptive in nature.
Small sample sizes have been a serious limitation for many earlier studies.
The lack of reliable instruments is particularly problematic for studies of …
None of the studies reviewed appear to have controlled for the effects of …
The generalisability of much published research on this issue is problematic.
This general lack of methodological rigour may put in question the results of …
However, few writers have been able to draw on any structured research into ...
There are obvious difficulties in accepting the reliability of self-report information.
However, these results were limited to X and are therefore not representative of ...
Most of the research on the association between X and Y is flawed methodologically.
The experimental data are rather controversial, and there is no general agreement about ...
Although extensive research has been carried out on X, no single study exists which adequately ...

2

De Bono, E. (2016) Parallel Thinking. London: Ebury Publishing (p.58).

88 | P a g e

Most studies of X

have only focused on ...
do not address the question of …
are unsatisfactory because they ...
fail to estimate economic rates of ...
have only investigated the impact of ...
have not included variables relating to …
are limited by weak designs and a failure to address …
have only been carried out in a small number of areas.

Identifying a weakness in a single study or paper
We are not told how …
The study suffers from …
The paper fails to specify …
No attempt has been made to …
The study makes no attempt to …
The article makes no reference to …
The report provides little evidence that …
A major problem with this experiment was that …
No attempt was made to quantify the association between X and Y.
The scope of this research was relatively narrow, being primarily concerned with …
Smith’s study of X is considered to be the most important, but it does suffer from the fact that ...
However, these results were based upon data from over 30 years ago and it is unclear whether …

it ignores …
it only considers …
it fails to provide …
it relies solely on …
it did not measure …
the sample is from …
it focuses solely on …
it investigates only one …
The study is limited in that
it does not take into account …
it did not assess frequency of …
the data collected come from …
it may be generalisable only to …
only 10 participants were included.
the definition of X did not encompass …
it does not clearly distinguish between …
it is a post-hoc analysis based on data gathered from …

89 | P a g e

The research

The paper

is limited by

its reliance on …
the absence of …
incomplete data for …
the possible effect of …
the relatively small sample.
the lack of information on ...
the fact that it only surveyed …
the lack of clarity surrounding …
the generalisation of the term …
the fact that it only includes …
the fact that it is retrospective.
the fact that it was restricted to …
the fact that there was no collection of …
the fact that it is cross-sectional in design.
the fact that it relies on a questionnaire data to …
the fact that the participants self-reported their …
the fact that it only focussed on the measurement of …
the fact that it does not account for variables such as …

fails to
does not
makes no attempt to

specify …
quantify …
separate …
compare …
account for …
suggest why …
analyse how …
ascertain whether …
distinguish between …
explain the meaning of …
provide information on …
address the question of …
assess the effectiveness of …
use a standardised method of …
give sufficient consideration to …
consider the long term impact of …
offer an adequate explanation for …
engage with current discourses on ...
determine the underlying causes of …
systematically review all the relevant literature.

90 | P a g e

selection bias.
limited sample size.
poor external validity.
multiple design flaws.
an overemphasis on …
serious statistical flaws.
insufficient sample size.
inconsistent definitions.
poorly developed theory.
historical and cultural bias.
methodological limitations.
serious sampling problems.
a lack of clarity in defining …
inadequate research design.
considerable design limitations.
the use of poorly matched controls.
a paucity of standardised measures.
notable methodological weaknesses.
fundamental flaws in research design.
lack of a strong theoretical framework.
certain ambiguities at the conceptual level.
an over-reliance on self-report methodology.
a restricted range of methodological approaches.
shortcomings in the methods used to select cases.
a lack of well-grounded theoretical considerations.
several conceptual and methodological weaknesses.

(However,)

the study
the paper

However,

the analysis is largely superficial, based solely on …
the sample size in this study was relatively small …
this research has a number of methodological weaknesses.
the degree of X experienced by patients was not measured.
a major weakness with this study is that there was no control for X.
a major problem with this experiment was that no control for X was used.
the main methodological weakness is that X was only monitored for 12 months.
one of the problems with the instrument the researchers used to measure X was ...

suffers from

No attempt has been made to

estimate the risk of …
determine whether …
investigate whether …
quantify the degree of …
model the dynamics of ...

91 | P a g e

Introducing problems and limitations with a theory or argument
The main weakness with this theory is that …
The key problem with this explanation is that ...
However, this theory does not fully explain why …
One criticism of much of the literature on X is that ...
Critics question the ability of the X theory to provide ...
However, there is an inconsistency with this argument.
There are limits to how far the concept of X can be taken.
A serious weakness with this argument, however, is that ...
However, such explanations tend to overlook the fact that ...
One question that needs to be asked, however, is whether ...
One of the main difficulties with this line of reasoning is that …
Smith’s argument relies too heavily on qualitative analysis of ...
Smith’s interpretation overlooks much of the historical research ...
Many writers have challenged Smith’s claim on the grounds that ...
The X theory has been criticised for being based on weak evidence.
Smith’s analysis does not take account of X, nor does he examine ...
The existing accounts fail to resolve the contradiction between X and Y.
It seems that Jones’ understanding of the X framework is questionable.
Aspects of X's theory have been criticised at a number of different levels.
One of the limitations with this explanation is that it does not explain why… .
A final criticism of the theory of X is that it struggles to explain some aspects of …
The X theory has been vigorously challenged in recent years by a number of writers.
A second criticism of the hypothesis draws upon research evidence which suggests …
The X hypothesis has been questioned on the basis of some conflicting experimental findings.
Around the 1970s the consensus was that …, but during the 1980s several researchers challenged
this view.

The theory is unable to

predict …
explain why …
fully account for …
adequately explain the …
explain what happens when …
make any useful prediction about …
explain the differences observed when …
provide a comprehensive explanation for …

The current model of X suffers from

poor scalability.
unnecessary complexity.
lack of empirical support.
several methodological problems.
certain weaknesses that hinder its ability to …

92 | P a g e

Introducing problems and limitations with a method or practice
The limitation of this approach is that …
A major problem with the X method is that ...
One major drawback of this approach is that ...
A criticism of this experimental design is that …
The main limitation of this technique, however, is ...
Selection bias is another potential concern because ...
Perhaps the most serious disadvantage of this method is that ...
Non-government agencies are also very critical of the new policies.
All the studies reviewed so far, however, suffer from the fact that ...
Critics of laboratory-based experiments contend that such studies …
The disadvantage of this method is its reliance on the availability of …
Another problem with this approach is that it fails to take X into account.
Difficulties arise, however, when an attempt is made to implement the policy.
There are obvious difficulties in accepting the reliability of self-report information.
In recent years, however, this approach has been challenged by the work of a number of …
There are certain problems with the use of focus groups. One of these is that there is less ...
Critics have also argued that not only do surveys provide an inaccurate measure of X, but the ...
Nevertheless, the strategy has not escaped criticism from governments, agencies and academics.
Many analysts now argue that the strategy of X has not been successful. Jones (2003), for example,
argues that …

However, all the previously mentioned methods suffer from (some) serious

However,

drawbacks.
limitations.
weaknesses.
shortcomings.
disadvantages.

this method of analysis has a number of limitations.
this method does involve potential measurement error.
approaches of this kind carry with them various well-known limitations.
questions have been raised about the reliability of self-report methods.

Selection bias is another (potential)

risk.
concern.
problem.
limitation.
weakness.
threat to internal validity.
limitation of systematic reviews.

93 | P a g e

Criticising an author or an author’s work
Smith seems to ignore …
Smith fails to grasp that …
Smith’s interpretation overlooks …
Smith overlooks a number of important sources.
Smith fails to acknowledge the social aspects of …
However, Smith’s accounts are clearly ideological.
Although Smith has argued that … she neglects to note that …
Many aspects of Smith’s interpretation have been questioned.
Smith’s meta-analysis has been subjected to considerable criticism.
Smith’s arguments for X have been forcefully questioned in recent years.
The most important of these criticisms is that Smith failed to note that ...
The most convincing rebuttal of Smith’s interpretations has been written by …
Smith’s decision to prioritise X as the primary cause of Y has been widely attacked.
The scope of this research was relatively narrow, being primarily concerned with …
Smith’s study of X is considered to be the most important, but it does suffer from the fact that ...

Smith
The book
The paper

Smith’s paper

fails to
does not
makes no attempt to

is

limited
deficient
problematic

specify …
quantify …
compare …
separate …
account for …
suggest why …
analyse how …
ascertain whether …
distinguish between …
explain the meaning of …
provide information on …
address the question of …
assess the effectiveness of …
use a standardised method of …
give sufficient consideration to …
consider the long term impact of …
offer an adequate explanation for …
engage with current discourses on ...
determine the underlying causes of …
systematically review all the relevant literature.

in three areas.
with regard to …
in two respects.
in that it ignores …
in the sense that …
for several reasons.

94 | P a g e

(However,)

the paper does not address …
Smith fails to fully define what ...
a major criticism of Smith’s work is that ...
Smith fails to acknowledge the significance of ...
the author overlooks the fact that X contributes to Y.
what Smith fails to do is to draw a distinction between ...
Smith’s paper would appear to be over ambitious in its claims.
the main weakness of the study is the failure to address how ...
another weakness is that we are given no explanation of how ...
the research does not take into account pre-existing ... such as ...
the study fails to consider the differing categories of damage that ...
the author offers no explanation for the distinction between X and Y.
Smith makes no attempt to differentiate between different types of X.

Smith
The book
The paper

the impact of …
the reasons for …
the evidence for …
the contexts in which …
several key aspects of …
the variable nature of …
other explanations for …
the complex nature of …
the potential impact of …
the social dimension of …
the dynamic aspects of ...
the underlying causes of …
demographic factors that ...
the ethical implications of ...
the important role played by …
the broader implications of how ...
the unique complexities faced by ...
the contextual factors that influence …

overlooks
fails to acknowledge
makes no attempt to consider

95 | P a g e

Offering constructive suggestions
The study would have been more interesting if it had included …
These studies would have been more useful if they had focused on …
The study would have been more relevant if the researchers had asked …
The questionnaire would have been more useful if it had asked participants about …
The research would have been more relevant if a wider range of X had been explored.

The study
The findings
Smith’s paper
Her conclusions

would have been
might have been

more
much more
far more

useful
original
relevant
convincing
interesting
persuasive

if he/she had
if the author had

used ...
adopted…
included …
provided …
considered …

A more comprehensive study would include all the groups of ...
A better study would examine a large, randomly selected sample of societies with ...
A much more systematic approach would identify how X interacts with other variables that ...

Evaluating work positively
This article provides a valuable insight into …
Overall, X’s study is a powerful explanation of …
Smith’s research is valuable for our understanding of …
The first major fieldwork project that was started in X was …
In his seminal text, XXXXX, Smith devoted some attention to …
One of the most influential accounts of X comes from Smith (1986) …
Smith’s synthesis remains one of the most comprehensive studies of …
Smith makes an interesting contribution with regard to the impact of …
In a well-designed and robust study, Smith (1998) examined data from …
A good summary of the classification of X has been provided in the work of …
The pioneering work of Smith remains crucial to our wider understanding of …
The most comprehensive study of X during this period has been undertaken by …
Smith, in his comprehensive two-volume biography of X, devoted a substantial section to …
Smith’s study is of great significance as it marks the first attempt to assess the broader impact of …
A more substantial approach to the longer-term significance of X can be found in Smith’s recent
article in …

96 | P a g e

Smith (1990)

In his
In her
In this

offers
provides
presents

useful
timely
seminal
detailed
thorough
excellent
influential
important
innovative
pioneering
impressive
wide-ranging
comprehensive
ground-breaking

seminal
landmark
influential
thoughtful
innovative
Smith’s
pioneering
fascinating
informative
wide-ranging
comprehensive
ground-breaking

a useful
a detailed
an original
an insightful
an extensive
an interesting
a contemporary
a comprehensive

analysis of …

found ...
concluded that ...
was able to show ...
study (of X),
survey (of X),
analysis (of X),
examination (of X),
investigation (into X),

study
analysis

Smith (2012)
Jones (2014)
argues that …
makes the case for …
provides a valuable ...

provides a valuable insight into …
makes a valuable contribution with regard to …
remains crucial to our wider understanding of …
is of great significance as it marks the first attempt to …

97 | P a g e

Introducing the critical responses of individual writers
Smith (2014) disputes this account of …
Jones (2003) has also questioned why ...
However, Jones (2015) points out that ...
The author challenges the widely held view that ...
Smith (1999) takes issue with the contention that …
The idea that … was first challenged by Smith (1992).
Smith is critical of the tendency to compartmentalise X.
However, Smith (1967) questioned this hypothesis and …
Smith (1980) broke with tradition by raising the question of …
Jones (2003) has challenged some of Smith’s conclusions, arguing that ...
Another major criticism of Smith’s study, made by Jones (2003), is that …
Jones (2003) is critical of the conclusions that Smith draws from his findings.
An alternative interpretation of the origins of X can be found in Smith (1976).
Jones (2003) is probably the best-known critic of the X theory. He argues that ...
In her discussion of X, Smith further criticises the ways in which some authors …
Smith’s decision to reject the classical explanation of X merits some discussion …
In a recent article in Academic Journal, Smith (2014) questions the extent to which …
The latter point has been devastatingly critiqued by Jones (2003), who argues that ...
A recently published article by Smith et al. (2011) casts doubt on Jones’ assumption that …
Other authors (see Harbison, 2003; Kaplan, 2004) question the usefulness of such an approach.
Smith criticised Jones for his overly restrictive and selective definition of X which was limited to …
Smith’s analysis has been criticised by a number of writers. Jones (1993), for example, points out ...

Smith

criticises …
questions …
challenges …
is critical of …
casts doubt on …
points out that …
takes issue with…
raises a number of questions about …

Introducing a section of text which has a critical purpose

The section below
The section that follows

critically

assesses
examines

the idea that …
the view that …
the quality of …
the claim that …
the concept of …
the role played by …
the argument that …
Smith’s analysis of …
the effectiveness of …
the current approaches to …

98 | P a g e

Classifying and Listing
When we classify things, we group and name them on the basis of something that they have in
common. By doing this we can understand certain qualities and features which they share as a class.
Classifying is also a way of understanding differences between things. In writing, classifying is often
used as a way of introducing a reader to a new topic. Along with writing definitions, the function of
classification may be used in the early part of an essay, or longer piece of writing. We list things
when we want to treat and present a series of items or different pieces of information
systematically. The order of a list may indicate ranked importance.

Classifying a topic
X can be classified into Xi and Xii.
X can be categorised into Xi, Xii and Xiii.
Several taxonomies for X have been developed …
Different methods have been proposed to classify …
X may be divided into several groups: a) …, b) …, c) …
Generally, X provides two types of information: Xi and Xii.
It has become commonplace to distinguish ‘Xi’ from ‘Xii’ forms of X.
X is generally classified into two types: Xi, also known as ..., and Xii or ...
There are two basic approaches currently being adopted in research into X. One is …
The theory distinguishes two different types of X, i.e. social X and semantic X (Smith, 2013).
The works of Smith fall under three headings: (1) dialogues and ..., (2) collections of facts, and (3) …

X may be divided into

three main

X may be classified

in terms of
according to
depending on
on the basis of

classes.
categories.
sub-groups.

Y

into Xi and Xii.

Specific classifications
Smith (2015) draws a distinction between …
Smith (2006) categorised X as being a) …, b) …, or c) …
Smith’s (1980) typology of X is the one most widely used.
Jones (1987) distinguishes between systems that are a) …, b) …, or c) …
A third method, proposed by Smith (2010), bases the classification on a …
To better understand X, Smith (2011) classified Y into three distinct types using ...
In 1960, Smith developed a system of classification that can be used by clinicians to …
In Jones’s system, individuals are classified as belonging to upper or lower categories of ...
For Smith, X is of four kinds: (1) X which ...; (2) X which ...; (3) X which ...; and (4) X which ...
Smith’s Taxonomy is a classification system used to define and distinguish different levels of …
Smith and Jones (2003) argue that there are two broad categories of Y, which are: a) ..., and b) ...
99 | P a g e

In Smith’s scheme,
In the traditional system,

Xs

are
were

grouped
classified

in terms of ...
on the basis of ...
according to whether ...

Smith (1996) describes

four basic kinds of validity:

logical, content, criterion, and construct.

Smith and Jones (1966)

divided
grouped
classified

into two broad types: Xis and Xiis.

Smith’s taxonomy is

Xs

used to classify …
a hierarchical model for classifying ...
a well-known description of levels of …
a classification of learning objectives ....
a widely acknowledged classification system useful for ....
a multi-tiered model of classifying X according to different levels of …

Commenting on a system of classification: positive or neutral

This system of classification

includes ...
allows for ...
is widely used in …
helps distinguish ...
is useful because ...
is very simple and …
provides a basis for ...
has clinical relevance.
was agreed upon after ...
can vary depending on ...
is still respected and used.
is particularly well suited for …
has withstood the test of time.
is a convenient way to describe …
has been broadened to include ...
was developed for the purpose of ...
is more scientific since it is based on …

100 | P a g e

Commenting on a system of classification: negative

This system of classification

is misleading.
is now out of date.
can be problematic.
is in need of revision.
poses a problem for ...
is not universally used.
is somewhat arbitrary.
is simplistic and arbitrary.
is inherently problematic.
has relevance only within …
has some clear deficiencies.
has now been largely abandoned.
has limited utility with respect to ...
is obsolete and tends to be avoided.

Introducing lists
This topic can best be treated under three headings: X, Y, and Z.
The key aspects of management can be listed as follows: X, Y, and Z.
There are two types of effect which result when a patient undergoes X. These are ...
The Three Voices for Mass is divided into six sections. These are: the Kyrie, Gloria, ....
There are three reasons why the English language has become so dominant. These are:
Appetitive stimuli have three separable basic functions. Firstly, they ... Secondly, they ...
This section has been included for several reasons: it is ...; it illustrates ...; and it describes...
The disadvantages of the new approach can be discussed under three headings, which are: ...
During his tour of Britain, he visited the following industrial centres: Manchester, Leeds, and ... The
Mass for Four Voices consists of five movements, which are: the Kyrie, Gloria, Credo, Sanctus, and
Agnus Dei.

Referring to other people’s lists
Smith and Jones (1991) list X, Y and Z as the major causes of failure.
Smith (2003) lists the main features of X as follows: it is A; it is B; and it has C.
Smith (2003) argues that there are two broad categories of Y, which are: a) ... and b) ...
Smith (2003) suggests three conditions for X . Firstly, X should be ... Secondly, it needs to be...
For Aristotle, motion is of four kinds: (1) motion which ...; (2) motion which ...; (3) motion which ...;
and (4) motion which...

101 | P a g e

Comparing and Contrasting
By understanding similarities and differences between two things, we can increase our
understanding and learn more about both. This usually involves a process of analysis, in which we
compare the specific parts as well as the whole. Comparison may also be a preliminary stage of
evaluation. For example, by comparing specific aspects of A and B, we can decide which is more
useful or valuable. Many paragraphs whose function is to compare or contrast will begin with an
introductory sentence expressed in general terms.

Introducing differences
X differs from Y in terms of …
X is different from Y in a number of respects.
X differs from Y in a number of important ways.
There are a number of important differences between X and Y.
Areas where significant differences have been found include X and Y.
In contrast to earlier findings, however, no evidence of X was detected.
A descriptive case study differs from an exploratory study in that it uses …
Smith (2013) found dramatic differences in the rate of decline of X between Y and Z.
Women and men differ not only in physical attributes but also in the way in which they ...
The nervous systems of Xs are significantly different from those of Ys in several key respects.

Smith (2003)

One of the most

found
observed

minor
major
distinct
notable
only slight
significant
considerable

crucial
salient
marked
striking
notable
obvious
important
significant
prominent
noticeable
interesting
fundamental
widely reported

differences

differences between X and Y.

between X and Y

is …

102 | P a g e

Introducing similarities
X is comparable to Y in terms of …
Both X and Y share a number of key features.
There are a number of similarities between X and Y.
The effects of X on human health are similar to those of Y.
Both X and Y generally take place in a ‘safe environment’.
These results are similar to those reported by (Smith et al. 1999).
This definition is similar to that found in (Smith, 2001) who writes:
The return rate is similar to that of comparable studies (e.g. Smith et al. 1999).
The approach used in this investigation is similar to that used by other researchers.
Studies have compared Xs in humans and animals and found that they are essentially identical.

The mode of processing used
by the right brain

is similar to that
is comparable to that
is comparable in complexity to that

used by the left brain.

Comparing within one sentence using subordinating adverbs
Oral societies tend to be more
concerned with the present

While
Whereas

while
whereas

literate societies have a very definite awareness
of the past.

oral societies tend to be more concerned with the present,

literate societies have
a very definite
awareness of the past.

Comparing within one sentence using prepositional phrases
In contrast to
Compared with

people in oral cultures,

people in literate cultures organise their lives around
clocks and calendars.

Comparing within one sentence using contrastive verbs

Smith’s interpretation

differs from that
contrasts with that
is different from that

of Jones (2004) who argues that ...

103 | P a g e

Comparing within one sentence using comparative forms
In the trial, women made more/fewer errors than men.
Women tend to have greater/less verbal fluency than men.
Women are more/less likely than men to perform well in tests.
Women are more/less accurate in tests of target-directed motor skills.
Women tend to perform better/worse than men on tests of perceptual speed.
Women are faster/slower than men at certain precision manual tasks, such as ...
Women are more/less likely to suffer from X when the front part of the brain is damaged.
The part of the brain connecting the two hemispheres may be more/less extensive in women.

Women

may be more/less susceptible to X
are more/less accurate in tests of X
are more/less likely to perform well
make more/fewer errors in tests of X
tend to have greater/less verbal fluency
tend to perform better/worse in tests of X

than men.

Indicating difference across two sentences
It is very difficult to get away
from calendar time in literate
societies.

By contrast,
In contrast,
On the other hand,

many people in oral communities have little
idea of the calendar year of their birth.

According to some studies, X is represented
as … (Smith, 2012; Jones, 2014).

Others propose … (Jones, 2014; Brown, 2015)

Smith (2013) found that X accounted for over
30% of Y.

Other researchers, however, who have looked at
X, have found ... Jones (2010), for example, ...

Jones (2002) reports that ...

However, Smith’s (2010) study of Y found no ...

104 | P a g e

Indicating similarity across two sentences
Similarly,
Young children learning their first
language need simplified input.

Likewise,

low level adult learners need graded
input supplied in most cases by a teacher.

In the same way,

Smith (2014) argues that ...
Jones (2015) sees X as ...

Similarly,

Brown (2015) asserts that ...

Likewise,

White (2016) holds the view that ...

In the same vein,

Green (2018) in his book XXXXX notes ...

105 | P a g e

Defining Terms
In academic work, students are often expected to give definitions of key words and phrases in order
to demonstrate to their tutors that they understand these terms well. Academic writers generally,
however, define terms so that their readers understand exactly what is meant when certain key
terms are used. When important words are not clearly understood misinterpretation may result. In
fact, many disagreements (academic, legal, diplomatic, personal) arise because of different
interpretations of the same term. In academic teaching and writing, lecturers and their students
often have to explore these differing interpretations before moving on to examine a topic in depth.

Introductory phrases
The term ‘X’ was first used by …
The term ‘X’ can be traced back to …
Previous studies mostly defined X as …
The term ‘X’ was introduced by Smith in her …
Historically, the term ‘X’ has been used to describe …
It is necessary here to clarify exactly what is meant by ...
This shows a need to be explicit about exactly what is meant by the word ‘X’.
Simple three-part definitions
A university is

an institution

where knowledge is produced and passed on to others.

Social Economics
may be defined as

the branch of
economics

[which is] concerned with the measurement, causes,
and consequences of social problems.

Research may be
defined as

a systematic
process

which consists of three elements or components: (1) a
question, problem, or hypothesis, (2) data, and (3)
analysis and interpretation of data.

Education is

a form of
learning

in which the knowledge, skills, or values of a group of
people are transferred from one generation to the next.

A scientific theory
can be defined as

an explanation of
some aspect of
the natural world

[which has been] confirmed by observation or
experiment.

Braille is

a system

of touch reading and writing for blind people in which
raised dots on paper represent letters.

Science is

the systematic
study of

the structure and behaviour of the physical and natural
world through observation and experiment.

106 | P a g e

General meanings or application of meanings
X can broadly be defined as …
X can be loosely described as …
X can be defined as ... It encompasses ...
In the literature, the term tends to be used to refer to ...
In broad terms, X can be defined as any stimulus that is ...
Whereas X refers to the operations of ..., Y refers to the ...
The broad use of the term ‘X’ is sometimes equated with ...
The term ‘disease’ refers to a biological event characterised by ...
Defined as …, X is now considered a worldwide problem and is associated with ...

The term ‘X’

X is a/an

refers to ...
encompasses A), B), and C).
has come to be used to refer to ...
is generally understood to mean ...
has been used to refer to situations in which ...
carries certain connotations in some types of …
is a relatively new name for a Y, commonly referred to as ...

broad
generic
common
umbrella
non-specific
relatively new

term

that refers to …
used to describe …
which encompasses …
covering a wide range of …

Indicating varying definitions
The definition of X has evolved.
There are multiple definitions of X.
Several definitions of X have been proposed.
In the field of X, various definitions of X are found.
The term ‘X’ embodies a multitude of concepts which ...
This term has two overlapping, even slightly confusing meanings.
Widely varying definitions of X have emerged (Smith and Jones, 1999).
Despite its common usage, X is used in different disciplines to mean different things.
Since the definition of X varies among researchers, it is important to clarify how the term is used in …

The meaning of this term

has evolved.
has varied over time.
has been extended to refer to …
has been broadened in recent years.
has not been consistent throughout …
has changed somewhat from its original definition, particularly in …
107 | P a g e

Indicating difficulties in defining a term
‘X’ is a contested term.
‘X’ is a rather nebulous term …
X is challenging to define because …
A precise definition of X has proved elusive.
A generally accepted definition of X is lacking.
Unfortunately, ‘X’ remains a poorly defined term.
There is no agreed definition on what constitutes …
There is little consensus about what X actually means.
There is a degree of uncertainty around the terminology in ...
These terms are often used interchangeably and without precision.
Numerous terms are used to describe X, the most common of which are ….
The definition of X varies in the literature and there is terminological confusion.
Smith (2001) identified four abilities that might be subsumed under the term ‘X’: a) ...
‘X’ is a term frequently used in the literature, but to date there is no consensus about ...
X is a commonly used notion in psychology and yet it is a concept difficult to define precisely.
Although differences of opinion still exist, there appears to be some agreement that X refers to ...

The meaning of this term

has been disputed.
has been debated ever since …
has proved to be notoriously hard to define.
has been an object of major disagreement in …
has been a matter of ongoing discussion among …

Referring to people’s definitions: author prominent
For Smith (2001), X means ...
Smith (2001) uses the term ‘X’ to refer to ...
Smith (1954) was apparently the first to use the term ...
This definition is close to that of Smith (2012) who defines X as …
In 1987, psychologist John Smith popularized the term ‘X’ to describe ...
According to a definition provided by Smith (2001:23), X is ‘the maximally ...
Smith, has shown that, as late as 1920, Jones was using the term ‘X’ to refer to particular ...
One of the first people to define nursing was Florence Nightingale (1860), who wrote: ‘... ...’
Chomsky writes that a grammar is a ‘device of some sort for producing the ....’ (1957, p.11).
Aristotle defines the imagination as ‘the movement which results upon an actual sensation.’
Smith et al. (2002) have provided a new definition of health: ‘health is a state of being with …
Referring to people’s definitions: author non-prominent
X is defined by Smith (2003: 119) as ‘... ...’
The term ‘X’ was introduced by Smith in her …
The term ‘X’ is used by Smith (2001) to refer to ...
The terms ‘X’ and ‘Y’ were first used by Smith (1954).
X is, for Smith (2012), the situation which occurs when …
A further definition is given by Smith (1982) who describes ...
A similar definition has been proposed by Smith et al. (1998), who have argued that …
The term ‘X’ is used by Aristotle in four overlapping senses. First, it is the underlying ...
X is the degree to which an assessment process or device measures … (Smith et al., 1986).
108 | P a g e

Commenting on a definition

This definition

includes ...
allows for ...
highlights the ...
helps distinguish ...
takes into account …
poses a problem for ...
will continue to evolve.
can vary depending on ...
was agreed upon after ...
is intended primarily for …
has largely fallen out of use.
fails to capture the idea of …
raises some important issues.
has been broadened to include ...
captures a number of important features of …

The following definition is

What is

useful
striking
notable
troubling
appealing
significant
important
distinctive
interesting
remarkable

intended to ...
modelled on …
too simplistic.
useful because ...
problematic as ...
rather imprecise.
inadequate since ...
does not recognise …
in need of revision since ...
important for what it excludes.
the most precise produced so far.

about this definition is

that it offers …
that it stresses …
the emphasis on …
that it recognises …
that it is based on …
that it clearly links …
that it acknowledges …
that it encompasses all …
that it takes for granted …
what it does not include …

109 | P a g e

Specifying terms that are used in an essay or thesis
The term ‘X’ is used here to refer to …
In the present study, X is defined as ...
The term ‘X’ will be used solely when referring to ...
This study utilises the concept of X first proposed by …
In this essay, the term ‘X’ will be used in its broadest sense to refer to all ...
In this paper, the term that will be used to describe this phenomenon is ‘X’.
In this dissertation, the terms ‘X’ and ‘Y’ are used interchangeably to mean ...
Throughout this thesis, the term ‘X’ is used to refer to informal systems as well as ...
While a variety of definitions of the term ‘X’ have been suggested, this paper will use the definition
first suggested by Smith (1968) who saw it as ...

110 | P a g e

Describing Trends and Projections
A trend is the general direction in which something is developing or changing over time. A
projection is a prediction of future change. Trends and projections are usually illustrated using line
graphs in which the horizontal axis represents time. Some of the language commonly used for
writing about trends and projections is given below.

Describing trends

The graph shows that there has been a
Figure 2 reveals that there has been a

slight
steep
sharp
steady
gradual
marked

fall
rise
drop
decline
increase
decrease

in the number of ….

Highlighting a trend in a table or chart

What is striking
What stands out
What is interesting
What can be clearly seen

in this

table
chart
figure

is the growth of …
is the high rate of …
is the variability of …
is the dominance of …
is the rapid decrease in …
is the steady decline of …
is the general pattern of …
is the dramatic decline in …
is the continual growth of …
is the difference between …
is the phenomenal growth of …

Describing high and low points in figures
Production of X peaked in 1985.
X rose to a high point and peaked in …
The peak age for committing a crime is 18.
The number of Xs reached a peak during …
Production of X reached a low point in 2008.
The rate fell to a low point of $5.00 at the end of the year.

111 | P a g e

Projecting trends

The rate of X
The amount of X
The number of Ys

is likely to
will probably
is expected to
is projected to
is anticipated to

fall
reach …
rise to …
increase
level off
decline by …
drop sharply
remain steady
be as high as …
decline steadily
continue decreasing
grow by more than …

after 2030.

112 | P a g e

Describing Quantities
The language for writing about quantities can be a complex area for non-native speakers because
there are many combinations of short grammar words, such as prepositions and pronouns, and
these can easily be confused. Many of the phrases given below also contain approximators such as:
nearly, approximately, over half, less than, just over.

Describing fractions and percentages
Over half of those surveyed indicated that ...
Nearly half of the respondents (48%) agreed that ...
Almost two-thirds of the participants (64%) said that ....
Approximately half of those surveyed did not comment on ...
Of the 270 participants, nearly one-third did not agree about …
Less than a third of those who responded (32%) indicated that ...
The number of cases in the United Kingdom fell by nearly two-fifths.
Of the 148 participants who completed the questionnaire, just over half indicated that ...
The incidence of X has been estimated as 10% …
70% of those who were interviewed indicated that ...
Since 1981, England has experienced an 89% increase in crime.
The response rate was 60% at six months and 56% at 12 months.
Returned surveys from 34 radiologists yielded a 34% response rate.
He also noted that fewer than 10% of the articles included in his study cited ...
With each year of advancing age, the probability of having X increased by 9.6% (p = 0.006) is ...
The mean income of the bottom 20 percent of U.S. families declined from $10,716 in 1970 to ...

Just over
Well over
More than
Many more than

half
a third
a quarter
of those surveyed
of the respondents
of those who responded

Almost
Around
Approximately
Just under
Less than
Fewer than
Well under

agreed that …
indicated that …
did not respond to this question.

40%
50%
80%

113 | P a g e

Describing averages
The average of 12 observations in the X, Y and Z is 19.2 mgs/m ...
Roman slaves probably had a lower than average life expectancy.
This figure can be seen as the average life expectancy at various ages.
The proposed model suggests a steep decline in mean life expectancy ...
The mean age of Xs with coronary atherosclerosis was 48.3 ± 6.3 years.
The mean estimated age at death was 38.1 ± 12.0 years (ranging from 10 to 60+ years)
The mean income of the bottom 20 percent of U.S. families declined from $10,716 in 1970 to ...
The mean score for the two trials was subjected to multivariate analysis of variance to determine ...

Roman slaves probably had a

much lower than average life expectancy.

The Roman nobility probably had a

much higher than average life expectancy.

Describing ranges
The respondents had practised X for an average of 15 years (range 6 to 35 years).
The participants were aged 19 to 25 and were from both rural and urban backgrounds.
They calculated ranges of journal use from 10.7%–36.4% for the humanities, 25%–57% for ...
The evidence shows that life expectancy from birth lies in the range of twenty to thirty years.
The mean income of the bottom 20 percent of U.S. families declined from $10,716 to $9,833.
Rates of decline ranged from 2.71– 0.08 cm per day (Table 11) with a mean of 0.97 cm per day.
Most estimates of X range from 200.000 to 700.000 and, in some cases, up to a million or more.
At between 575 and 590 metres depth, the sea floor is extremely flat, with an average slope of ...

Describing ratios and proportions
X has the highest proportion of….
X had the lowest proportion of Y at only 14 per cent.
The annual birth rate dropped from 44.4 to 38.6 per 1000 per annum.
The proportion of live births outside marriage reached one in ten in 1945.
The proportion of the population attending emergency departments was 65% higher in X than ...

114 | P a g e

Explaining Causality
A great deal of academic work involves understanding and suggesting solutions to problems. At
postgraduate level, particularly in applied fields, students search out problems to study. In fact, one
could say that problems are the raw material for a significant proportion of academic activity.
However, solutions cannot be suggested unless the problem is fully analysed, and this involves a
thorough understanding of the causes. Some of the language that you may find useful for explaining
causes and effects is listed below.
Verbs indicating causality

Lack of iron in the diet

may cause
can lead to
can result in
can give rise to

tiredness and fatigue.

Scurvy is a disease

caused by
resulting from
stemming from

lack of vitamin C.

Much of the instability in X

is driven by
stems from
is caused by
can be attributed to

the economic effects of the war.

Nouns indicating causality
One reason why Xs have declined is that ...
A consequence of vitamin A deficiency is blindness.
X can have profound health consequences for older people.
The most likely causes of X are poor diet and lack of exercise.
The causes of X have been the subject of intense debate within ...

Prepositional phrases indicating causality

Around 200,000 people per year suffer from X

owing to
because of
as a result of
as a consequence of

poor diet.

115 | P a g e

Sentence connectors indicating causality

If undernourished children do survive to
become adults, they have decreased
learning ability.

Therefore,
Consequently,
Because of this,
As a result (of this),

when they grow up, it will
probably be difficult for them
to find work.

Adverbial elements indicating causality
Malnutrition leads to illness and a reduced ability to
work in adulthood,
The warm air rises above the surface of the sea,

thus
thereby

perpetuating the poverty cycle.

creating an area of low pressure.

Nouns indicating contributing agency
X is a key factor in …
X is a major influence on …
X has a positive effect on …
X has a significant impact on …
X is an important determinant of …
X and Y are important driving factors of Z.
X is generally seen as a factor strongly related to Y.
X is a significant contributory factor to the development of …
This work has revealed several factors that are responsible for …
The study found that loneliness has twice the impact on early death as obesity does.

X is a/an

risk
common
dominant
predictive
important
significant
underlying
contributing
confounding
complicating

factor

in …
for …

116 | P a g e

Verbs indicating contributing agency
X has contributed to the decline in …
It is now understood that X plays an important role in …
A number of factors play a role in determining the effects of …
The mixing of X and Y exerts a powerful effect upon Z through...
Recent research has revealed that X has a detrimental effect on …
A number of factors are known to affect the volume and type of …
All these factors can impact on the efficiency and effectiveness of …
X is only one of many factors that help to determine the quality of …

Several factors are known to

X

affect X.
shape X.
predict X.
increase X.
influence X.
determine X.
encourage X.
affect the rate of …
be associated with …
increase the risk of …
play a role in determining X.
be partially responsible for …

Contributory agency

Preventative agency

aids
fuels
assists
boosts
fosters
enables
amplifies
facilitates
promotes
intensifies
speeds up
stimulates
aggravates
accelerates
encourages
exacerbates

blocks
deters
delays
shrinks
impairs
inhibits
hinders
reduces
controls
weakens
impedes
prevents
obstructs
decreases
moderates
counteracts

Y

X

Y

117 | P a g e

Verbs describing activity to understand causes

Few studies
Many studies
Previous studies

have

analysed
explored
described
examined
addressed
investigated

the causes of X.

Expressing a causal relationship tentatively
X may have been an important factor in ...
X may have contributed to the increase in ...
X may have been caused by an increase in ...
X may have played a vital role in bringing about ...
X appears to be linked to Y.
In the literature, X has been associated with Y.
A high consumption of X could be associated with infertility.
X in many cases may be associated with certain bacterial infections.
There is some evidence that X may affect Y.
It is not yet clear whether X is made worse by Y.
This suggests a weak link may exist between X and Y.
The use of X may be linked to behaviour problems in ...
The human papilloma virus is linked to many cancers in ….
The findings indicate that regular exercise could improve cognitive function in people at risk of ...

Speculating on causes in the past

X may have

caused Y.
given rise to Y.
brought about Y.
been an important factor in Y.
contributed to the increase in Y.
been caused by an increase in Y.
played a vital role in bringing about Y.

X may have been

due to Y.
caused by Y.
attributed to Y.
brought about by Y.
118 | P a g e

Giving Examples as Support
Writers may give specific examples as evidence to support their general claims or arguments.
Examples can also be used to help the reader or listener understand unfamiliar or difficult concepts,
and they tend to be easier to remember. For this reason, they are often used in teaching. Finally,
students may be required to give examples in their work to demonstrate that they have understood
a complex problem or concept. When statements and arguments are supported with examples, it
is helpful to the reader when explicit language is used to signal this.

Giving examples as the main information in a sentence
A classic
A useful
A notable
A prominent
An important
A well-known

example of X is ....

For example, the word ‘doctor’ used to mean a ‘learned man’.
For example, Smith and Jones (2004) conducted a series of semi-structured interviews in ...
Young people begin smoking for a variety of reasons. They may, for example, be influenced by ....
Another example of what is meant by X is ...
This is exemplified in the work undertaken by ...
To give a well-known example for the sake of clarity, …
This distinction is further exemplified in studies using ...
An example of this is the study carried out by Smith (2004) in which ...
The effectiveness of the X technique has been exemplified in a report by Smith et al. (2010).
This is evident in the case of ...
This is certainly true in the case of ...
The case of X illustrates the nature of …
The evidence of X can be clearly seen in the case of ...
In a similar case in America, Smith (1992) identified ...
This can be seen in the case of the two London physics laboratories which ...
X is a good illustration of ...
X illustrates this point clearly.
This can be illustrated briefly by ...
The most dramatic illustration of this is …
By way of illustration, Smith (2003) shows how the data for ...
These experiments illustrate that X and Y have distinct functions in ...

119 | P a g e

Giving examples as additional information in a sentence
Young people begin smoking for a variety of reasons, such as pressure from peers or …
The prices of resources, such as copper, iron ore, and aluminium, have declined over …
Many diseases can result at least in part from stress, including: arthritis, asthma, and migraine.
Gassendi kept in close contact with many other scholars, such as Kepler, Galileo, Descartes, and …
Pavlov found that if some other stimulus, for example the ringing of a bell, preceded the food, the …
Reporting cases as support
This case has shown that ...
This has been seen in the case of ...
The case reported here illustrates the ...
From these examples, it is evident that …
Overall, these cases support the view that ...
This case study confirms the importance of ...
It is evident from the examples given here that …
The evidence presented thus far supports the idea that ...
This case demonstrates the need for better strategies for ...
As this case very clearly demonstrates, it is important that ...
This case reveals the need for further investigation in patients with ...
This case demonstrates how X used innovative marketing strategies in ...
Recent cases reported by Smith et al. (2013) also support the hypothesis that ...
In support of this approach, Y has been shown to induce Y in several cases (Smith et al., 2001).

This case
These cases

the need for …
the dangers of …
the possibility of …
the necessity of …
the benefit of using …
how important it is to …
what can happen when …
illustrate(s)
demonstrate(s) the potential harm from …
the central role played by …
(some of) the problems caused by …
(some of) the differences between …
(some of) the difficulties that arise when …

120 | P a g e

Signalling Transition
Previewing what is to follow in a paper or dissertation is like showing a map to a driver; it enables
them to see where they are going. So it is useful to think of a preview section as a 'road map' for
the reader. It must be accurate, but it must be easy to follow.
Writers are also expected to indicate to the reader when they are moving from one topic to
another, or from one section of text to another. These are known as transition statements and
examples of these, together with some previewing statements, are given below (also refer to A
note on Academic Presentations).

Previewing a section of text
The following is a brief description of ...
In the section that follows, it will be argued that ...
The problem of X is discussed in the following section.
A more detailed account of X is given in the following section.
The structure and functions of X will be explained in the following section.
The following part of this paper moves on to describe in greater detail the...
This introductory section provides a brief overview of ... It then goes on to ...

In the following

In the section

pages,
section,
paragraphs,

below,
that follows,

The section below
The following section

What follows is

I

review …
argue that …
will describe how …
will briefly discuss …
will attempt to explore …
will present two influential theories of …

reviews …
presents …
discusses …
describes …
examines …
draws together …

a review of …
a summary of …
an account of …
a description of …
a brief outline of …
a brief overview of …

121 | P a g e

Previewing a short paper (also refer to Introducing Work)
In this paper, I argue that …
The aim of this paper is to …
The central thesis of this paper is that ...
This paper has been divided into four parts. This first …

This paper

aims to …
begins by …
argues that …
gives an account of …
discusses the case of …
has been divided into …
analyses the impact of …
attempts to show that …
contests the claim that …
provides an overview of …
first gives a brief overview of …

Previewing a chapter or section
The aim of the chapter is to introduce …
This section will attempt to assess whether …
This chapter is subdivided into three sections.
The central section of this paper seeks to provide a …
Experiments described in this chapter examine the effect of …
In this chapter, I describe the data collection procedures and …
The second part highlights the key theoretical concepts which …
This chapter of the dissertation is divided into two parts. The first ...
This part of the thesis discusses the findings which emerged from …
The purpose of this chapter is to review the literature on X. It begins by ...
This chapter is divided into four main sections, each of which presents the results relating to …
This chapter discusses the specific methods by which the research and analyses were conducted.

The main

topics
issues
themes
periods
developments

This chapter

reviews …
assesses …
discusses …
draws together …
attempts to provide …
describes the methods used in this investigation. The first section ...
contextualises the research by providing background information on …

covered in this chapter are …

122 | P a g e

Introducing a new topic or aspect of a topic
Regarding X, ...
As regards X, ...
In terms of X, ...
In the case of X ...
With regard to X, ...
With respect to X, ...
On the question of X, …
As far as X is concerned, ...
Another important aspect of X is …
Reintroducing a topic
As discussed above, ...
As explained earlier, ...
As previously stated, …
As indicated previously …
As has already been noted …
As described on the previous page, ...
As was mentioned in the previous chapter, ...
Returning (briefly) to the (subject/issue) of X, ...
As explained in the introduction, it is clear that ...
As was pointed out in the introduction to this paper, ...
Moving from one section to the next
Turning now to …
Let us now turn to …
Let us now consider …
Moving on now to consider …
It would be useful at this stage to consider …
Turning now to the experimental evidence on ...
Before proceeding to examine X, it is important to ...
Before explaining these theories, it is necessary to ...
Having defined what is meant by X, I will now move on to discuss ...
So far this paper has focused on X. The following section will discuss ...
Having analysed X in some detail, we are now in a position to return to …
This chapter has demonstrated that ... It is now necessary to explain the course of ...
Having discussed how to construct X, the final section of this paper addresses ways of ...
This section has analysed the causes of X and has argued that ... The next part of this paper will ...
Moving from one section to the next whilst indicating addition, contrast or opposition
Another significant aspect of X is …
In addition, it is important to ask ...
Unlike Smith, Jones (2014) has argued …
In contrast to Smith, Jones (2014) maintains …
Despite this, little progress has been made in the ...
However, this system also has a number of serious drawbacks.
On the other hand, in spite of these recent findings about the role of ...,

123 | P a g e

Summarising a section or chapter
Thus far, it has been argued that …
The previous section has shown that …
To conclude this section, the literature identifies …
This section has reviewed the three key aspects of ...
In summary, it has been shown from this review that …
This chapter has described the methods used in this investigation and it has ...
This section has attempted to provide a brief summary of the literature relating to …
This chapter began by describing X and arguing that ... It went on to suggest that the ...
In this section, it has been explained that ... The chapter that follows moves on to consider the ...
Previewing a following chapter
The next chapter describes synthesis and evaluation of ...
A summary of the main findings, together with …, is provided in the next chapter.
The next chapter describes the procedures and methods used in this investigation …
In the next section, I will present the principal findings of the current investigation ...
These analytical procedures and the results obtained from them are described in the next chapter.

(briefly)

review …
present …
describe …
examine …
argue that …
comment on …
use the results obtained to discuss …

In the chapter that follows

I

The next chapter
The chapter that follows

moves on to consider …
provides an account of …
presents a case study of …
establishes the framework for …
reviews the literature related to …
explores the relationship between …
summarises the main themes that emerged …

124 | P a g e

Indicating Shared Knowledge or Understanding
Sometimes a writer wishes to show that they are aware that an observation is probably shared by
the reader or that a fact is known by other members of the academic discipline. Phrases for
signalling this are listed below.

Assuming shared understanding with the reader
Of course, …
Quite clearly, …
It is clear that …
It is obvious that …
It is undeniable that …
There is now no doubt that …
Given this situation, it is hardly surprising that …
One should not, of course, accept without question all …

It is, of course,

Smith

is
was

true that …
difficult to …
possible that …
inevitable that …
recognised that …
often the case that …
debatable whether …
unrealistic to expect …
entirely possible that …
too early to say whether …
important to acknowledge …
legitimate and highly desirable for …
important to be very cautious about …
impossible to arrive at a very reliable estimate of …

clearly
obviously

right
correct

to

include …
criticise …
say that …
highlight …
question …
argue that …
point out that …
draw our attention to …
stress the importance of …

125 | P a g e

Assuming shared knowledge with members of the discipline
As is well known,
As has been shown …
It is well known that …
It is a well-known fact that …
There is now broad consensus that …
Smith’s well-known argument is that …
It is well known among social scientists that …
What has been established and is now generally accepted is that …
There is now relatively large consensus across the various disciplines that …

It is

well established that …
widely accepted that …
generally understood that …
widely acknowledged that ...
common knowledge that X is …
well known from previous studies that …

126 | P a g e

Writing about the Past
Writing about the past in English involves choosing from the rather complex tense system. The
phrases grouped below give an indication of the uses of the main tenses in academic writing. For a
comprehensive explanation of the uses of the various tenses you will need to consult an English
grammar book. A good recommendation is Practical English Usage by Michael Swan, Oxford
University Press.

Time phrases associated with the simple past tense: specific times or periods of time in the past
In 1933,
From 1933 to 1945,
In the 1930s and 1940s,
During the Nazi period,
Between 1933 and 1945,

restrictions were placed on German academics.

For centuries,
Throughout the 19th century,
At the start of the 19th century,
In the latter half of the 19th century,
At the beginning of the 19th century,
Towards the end of the 19th century,
In the early years of the 19th century,
At the end of the nineteenth century,
In the second half of the 19th century,

In the 1930s,
Half a century later,
Following World War I,

authorities in X placed restrictions on academics.

Fleming actively searched for anti-bacterial agents.
he was named one of the 100 Most Important People of the century.

Describing research history with past tense constructions
The link between X and Y was established in 2000 by Smith et al.
The association between X and Y was not demonstrated until 2012.
Prior to the work of Smith (1983), the role of X was largely unknown.
Before 1950, the X had received only cursory attention from historians.
The construct of X was first articulated by Smith (1977) and popularised in his book: …
It was not until the late 1960s that historians considered X worthy of scholarly attention.
Awareness of X is not recent, having possibly first been described in the 5th century BCE by …
The next research period involved innovative laboratory work in the late 1960s and into the 1970s.
127 | P a g e

Time phrases associated with the use of the present perfect tense: past and present connected
To date, little evidence has been found associating X with Y.
Up to now, the research has tended to focus on X rather than on Y.
It is only since the work of Smith (2001) that the study of X has gained momentum.
So far, three factors have been identified as being potentially important: X, Y, and Z.
Since 1965, these four economies have doubled their share of world production and trade.
Until recently, there has been little interest in X.
Only in the past ten years have studies of X directly addressed how …
Recently, these questions have been addressed by researchers in many fields.
In recent years, researchers have investigated a variety of approaches to X but ...
More recently, literature has emerged that offers contradictory findings about ...
Over the past century there has been a dramatic increase in ...
The past decade has seen the rapid development of X in many ...
Over the past 30 years there has been a significant increase in ...
Over the past two decades, major advances in molecular biology have allowed …
Over the past few decades, the world has seen the stunning transformation of X, Y and Z.

The present perfect tense may also be used to describe relatively recent research with several
contributors
Several studies have revealed that ...
Previous studies of X have not dealt with ...
X has been intensively investigated recently due to its …
A considerable amount of literature has been published on X.
X has been identified as major contributing factors for the decline of ....
Factors thought to be influencing X have been explored in several studies.
The new material has been shown to enhance X (Smith, 1985, Jones, 1987).
The relationship between X and Y has been widely investigated (Smith, 1985, Jones, ...
There have been several investigations into the causes of X (Smith, 1985; Jones, 1987).

For reference to single investigations or publications in the past, the simple past tense is used
The first systematic study of X was reported by Smith et al. in 1986.
The first experimental realisation of ..., by Smith et al. [12], used a ...
An experimental demonstration of this effect was first carried out by ...
Smith and Jones (1994) were the first to describe X, and reported that ...
X was originally isolated from Y in a soil sample from ... (Smith et al., 1952).
Thirty years later, Smith (1974) reported three cases of ….
In the 1950s, Smith pointed to some of the ways in which ...
In 1960, Smith introduced a system of classification based on …
In 1975, Smith et al. published a paper in which they described ...
In 1984, Jones et al. made several amino acid esters of X and evaluated them as ...
In 1981, Smith and co-workers demonstrated that X induced in vitro resistance to ...
In 1990, Jones et al. demonstrated that replacement of H2O with heavy water led to ...

128 | P a g e

Writing Abstracts
An abstract is a short statement that describes a much longer piece of writing or a prospective
conference presentation. Abstracts for research papers or theses should provide the reader with a
quick overview of the entire study. Abstracts written for PhDs typically contain the following
elements:

•

Importance of the topic
and/or
Reference to the current literature
and/or
Identification of a knowledge gap

•

Aim(s) of the current study

•

Indication of the methods used

•

Statement of the key finding(s)

•

Implications of the findings
and/or
Value of the current study

The first three elements listed above are grouped together because, although they may substitute
each other, it is possible to find all three together. However, it is also possible to find PhD abstracts
where none of them are present. Of all the elements listed above, only the ‘aims of the current
study’ and the ‘statement of key findings’ appear to be obligatory and so these appear here in bold.
Note that all except the last two may also be found in the introductory section of a research paper;
the last two are normally found in the discussion and conclusion sections. Phrases associated with
all these elements are listed below.

Highlighting the importance of the topic
X is vital for …
X plays a key role in …
X is a classic problem in …
Xs were a major element of …
There is a recognised need for …
X is a condition that is characterized by …
X is a pathogenic bacterium that causes …
Recently, there has been renewed interest in …
Since the 1960s, gradual changes in X have been observed.
The X industry is estimated to be worth over $300 billion annually.

129 | P a g e

Reference to current literature
Several studies have documented …
Studies of X show the importance of …
Several attempts have been made to …
A growing body of evidence suggests …
X is becoming a common trend in Y research.
Recent studies related to X have shown that …
X has been the focus of much investigation in the search for …
X has emerged as a powerful tool in studying the behaviour of …
There has been substantial research undertaken on the role of …
Previous research has indicated potential associations between …
X has attracted considerable attention, both scholarly and popular.
Identification of a knowledge gap
However, X has yet to be understood.
Previous studies of X have not dealt with ...
Researchers have not treated X in much detail.
The historiography of X largely ignores the role of Y.
Most studies in the field of X have only focused on ...
The contribution of X has received little attention within …
For the past three decades, studies of X have been restricted to …
The cellular mechanisms underlying those defects are still poorly understood.
No known empirical research has focused on exploring relationships between …
This research has been impeded by the lack of appropriate attachment measures.
Aim of the current study
The aim of this study was to …
This study set out to examine …
This study set out to determine whether …
The principal objective of this project was to investigate …
In this study, techniques for X were developed and applied to …
The present study aimed to explore the relationship between …

This thesis

argues …
reports on …
investigates …
analyses the roles played by …
explores the degree to which …
addresses a neglected aspect of …
aims to portray the different ways in which …
examines the chronology and geography of …
seeks to understand and explain the role of …

130 | P a g e

Indication of methods used
The research is based on four case studies.
Contemporary source material was used to examine …
This study provides a novel approach to quantifying X using …
This study used a phenomenographic approach to identify the …
An online survey provided quantitative data from 670 participants.
Questionnaire assessments of X were collected from 116 adults who …
The study utilised a comparison control group design with three groups of …
The research consisted of an extensive ethnographic enquiry that included …
A combined qualitative and quantitative methodological approach was used to …
A cross-sectional study was undertaken to explore the potential relationship between …
Statement of key findings
Results showed that …
This study identified …
The findings show that …
Respondents reported …
The thesis concludes that …
Analysis of X revealed that …
The experimental data suggested that …
Evidence is presented which shows that …
The research presented here confirms that …
The study identified limited evidence of the …
The principal findings of this research are that …
In this study, X was shown to vary in response to …
This review found evidence that early interventions are effective in …
The findings indicated that there was a positive relationship between …
Significant associations for X were identified for ten variables, including …
Implications and/or the value of the current study
The study implies that …
The involvement of X implies that …
It is evidently clear from the findings that …
An implication of this is the possibility that ...
The results of this study support the view that …
These findings provide a solid evidence base for …
The present results highlight the detrimental effects that X has on …
These data support further clinical development of …
The findings can contribute to a better understanding of …
This research provides a timely and necessary study of the …
The findings presented in this thesis add to our understanding of …
The research results represent a further step towards developing …
This study should, therefore, be of value to practitioners wishing to …
As a result of these investigations, suggestions were identified for future research.

131 | P a g e

Writing Acknowledgements
The ‘acknowledgments’ sections in PhD theses are not simply a polite formality. They are
important because they reveal and pay tribute to the other people and to the bodies who made
the research possible. Typically included are: funding organisations, research institutes,
institutions, supervisors, collaborators, close colleagues and family members. In the majority of
cases, the structure moves from acknowledging the more formal support (funding bodies,
institutions, supervisors) to the most familiar (close friends and family members). The phrases
listed below illustrate some of the ways that thanks and appreciation can be expressed.

Firstly,
Secondly,
Finally,

I wish to
I want to
I would like to

Most of all,
In particular,
First and foremost,
Last but not least,

I am

also
very
deeply
forever
equally
eternally
especially
extremely
immensely
particularly

thank X
extend my thanks to X
give special thanks to X
express my gratitude to X

I would like to thank

for his constant
for her continuous

advice.
support.
tolerance.
patience.
guidance.
forbearance.
reassurance.
encouragement.

my supervisor for …
the University of X for …
each of the participants in this study for …

grateful to X for …

132 | P a g e

I owe a great deal to …
I owe a debt of gratitude to …
I want to express my gratitude to …
I am indebted to my supervisors for their …
I must thank X for the award of the funding which enabled me to undertake …
I think it is essential that I thank my long term friend and companion, X, for his …
I welcome this opportunity to thank the friends, family and colleagues who provided …
I must express my sincere appreciation to X for her constant and continued support and patience.

My

special
sincere
warmest
heartfelt

thanks

go to
are due to

who has always encouraged me to …
who provided the help, guidance and support …
who has been an unstinting source of support …
who always made time to help and support me …
X
for his continued support and patience.
for agreeing to participate in this study.
for her guidance, encouragement and support.
for her academic supervision and personal support.

A very special thank you goes out to …
Thanks also to the University of X, for providing the data for …
Thanks to the staff of X for their contributions to the research …
My gratitude is also extended to the following funding bodies:
My acknowledgements would not be complete without thanking …
There were a multitude of individuals who helped me to arrive at this point, and …
Most importantly, I would not have been able to afford to undertake this endeavour without …

X has been

supportive and patient throughout the writing of this thesis.
an unfailing source of encouragement, advice and reassurance.
a continuing source of encouragement and optimism throughout.
supportive and has provided me with invaluable teaching opportunities.

X has offered valuable advice on specific aspects of ...
X has provided valuable assistance with accessing online resources.
X’s enthusiasm for my topic, was essential in helping me complete this project.
X has monitored my progress and offered advice and encouragement throughout.

133 | P a g e

Notes on Academic Writing

134 | P a g e

A Note on Academic Style
The principal characteristics of written academic style are listed below.
1. Academic writing is evidence-based
Perhaps the most important distinguishing feature of written academic style is that it is evidencebased. Writers support their arguments and claims with evidence from the body of knowledge
relevant to their discipline. Furthermore, any research that is undertaken must make reference to
previous work in the field. As a result, academic texts are rich in attributions to other writers and
references to previous research, as seen in the examples below:
•

Previous studies have shown that ...

•

These sources suggest that from the fifth century onwards ....

•

According to the 1957 Annual Medical Report, the death of the 960 inhabitants of ...

•

However, as has been shown elsewhere (e.g. Smith, 1992), the increase in ...

For further examples, refer to the section on Referring to the Literature in this document.
In addition, general propositions are usually supported with real examples.
•

This can be seen in the case of ...

•

A good example of this can be found in ...

2. Academic writing contains many words of classical origin
Unlike everyday English, academic writing is characterised by a high frequency of words of classical
origin (Greek and Latin). The main reason for this is that Latin was the lingua academica during the
European renaissance; in other words, it was the international language of scholars. Even up until
relatively recently, great works of science, such as Isaac Newton’s Philosophiæ Naturalis Principia
Mathematica (1687), were written in Latin. Where academic texts were written in English, words of
classical origin were used for concepts and phenomena for which there was no equivalent in English.
Although the lingua academica of today is English, writers of academic English still tend to use words
which are derived from Latin, and also, mainly through Latin, from Greek.
everyday words
a lot of
big
bring together
get rid of
not enough
story
thing
trouble
way (of doing)
worry

→

academic words
considerable
significant
synthesise
eradicate
insufficient
anecdote
object
difficulty
method
concern

135 | P a g e

There are also some changes to grammatical words (though these are not of classical origin):
everyday words
not much research
not many studies
isn’t any evidence

→

academic words
little research
few studies
no evidence

3. Academic writing tends to be cautious
Academic writers are careful about the claims they make: they take care not to appear certain where
some doubt may exist, and they are careful not to over-generalise. An example of this kind of
transformation can be seen below. The second sentence is in academic style:
•

Drinking alcohol causes breast cancer in women. →

•

Some studies suggest that drinking alcohol increases the risk of breast cancer in women.

For more examples of this kind of language, refer to the section on Being Cautious.
4. Academic writing is normally impersonal
In the interests of objectivity, academic writers tend to remove themselves from the writing. The
focus is on ‘what’ happened, ‘how’ it was done, and ‘what’ was found. The ‘who’ (the writer) is not
normally given very much attention. This is one of the reasons why personal pronouns (‘I’ and ‘we’)
tend not to be used. In addition, academic texts rarely address the reader directly and the pronoun
normally used for this, ‘you’, is avoided. The second sentence is in academic style:
•

You could say that Churchill made some catastrophic decisions early in the War. →

•

It can be said that Churchill made some catastrophic decisions early in the War.

There are some exceptions: in certain disciplines, it may be appropriate for a writer to explain their
personal interest in the research area. In some disciplines, the researcher may participate in the
research as a participant-observer. In these cases, ‘I’ will be used. The example below, which
illustrates the former situation, is taken from a dissertation in History.
I became interested in X after reading …… I hope to convey some of my fascination for the
subject, as well as expressing my admiration of the artistic achievements of those involved.
In research undertaken by teams, for example in medicine and science, it is common for the research
to be reported using the personal pronoun, e.g. ‘we’.
5. Academic writing avoids contracted forms
Contracted forms (e.g. it’s, don’t, isn’t, aren’t) should not be used in academic writing. The only
exception would be if you are transcribing a recorded conversation or interview.

136 | P a g e

6. Academic writing uses nominalisation
There is a tendency for academic writers to transform verbs (actions) into nouns. In the example
below, the verb ‘opened’ becomes the noun ‘opening’.
•

The Liverpool and Manchester railway opened in 1830. This brought increased prosperity to
both cities.

•

The opening of the Liverpool and Manchester railway in 1830 brought increased prosperity to
both cities.

As a result of this kind of transformation, academic writing is characterised by long noun phrase
constructions, as in: ‘The opening of the Liverpool and Manchester railway in 1830’. In certain cases,
these nominalised forms can become very long and complex:
•

the effect of reducing aggressiveness by producing an ACTH-mediated condition of decreased
androgen levels.

Although this kind of construction is considered normal in scientific writing, unless the reader is
familiar with the constructions, it does make reading difficult as there are so many pieces of
information to process in the one sentence. There is an argument that too much nominalisation
should be discouraged.
7. Academic writing avoids rhetorical questions
Questions to introduce significant new ideas are avoided, and are replaced with statements:
•

Is the welfare system good or not? →

•

It is important to consider the effectiveness of the British welfare system.

However, setting out a list of research questions in the introductory section of a research report is
quite common.
8. Academic writing is precise and detailed
Last of all, one of the most noticeable features of academic writing is that it is very precise and
detailed. This relates to the setting out and development of the thinking and the ideas, as well as to
the language used in the writing.

137 | P a g e

A Note on Style in Academic Presentations
In contrast to written style, the communicative style of academic presentations tends to be much
more personal and familiar. The majority of the phrases listed below serve as useful ‘signposts’ for
spoken academic presentations. ‘Signposts’ help the listeners follow where the talk is going. Notice
how the personal pronouns (‘I’, ‘we’, and ‘you’) are used in most of these phrases.
Introducing the presentation
report on a study which aimed to …
explore a very important aspect of ...
examine two important problems facing ...
describe some of the more recent developments in …

I'd like to
In this paper,

I’ll mainly focus on …

This afternoon, I'd like to

discuss ...
describe ...
speak about ...
present my findings on …
address the question of …

The aim of my presentation is to

assess …
discuss …
explore …
examine…
compare …
argue that …
critically evaluate …
offer a new model for …
address the question of …
explore the ways in which …
report on the findings of my study which …

is

fundamental to …
a leading cause of …
an important aspect of …

has
plays

a critical role in …
a pivotal role in …

We know that X

138 | P a g e

One of the most

pressing
important
interesting
challenging

problems in this area is ...

Defining and organising the topic

There are

three main types of X in ...
many different kinds of ...

In this paper, I use the term ‘X’ to refer to …
In this presentation, I am using the term ‘X’ to refer to …
X can best be treated under three headings. These are: ...
I've divided my presentation into three sections. The first section …
Indicating sequence
First of all,
To begin with,
In the first part of this paper,

I'd like to talk about ...

and then (I’ll) go on to …

I’ll begin by …
I’ll then go on to …
Another important aspect of X is ...
Finally, I’ll argue that …
Finally, I'd like to consider X.
Highlighting statements

There are two important

causes of ...
reasons for ...
consequences of ...

It is worth noting that …
It is important to stress that …
Perhaps the most interesting aspect of this is ...
What is important for us to recognise here, is that …

139 | P a g e

Referring to a visual

If we could

focus for a moment on Figure 1, ...
turn for a moment to look at Table 2,

we can see that …

Here we can see that …
This can be clearly seen when we look at …
We can see this clearly in the following diagram:
Indicating transition

I'd like now to move on to

discuss …
examine …
consider …
address the question of …

Turning now to ...
Moving on to look at the relationship between …,
Having looked at ..., I'd now like to move on to discuss ...
Before I move on to consider X, I'd like to briefly look at ...
Concluding a talk

In this presentation, I’ve

shown that …
argued that …
explained that …

So, to conclude, …
I’d like to conclude by saying that …
In conclusion, I'd like to suggest that ...
Are there any questions?
Does anyone have any questions?
That covers the main points. If you have any questions, I'll be happy to answer them.

140 | P a g e

A Note on British and US Spelling
The most common difference which is noticed in academic writing concerns verbs which end in
ise/yse Br. or ize/yze US:
•
•
•

analyse Br. v analyze US.
industrialise Br. v industrialize US.
summarise Br. v summarize US.

This difference also affects the nouns derived from the verbs:
•
•
•

organisation Br. v organization US.
globalisation Br. v globalization US.
colonisation Br. v colonization US.

Another noticeable difference relates to words ending in re:
•
•
•

centre Br. v center US.
metre Br. v meter US.
litre Br. v liter US.

Below are some other differences. Can you see any patterns?
British
aeroplane
analogue
behaviour
catalogue
colour
connection
defence
dialogue
endeavour
encyclopaedia
fibre
foetus
instalment
labour
paediatric
plough
programme
rigour
sceptical
skilful
travelled

US
airplane
analog
behavior
catalog
color
connexion
defense
dialog
endeavor
encyclopedia
fiber
fetus
installment
labor
pediatric
plow
program
rigor
skeptical
skillful
traveled

If you are writing for a British university or a British journal, you should use the British spelling.
If you are writing for a US university or journal, you should use the US spelling.
141 | P a g e

A Note on Punctuation
As the purpose of punctuation is to make written English easier to read and to make the meaning
clear and unambiguous, good, accurate punctuation is important in academic writing. The following
notes highlight points of particular relevance to academic writing.
1. Full stop .
•
•
•

To indicate the end of a sentence
To indicate an abbreviation such as etc., et al. (not always used)
To indicate an omission in a quoted text [ ... ].

2. Comma ,
•
•
•
•
•

To separate two main parts of a sentence (two clauses) joined by words such as and, or, but,
To separate a dependent part of a sentence (beginning with words such as although, when,
because) from the main part, particularly if the dependent part comes first in the sentence
To indicate additional information, however relevant it may be, in a sentence
To indicate a non-defining relative clause, which simply provides additional information, in a
sentence
To separate items in a list such as: apples, oranges, and pears (note that the final comma
before and is often omitted).

3. Colon :
•
•
•

To introduce an explanation: The reason the experiment failed was obvious: the equipment
was faulty.
To introduce a list, particularly a grammatically complex list. See the example below under
semi-colon
To introduce a direct quotation, particularly a long one: Jones (2003) states that: ‘ ’.

4. Semi-colon ;
•
•

To separate two sentences that are very closely connected in meaning (optional, in place of a
full stop): Some students prefer to write essays; others prefer to give presentations.
To separate clearly items in a grammatically complex list: For Aristotle, motion is of four
kinds: (1) motion which ...; (2) motion which ...; (3) motion which ...; and (4) motion which...

5. Quotation marks ‘ ’ / “ ”
•
•

To indicate a direct quotation
To highlight words or phrases used in a special or unusual way: Quotation marks are also
called ‘inverted commas’.

NB Single quotation marks now seem to be more commonly used than double. For quotations within
quotations, use double quotation marks inside single (or single inside double).
6. Dash –
•

Generally avoid in formal academic writing. Replace by colon, semi-colon, or brackets, as
appropriate.
142 | P a g e

A Note on Article Use
Article use in English is a very complex area. However, there are a few simple rules which will help
you in many situations and these are explained below:
1. Singular countable nouns
All singular countable nouns are always preceded by a small modifying word known in grammar as a
determiner, and this is often an article (a/an, the). Countable words which are common in academic
writing and which often cause problems for non-native speakers of English, include: system, model,
method, approach, group, problem, effect, level, investigation, sector, study, participant, condition,
category
Note that even if these words are preceded by attributive nouns or adjectives, a determiner is still
needed:
•
•

the greenhouse effect, the transport system, the control group
a high level, a systematic approach, a rigorous study, an exploratory investigation

2. Plural countable nouns
If the writer is thinking about a specific group, then the definite article is normally used: The books
in this collection were published in the 19th or early 20th century.
Otherwise no article is used:
•

Learners tend to remember new facts when they are contextualised.

3. Uncountable nouns
Uncountable nouns are not normally accompanied by an article:
•
•

Science has been defined as a systematic approach to answering questions.
Reliability is an important quality of any test.

But if they are post-modified by of...., or which … the definite article is normally used:
•
•
•

The science of global warming is a complex and controversial area.
The reliability of this instrument is poor.
Chemistry is the science which addresses the composition and behaviour of matter.

143 | P a g e

4. Names
Names and titles are not normally preceded by the definite article (the)
•

Manchester University, Manchester

But this changes if the noun phrase contains a post-modifying structure (of ...)
•

The University of Manchester, The United States of America

or if they contain words like organisation, association or institute
•

The World Health Organisation, The American Heart Association, The Royal Society. The SETI
Institute

Apart from these simple rules, the other thing you need to do is to check how noun phrases are used
in the texts that you read. Make a mental note of this as you read, or check back to the source text
when you are writing.

144 | P a g e

A Note on Sentence Structure

1. Simple sentences
In written English, all sentences contain a Subject → Verb structure. The subject always precedes the
verb, except in questions where the order is reversed.
S
An electron

V
is

an elementary particle.

The subject may be one word, but it is usually a group of words centred around a noun. The verb,
which can indicate an action, a state, or simply serve to link the subject to other information, may
also consist of more than one word. Various other sentence elements may be placed before or after
the Subject → Verb structure:
S
restrictions

Between 1933 and 1945,

V
were placed

on German academics.

It is common for the subject to consist of many words:
S
The information on various types of
wasps and bees in the report

V
was

useful to environmentalists who were
fighting the use of pesticides.

Sometimes, however, the subject and verb can just be one word each:
S
It

V
is

almost certain that a lower speed limit will result in fewer injuries to pedestrians.

These simple sentences always end with a full stop. In academic writing, however, many sentences
are more complicated than this simple pattern.

2. Complex sentences
Many sentences contain more than one Subject → Verb structure, but in a complex sentence one of
these parts (known grammatically as clauses) will convey the main meaning and will make sense by
itself:
Dependent part

S
Although recent research

V
has shown

Main part

X,

S
V
no controlled studies have been reported.

The main part of the sentence is also known as the independent part.

145 | P a g e

The main part of the sentence can also be placed before the dependent part.
S
Oral societies

whereas

V
tend to be

S
literate societies

Main part
more concerned with the present
Dependent part
V
have
a very definite awareness of the past.

The dependent part of complex sentence is usually preceded by a word or phrase such as: although,
even though, if, even if, when, because, as, since, whereas, while (refer to subordinators on the next
page).

3. Compound sentences
Some sentences may have two Subject → Verb structures and each of these convey meaning that
can make sense by itself; in other words, there are two main parts. The two parts may be joined by
words like and, or, but, so, or by using a semi-colon (;) .
S
V
Supporters of the ‘Great Divide’ theory agree

but

S
they

V
consider

that something is lost as well as gained when
people become literate,

it is worth losing some benefits in order to obtain many others.

4. Common problems relating to sentence structure
It is incorrect to write the dependent part of a complex sentence as a complete sentence with a full
stop:
•
•

Whereas literate societies have a very definite awareness of the past. X
Although a number of studies have been undertaken. X

It is incorrect to write two independent parts as one sentence without a joining word.
•

Supporters of the ‘Great Divide’ theory agree that something is lost as well as gained when
people become literate, they consider it is worth losing some benefits in order to obtain many
others. X

146 | P a g e

A Note on Paragraph Structure
A pattern that can be identified in many well-written paragraphs is that of a controlling idea followed
by supporting information. The controlling idea, sometimes referred to as the topic sentence,
introduces a new idea, topic, argument or piece of information into the main text. This is then either
explained further or supported by subsequent sentences. This structure can be represented
schematically thus:
Topic Sentence
(new point, expressed in general terms)
Supporting Information which may include a combination of:
•
•
•
•
•
•
•
•

statistics
examples
quotations
a development in time
an explanation or reason
specific aspects or details
an effect or consequence
reference to previous research

It is important that the explanatory or supporting information in a paragraph should relate to the topic
sentence. If new points or ideas are to be stated, then these should be treated in a separate paragraph.
It is also important that the explanatory or supporting information should not repeat the general ideas
expressed in the topic sentence.
An example of the kind of paragraph structure suggested above is given below. Note the
development from the general idea to the more detailed information. Also note the thematic linking,
which is signalled by the words in bold, between the sentences. Each of these words and phrases
links back to an idea introduced in the previous sentence. Here, the sentences have been separated.
Many children become interested in competitive sport at early
ages.
Early involvement (prior to maturity) in competitive sport often
exposes individuals to types of stress that may affect their growth,
producing a disruption of the normal growth pattern (Wang, 1978;
Brown, 1998).
Among cyclists the most potentially serious of these disorders is
likely to be increased thoracic curvature.
Cycling alters the anatomical position of the spine (to a flexed
position) particularly the thoracic spine, and exposes the anterior
portion of the vertebral column to higher compression (Smith,
1998; Jones, 2002).
147 | P a g e

A Note on the Writing Process

So far this document has been about ‘what we write’. The following section comprises a set of notes
which are concerned with ‘how’ we write. It is organised into a series of helpful tips. Although only
two pages are devoted to these ideas, together they have the potential to make a significant
deference to the quality and quantity of your written output.

Tip No. 1. The importance of planning: Research has shown that
experienced writers plan extensively. Initially, planning may involve
simply generating ideas and exploring the relationships between
them schematically, as in the diagram to the right. At a more
advanced stage of the planning process, a chapter outline of the
thesis or dissertation will be necessary. This will become more
detailed as you work on your study. You need to think of a writing
plan as a road map. Without a map, you will probably lose your way
or travel in circles.

Tip No. 2. Getting started: Many writers suffer from ‘writers’ block’;
they find it difficult to get started. One way of overcoming this is to
give yourself a short period of time (say four minutes), and without
stopping, write whatever comes into your mind about the topic. The
important thing to do is to keep writing, or if you are using a
keyboard, to keep typing. Don’t worry about spelling of grammar –
just keep producing words. You will be surprised at how much text
you will produce, and how many ideas are generated in such a short
time. Now you can begin to organise the ideas you have produced,
ensuring that they are written in logically developed and grammatically correct sentences.

Tip No. 3. Be regular: You should timetable yourself so that you have a regular daily writing slot. This
may seem obvious, but it is fundamental to ensuring the production of written text. Timetable a
writing period each day, and aim to produce some text every time. How much you produce will vary,
and what you produce, even if it is just a few paragraphs, may only be in the initial draft stage. This is
not so important. The important thing is that the writing becomes a part of your daily routine. Simply
getting your body to sit in front of a computer at a certain time each day will produce results.

Tip No. 4. Keep a notebook: When we are writing up a major piece
of work, many ideas and insights come to us when we are not
actually writing. Often, some of the most insightful ideas emerge
when we are in a non-focused cognitive state, such as when we are
walking, running, or swimming. Unless you can capture these ideas
soon after they come to you, they may be lost. A small notebook and
a pen is probably the best way to capture these thoughts before they
disappear. The notebook itself can become a place where you
develop the ideas and even start to formulate how the ideas will be developed in textual form.

148 | P a g e

Tip No. 5. Understand the recursive process: Writing at the
academic level is not something we can do once and then leave. It
is a recursive process. This means writers return to their initial
texts, revising and redrafting them. This process is ongoing. In fact,
many writers find it difficult to stop improving their writing, but
with time being limited, they try to do as much as they can before
the onset of a particular deadline. One thing we do know:
successful writers write initial drafts, redraft, work on final drafts
and then edit their work.
Tip No. 6. Read your own writing: Read what you have written back to yourself, out loud if
necessary, and ask yourself: i) do I understand what I have written? ii) does it sound natural?
Reading your text out load is actually the best way of checking this. If what you have written does not
sound right to you when you do this, it is probably badly written. One famous French writer (Gustav
Flaubert) used to shout out his manuscripts before sending them off to be published. He claimed that
bad writing never passed this simple test.
Tip No. 7. Stand back from your writing: Think of yourself as a
mountain climber. Most climbers, during a climb, can only see a few
feet in front of their faces. They cannot see the whole mountain.
They can see other mountains, but not the one they are climbing. To
do this they need to move a few kilometres away. At such a distance,
they can see the route they are planning and they can see how their
planned route moves up the mountain. As a writer, you should ask
yourself: Is the route to the ‘top’ unbroken? Do all the minor ‘steps’
move upwards? Can the minor ‘steps’ be ‘carried out’ more clearly?
The best way to create a sense of distance with your writing is with time: Leave it a few days, or longer,
and comeback to your writing with fresh eyes and with a better sense of the overall structure.
Tip No. 8. Talk about your writing: Writing is a very solitary activity and we tend not to talk about it
to others. This is quite strange given that we spend so many hours on this activity. Asking another
person to read some of what you have written and to give feedback can be a very useful experience;
particularly if the feedback is reciprocal and both of you receive constructive criticism. It is worth
bearing in mind that academic writers often receive their papers back from journal editors or
publishers asking them to make changes. You might also consider forming a group of writers like
yourself. Together you can read each other’s writing and share the feedback.

149 | P a g e

Useful Lists

150 | P a g e

A List of Words and Phrases Used to Connect Ideas
As well as using simple conjunctions (e.g., and, but, or) to link ideas, academic writers have available
to them a broad range of more sophisticated words and phrases. Some of the more commonly used
ones are listed below.

Addition

Adversativity

Aspect
Clarification

Words and phrases which
link ideas across two
sentences1
also
moreover
in addition
furthermore
yet
however
nevertheless
on the other hand
in this respect
in other respects
from this perspective
that is
in other words

Consequence thus
hence
therefore
as a result
consequently
Contrast
however
in contrast
on the other hand
Illustration
for example
for instance
Reason

Sequence

firstly
first of all
secondly
finally
in conclusion

Words or phrases
which precede a noun
phrase2
in addition to

Subordinators: express
relationships within one
sentence (with two clauses)3

despite
in spite of

although
even though

unlike
in contrast to

while
whereas

due to
owing to
because of
on account of

as
since
because

1

He did not sleep very much. However, he still managed to pass the exam.
He did not sleep very much; however, he still managed to pass the exam.

2

Despite the lack of sleep, he still managed to pass the exam.
He still managed to pass the exam despite the lack of sleep.

3

Even though he was unable to sleep, he still managed to pass the exam.
He still managed to pass the exam even though he was unable to sleep.

151 | P a g e

A List of Commonly Used Verbs
The tables below contain a list of verbs that can be found in academic writing. The list, which is
organised alphabetically, only includes the more generic and commonly used verbs. Note that British
spellings are used. Most of the verbs below are found in the Academic Phrasebank and a small
number of additional verbs have been drawn from Coxhead’s Academic Word List.
https://www.wgtn.ac.nz/lals/resources/academicwordlist/awl-headwords
A
abandon
accelerate
accentuate
accept
access
accommodate
accompany
accomplish
account for
accumulate
achieve
acknowledge
acquire
adapt
add to
adopt
address
adjust
administer
advocate
affect
aggravate
aggregate
agree
aid
allocate
allow
alter
amend
amplify
analyse
anonymise
anticipate
append
apply
appraise
appreciate
approach
approve
approximate
argue

arise
arrange
ascertain
assay
assemble
assert
assess
assign
assist
associate
assume
assure
attach
attain
attempt
attend
attract
attribute
automate
avoid
B
base on
benefit
boost
broaden
brief
bring about
C
calculate
capture
carry out
cast doubt on
categorise
cause
caution
cease
challenge
change
channel
cite

claim
clarify
classify
code
coincide
collapse
collect
commence
comment
commit
communicate
compare
compensate
compile
complement
complete
compose
comprehend
comprise
compute
concede
conceive
concentrate
conceptualise
concern
conclude
conduct
confer
confine
confirm
conflict
conform
confound
connect
consent
consider
consist
constitute
constrain
contradict
construct
consult

consume
contradict
contrast
contribute
control
convene
converse
convert
convince
cooperate
coordinate
counteract
correspond
corroborate
cover
create
credit
criticise
critique
D
date
deal with
debate
decline
decrease
deduce
defend
define
delay
demonstrate
denote
deny
depress
derive
describe
design
detect
deter
determine
develop
deviate

devote
differ
differentiate
diminish
discover
discriminate
discuss
display
displace
dispute
dissect
dispose
distinguish
divide
document
draft
draw from
draw together
draw (up)on
draw up
drive
E
edit
elicit
eliminate
elucidate
embody
embrace
emerge
employ
enable
encompass
encourage
engage
enhance
ensure
equate
establish
estimate
evaluate
evolve

exacerbate
examine
exceed
exclude
execute
exemplify
exist
experience
experiment
explain
explore
express
extend
extract
extrapolate
F
fabricate
facilitate
fail
familiarise
find
fluctuate
focus
format
formulate
foster
found
G
gain
gather
gauge
generalise
generate
grade
grant
grasp
group
grow
guarantee

152 | P a g e

H
heighten
highlight
hinder
hold
hypothesise
I
identify
ignore
illustrate
impair
impede
implement
implicate
imply
impose
improve
incline
include
incorporate
increase
include
indicate
induce
influence
inhibit
initiate
infer
influence
innovate
input
insert
insist
inspect
instruct
integrate
intensify
interact
interfere
interpret
intervene
interview
introduce
invest
investigate
invoke
involve
isolate

J
judge
justify
L
label
lack
layer lay out
lead
lecture
level off
limit
link
list
locate
M
maintain
manipulate
match
maximise
measure
mediate
mention
migrate
minimise
mislead
model
moderate
modify
monitor
N
negate
neglect
normalise
note
notify
O
observe
obstruct
obtain
occupy
occur
offer
offset
operate
oppose
order

organise
originate
outline
overlap
overlook
P
paraphrase
participate
pay attention
to
perceive
perform
perpetuate
persist
persuade
pinpoint
pioneer
play a role
plot
point to/
towards
point out
popularise
pose
postulate
prepare
precede
preclude
predict
prescribe
present
presume
prevent
prioritise
proceed
prohibit
project
promote
prompt
propose
proscribe
prove
provide
publish
pursue
Q
qualify
quantify

quote
question
R
raise
rank rate
reach
react
recall
recognise
recommend
record
recover
recruit
reduce
refer
refine
reflect
refuse
regard
register
regulate
reinforce
reject
relate
relax
release
relinquish
rely
remain
remedy
remark
remind
remove
renew
repeat
report
represent
require
research
reside
resolve
respond
restate
restore
restrain
restrict
result from
result in
retain

reverse
reveal
retrieve
review
revise
rise
rule out
S
search
secure
seek
select
separate
sequence
serve
set out
set up
shed light on
shift
show
signify
simplify
simulate
skew
solve
source
speculate
specify
speed up
state
stimulate
stress
structure
struggle
subdivide
subject to
submit
subscribe
substantiate
substitute
succeed
suffer
suggest
summarise
supplement
support
surrender
survey
sustain

synthesise
survive
suspend
T
tabulate
tackle
take into
account
take issue
with
target
tend
terminate
test
throw up
tie together
trace
transfer
transform
transcribe
translate
transmit
treat
trigger
U
underestimate
undergo
underlie
understand
undertake
unify
use
utilise
V
validate
value
vary
violate
visualise
W
weaken
withstand
witness

153 | P a g e

A List of Commonly Confused Words
Your spellchecker will only indicate words that are misspelt which it does not recognise. However, if
the word that you have misspelt is correct when it has a different meaning, the spellchecker will not
show you the correct form of the word you want. In these cases, the writer has to know the correct
spelling. The list below contains words which are commonly misspelt, as well as words which may be
spelt correctly but which are simply confused.
abbreviation/acronym
An abbreviation is a shortened form of a word or phrase. Usually, but not always, it consists of a
letter or group of letters taken from the word or phrase. Dr. and Prof. are common examples. An
acronym is an abbreviation formed from the initial components in a phrase or a word. These
elements in turn form a new word: NATO, Benelux, UNESCO.
affect/effect
Affect is a verb, e.g. A affects B;
Effect is a noun and is therefore, in its singular form, always used after an article/determiner (‘an’ or
‘the’/’this’), e.g. The Greenhouse Effect.
compliment/complement
Compliment (verb) means to praise someone. Complement (verb) means to complete or add
something in a way that usually improves it. Both words can also be used as nouns.
comprise/consist
Both words mean ‘to be made up of’, but only consist is accompanied by of.
discrete/discreet
Discrete is an adjective which means ‘separate’ or ‘distinct’. Discreet is an adjective which means ‘to
keep silent or tactful about something’.
formerly/formally
Formerly means ‘earlier’. Formally means ‘conventionally’ or ‘officially’.
i.e./e.g.
i.e. is the abbreviation for id est which mean ‘that is’ or ‘in other words’.
e.g. is the abbreviation for exempli gratia which has the same meaning as ‘for example’ and ‘for
instance’.
its/it's
its – without an apostrophe - is a possessive determiner similar to 'my' or 'your' .
it's is a contracted form of 'it is' or 'it has' . Note, however, that contracted forms are avoided in
academic writing.
later/latter
Later is an adverb which means ‘at an advanced point of time’. Latter is an adjective used to refer to
an item listed in a text. It means ‘most recently mentioned’; in other words, the last item.

154 | P a g e

practice/practise
In British English, practice is a noun and practise is a verb. American English allows both spellings for
both forms.
precede/proceed
The verb precede means ‘to come before’. The verb proceed means ‘to go forward’ or ‘to begin to
carry out’.
principle/principal
Principle is a noun which means ‘a basic belief, theory or rule’. Principal is an adjective which means
‘main’ or ‘most important’; it can also refer to a head teacher of a school.
there/their
There is used to indicate the existence of something, e.g. There are two famous football teams in
Manchester. The word their is used to indicate possession, i.e. if something belongs to someone or
something.
prescribe/proscribe
The verb prescribe means to advise or authorise the use of something. The verb proscribe means to
forbid or to restrict.

155 | P a g e

arXiv:1912.04977v3 [cs.LG] 9 Mar 2021

Advances and Open Problems in Federated Learning
Peter Kairouz7 *
H. Brendan McMahan7∗
Brendan Avent21
Aurélien Bellet9
19
13
7
Mehdi Bennis
Arjun Nitin Bhagoji
Kallista Bonawitz
Zachary Charles7
Graham Cormode23
Rachel Cummings6
Rafael G.L. D’Oliveira14
Hubert Eichner7
Salim El Rouayheb14
David Evans22
Josh Gardner24
Zachary Garrett7
Adrià Gascón7
Badih Ghazi7
Phillip B. Gibbons2
Marco Gruteser7,14
Zaid Harchaoui24
Chaoyang He21
Lie He 4
Zhouyuan Huo 20
Ben Hutchinson7
Justin Hsu25
Martin Jaggi4
Tara Javidi17
2
2
7
Gauri Joshi
Mikhail Khodak
Jakub Konečný
Aleksandra Korolova21
Farinaz Koushanfar17
Sanmi Koyejo7,18
Tancrède Lepoint7
Yang Liu12
Prateek Mittal13
Mehryar Mohri7
Richard Nock1
Ayfer Özgür15
Rasmus Pagh7,10
Hang Qi7
Daniel Ramage7
Ramesh Raskar11
Mariana Raykova7
Dawn Song16
Weikang Song7
Sebastian U. Stich4
Ziteng Sun3
Ananda Theertha Suresh7
Florian Tramèr15
Praneeth Vepakomma11
2
5
7
8
Jianyu Wang
Li Xiong
Zheng Xu
Qiang Yang
Felix X. Yu7
Han Yu12
Sen Zhao7
1
4
7

Australian National University, 2 Carnegie Mellon University, 3 Cornell University,

École Polytechnique Fédérale de Lausanne, 5 Emory University, 6 Georgia Institute of Technology,

Google Research, 8 Hong Kong University of Science and Technology, 9 INRIA, 10 IT University of Copenhagen,
11

Massachusetts Institute of Technology, 12 Nanyang Technological University, 13 Princeton University,
14

17

Rutgers University, 15 Stanford University, 16 University of California Berkeley,

University of California San Diego, 18 University of Illinois Urbana-Champaign, 19 University of Oulu,
20
23

University of Pittsburgh, 21 University of Southern California, 22 University of Virginia,

University of Warwick, 24 University of Washington, 25 University of Wisconsin–Madison

Abstract
Federated learning (FL) is a machine learning setting where many clients (e.g. mobile devices or
whole organizations) collaboratively train a model under the orchestration of a central server (e.g. service
provider), while keeping the training data decentralized. FL embodies the principles of focused data
collection and minimization, and can mitigate many of the systemic privacy risks and costs resulting
from traditional, centralized machine learning and data science approaches. Motivated by the explosive
growth in FL research, this paper discusses recent advances and presents an extensive collection of open
problems and challenges.
* Peter Kairouz and H. Brendan McMahan conceived, coordinated, and edited this work.

google.com and mcmahan@google.com.

1

Correspondence to kairouz@

Contents
1

Introduction
1.1 The Cross-Device Federated Learning Setting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.1.1 The Lifecycle of a Model in Federated Learning . . . . . . . . . . . . . . . . . . . . . . . .
1.1.2 A Typical Federated Training Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2 Federated Learning Research . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.3 Organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4
5
7
8
9
10

2

Relaxing the Core FL Assumptions: Applications to Emerging Settings and Scenarios
2.1 Fully Decentralized / Peer-to-Peer Distributed Learning . . . . . . . . . . . . . . . . . . . . . . . . .
2.1.1 Algorithmic Challenges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.1.2 Practical Challenges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2 Cross-Silo Federated Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3 Split Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4 Executive summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

11
11
12
14
14
16
17

3

Improving Efficiency and Effectiveness
3.1 Non-IID Data in Federated Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.1.1 Strategies for Dealing with Non-IID Data . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Optimization Algorithms for Federated Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.1 Optimization Algorithms and Convergence Rates for IID Datasets . . . . . . . . . . . . . . .
3.2.2 Optimization Algorithms and Convergence Rates for Non-IID Datasets . . . . . . . . . . . .
3.3 Multi-Task Learning, Personalization, and Meta-Learning . . . . . . . . . . . . . . . . . . . . . . . .
3.3.1 Personalization via Featurization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.2 Multi-Task Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.3 Local Fine Tuning and Meta-Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.4 When is a Global FL-trained Model Better? . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4 Adapting ML Workflows for Federated Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4.1 Hyperparameter Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4.2 Neural Architecture Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4.3 Debugging and Interpretability for FL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.5 Communication and Compression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.6 Application To More Types of Machine Learning Problems and Models . . . . . . . . . . . . . . . .
3.7 Executive summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

18
18
19
20
21
25
28
28
28
29
30
30
31
31
32
32
34
34

4

Preserving the Privacy of User Data
4.1 Actors, Threat Models, and Privacy in Depth . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.2 Tools and Technologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.2.1 Secure Computations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.2.2 Privacy-Preserving Disclosures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.2.3 Verifiability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3 Protections Against External Malicious Actors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3.1 Auditing the Iterates and Final Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3.2 Training with Central Differential Privacy . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3.3 Concealing the Iterates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3.4 Repeated Analyses over Evolving Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3.5 Preventing Model Theft and Misuse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.4 Protections Against an Adversarial Server . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.4.1 Challenges: Communication Channels, Sybil Attacks, and Selection . . . . . . . . . . . . . .
4.4.2 Limitations of Existing Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.4.3 Training with Distributed Differential Privacy . . . . . . . . . . . . . . . . . . . . . . . . . .
4.4.4 Preserving Privacy While Training Sub-Models . . . . . . . . . . . . . . . . . . . . . . . . .

36
37
38
40
44
46
48
49
49
51
52
52
53
53
54
55
58

2

4.5

User Perception . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.5.1 Understanding Privacy Needs for Particular Analysis Tasks . . . . . . . . . . . . . . . . . . .
4.5.2 Behavioral Research to Elicit Privacy Preferences . . . . . . . . . . . . . . . . . . . . . . . .
Executive Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

59
59
60
60

5

Defending Against Attacks and Failures
5.1 Adversarial Attacks on Model Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.1.1 Goals and Capabilities of an Adversary . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.1.2 Model Update Poisoning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.1.3 Data Poisoning Attacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.1.4 Inference-Time Evasion Attacks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.1.5 Defensive Capabilities from Privacy Guarantees . . . . . . . . . . . . . . . . . . . . . . . . .
5.2 Non-Malicious Failure Modes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.3 Exploring the Tension between Privacy and Robustness . . . . . . . . . . . . . . . . . . . . . . . . .
5.4 Executive Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

62
62
63
66
67
69
70
71
73
73

6

Ensuring Fairness and Addressing Sources of Bias
6.1 Bias in Training Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.2 Fairness Without Access to Sensitive Attributes . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.3 Fairness, Privacy, and Robustness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.4 Leveraging Federation to Improve Model Diversity . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.5 Federated Fairness: New Opportunities and Challenges . . . . . . . . . . . . . . . . . . . . . . . . .
6.6 Executive Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

75
75
76
77
78
79
79

7

Addressing System Challenges
7.1 Platform Development and Deployment Challenges . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.2 System Induced Bias . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.2.1 Device Availability Profiles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.2.2 Examples of System Induced Bias . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.2.3 Open Challenges in Quantifying and Mitigating System Induced Bias . . . . . . . . . . . . .
7.3 System Parameter Tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.4 On-Device Runtime . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.5 The Cross-Silo Setting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.6 Executive Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

81
81
82
82
83
84
85
86
87
88

8

Concluding Remarks

89

4.6

A Software and Datasets for Federated Learning

119

3

1

Introduction

Federated learning (FL) is a machine learning setting where many clients (e.g. mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (e.g. service provider),
while keeping the training data decentralized. It embodies the principles of focused collection and data
minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning. This area has received significant interest recently, both from research and applied
perspectives. This paper describes the defining characteristics and challenges of the federated learning setting, highlights important practical constraints and considerations, and then enumerates a range of valuable
research directions. The goals of this work are to highlight research problems that are of significant theoretical and practical interest, and to encourage research on problems that could have significant real-world
impact.
The term federated learning was introduced in 2016 by McMahan et al. [337]: “We term our approach
Federated Learning, since the learning task is solved by a loose federation of participating devices (which
we refer to as clients) which are coordinated by a central server.” An unbalanced and non-IID (identically
and independently distributed) data partitioning across a massive number of unreliable devices with limited
communication bandwidth was introduced as the defining set of challenges.
Significant related work predates the introduction of the term federated learning. A longstanding goal
pursued by many research communities (including cryptography, databases, and machine learning) is to analyze and learn from data distributed among many owners without exposing that data. Cryptographic methods
for computing on encrypted data were developed starting in the early 1980s [396, 492], and Agrawal and
Srikant [11] and Vaidya et al. [457] are early examples of work that sought to learn from local data using
a centralized server while preserving privacy. Conversely, even since the introduction of the term federated
learning, we are aware of no single work that directly addresses the full set of FL challenges. Thus, the term
federated learning provides a convenient shorthand for a set of characteristics, constraints, and challenges
that often co-occur in applied ML problems on decentralized data where privacy is paramount.
This paper originated at the Workshop on Federated Learning and Analytics held June 17–18th, 2019,
hosted at Google’s Seattle office. During the course of this two-day event, the need for a broad paper
surveying the many open challenges in the area of federated learning became clear.1
A key property of many of the problems discussed is that they are inherently interdisciplinary — solving
them likely requires not just machine learning, but techniques from distributed optimization, cryptography,
security, differential privacy, fairness, compressed sensing, systems, information theory, statistics, and more.
Many of the hardest problems are at the intersections of these areas, and so we believe collaboration will be
essential to ongoing progress. One of the goals of this work is to highlight the ways in which techniques from
these fields can potentially be combined, raising both interesting possibilities as well as new challenges.
Since the term federated learning was initially introduced with an emphasis on mobile and edge device
applications [337, 334], interest in applying FL to other applications has greatly increased, including some
which might involve only a small number of relatively reliable clients, for example multiple organizations
collaborating to train a model. We term these two federated learning settings “cross-device” and “cross-silo”
respectively. Given these variations, we propose a somewhat broader definition of federated learning:
Federated learning is a machine learning setting where multiple entities (clients) collaborate
in solving a machine learning problem, under the coordination of a central server or service
provider. Each client’s raw data is stored locally and not exchanged or transferred; instead,
1

During the preparation of this work, Li et al. [301] independently released an excellent but less comprehensive survey.

4

focused updates intended for immediate aggregation are used to achieve the learning objective.
Focused updates are updates narrowly scoped to contain the minimum information necessary for the specific
learning task at hand; aggregation is performed as early as possible in the service of data minimization. We
note that this definition distinguishes federated learning from fully decentralized (peer-to-peer) learning
techniques as discussed in Section 2.1.
Although privacy-preserving data analysis has been studied for more than 50 years, only in the past
decade have solutions been widely deployed at scale (e.g. [177, 154]). Cross-device federated learning and
federated data analysis are now being applied in consumer digital products. Google makes extensive use of
federated learning in the Gboard mobile keyboard [376, 222, 491, 112, 383], as well as in features on Pixel
phones [14] and in Android Messages [439]. While Google has pioneered cross-device FL, interest in this
setting is now much broader, for example: Apple is using cross-device FL in iOS 13 [25], for applications
like the QuickType keyboard and the vocal classifier for “Hey Siri” [26]; doc.ai is developing cross-device
FL solutions for medical research [149], and Snips has explored cross-device FL for hotword detection
[298].
Cross-silo applications have also been proposed or described in myriad domains including finance risk
prediction for reinsurance [476], pharmaceuticals discovery [179], electronic health records mining [184],
medical data segmentation [15, 139], and smart manufacturing [354].
The growing demand for federated learning technology has resulted in a number of tools and frameworks
becoming available. These include TensorFlow Federated [38], Federated AI Technology Enabler [33],
PySyft [399], Leaf [35], PaddleFL [36] and Clara Training Framework [125]; more details in Appendix A.
Commercial data platforms incorporating federated learning are in development from established technology
companies as well as smaller start-ups.
Table 1 contrasts both cross-device and cross-silo federated learning with traditional single-datacenter
distributed learning across a range of axes. These characteristics establish many of the constraints that
practical federated learning systems must typically satisfy, and hence serve to both motivate and inform the
open challenges in federated learning. They will be discussed at length in the sections that follow.
These two FL variants are called out as representative and important examples, but different FL settings
may have different combinations of these characteristics. For the remainder of this paper, we consider the
cross-device FL setting unless otherwise noted, though many of the problems apply to other FL settings as
well. Section 2 specifically addresses some of the many other variations and applications.
Next, we consider cross-device federated learning in more detail, focusing on practical aspects common
to a typical large-scale deployment of the technology; Bonawitz et al. [81] provides even more detail for a
particular production system, including a discussion of specific architectural choices and considerations.

1.1

The Cross-Device Federated Learning Setting

This section takes an applied perspective, and unlike the previous section, does not attempt to be definitional.
Rather, the goal is to describe some of the practical issues in cross-device FL and how they might fit into a
broader machine learning development and deployment ecosystem. The hope is to provide useful context
and motivation for the open problems that follow, as well as to aid researchers in estimating how straightforward it would be to deploy a particular new approach in a real-world system. We begin by sketching the
lifecycle of a model before considering a FL training process.

5

Datacenter
distributed learning

Cross-silo
federated learning

Cross-device
federated learning

Setting

Training a model on a large
but “flat” dataset. Clients
are compute nodes in a single cluster or datacenter.

Training a model on siloed data.
Clients are different organizations (e.g. medical or financial)
or geo-distributed datacenters.

The clients are a very large number of
mobile or IoT devices.

Data
distribution

Data is centrally stored and
can be shuffled and balanced
across clients. Any client can
read any part of the dataset.

Data is generated locally and remains decentralized. Each client stores
its own data and cannot read the data of other clients. Data is not independently or identically distributed.

Orchestration

Centrally orchestrated.

A central orchestration server/service organizes the training, but never
sees raw data.

Wide-area
None
(fully
connected
communication clients in one datacenter/cluster).
Data
availability

Typically a hub-and-spoke topology, with the hub representing a coordinating service provider (typically without data) and the spokes connecting
to clients.

All clients are almost always available.

Only a fraction of clients are available at
any one time, often with diurnal or other
variations.

Distribution
scale

Typically 1 - 1000 clients.

Typically 2 - 100 clients.

Massively parallel, up to 1010 clients.

Primary
bottleneck

Computation is more often
the bottleneck in the datacenter, where very fast networks
can be assumed.

Might be computation or communication.

Communication is often the primary
bottleneck, though it depends on the
task. Generally, cross-device federated
computations use wi-fi or slower connections.

Addressability

Each client has an identity or name that allows the system to
access it specifically.

Clients cannot be indexed directly (i.e.,
no use of client identifiers).

Client
statefulness

Stateful — each client may participate in each round of the computation, carrying state from round to round.

Stateless — each client will likely participate only once in a task, so generally a fresh sample of never-before-seen
clients in each round of computation is
assumed.

Client
reliability

Relatively few failures.

Highly unreliable — 5% or more of the
clients participating in a round of computation are expected to fail or drop out
(e.g. because the device becomes ineligible when battery, network, or idleness
requirements are violated).

Data partition
axis

Data can be partitioned / repartitioned arbitrarily across
clients.

Partition is fixed. Could be
example-partitioned (horizontal)
or feature-partitioned (vertical).

Fixed partitioning by example (horizontal).

Table 1: Typical characteristics of federated learning settings vs. distributed learning in the datacenter (e.g. [150]).
Cross-device and cross-silo federated learning are two examples of FL domains, but are not intended to be exhaustive.
The primary defining characteristics of FL are highlighted in bold, but the other characteristics are also critical in
determining which techniques are applicable.

6

admin

clients

model
testing

server

engineers
& analysts

federated
learning

rest of
the world

model
deployment

Figure 1: The lifecycle of an FL-trained model and the various actors in a federated learning system. This
figure is revisited in Section 4 from a threat models perspective.
1.1.1

The Lifecycle of a Model in Federated Learning

The FL process is typically driven by a model engineer developing a model for a particular application. For
example, a domain expert in natural language processing may develop a next word prediction model for
use in a virtual keyboard. Figure 1 shows the primary components and actors. At a high level, a typical
workflow is:
1. Problem identification: The model engineer identifies a problem to be solved with FL.
2. Client instrumentation: If needed, the clients (e.g. an app running on mobile phones) are instrumented to store locally (with limits on time and quantity) the necessary training data. In many cases,
the app already will have stored this data (e.g. a text messaging app must store text messages, a photo
management app already stores photos). However, in some cases additional data or metadata might
need to be maintained, e.g. user interaction data to provide labels for a supervised learning task.
3. Simulation prototyping (optional): The model engineer may prototype model architectures and test
learning hyperparameters in an FL simulation using a proxy dataset.
4. Federated model training: Multiple federated training tasks are started to train different variations
of the model, or use different optimization hyperparameters.
5. (Federated) model evaluation: After the tasks have trained sufficiently (typically a few days, see
below), the models are analyzed and good candidates selected. Analysis may include metrics computed on standard datasets in the datacenter, or federated evaluation wherein the models are pushed to
held-out clients for evaluation on local client data.
6. Deployment: Finally, once a good model is selected, it goes through a standard model launch process,
including manual quality assurance, live A/B testing (usually by using the new model on some devices
and the previous generation model on other devices to compare their in-vivo performance), and a
7

Total population size
Devices selected for one round of training
Total devices that participate in training one model
Number of rounds for model convergence
Wall-clock training time

106 –1010 devices
50 – 5000
105 –107
500 – 10000
1 – 10 days

Table 2: Order-of-magnitude sizes for typical cross-device federated learning applications.
staged rollout (so that poor behavior can be discovered and rolled back before affecting too many
users). The specific launch process for a model is set by the owner of the application and is usually
independent of how the model is trained. In other words, this step would apply equally to a model
trained with federated learning or with a traditional datacenter approach.
One of the primary practical challenges an FL system faces is making the above workflow as straightforward as possible, ideally approaching the ease-of-use achieved by ML systems for centralized training.
While much of this paper concerns federated training specifically, there are many other components including federated analytics tasks like model evaluation and debugging. Improving these is the focus of
Section 3.4. For now, we consider in more detail the training of a single FL model (Step 4 above).
1.1.2

A Typical Federated Training Process

We now consider a template for FL training that encompasses the Federated Averaging algorithm of McMahan et al. [337] and many others; again, variations are possible, but this gives a common starting point.
A server (service provider) orchestrates the training process, by repeating the following steps until training is stopped (at the discretion of the model engineer who is monitoring the training process):
1. Client selection: The server samples from a set of clients meeting eligibility requirements. For
example, mobile phones might only check in to the server if they are plugged in, on an unmetered
wi-fi connection, and idle, in order to avoid impacting the user of the device.
2. Broadcast: The selected clients download the current model weights and a training program (e.g. a
TensorFlow graph [2]) from the server.
3. Client computation: Each selected device locally computes an update to the model by executing the
training program, which might for example run SGD on the local data (as in Federated Averaging).
4. Aggregation: The server collects an aggregate of the device updates. For efficiency, stragglers might
be dropped at this point once a sufficient number of devices have reported results. This stage is also
the integration point for many other techniques which will be discussed later, possibly including:
secure aggregation for added privacy, lossy compression of aggregates for communication efficiency,
and noise addition and update clipping for differential privacy.
5. Model update: The server locally updates the shared model based on the aggregated update computed
from the clients that participated in the current round.
Table 2 gives typical order-of-magnitude sizes for the quantities involved in a typical federated learning
application on mobile devices.
8

The separation of the client computation, aggregation, and model update phases is not a strict requirement of federated learning, and it indeed excludes certain classes of algorithms, for example asynchronous
SGD where each client’s update is immediately applied to the model, before any aggregation with updates
from other clients. Such asynchronous approaches may simplify some aspects of system design, and also
be beneficial from an optimization perspective (though this point can be debated). However, the approach
presented above has a substantial advantage in affording a separation of concerns between different lines of
research: advances in compression, differential privacy, and secure multi-party computation can be developed for standard primitives like computing sums or means over decentralized updates, and then composed
with arbitrary optimization or analytics algorithms, so long as those algorithms are expressed in terms of
aggregation primitives.
It is also worth emphasizing that in two respects, the FL training process should not impact the user
experience. First, as outlined above, even though model parameters are typically sent to some devices
during the broadcast phase of each round of federated training, these models are an ephemeral part of the
training process, and not used to make “live” predictions shown to the user. This is crucial, because training
ML models is challenging, and a misconfiguration of hyperparameters can produce a model that makes bad
predictions. Instead, user-visible use of the model is deferred to a rollout process as detailed above in Step 6
of the model lifecycle. Second, the training itself is intended to be invisible to the user — as described
under client selection, training does not slow the device or drain the battery because it only executes when
the device is idle and connected to power. However, the limited availability these constraints introduce
leads directly to open research challenges which will be discussed subsequently, such as semi-cyclic data
availability and the potential for bias in client selection.

1.2

Federated Learning Research

The remainder of this paper surveys many open problems that are motivated by the constraints and challenges of real-world federated learning settings, from training models on medical data from a hospital system to training using hundreds of millions of mobile devices. Needless to say, most researchers working on
federated learning problems will likely not be deploying production FL systems, nor have access to fleets of
millions of real-world devices. This leads to a key distinction between the practical settings that motivate the
work and experiments conducted in simulation which provide evidence of the suitability of a given approach
to the motivating problem.
This makes FL research somewhat different than other ML fields from an experimental perspective, leading to additional considerations in conducting FL research. In particular, when highlighting open problems,
we have attempted, when possible, to also indicate relevant performance metrics which can be measured
in simulation, the characteristics of datasets which will make them more representative of real-world performance, etc. The need for simulation also has ramifications for the presentation of FL research. While
not intended to be authoritative or absolute, we make the following modest suggestions for presenting FL
research that addresses the open problems we describe:
• As shown in Table 1, the FL setting can encompass a wide range of problems. Compared to fields
where the setting and goals are well-established, it is important to precisely describe the details of
the particular FL setting of interest, particularly when the proposed approach makes assumptions that
may not be appropriate in all settings (e.g. stateful clients that participate in all rounds).
• Of course, details of any simulations should be presented in order to make the research reproducible.
But it is also important to explain which aspects of the real-world setting the simulation is designed
to capture (and which it is not), in order to effectively make the case that success on the simulated
9

problem implies useful progress on the real-world objective. We hope that the guidance in this paper
will help with this.
• Privacy and communication efficiency are always first-order concerns in FL, even if the experiments
are simulations running on a single machine using public data. More so than with other types of ML,
for any proposed approach it is important to be unambiguous about where computation happens as
well as what is communicated.
Software libraries for federated learning simulation as well as standard datasets can help ease the challenges of conducting effective FL research; Appendix A summarizes some of the currently available options.
Developing standard evaluation metrics and establishing standard benchmark datasets for different federated
learning settings (cross-device and cross-silo) remain highly important directions for ongoing work.

1.3

Organization

Section 2 builds on the ideas in Table 1, exploring other FL settings and problems beyond the original
focus on cross-device settings. Section 3 then turns to core questions around improving the efficiency
and effectiveness of federated learning. Section 4 undertakes a careful consideration of threat models and
considers a range of technologies toward the goal of achieving rigorous privacy protections. As with all
machine learning systems, in federated learning applications there may be incentives to manipulate the
models being trained, and failures of various kinds are inevitable; these challenges are discussed in Section 5.
Finally, we address the important challenges of providing fair and unbiased models in Section 6.

10

2

Relaxing the Core FL Assumptions: Applications to Emerging Settings
and Scenarios

In this section, we will discuss areas of research related to the topics discussed in the previous section. Even
though not being the main focus of the remainder of the paper, progress in these areas could motivate design
of the next generation of production systems.

2.1

Fully Decentralized / Peer-to-Peer Distributed Learning

In federated learning, a central server orchestrates the training process and receives the contributions of
all clients. The server is thus a central player which also potentially represents a single point of failure.
While large companies or organizations can play this role in some application scenarios, a reliable and
powerful central server may not always be available or desirable in more collaborative learning scenarios
[459]. Furthermore, the server may even become a bottleneck when the number of clients is very large, as
demonstrated by Lian et al. [305] (though this can be mitigated by careful system design, e.g. [81]).
The key idea of fully decentralized learning is to replace communication with the server by peer-topeer communication between individual clients. The communication topology is represented as a connected
graph in which nodes are the clients and an edge indicates a communication channel between two clients.
The network graph is typically chosen to be sparse with small maximum degree so that each node only
needs to send/receive messages to/from a small number of peers; this is in contrast to the star graph of the
server-client architecture. In fully decentralized algorithms, a round corresponds to each client performing
a local update and exchanging information with their neighbors in the graph2 . In the context of machine
learning, the local update is typically a local (stochastic) gradient step and the communication consists in
averaging one’s local model parameters with the neighbors. Note that there is no longer a global state of the
model as in standard federated learning, but the process can be designed such that all local models converge
to the desired global solution, i.e., the individual models gradually reach consensus. While multi-agent
optimization has a long history in the control community, fully decentralized variants of SGD and other
optimization algorithms have recently been considered in machine learning both for improved scalability
in datacenters [29] as well as for decentralized networks of devices [127, 459, 443, 59, 278, 291, 173].
They consider undirected network graphs, although the case of directed networks (encoding unidirectional
channels which may arise in real-world scenarios such as social networks or data markets) has also been
studied in [29, 226].
It is worth noting that even in the decentralized setting outlined above, a central authority may still be in
charge of setting up the learning task. Consider for instance the following questions: Who decides what is
the model to be trained in the decentralized setting? What algorithm to use? What hyperparameters? Who
is responsible for debugging when something does not work as expected? A certain degree of trust of the
participating clients in a central authority would still be needed to answer these questions. Alternatively, the
decisions could be taken by the client who proposes the learning task, or collaboratively through a consensus
scheme (see Section 2.1.2).
Table 3 provides a comparison between federated and peer-to-peer learning. While the architectural
assumptions of decentralized learning are distinct from those of federated learning, it can often be applied to
similar problem domains, many of the same challenges arise, and there is significant overlap in the research
communities. Thus, we consider decentralized learning in this paper as well; in this section challenges
2

Note, however, that the notion of a round does not need to even make sense in this setting. See for instance the discussion on
clock models in [85].

11

Federated learning

Fully decentralized
(peer-to-peer) learning

Orchestration

A central orchestration server or service organizes the training, but never
sees raw data.

No centralized orchestration.

Wide-area communication

Typically a hub-and-spoke topology,
with the hub representing a coordinating service provider (typically
without data) and the spokes connecting to clients.

Peer-to-peer topology, with a possibly dynamic connectivity graph.

Table 3: A comparison of the key distinctions between federated learning and fully decentralized learning.
Note that as with FL, decentralized learning can be further divided into different use-cases, with distinctions
similar to those made in Table 1 comparing cross-silo and cross-device FL.
specific to the decentralized approach are explicitly considered, but many of the open problems in other
sections also arise in the decentralized case.
2.1.1

Algorithmic Challenges

A large number of important algorithmic questions remain open on the topic of real-world usability of decentralized schemes for machine learning. Some questions are analogous to the special case of federated
learning with a central server, and other challenges come as an additional side-effect of being fully decentralized or trust-less. We outline some particular areas in the following.
Effect of network topology and asynchrony on decentralized SGD Fully decentralized algorithms for
learning should be robust to the limited availability of the clients (with clients temporarily unavailable,
dropping out or joining during the execution) and limited reliability of the network (with possible message
drops). While for the special case of generalized linear models, schemes using the duality structure could
enable some of these desired robustness properties [231], for the case of deep learning and SGD this remains
an open question. When the network graph is complete but messages have a fixed probability to be dropped,
Yu et al. [498] show that one can achieve convergence rates that are comparable to the case of a reliable network. Additional open research questions concern non-IID data distributions, update frequencies, efficient
communication patterns and practical convergence time [443], as we outline in more detail below.
Well-connected or denser networks encourage faster consensus and give better theoretical convergence
rates, which depend on the spectral gap of the network graph. However, when data is IID, sparser topologies
do not necessarily hurt the convergence in practice: this was analyzed theoretically in [357]. Denser networks typically incur communication delays which increase with the node degrees. Most of optimizationtheory works do not explicitly consider how the topology affects the runtime, that is, wall-clock time required to complete each SGD iteration. Wang et al. [469] propose MATCHA, a decentralized SGD method
based on matching decomposition sampling, that reduces the communication delay per iteration for any
given node topology while maintaining the same error convergence speed. The key idea is to decompose the
graph topology into matchings consisting of disjoint communication links that can operate in parallel, and
carefully choose a subset of these matchings in each iteration. This sequence of subgraphs results in more
12

frequent communication over connectivity-critical links (ensuring fast error convergence) and less frequent
communication over other links (saving communication delays).
The setting of decentralized SGD also naturally lends itself to asynchronous algorithms in which each
client becomes active independently at random times, removing the need for global synchronization and
potentially improving scalability [127, 459, 59, 29, 306].
Local-update decentralized SGD The theoretical analysis of schemes which perform several local update
steps before a communication round is significantly more challenging than those using a single SGD step, as
in mini-batch SGD. While this will also be discussed later in Section 3.2, the same also holds more generally
in the fully decentralized setting of interest here. Schemes relying on a single local update step are typically
proven to converge in the case of non-IID local datasets [278, 279]. For the case with several local update
steps, [467, 280] recently provided convergence analysis. Further, [469] provides a convergence analysis
for the non-IID data case, but for the specific scheme based on matching decomposition sampling described
above. In general, however, understanding the convergence under non-IID data distributions and how to
design a model averaging policy that achieves the fastest convergence remains an open problem.
Personalization, and trust mechanisms Similarly to the cross-device FL setting, an important task for
the fully decentralized scenario under the non-IID data distributions available to individual clients is to
design algorithms for learning collections of personalized models. The work of [459, 59] introduces fully
decentralized algorithms to collaboratively learn a personalized model for each client by smoothing model
parameters across clients that have similar tasks (i.e., similar data distributions). Zantedeschi et al. [504]
further learn the similarity graph together with the personalized models. One of the key unique challenges
in the decentralized setting remains the robustness of such schemes to malicious actors or contribution of
unreliable data or labels. The use of incentives or mechanism design in combination with decentralized
learning is an emerging and important goal, which may be harder to achieve in the setting without a trusted
central server.
Gradient compression and quantization methods In potential applications, the clients would often
be limited in terms of communication bandwidth available and energy usage permitted. Translating and
generalizing some of the existing compressed communication schemes from the centralized orchestratorfacilitated setting (see Section 3.5) to the fully decentralized setting, without negatively impacting the convergence is an active research direction [278, 391, 444, 279]. A complementary idea is to design decentralized optimization algorithms which naturally give rise to sparse updates [504].
Privacy An important challenge in fully decentralized learning is to prevent any client from reconstructing
the private data of another client from its shared updates while maintaining a good level of utility for the
learned models. Differential privacy (see Section 4) is the standard approach to mitigate such privacy risks.
In decentralized federated learning, this can be achieved by having each client add noise locally, as done in
[239, 59]. Unfortunately, such local privacy approaches often come at a large cost in utility. Furthermore,
distributed methods based on secure aggregation or secure shuffling that are designed to improve the privacyutility trade-off in the standard FL setting (see Section 4.4.3) do not easily integrate with fully decentralized
algorithms. A possible direction to achieve better trade-offs between privacy and utility in fully decentralized
algorithms is to rely on decentralization itself to amplify differential privacy guarantees, for instance by
considering appropriate relaxations of local differential privacy [146].

13

2.1.2

Practical Challenges

An orthogonal question for fully decentralized learning is how it can be practically realized. This section
outlines a family of related ideas based on the idea of a distributed ledger, but other approaches remain
unexplored.
A blockchain is a distributed ledger shared among disparate users, making possible digital transactions,
including transactions of cryptocurrency, without a central authority. In particular, smart contracts allow
execution of arbitrary code on top of the blockchain, essentially a massively replicated eventually-consistent
state machine. In terms of federated learning, use of the technology could enable decentralization of the
global server by using smart contracts to do model aggregation, where the participating clients executing the
smart contracts could be different companies or cloud services.
However, on today’s blockchain platforms such as Ethereum [478], data on the blockchains is publicly
available by default, this could discourage users from participating in the decentralized federated learning
protocol, as the protection of the data is typically the primary motivating factor for FL. To address such
concerns, it might be possible to modify the existing privacy-preserving techniques to fit into the scenario of
decentralized federated learning. First of all, to prevent the participating nodes from exploiting individually
submitted model updates, existing secure aggregation protocols could be used. A practical secure aggregation protocol already used in cross-device FL was proposed by Bonawitz et al. [80], effectively handling
dropping out participants at the cost of complexity of the protocol. An alternative system would be to have
each client stake a deposit of cryptocurrency on blockchain, and get penalized if they drop out during the
execution. Without the need of handling dropouts, the secure aggregation protocol could be significantly
simplified. Another way of achieving secure aggregation is to use confidential smart contract such as what is
enabled by the Oasis Protocol [119] which runs inside secure enclaves. With this, each client could simply
submit an encrypted local model update, knowing that the model will be decrypted and aggregated inside
the secure hardware through remote attestation (though see discussion of privacy-in-depth in Section 4.1).
In order to prevent any client from trying to reconstruct the private data of another client by exploiting
the global model, client-level differential privacy [338] has been proposed for FL. Client-level differential
privacy is achieved by adding random Gaussian noise on the aggregated global model that is enough to hide
any single client’s update. In the context of blockchain, each client could locally add a certain amount of
Gaussian noise after local gradient descent steps and submit the model to blockchain. The local noise scale
should be calculated such that the aggregated noise on blockchain is able to achieve the same client-level
differential privacy as in [338]. Finally, the aggregated global model on blockchain could be encrypted and
only the participating clients hold the decryption key, which protects the model from the public.

2.2

Cross-Silo Federated Learning

In contrast with the characteristics of cross-device federated learning, see Table 1, cross-silo federated learning admits more flexibility in certain aspects of the overall design, but at the same time presents a setting
where achieving other properties can be harder. This section discusses some of these differences.
The cross-silo setting can be relevant where a number of companies or organizations share incentive to
train a model based on all of their data, but cannot share their data directly. This could be due to constraints
imposed by confidentiality or due to legal constraints, or even within a single company when they cannot
centralize their data between different geographical regions. These cross-silo applications have attracted
substantial attention.

14

Data partitioning In the cross-device setting the data is assumed to be partitioned by examples. In the
cross-silo setting, in addition to partitioning by examples, partitioning by features is of practical relevance.
An example could be when two companies in different businesses have the same or overlapping set of
customers, such as a local bank and a local retail company in the same city. This difference has been also
referred to as horizontal and vertical federated learning by Yang et al. [490].
Cross-silo FL with data partitioned by features, employs a very different training architecture compared
to the setting with data partitioned by example. It may or may not involve a central server as a neutral party,
and based on specifics of the training algorithm, clients exchange specific intermediate results rather than
model parameters, to assist other parties’ gradient calculations; see for instance [490, Section 2.4.2]. In this
setting, application of techniques such as secure multi-party computation or homomorphic encryption have
been proposed in order to limit the amount of information other participants can infer from observing the
training process. The downside of this approach is that the training algorithm is typically dependent on the
type of machine learning objective being pursued. Currently proposed algorithms include trees [118], linear
and logistic regression [490, 224, 316], and neural networks [317]. Local updates similar to Federated Averaging (see Section 3.2) has been proposed to address the communication challenges of feature-partitioned
systems [316], and [238, 318] study the security and privacy related challenges inherent in such systems.
Federated transfer learning [490] is another concept that considers challenging scenarios in which data
parties share only a partial overlap in the user space or the feature space, and leverage existing transfer
learning techniques [365] to build models collaboratively. The existing formulation is limited to the case of
2 clients.
Partitioning by examples is usually relevant in cross-silo FL when a single company cannot centralize
their data due to legal constraints, or when organizations with similar objectives want to collaboratively improve their models. For instance, different banks can collaboratively train classification or anomaly detection
models for fraud detection [476], hospitals can build better diagnostic models [139], and so on.
An open-source platform supporting the above outlined applications is currently available as Federated
AI Technology Enabler (FATE) [33]. At the same time, the IEEE P3652.1 Federated Machine Learning
Working Group is focusing on standard-setting for the Federated AI Technology Framework. Other platforms include [125] focused on a range of medical applications and [321] for enterprise use cases. See
Appendix A for more details.
Incentive mechanisms In addition to developing new algorithmic techniques for FL, incentive mechanism
design for honest participation is an important practical research question. This need may arise in crossdevice settings (e.g. [261, 260]), but is particularly relevant in the cross-silo setting, where participants may
at the same time also be business competitors. The incentive can be in the form of monetary payout [499]
or final models with different levels of performance [324]. The option to deliver models with performance
commensurate to the contributions of each client is especially relevant in collaborative learning situations
in which competitions exist among FL participants. Clients might worry that contributing their data to
training federated learning models will benefit their competitors, who do not contribute as much but receive
the same final model nonetheless (i.e. the free-rider problem). Related objectives include how to divide
earnings generated by the federated learning model among contributing data owners in order to sustain
long-term participation, and also how to link the incentives with decisions on defending against adversarial
data owners to enhance system security, optimizing the participation of data owners to enhance system
efficiency.

15

Differential privacy The discussion of actors and threat models in Section 4.1 is largely relevant also for
the cross-silo FL. However, protecting against different actors might have different priorities. For example,
in many practical scenarios, the final trained model would be released only to those who participate in the
training, which makes the concerns about “the rest of the world” less important.
On the other hand, for a practically persuasive claim, we would usually need a notion of local differential
privacy, as the potential threat from other clients is likely to be more important. In cases when the clients
are not considered a significant threat, each client could control the data from a number of their respective
users, and a formal privacy guarantee might be needed on such user-level basis. Depending on application,
other objectives could be worth pursuing. This area has not been systematically explored.
Tensor factorization Several works have also studied cross-silo federated tensor factorization where multiple sites (each having a set of data with the same feature, i.e. horizontally partitioned) jointly perform
tensor factorization by only sharing intermediate factors with the coordination server while keeping data
private at each site. Among the existing works, [272] used an alternating direction method of multipliers (ADMM) based approach and [325] improved the efficiency with the elastic averaging SGD (EASGD)
algorithm and further ensures differential privacy for the intermediate factors.

2.3

Split Learning

In contrast with the previous settings which focus on data partitioning and communication patterns, the key
idea behind split learning [215, 460]3 is to split the execution of a model on a per-layer basis between the
clients and the server. This can be done for both training and inference.
In the simplest configuration of split learning, each client computes the forward pass through a deep
network up to a specific layer referred to as the cut layer. The outputs at the cut layer, referred to as
smashed data, are sent to another entity (either the server or another client), which completes the rest of the
computation. This completes a round of forward propagation without sharing the raw data. The gradients
can then be back propagated from its last layer until the cut layer in a similar fashion. The gradients at the
cut layer – and only these gradients – are sent back to the clients, where the rest of back propagation is
completed. This process is continued until convergence, without having clients directly access each others
raw data. This setup is shown in Figure 2(a) and a variant of this setup where labels are also not shared
along with raw data is shown in Figure 2(b). Split learning approaches for data partitioned by features have
been studied in [101].
In several settings, the overall communication requirements of split learning and federated learning
were compared in [421]. Split learning brings in another dimension of parallelism in the training, parallelization among parts of a model, e.g. client and server. The ideas in [245, 240], where the authors break
the dependencies between partial networks and reduced total centralized training time by parallelizing the
computations in different parts, can be relevant here as well. However, it is still an open question to explore
such parallelization of split learning on edge devices. Split learning also enables matching client-side model
components with the best server-side model components for automating model selection as shown in the
ExpertMatcher [413].
The values communicated can nevertheless, in general, reveal information about the underlying data.
How much, and whether this is acceptable, is likely going to be application and configuration specific. A
variation of split learning called NoPeek SplitNN [462] reduces the potential leakage via communicated activations, by reducing their distance correlation [461, 442] with the raw data, while maintaining good model
3

See also split learning project website - https://splitlearning.github.io/.

16

(a) Vanilla split learning

(b) U-shaped split learning

Figure 2: Split learning configurations showing raw data is not transferred in the vanilla setting and that raw
data as well as labels are not transferred between the client and server entities in the U-shaped split learning
setting.
performance via categorical cross-entropy. The key idea is to minimize the distance correlation between the
raw data points and communicated smashed data. The objects communicated could otherwise contain information highly correlated with the input data if used without NoPeek SplitNN, the use of which also enables
the split to be made relatively early-on given the decorrelation it provides. One other engineering driven
approach to minimize the amount of information communicated in split learning has been via a specifically
learnt pruning of channels present in the client side activations [422]. Overall, much of the discussion in
Section 4 is relevant here as well, and analysis providing formal privacy guarantees specifically for split
learning is still an open problem.

2.4

Executive summary

The motivation for federated learning is relevant for a number of related areas of research.
• Fully decentralized learning (Section 2.1) removes the need for a central server coordinating the overall computation. Apart from algorithmic challenges, open problems are in practical realization of the
idea and in understanding of what form of trusted central authority is needed to set up the task.
• Cross-silo federated learning (Section 2.2) admits problems with different kinds of modelling constraints, such as data partitioned by examples and/or features, and faces different set of concerns
when formulating formal privacy guarantees or incentive mechanisms for clients to participate.
• Split learning (Section 2.3) is an approach to partition the execution of a model between the clients
and the server. It can deliver different options for overall communication constraints, but detailed
analysis of when the communicated values reveal sensitive information is still missing.

17

3

Improving Efficiency and Effectiveness

In this section we explore a variety of techniques and open questions that address the challenge of making
federated learning more efficient and effective. This encompasses a myriad of possible approaches, including: developing better optimization algorithms; providing different models to different clients; making ML
tasks like hyperparameter search, architecture search, and debugging easier in the FL context; improving
communication efficiency; and more.
One of the fundamental challenges in addressing these goals is the presence of non-IID data, so we begin
by surveying this issue and highlighting potential mitigations.

3.1

Non-IID Data in Federated Learning

While the meaning of IID is generally clear, data can be non-IID in many ways. In this section, we provide
a taxonomy of non-IID data regimes that may arise for any client-partitioned dataset. The most common
sources of dependence and non-identicalness are due to each client corresponding to a particular user, a
particular geographic location, and/or a particular time window. This taxonomy has a close mapping to
notions of dataset shift [353, 380], which studies differences between the training distribution and testing
distribution; here, we consider differences in the data distribution on each client.
For the following, consider a supervised task with features x and labels y. A statistical model of federated learning involves two levels of sampling: accessing a datapoint requires first sampling a client i ∼ Q,
the distribution over available clients, and then drawing an example (x, y) ∼ Pi (x, y) from that client’s
local data distribution.
When non-IID data in federated learning is referenced, this typically refers to differences between Pi
and Pj for different clients i and j. However, it is also important to note that the distribution Q and Pi may
change over time, introducing another dimension of “non-IIDness”.
For completeness, we note that even considering the dataset on a single device, if the data is in an
insufficiently-random order, e.g. ordered by time, then independence is violated locally as well. For example, consecutive frames in a video are highly correlated. Sources of intra-client correlation can generally be
resolved by local shuffling.
Non-identical client distributions We first survey some common ways in which data tend to deviate
from being identically distributed, that is Pi 6= Pj for different clients i and j. Rewriting Pi (x, y) as
Pi (y | x)Pi (x) and Pi (x | y)Pi (y) allows us to characterize the differences more precisely.
• Feature distribution skew (covariate shift): The marginal distributions Pi (x) may vary across clients,
even if P(y | x) is shared.4 For example, in a handwriting recognition domain, users who write the
same words might still have different stroke width, slant, etc.
• Label distribution skew (prior probability shift): The marginal distributions Pi (y) may vary across
clients, even if P(x | y) is the same. For example, when clients are tied to particular geo-regions,
the distribution of labels varies across clients — kangaroos are only in Australia or zoos; a person’s
face is only in a few locations worldwide; for mobile device keyboards, certain emoji are used by one
demographic but not others.
4

We write “P(y | x) is shared” as shorthand for Pi (y | x) = Pj (y | x) for all clients i and j.

18

• Same label, different features (concept drift): The conditional distributions Pi (x | y) may vary across
clients even if P(y) is shared. The same label y can have very different features x for different
clients, e.g. due to cultural differences, weather effects, standards of living, etc. For example, images
of homes can vary dramatically around the world and items of clothing vary widely. Even within the
U.S., images of parked cars in the winter will be snow-covered only in certain parts of the country. The
same label can also look very different at different times, and at different time scales: day vs. night,
seasonal effects, natural disasters, fashion and design trends, etc.
• Same features, different label (concept shift): The conditional distribution Pi (y | x) may vary across
clients, even if P(x) is the same. Because of personal preferences, the same feature vectors in a
training data item can have different labels. For example, labels that reflect sentiment or next word
predictors have personal and regional variation.
• Quantity skew or unbalancedness: Different clients can hold vastly different amounts of data.
Real-world federated learning datasets likely contain a mixture of these effects, and the characterization
of cross-client differences in real-world partitioned datasets is an important open question. Most empirical
work on synthetic non-IID datasets (e.g. [337, 236]) have focused on label distribution skew, where a nonIID dataset is formed by partitioning a “flat” existing dataset based on the labels. A better understanding of
the nature of real-world non-IID datasets will allow for the construction of controlled but realistic non-IID
datasets for testing algorithms and assessing their resilience to different degrees of client heterogeneity.
Further, different non-IID regimes may require the development of different mitigation strategies. For
example, under feature-distribution skew, because P(y | x) is assumed to be common, the problem is at least
in principle well specified, and training a single global model that learns P(y | x) may be appropriate. When
the same features map to different labels on different clients, some form of personalization (Section 3.3)
may be essential to learning the true labeling functions.
Violations of independence Violations of independence are introduced any time the distribution Q changes
over the course of training; a prominent example is in cross-device FL, where devices typically need to meet
eligibility requirements in order to participate in training (see Section 1.1.2). Devices typically meet those
requirements at night local time (when they are more likely to be charging, on free wi-fi, and idle), and so
there may be significant diurnal patterns in device availability. Further, because local time of day corresponds directly to longitude, this introduces a strong geographic bias in the source of the data. Eichner et al.
[171] described this issue and some mitigation strategies, but many open questions remain.
Dataset shift Finally, we note that the temporal dependence of the distributions Q and P may introduce
dataset shift in the classic sense (differences between the train and test distributions). Furthermore, other
criteria may make the set of clients eligible to train a federated model different from the set of clients where
that model will be deployed. For example, training may require devices with more memory than is needed
for inference. These issues are explored in more depth in Section 6. Adapting techniques for handling
dataset shift to federated learning is another interesting open question.
3.1.1

Strategies for Dealing with Non-IID Data

The original goal of federated learning, training a single global model on the union of client datasets, becomes harder with non-IID data. One natural approach is to modify existing algorithms (e.g. through

19

different hyperparameter choices) or develop new ones in order to more effectively achieve this objective.
This approach is considered in Section 3.2.2.
For some applications, it may be possible to augment data in order to make the data across clients more
similar. One approach is to create a small dataset which can be shared globally. This dataset may originate
from a publicly available proxy data source, a separate dataset from the clients’ data which is not privacy
sensitive, or perhaps a distillation of the raw data following Wang et al. [473].
The heterogeneity of client objective functions gives additional importance to the question of how to
craft the objective function — it is no-longer clear that treating all examples equally makes sense. Alternatives include limiting the contributions of the data from any one user (which is also important for privacy,
see Section 4) and introducing other notions of fairness among the clients; see discussion in Section 6.
But if we have the capability to run training on the local data on each device (which is necessary for
federated learning of a global model), is training a single global model even the right goal? There are
many cases where having a single model is to be preferred, e.g. in order to provide a model to clients with
no data, or to allow manual validation and quality assurance before deployment. Nevertheless, since local
training is possible, it becomes feasible for each client to have a customized model. This approach can turn
the non-IID problem from a bug to a feature, almost literally — since each client has its own model, the
client’s identity effectively parameterizes the model, rendering some pathological but degenerate non-IID
distributions trivial. For example, if for each i, Pi (y) has support on only a single label, finding a highaccuracy global model may be very challenging (especially if x is relatively uninformative), but training a
high-accuracy local model is trivial (only a constant prediction is needed). Such multi-model approaches
are considered in depth in Section 3.3. In addition to addressing non-identical client distributions, using a
plurality of models can also address violations of independence stemming from changes in client availability.
For example, the approach of Eichner et al. [171] uses a single training run but averages different iterates in
order to provide different models for inference based on the timezone / longitude of clients.

3.2

Optimization Algorithms for Federated Learning

In prototypical federated learning tasks, the goal is to learn a single global model that minimizes the empirical risk function over the entire training dataset, that is, the union of the data across all the clients. The
main difference between federated optimization algorithms and standard distributed training methods is the
need to address the characteristics of Table 1 — for optimization, non-IID and unbalanced data, limited
communication bandwidth, and unreliable and limited device availability are particularly salient.
FL settings where the total number of devices is huge (e.g. across mobile devices) necessitate algorithms
that only require a handful of clients to participate per round (client sampling). Further, each device is likely
to participate no more than once in the training of a given model, so stateless algorithms are necessary. This
rules out the direct application of a variety of approaches that are quite effective in the datacenter context,
for example stateful optimization algorithms like ADMM, and stateful compression strategies that modify
updates based on residual compression errors from previous rounds.
Another important practical consideration for federated learning algorithms is composability with other
techniques. Optimization algorithms do not run in isolation in a production deployment, but need to be
combined with other techniques like cryptographic secure aggregation protocols (Section 4.2.1), differential
privacy (DP) (Section 4.2.2), and model and update compression (Section 3.5). As noted in Section 1.1.2,
many of these techniques can be applied to primitives like “sum over selected clients” and
“broadcast to selected clients”, and so expressing optimization algorithms in terms of these
primitives provides a valuable separation of concerns, but may also exclude certain techniques such as ap20

N
M
T
K

Total number of clients
Clients per round
Total communication rounds
Local steps per round.

Table 4: Notation for the discussion of FL
algorithms including Federated Averaging.

Server executes:
initialize x0
for each round t = 1, 2, . . . , T do
St ← (random set of M clients)
for each client i ∈ St in parallel do
xit+1 ← ClientUpdate(i, xt )
P
1 i
xt+1 ← M
k=1 M xt+1
ClientUpdate(i, x):
for local step j = 1, . . . , K do
x ← x − ηOf (x; z) for z ∼ Pi
return x to server
Algorithm 1: Federated Averaging (local SGD), when all
clients have the same amount of data.

plying updates asynchronously.
One of the most common approaches to optimization for federated learning is the Federated Averaging
algorithm [337], an adaption of local-update or parallel SGD.5 Here, each client runs some number of SGD
steps locally, and then the updated local models are averaged to form the updated global model on the
coordinating server. Pseudocode is given in Algorithm 1.
Performing local updates and communicating less frequently with the central server addresses the core
challenges of respecting data locality constraints and of the limited communication capabilities of mobile
device clients. However, this family of algorithms also poses several new algorithmic challenges from
an optimization theory point of view. In Section 3.2, we discuss recent advances and open challenges
in federated optimization algorithms for the cases of IID and non-IID data distribution across the clients
respectively. The development of new algorithms that specifically target the characteristics of the federated
learning setting remains an important open problem.
3.2.1

Optimization Algorithms and Convergence Rates for IID Datasets

While a variety of different assumptions can be made on the per-client functions being optimized, the most
basic split is between assuming IID and non-IID data. Formally, having IID data at the clients means
that each mini-batch of data used for a client’s local update is statistically identical to a uniformly drawn
sample (with replacement) from the entire training dataset (the union of all local datasets at the clients).
Since the clients independently collect their own training data which vary in both size and distribution, and
these data are not shared with other clients or the central node, the IID assumption clearly almost never
holds in practice. However, this assumption greatly simplifies theoretical convergence analysis of federated
optimization algorithms, as well as establishes a baseline that can be used to understand the impact of nonIID data on optimization rates. Thus, a natural first step is to obtain an understanding of the landscape of
optimization algorithms for the IID data case.
5

Federated Averaging applies local SGD to a randomly sampled subset of clients on each round, and proposes a specific update
weighting scheme.

21

Formally, for the IID setting let us standardize the stochastic optimization problem
min F (x) := E [f (x; z)] .

x∈Rm

z∼P

We assume an intermittent communication model as in e.g. Woodworth et al. [480, Sec. 4.4], where M
stateless clients participate in each of T rounds, and during each round, each client can compute gradients
for K samples (e.g. minibatches) z1 , . . . , zK sampled IID from P (possibly using these to take sequential
steps). In the IID-data setting clients are interchangeable, and we can without loss of generality assume
M = N . Table 4 summarizes the notation used in this section.
Different assumptions on f will produce different guarantees. We will first discuss the convex setting
and later review results for non-convex problems.
Baselines and state-of-the-art for convex problems In this section we review convergence results for
H-smooth, convex (but not necessarily strongly convex) functions under the assumption that the variance
of the stochastic gradients is bounded by σ 2 . More formally, by H-smooth we mean that for all z, f (·; z) is
differentiable and has a H-Lipschitz gradient, that is, for all choices of x, y
k∇f (x, z) − ∇f (y, z)k ≤ Hkx − yk.
We also assume that for all x, the stochastic gradient ∇x f (x; z) satisfies
E k∇x f (x; z) − ∇F (x)k ≤ σ 2 .

z∼P

When analyzing the convergence rate of an algorithm with output xT after T iterations, we consider the
term
E[F (xT )] − F (x∗ )
(1)
where x∗ = arg minx F (x). All convergence rates discussed herein are upper bounds on this term. A
summary of convergence results for such functions is given in Table 5.
Federated averaging (a.k.a. parallel SGD/local SGD) competes with two natural baselines: First, we
may keep x fixed in local updates during each round, and compute a total of KM gradients at the current x,
in order to run accelerated minibatch SGD. Let x̄ denote the average of T iterations of this algorithm. We
then have the upper bound


H
σ
O
+√
T2
T KM
for convex objectives [294, 137, 151]. Note that the first expectation is taken with respect to the randomness
of z in the training procedure as well.
A second natural baseline is to ignore all but 1 of the M active clients, which allows (accelerated)
sequential SGD to execute for KT steps. Applying the same general bounds cited above, this approach
offers an upper bound of


H
σ
O
+√
.
(T K)2
TK
√

Comparing these two results, we see that minibatch SGD attains the optimal ‘statistical’ term (σ/ T KM ),
whilst SGD on a single device (ignoring the updates of the other devices) achieves the optimal ‘optimization’
term (H/(T K)2 ).
The convergence analysis of local-update SGD methods is an active current area of research [434, 310,
500, 467, 390, 371, 269, 481]. The first convergence results for local-update SGD methods were derived
22

Method

Comments

Convergence

mini-batch SGD

batch size KM

O

SGD

(on 1 worker, no communication)

O

A-mini-batch SGD [294, 137]

batch size KM

O

A-SGD [294]

(on 1 worker, no communication)

O

gradient norm bounded by G

O

Baselines
H
T
H
TK

+ √T σKM

+ √Tσ K



H
2
T

+ √T σKM

+ √Tσ K



Baselines with accelerationa
H
(T K)2

Parallel SGD / Fed-Avg / Local SGD

Yu et al. [500]b , Stich [434]c

Wang and Joshi [467]b , Stich and Karimireddy [435]

O





HKM G2 √ σ
+ T KM
T
σ2

HM
√ σ
+
T
T KM

Other algorithms

SCAFFOLD [265]

control variates and two stepsizes

O

H
T

+ √T σKM



a

There are no accelerated fed-avg/local SGD variants so far
This paper considers the smooth non-convex setting, we adapt here the results for our setting.
c
This paper considers the smooth strongly convex setting, we adapt here the results for our setting.

b

Table 5: Convergence rates for a (non-comprehensive) set of distributed optimization algorithms in the IIDdata setting. We assume M devices participate in each iterations, and the loss functions are H-smooth,
convex, and we have access to stochastic gradients with variance at most σ 2 . All rates are upper bounds
on (1) after T iterations (potentially with some iterate averaging scheme).

under the bounded gradient norm assumption in Stich [434] for strongly-convex
√ and in Yu et al. [500] for
non-convex objective functions. These analyses could attain the desired σ/ T KM statistical term with
suboptimal optimization term (in Table 5 we summarize these results for the middle ground of convex
functions).
By removing the bounded gradient assumption, Wang and Joshi [467] and Stich and Karimireddy [435]
could further improve the optimization term to HM/T . These result show that if the number of local steps
K is smaller than T /M 3 then the (optimal) statistical term is dominating the rate. However, for typical
cross-device applications we might have T = 106 and M = 100 (Table 2), implying K = 1.
Often in the literature the convergence bounds are accompanied by a discussion on how large K may
be chosen in order to reach asymptotically the same statistical term as the convergence rate of mini-batch
SGD. For strongly convex functions, this bound was improved by Khaled et al. [269] and further in Stich
and Karimireddy [435].
For non-convex
objectives, Yu et al. [500] showed that local SGD can achieve asymptotically an error
√
bound 1/ T KM if the number of local updates K are smaller than T 1/3 /M . This convergence guarantee
was further improved by Wang and Joshi [467] who removed the bounded gradient norm assumption and
showed that the number of local updates can be as large as T /M 3 . The analysis in [467] can also be applied
to other algorithms with local updates, and thus yields the first convergence guarantee for decentralized
SGD with local updates (or periodic decentralized SGD) and elastic averaging SGD [505]. Haddadpour
et al. [216] improves the bounds in Wang and Joshi [467] for functions satisfying the Polyak-Lojasiewicz
23

(PL) condition [262], a generalization of strong convexity. In particular, Haddadpour et al. [216] show that
for PL functions, T 2 /M local updates per round leads to a O(1/T KM ) convergence.
While the above works focus on convergence as a function of the number of iterations performed, practitioners often care about wall-clock convergence speed. Assessing this must take into account the effect
of the design parameters on the time spent per iteration based on the relative cost of communication and
local computation. Viewed in this light, the focus on seeing how large K can be while maintaining the
statistical rate may not be the primary concern in federated learning, where one may assume almost infinite
datasets (very large N ). The costs (at least in wall-clock time) are small for increasing M , and so it may
be more natural to increase M sufficiently to match the optimization term, and then tune K to maximize
wall-clock optimization performance. How then to choose K? Performing more local updates at the clients
will increase the divergence between the resulting local models at the clients, before they are averaged. As a
result, the error convergence in terms of training loss versus the total number of sequential SGD steps T K is
slower. However, performing more local updates saves significant communication cost and reduces the time
spent per iteration. The optimal number of local updates strikes a balance between these two phenomena
and achieves the fastest error versus wallclock time convergence. Wang and Joshi [468] propose an adaptive
communication strategy that adapts K according to the training loss at regular intervals during the training.
Another important design parameter in federated learning is the model aggregation method used to
update the global model using the updates made by the selected clients. In the original federated learning
paper, McMahan et al. [337] proposes taking a weighted average of the local models, in proportion to the
size of local datasets. For IID data, where each client is assumed to have a infinitely large dataset, this
reduces to taking a simple average of the local models. However, it is unclear whether this aggregation
method will result in the fastest error convergence.
There are many open questions in federated optimization, even with IID data. Woodworth et al. [480]
highlights several gaps between upper and lower bounds for optimization relevant to the federated learning
setting, particularly for “intermittent communication graphs”, which captures local SGD approaches, but
convergence rates for such approaches are not known to match the corresponding lower bounds. In Table 5
we highlight convergence results for the convex setting. Whilst most schemes are able to reach the asymptotically dominant statistical term, none are able to match the convergence rate of accelerated mini-batch
SGD. It is an open problem if federated averaging algorithms can close this gap.
Local-update SGD methods where all M clients perform the same number of local updates may suffer
from a common scalability issue—they can be bottlenecked if any one client unpredictably slows down
or fails. Several approaches for dealing with this are possible, but it is far from clear which are optimal,
especially when the potential for bias is considered (see Section 6). Bonawitz et al. [81] propose overprovisioning clients (e.g., request updates from 1.3M clients), and then accepting the first M updates received and rejecting updates from stragglers. A slightly more sophisticated solution is to fix a time window
and allow clients to perform as many local updates Ki as possible within this time, after which their models
are averaged by a central server. Wang et al. [471] analyzed the computational heteogeneity introduced by
this approach in theory. An alternative method to overcome the problem of straggling clients is to fix the
number of local updates at τ , but allow clients to update the global model in an asynchronous or lock-free
fashion. Although some previous works [505, 306, 163] have proposed similar methods, the error convergence analysis is an open and challenging problem. A larger challenge in the FL setting, however, is that
as discussed at the beginning of Section 3.2, asynchronous approaches may be difficult to combine with
complimentary techniques like differential privacy or secure aggregation.
Besides the number of local updates, the choice of the size of the set of clients selected per training round
presents a similar trade-off as the number of local updates. Updating and averaging a larger number of client
models per training round yields better convergence, but it makes the training vulnerable to slowdown due
24

to unpredictable tail delays in computation/communication at/with the clients.
The analysis of local SGD / Federated Averaging in the non-IID setting is even more challenging; results
and open questions related to this are considered in the next section, along with specialized algorithms which
directly address the non-IID problem.
3.2.2

Optimization Algorithms and Convergence Rates for Non-IID Datasets

In contrast to well-shuffled mini-batches consisting of independent and identically distributed (IID) examples in centralized learning, federated learning uses local data from end user devices, leading to many
varieties of non-IID data (Section 3.1).
In this setting, each of N clients has a local data distribution Pi and a local objective function
fi (x) = E [f (x; z)]
z∼Pi

where we recall that f (x; z) is the loss of a model x at an example z. We typically wish to minimize
N

F (x) =

1 X
fi (x) .
N

(2)

i=1

Note that we recover the IID setting when each Pi is identical. We will let F ∗ denote the minimum value of
F , obtained the point x∗ . Analogously, we will let fi∗ denote the minimum value of fi .
As in the IID setting, we assume an intermittent communication model (e.g. Woodworth et al. [480,
Sec. 4.4]), where M stateless clients participate in each of T rounds, and during each round, each client can
compute gradients for K samples (e.g. minibatches). The difference here is that the samples zi,1 , . . . , zi,K
sampled at client i are drawn from the client’s local distribution Pi . Unlike the IID setting, we cannot
necessarily assume M = N , as the client distributions are not all equal. In the following, if an algorithm
relies on M = N , we will omit M and simply write N . We note that while such an assumption may
be compatible with the cross-silo federated setting in Table 1, it is generally infeasible in the cross-device
setting.
While [434, 500, 467, 435] mainly focused on the IID case, the analysis technique can be extended to
the non-IID case by adding an assumption on data dissimilarities, for example by constraining the difference
between client gradients and the global gradient [305, 300, 304, 469, 471] or the difference between client
and global optimum values [303, 268]. Under this assumption, Yu et al. [501] showed√that the error bound
of local SGD in the non-IID case becomes worse. In order to achieve the rate of 1/ T KN (under nonconvex objectives), the number of local updates K should be smaller than T 1/3 /N , instead of T /N 3 as in
the IID case [467]. Li et al. [300] proposed to add a proximal term in each local objective function so as
to make the algorithm be more robust to the heterogeneity across local objectives. The proposed FedProx
algorithm empirically improves the performance of federated averaging. Khaled et al. [268] assumes all
clients participate, and uses batch gradient descent on clients, which can potentially converge faster than
stochastic gradients on clients.
Recently, a number of works have made progress in relaxing the assumptions necessary for analysis so as
to better apply to practical uses of Federated Averaging. For example, Li et al. [303] studied the convergence
of Federated Averaging in a more realistic setting where only a subset of clients are involved in each round.
In order to guarantee the convergence, they assumed that the clients are selected either uniformly at random
or with probabilities that are in proportion to the sizes of local datasets. Nonetheless, in practice the server
may not be able to sample clients in these idealized ways — in particular, in cross-device settings only
25

Non-IID assumptions
Symbol

Full name

Explanation

BCGV
BOBD
BOGV
BGV

bounded inter-client gradient variance
bounded optimal objective difference
bounded optimal gradient variance
bounded gradient dissimilarity

Ei k∇fi (x) − ∇F (x)k2 ≤ η 2
F ∗ − Ei [fi∗ ] ≤ η 2
Ei k∇fi (x∗ )k2 ≤ η 2
Ei k∇fi (x)k2/k∇F (x)k2 ≤ η 2

Other assumptions and variants
Symbol

Explanation

CVX
SCVX
BNCVX
BLGV
BLGN
LBG
Dec
AC
1step
Prox
VR

Each client function fi (x) is convex.
Each client function fi (x) is µ-strongly convex.
Each client function has bounded nonconvexity with ∇2 fi (x)  −µI.
The variance of stochastic gradients on local clients is bounded.
The norm of any local gradient is bounded.
Clients use the full batch of local samples to compute updates.
Decentralized setting, assumes the the connectivity of network is good.
All clients participate in each round.
One local update is performed on clients in each round.
Use proximal gradient steps on clients.
Variance reduction which needs to track the state.
Convergence rates

Method

Non-IID

Other assumptions

Variant

Rate

Lian et al. [305]
PD-SGD [304]
MATCHA [469]
Khaled et al. [268]
Li et al. [303]
FedProx [300]
SCAFFOLD [265]

BCGV
BCGV
BCGV
BOGV
BOBD
BGV
-

BLGV
BLGV
BLGV
CVX
SCVX; BLGV; BLGN
BNCVX
SCVX; BLGV

Dec; AC; 1step
Dec; AC
Dec
AC; LBG
Prox
VR

O(1/T ) + O(1/ N T )
√
O(N/T ) + O(1/ N T )
√
O(1/ T KM ) + O(M/KT )
√
O(N/T ) + O(1/ N T )
O(K/T )
√
O(1/ T )
O(1/T KM ) + O(e−T )

√

Table 6: Convergence rates for a (non-comprehensive) set of federated optimization methods in non-IID
settings. We summarize the key assumptions for non-IID data, local functions on each client, and other
assumptions. We also present the variant of the algorithm comparing to Federated Averaging and the convergence rates that eliminate constant.

26

devices that meet strict eligibility requirements (e.g. charging, idle, free WiFi) will be selected to participate
in the computation. At different times within a day, the clients characteristics can vary significantly. Eichner
et al. [171] formulated this problem and studied the convergence of semi-cyclic SGD, where multiple blocks
of clients with different characteristics are sampled from following a regular cyclic pattern (e.g. diurnal).
Clients can perform different local steps because of heterogeneity in their computing capacities. Wang
et al. [471] proves that FedAvg and many other federated learning algorithms will converge to the stationary
points of a mismatched objective function in the presence of heterogeneous local steps. They refer to this
problem as objective inconsistency and propose a simple technique to eliminate the inconsistency problem
from federated learning algorithms.
We summarize recent theoretical results in Table 6. All the methods in Table 6 assume smoothness or
Lipschitz gradients for the local functions on clients. The error bound is measured by optimal objective
(1) for convex functions and norm of gradient for nonconvex functions. For each method, we present the
key non-IID assumption, assumptions on each client function fi (x), and other auxiliary assumptions. We
also briefly describe each method as a variant of the federated averaging algorithm, and show the simplified
convergence rate eliminating constants. Assuming the client functions are strongly convex could help the
convergence rate [303, 265]. Bounded gradient variance, which is a widely used assumption to analyze
stochastic gradient methods, is often used when clients use stochastic local updates [305, 303, 304, 469,
265]. Li et al. [303] directly analyzes the Federated Averaging algorithm, which applies K steps of local
updates on randomly sampled M clients in each round, and presents a rate that suggests local updates
(K > 1) could slow down the convergence. Clarifying the regimes where K > 1 may hurt or help
convergence is an important open problem.
Connections to decentralized optimization The objective function of federated optimization has been
studied for many years in the decentralized optimization community. As first shown in Wang and Joshi [467],
the convergence analysis of decentralized SGD can be applied to or combined with local SGD with a proper
setting of the network topology matrix (mixing matrix). In order to reduce the communication overhead,
Wang and Joshi [467] proposed periodic decentralized SGD (PD-SGD) which allows decentralized SGD to
have multiple local updates as Federated Averaging. This algorithm is extended by Li et al. [304] to the
non-IID case. MATCHA [469] further improves the performance of PD-SGD by randomly sampling clients
for computation and communication, and provides a convergence analysis showing that local updates can
accelerate convergence.
Acceleration, variance reduction and adaptivity Momentum, variance-reduction, and adaptive learning rates are all promising techniques to improve convergence and generalization of first-order methods.
However, there is no single manner in which to incorporate these techniques into FedAvg. SCAFFOLD
[265] models the difference in client updates using control variates to perform variance reduction. Notably,
this allows convergence results not relying on bounding the amount of heterogeneity among clients. As for
momentum, Yu et al. [501] propose allowing each client to maintain a local momentum buffer and average the local buffers and the local model parameters at each communication round. Although this method
empirically improves the final accuracy of local SGD, this doubles the per-round communication cost. A
similar scheme is used by Xie et al. [485] to design a variant of local SGD in which clients locally perform
Adagrad [335, 161]. Reddi et al. [389] instead proposes using adaptive learning rates at the server-level,
developing federated versions of adaptive optimization methods with the same communication cost as FedAvg. This framework generalizes the server momentum framework proposed by Hsu et al. [237], Wang
et al. [470], which allows momentum without increasing communication costs. While both [501, 470]
showed that the momentum variants of local SGD can converge to stationary points of non-convex objective

27

functions at the same rate as synchronous mini-batch SGD, it is challenging to prove momentum accelerates
the convergence rate in the federated learning setting. Recently, Karimireddy et al. [264] proposed a general
approach for adapting centralized optimization algorithms to the heterogeneous federated setting (MIME
framework and algorithms).

3.3

Multi-Task Learning, Personalization, and Meta-Learning

In this section we consider a variety of “multi-model” approaches — techniques that result in effectively
using different models for different clients at inference time. These techniques are particularly relevant when
faced with non-IID data (Section 3.1), since they may outperform even the best possible shared global model.
We note that personalization has also been studied in the fully decentralized setting [459, 59, 504, 19], where
training individual models is particularly natural.
3.3.1

Personalization via Featurization

The remainder of this section specifically considers techniques that result in different users running inference
with different model parameters (weights). However, in some applications similar benefits can be achieved
by simply adding user and context features to the model. For example, consider a language model for nextword-prediction in a mobile keyboard as in Hard et al. [222]. Different clients are likely to use language
differently, and in fact on-device personalization of model parameters has yielded significant improvements
for this problem [472]. However, a complimentary approach may be to train a federated model that takes
as input not only the words the user has typed so far, but a variety of other user and context features—
What words does this user frequently use? What app are they currently using? If they are chatting, what
messages have they sent to this person before? Suitably featurized, such inputs can allow a shared global
model to produce highly personalized predictions. However, largely because few public datasets contain
such auxiliary features, developing model architectures that can effectively incorporate context information
for different tasks remains an important open problem with the potential to greatly increase the utility of
FL-trained models.
3.3.2

Multi-Task Learning

If one considers each client’s local problem (the learning problem on the local dataset) as a separate task
(rather than as a shard of a single partitioned dataset), then techniques from multi-task learning [506] immediately become relevant. Notably, Smith et al. [424] introduced the MOCHA algorithm for multi-task
federated learning, directly tackling challenges of communication efficiency, stragglers, and fault tolerance.
In multi-task learning, the result of the training process is one model per task. Thus, most multi-task learning algorithms assume all clients (tasks) participate in each training round, and also require stateful clients
since each client is training an individual model. This makes such techniques relevant for cross-silo FL
applications, but harder to apply in cross-device scenarios.
Another approach is to reconsider the relationship between clients (local datasets) and learning tasks
(models to be trained), observing that there are points on a spectrum between a single global model and
different models for every client. For example, it may be possible to apply techniques from multi-task
learning (as well as other approaches like personalization, discussed next), where we take the “task” to be
a subset of the clients, perhaps chosen explicitly (e.g. based on geographic region, or characteristics of the
device or user), or perhaps based on clustering [331] or the connected components of a learned graph over
the clients [504]. The development of such algorithms is an important open problem. See Section 4.4.4
28

for a discussion of how sparse federated learning problems, such as those arising naturally in this type of
multi-task problem, might be approached without revealing to which client subset (task) each client belongs.
3.3.3

Local Fine Tuning and Meta-Learning

By local fine tuning, we refer to techniques which begin with the federated training of a single model, and
then deploy that model to all clients, where it is personalized by additional training on the local dataset before
use in inference. This approach integrates naturally into the typical lifecycle of a model in federated learning
(Section 1.1.1). Training of the global model can still proceed using only small samples of clients on each
round (e.g. 100s); the broadcast of the global model to all clients (e.g. many millions) only happens once,
when the model is deployed. The only difference is that before the model is used to make live predictions
on the client, a final training process occurs, personalizing the model to the local dataset.
Given a global model that performs reasonably well, what is the best way to personalize it? In nonfederated learning, researchers often use fine-tuning, transfer learning, domain adaptation [329, 132, 61,
332, 133], or interpolation with a personal local model. Of course, the precise technique used for such
interpolations is key and it is important to determine its corresponding learning guarantees in the context of
federated learning. Further, these techniques often assume only a pair of domains (source and target), and
so some of the richer structure of federated learning may be lost.
One approach for studying personalization and non-IID data is via a connection to meta-learning, which
has emerged as a popular setting for model adaptation. In the standard learning-to-learn (LTL) setup [56],
one has a meta-distribution over tasks, samples from which are used to learn a learning algorithm, for
example by finding a good restriction of the hypothesis space. This is in fact a good match for the statistical
setting discussed in Section 3.1, where we sample a client (task) i ∼ Q, and then sample data for that client
(task) from Pi .
Recently, a class of algorithms referred to as model-agnostic meta-learning (MAML) have been developed that meta-learn a global model, which can be used as a starting point for learning a good model adapted
to a given task, using only a few local gradient steps [187]. Most notably, the training phase of the popular
Reptile algorithm [358] is closely related to Federated Averaging [337] — Reptile allows for a server learning rate and assumes all clients have the same amount of data, but is otherwise the same. Khodak et al. [270]
and Jiang et al. [250] explore the connection between FL and MAML, and show how the MAML setting
is a relevant framework to model the personalization objectives for FL. Chai Sim et al. [102] applied local
fine tuning to personalize speech recognition models in federated learning. Fallah et al. [181] developed a
new algorithm called Personalized FedAvg by connecting MAML instead of Reptile to federated learning.
Additional connections with differential privacy were studied in [299].
The general direction of combining ideas from FL and MAML is relatively new, with many open questions:
• The evaluation of MAML algorithms for supervised tasks is largely focused on synthetic image classification problems [290, 386] in which infinite artificial tasks can be constructed by subsampling from
classes of images. FL problems, modeled by existing datasets used for simulated FL experiments
(Appendix A), can serve as realistic benchmark problems for MAML algorithms.
• In addition to an empirical study, or optimization results, it would be useful to analyze the theoretical
guarantees of MAML-type techniques and study under what assumptions they can be successful, as
this will further elucidate the set of FL domains to which they may apply.
• The observed gap between the global and personalized acccuracy [250] creates a good argument
29

that personalization should be of central importance to FL. However, none of the existing works
clearly formulates what would be comprehensive metrics for measuring personalized performance;
for instance, is a small improvement for every client preferable to a larger improvement for a subset
of clients? See Section 6 for a related discussion.
• Jiang et al. [250] highlighted the fact that models of the same structure and performance, but trained
differently, can have very different capacity to personalize. In particular, it appears that training
models with the goal of maximizing global performance might actually hurt the model’s capacity for
subsequent personalization. Understanding the underlying reasons for this is a question relevant for
both FL and the broader ML community.
• Several challenging FL topics including personalization and privacy have begun to be studied in this
multi-task/LTL framework [270, 250, 299]. Is it possible for other issues such as concept drift to also
be analyzed in this way, for example as a problem in lifelong learning [420]?
• Can non-parameter transfer LTL algorithms, such as ProtoNets [425], be of use for FL?
3.3.4

When is a Global FL-trained Model Better?

What can federated learning do for you that local training on one device cannot? When local datasets are
small and the data is IID, FL clearly has an edge, and indeed, real-world applications of federated learning
[491, 222, 112] benefit from training a single model across devices. On the other hand, given pathologically
non-IID distributions (e.g. Pi (y | x) directly disagree across clients), local models will do much better. Thus,
a natural theoretical question is to determine under what conditions the shared global model is better than
independent per-device models. Suppose we train a model hk for each client k, using the sample of size mk
available from that client. Can we guarantee that the model hFL learned via federated learning is at least
as accurate as hk when used for client k? Can we quantify how much improvement can be expected via
federated leaning? And can we develop personalization strategies with theoretical guarantees that at least
match the performance of both natural baselines (hk and hFL )?
Several of these problems relate to previous work on multiple-source adaptation and agnostic federated
learning [329, 330, 234, 352]. The hardness of these questions depends on how the data is distributed among
parties. For example, if data is vertically partitioned, each party maintaining private records of different
feature sets about common entities, these problems may require addressing record linkage [124] within the
federated learning task. Independently of the eventual technical levy of carrying out record linkage privately
[407], the task itself happens to be substantially noise prone in the real world [406] and only sparse results
have addressed its impact on training models [224]. Techniques for robustness and privacy can make local
models relatively stronger, particularly for non-typical clients [502]. Loss factorization tricks can be used
in supervised learning to alleviate up to the vertical partition assumption itself, but the practical benefits
depend on the distribution of data and the number of parties [373].

3.4

Adapting ML Workflows for Federated Learning

Many challenges arise when adapting standard machine learning workflows and pipelines (including data
augmentation, feature engineering, neural architecture design, model selection, hyperparameter optimization, and debugging) to decentralized datasets and resource-constrained mobile devices. We discuss several
of these challenges below.

30

3.4.1

Hyperparameter Tuning

Running many rounds of training with different hyperparameters on resource-constrained mobile devices
may be restrictive. For small device populations, this might result in the over-use of limited communication and compute resources. However, recent deep neural networks crucially depend on a wide range of
hyperparameter choices regarding the neural network’s architecture, regularization, and optimization. Evaluations can be expensive for large models and large-scale on-device datasets. Hyperparameter optimization
(HPO) has a long history under the framework of AutoML [395, 273, 277], but it mainly concerns how
to improve the model accuracy [64, 426, 374, 180] rather than communication and computing efficacy for
mobile devices. Therefore, we expect that further research should consider developing solutions for efficient
hyperparameter optimization in the context of federated learning.
In addition to general-purpose approaches to the hyperparameter optimization problem, in the training
space specifically the development of easy-to-tune optimization algorithms is a major open area. Centralized
training already requires tuning parameters like learning rate, momentum, batch size, and regularization.
Federated learning adds potentially more hyperparameters — separate tuning of the aggregation / global
model update rule and local client optimizer, number of clients selected per round, number of local steps per
round, configuration of update compression algorithms, and more. Such hyperparameters can be crucial to
obtaining a good trade-off between accuracy and convergence, and may actually impact the quality of the
learned model [106]. In addition to a higher-dimensional search space, federated learning often also requires
longer wall-clock training times and limited compute resources. These challenges could be addressed by
optimization algorithms that are robust to hyperparameter settings (the same hyperparameter values work for
many different real world datasets and architectures), as well as adaptive or self-tuning algorithms [446, 82].
3.4.2

Neural Architecture Design

Neural architecture search (NAS) in the federated learning setting is motivated by the drawbacks of the
current practice of applying predefined deep learning models: the predefined architecture of a deep learning
model may not be the optimal design choice when the data generated by users are invisible to model developers. For example, the neural architecture may have some redundant component for a specific dataset,
which may lead to unnecessary computing on devices; there may be a better architectural design for the nonIID data distribution. The approaches to personalization discussed in Section 3.3 still share the same model
architecture among all clients. The recent progress in NAS [230, 387, 175, 388, 60, 375, 313, 488, 175, 323]
provides a potential way to address these drawbacks. There are three major methods for NAS, which utilize
evolutionary algorithms, reinforcement learning, or gradient descent to search for optimal architectures for
a specific task on a specific dataset. Among these, the gradient-based method leverages efficient gradient
back-propagation with weight sharing, reducing the architecture search process from over 3000 GPU days to
only 1 GPU day. Another interesting paper recently published, involving Weight Agnostic Neural Networks
[192], claims that neural network architectures alone, without learning any weight parameters, may encode
solutions for a given task. If this technique further develops and reaches widespread use, it may be applied
to the federated learning without collaborative training among devices. Although these methods have not
been developed for distributed settings such as federated learning, they are all feasible to be transferred to
the federated setting. Neural Architecture Search (NAS) for a global or personalized model in the federated
learning setting is promising, and early exploration has been made in [228].

31

3.4.3

Debugging and Interpretability for FL

While substantial progress has been made on the federated training of models, this is only part of a complete
ML workflow. Experienced modelers often directly inspect subsets of the data for tasks including basic sanity checking, debugging misclassifications, discovering outliers, manually labeling examples, or detecting
bias in the training set. Developing privacy-preserving techniques to answer such questions on decentralized data is a major open problem. Recently, Augenstein et al. [31] proposed the use of differentially private
generative models (including GANs), trained with federated learning, to answer some questions of this type.
However, many open questions remain (see discussion in [31]), in particular the development of algorithms
that improve the fidelity of FL DP generative models.

3.5

Communication and Compression

It is now well-understood that communication can be a primary bottleneck for federated learning since
wireless links and other end-user internet connections typically operate at lower rates than intra- or interdatacenter links and can be potentially expensive and unreliable. This has led to significant recent interest
in reducing the communication bandwidth of federated learning. Methods combining Federated Averaging with sparsification and/or quantization of model updates to a small number of bits have demonstrated
significant reductions in communication cost with minimal impact on training accuracy [282]. However, it
remains unclear if communication cost can be further reduced, and whether any of these methods or their
combinations can come close to providing optimal trade-offs between communication and accuracy in federated learning. Characterizing such fundamental trade-offs between accuracy and communication has been
of recent interest in theoretical statistics [507, 89, 221, 7, 49, 444, 50]. These works characterize the optimal
minimax rates for distributed statistical estimation and learning under communication constraints. However, it is difficult to deduce concrete insights from these theoretical works for communication bandwidth
reduction in practice as they typically ignore the impact of the optimization algorithm. It remains an open
direction to leverage such statistical approaches to inform practical training methods.
Compression objectives Motivated by the limited resources of current devices in terms of compute, memory and communication, there are several different compression objectives of practical value.
(a) Gradient compression6 – reduce the size of the object communicated from clients to server, which is
used to update the global model.
(b) Model broadcast compression – reduce the size of the model broadcast from server to clients, from
which the clients start local training.
(c) Local computation reduction – any modification to the overall training algorithm such that the local
training procedure is computationally more efficient.
These objectives are in most cases complementary. Among them, (a) has the potential for the most significant practical impact in terms of total runtime. This is both because clients’ connections generally have
slower upload than download bandwidth7 – and thus there is more to be gained, compared to (b) – and because the effects of averaging across many clients can enable more aggressive lossy compression schemes.
Usually, (c) could be realized jointly with (a) and (b) by specific methods.
6

In this section, we use “gradient compression” to include compression applied to any model update, such as the updates
produced by Federated Averaging when clients take multiple gradient steps.
7
See for instance https://www.speedtest.net/reports/

32

Much of the existing literature applies to the objective (a) [282, 440, 281, 17, 235, 55]. The impact of
(b) on convergence in general has not been studied until very recently; an analysis is presented in [123].
Very few methods intend to address all of (a), (b) and (c) jointly. Caldas et al. [95] proposed a practical
method by constraining the desired model update such that only particular submatrices of model variables
are necessary to be available on clients; Hamer et al. [219] proposed a communication-efficient federated
algorithm for learning mixture weights on an ensemble of pre-trained models, based on communicating only
a subset of the models to any one device; He et al. [227] utilizes bidirectional and alternative knowledge
distillation method to transfer knowledge from many compact DNNs to a dense server DNN, which can
reduce the local computational burden at the edge devices.
In cross-device FL, algorithms generally cannot assume any state is preserved on the clients (Table 1).
However, this constraint would typically not be present in the cross-silo FL setting, where the same clients
participate repeatedly. Consequently, a wider set of ideas related to error-correction such as [311, 405, 463,
444, 263, 435] are relevant in this setting, many of which could address both (a) and (b).
An additional objective is to modify the training procedure such that the final model is more compact,
or efficient for inference. This topic has received a lot of attention in the broader ML community [220, 138,
509, 309, 362, 74], but these methods either do not have a straightforward mapping to federated learning,
or make the training process more complex which makes it difficult to adopt. Research that simultaneously
yields a compact final model, while also addressing the three objectives above, has significant potential for
practical impact.
For gradient compression, some existing works [440] are developed in the minimax sense to characterize
the worst case scenario. However usually in information theory, the compression guarantees are instance
specific and depend on the entropy of the underlying distribution [140]. In other words, if the data is
easily compressible, they are provably compressed heavily. It would be interesting to see if similar instance
specific results can be obtained for gradient compression. Similarly, recent works show that learning a
compression scheme in a data-dependent fashion can lead to significantly better compression ratio for the
case of data compression [482] as well as gradient compression. It is therefore worthwhile to evaluate these
data-dependent compression schemes in the federated settings [193].
Compatibility with differential privacy and secure aggregation Many algorithms used in federated
learning such as Secure Aggregation [79] and mechanisms of adding noise to achieve differential privacy [3,
338] are not designed to work with compressed or quantized communications. For example, straightforward
application of the Secure Aggregation protocol of Bonawitz et al. [80], Bell et al. [58] requires an additional
O(log M ) bits of communication for each scalar, where M is the number of clients being summed over,
and this may render ineffective the aggressive quantization of updates when M is large (though see [82]
for a more efficient approach). Existing noise addition mechanisms assume adding real-valued Gaussian
or Laplacian noise on each client, and this is not compatible with standard quantization methods used to
reduce communication. We note that several recent works allow biased estimators and would work nicely
with Laplacian noise [435], however those would not give differential privacy, as they break independence
between rounds. There is some work on adding discrete noise [9], but there is no notion whether such
methods are optimal. Joint design of compression methods that are compatible with Secure Aggregation, or
for which differential privacy guarantees can be obtained, is thus a valuable open problem.
Wireless-FL co-design The existing literature in federated learning usually neglects the impact of wireless channel dynamics during model training, which potentially undermines both training latency and thus
reliability of the entire production system. In particular, wireless interference, noisy channels and channel

33

fluctuations can significantly hinder the information exchange between the server and clients (or directly
between individual clients, as in the fully decentralized case, see Section 2.1). This represents a major
challenge for mission-critical applications, rooted in latency reduction and reliability enhancements. Potential solutions to address this challenge include federated distillation (FD), in which workers exchange their
model output parameters (logits) as opposed to the model parameters (gradients and/weights), and optimizing workers’ scheduling policy with appropriate communication and computing resources [248, 368, 402].
Another solution is to leverage the unique characteristics of wireless channels (e.g. broadcast and superposition) as natural data aggregators, in which the simultaneously transmitted analog-waves by different workers
are superposed at the server and weighed by the wireless channel coefficients [4]. This yields faster model
aggregation at the server, and faster training by a factor up to the number of workers. This is in sharp contrast with the traditional orthogonal frequency division multiplexing (OFDM) paradigm, whereby workers
upload their models over orthogonal frequencies whose performance degrades with increasing number of
workers [174].

3.6

Application To More Types of Machine Learning Problems and Models

To date, federated learning has primarily considered supervised learning tasks where labels are naturally
available on each client. Extending FL to other ML paradigms, including reinforcement learning, semisupervised and unsupervised learning, active learning, and online learning [226, 508] all present interesting
and open challenges.
Another important class of models, highly relevant to FL, are those that can characterize the uncertainty in their predictions. Most modern deep learning models cannot represent their uncertainty nor allow
for a probability interpretation of parametric learning. This has motivated recent developments of tools
and techniques combining Bayesian models with deep learning. From a probability theory perspective, it
is unjustifiable to use single point-estimates for classification. Bayesian neural networks [419] have been
proposed and shown to be far more robust to over-fitting, and can easily learn from small datasets. The
Bayesian approach further offers uncertainty estimates via its parameters in form of probability distributions, thus preventing over-fitting. Moreover, appealing to probabilistic reasoning, one can predict how the
uncertainty can decrease, allowing the decisions made by the network to become more deterministic as the
data size grows.
Since Bayesian methods gave us tools to reason about deep models’ confidence and also achieve state-ofthe-art performance on many tasks, one expects Bayesian methods to provide a conceptual improvement to
the classical federated learning. In fact, preliminary work from Lalitha et al. [292] shows that incorporating
Bayesian methods allows for model aggregation across non-IID data and heterogeneous platforms. However,
many questions regarding scalability and computational feasibility have to be addressed.

3.7

Executive summary

Efficient and effective federated learning algorithms face different challenges compared to centralized training in a datacenter.
• Non-IID data due to non-identical client distributions, violation of independence, and dataset drift
(Section 3.1) pose a key challenge. Though various methods have been surveyed and discussed in this
section, defining and dealing with non-IID data remains an open problem and one of the most active
research topics in federated learning.

34

• Optimization algorithms for federated learning are analyzed in Section 3.2 under different settings,
e.g., convex and nonconvex functions, IID and non-IID data. Theoretical analysis has proven difficult
for the parallel local updates commonly used in federated optimization, and often strict assumptions
have to be made to constrain the client heterogeneity. Currently, known convergence rates do not fully
explain the empirically-observed effectiveness of the Federated Averaging algorithm over methods
such as mini-batch SGD [481].
• Client-side personalization and “multi-model” approaches (Section 3.3) can address data heterogeneity and give hope of surpassing the performance of the best fixed global model. Simple personalization
methods like fine-tuning can be effective, and offer intrinsic privacy advantages. However, many theoretical and empirical questions remain open: when is a global model better? How many models are
necessary? Which federated optimization algorithms combine best with local fine-tuning?
• Adapting centralized training workflows such as hyper-parameter tuning, neural architecture design,
debugging, and interpretability tasks to the federated learning setting (Section 3.4) present roadblocks
to the widespread adoption of FL in practical settings, and hence constitute important open problems.
• While there has been significant work on communication efficiency and compression for FL (Section 3.5), it remains an important and active area. In particular, fully automating the process of
enabling compression without impacting convergence for a wide class of models is an important practical goal. Relatively new directions on the theoretical study of communication, compatibility with
privacy methods, and co-design with wireless infrastructure are discussed.
• There are many open questions in extending federated learning from supervised tasks to other machine
learning paradigms including reinforcement learning, semi-supervised and unsupervised learning, active learning, and online learning (Section 3.6).

35

4

Preserving the Privacy of User Data

Machine learning workflows involve many actors functioning in disparate capacities. For example, users
may generate training data through interactions with their devices, a machine learning training procedure
extracts cross-population patterns from this data (e.g. in the form of trained model parameters), the machine
learning engineer or analyst may assess the quality of this trained model, and eventually the model may be
deployed to end users in order to support specific user experiences (see Figure 1 below).
In an ideal world, each actor in the system would learn nothing more than the information needed to play
their role. For example, if an analyst only needs to determine whether a particular quality metric exceeds
a desired threshold in order to authorize deploying the model to end users, then in an idealized world, that
is the only bit of information that would be available to the analyst; such an analyst would need access
to neither the training data nor the model parameters, for instance. Similarly, end users enjoying the user
experiences powered by the trained model might only require predictions from the model and nothing else.
Furthermore, in an ideal world every participant in the system would be able to reason easily and accurately about what personal information about themselves and others might be revealed by their participation
in the system, and participants would be able to use this understanding to make informed choices about how
and whether to participate at all.
Producing a system with all of the above ideal privacy properties would be a daunting feat on its own,
and even more so while also guaranteeing other desirable properties such as ease of use for all participants,
the quality and fairness of the end user experiences (and the models that power them), the judicious use of
communication and computation resources, resilience against attacks and failures, and so on.
Rather than allowing perfect to be the enemy of good, we advocate a strategy wherein the overall system is composed of modular units which can be studied and improved relatively independently, while also
reminding ourselves that we must, in the end, measure the privacy properties of the complete system against
our ideal privacy goals set out above. The open questions raised throughout this section will highlight areas

admin

clients

model
testing

server

engineers
& analysts

federated
learning

rest of
the world

model
deployment

Figure 1: The lifecycle of an FL-trained model and the various actors in a federated learning system.
(repeated from Page 7)
36

wherein we do not yet understand how to simultaneously achieve all of our goals, either for an individual
module or for the system as a whole.
Federated learning provides an attractive structure for decomposing the overall machine learning workflow into the approachable modular units we desire. One of the primary attractions of the federated learning
model is that it can provide a level of privacy to participating users through data minimization: the raw
user data never leaves the device, and only updates to models (e.g., gradient updates) are sent to the central
server. These model updates are more focused on the learning task at hand than is the raw data (i.e. they
contain strictly no additional information about the user, and typically significantly less, compared to the
raw data), and the individual updates only need to be held ephemerally by the server.
While these features can offer significant practical privacy improvements over centralizing all the training data, there is still no formal guarantee of privacy in this baseline federated learning model. For instance,
it is possible to construct scenarios in which information about the raw data is leaked from a client to the
server, such as a scenario where knowing the previous model and the gradient update from a user would
allow one to infer a training example held by that user. Therefore, this section surveys existing results
and outlines open challenges towards designing federated learning systems that can offer rigorous privacy
guarantees. We focus on questions specific to the federated learning and analytics setting and leave aside
questions that also arise in more general machine learning settings as surveyed in [344].
Beyond attacks targeting user privacy, there are also other classes of attacks on federated learning; for
example, an adversary might attempt to prevent a model from being learned at all, or they might attempt to
bias the model to produce inferences that are preferable to the adversary. We defer consideration of these
types of attacks to Section 5.
The remainder of this section is organized as follows. Section 4.1 discusses various threat models
against which we wish to give protections. Section 4.2 lays out a set of core tools and technologies that can
be used towards providing rigorous protections against the threat models discussed in Section 4.1. Section
4.3 assumes the existence of a trusted server and discusses the open problems and challenges in providing
protections against adversarial clients and/or analysts. Section 4.4 discusses the open problems and challenges in the absence of a fully trusted server. Finally, Section 4.5 discusses open questions around user
perception.

4.1

Actors, Threat Models, and Privacy in Depth

A formal treatment of privacy risks in FL calls for a holistic and interdisciplinary approach. While some of
the risks can be mapped to technical privacy definitions and mitigated with existing technologies, others are
more complex and require cross-disciplinary efforts.
Privacy is not a binary quantity, or even a scalar one. This first step towards such formal treatment
is a careful characterization of the different actors (see Figure 1 from Section 1, repeated on page 36 for
convenience) and their roles to ultimately define relevant threat models (see Table 7). Thus, for instance, it
is desirable to distinguish the view of the server administrator from the view of the analysts that consume
the learned models, as it is conceivable that a system that is designed to offer strong privacy guarantees
against a malicious analyst may not provide any guarantees with respect to a malicious server. These actors
map well onto the threat models discussed elsewhere in the literature; for example, in Bittau et al. [73, Sec
3.1], where the “encoder” corresponds to the client, the “shuffler” generally corresponds to the server, the
“analyzer“ may correspond to the server or post-processing done by the analyst.

37

As an example, a particular system might offer a differential privacy8 guarantee with a particular parameter ε to the view of the server administrator, while the results observed by analysts might have a higher
protection ε0 < ε.
Furthermore, it is possible that this guarantee holds only against adversaries with particular limits on
their capabilities, e.g. an adversary that can observe everything that happens on the server (but cannot
influence the server’s behavior) while simultaneously controlling up to a fraction γ of the clients (observing
everything they see and influencing their behavior in arbitrary ways); the adversary might also be assumed
to be unable to break cryptographic mechanisms instantiated at a particular security level σ. Against an
adversary whose strength exceeds these limits, the view of the server administrator might still have some
differential privacy, but at weaker level ε0 > ε.
As we see in this example, precisely specifying the assumptions and privacy goals of a system can
easily implicate concrete instantiations of several parameters (ε, ε0 , ε0 , γ, σ, etc.) as well as concepts such
as differential privacy and honest-but-curious security.
Achieving all the desired privacy properties for federated learning will typically require composing many
of the tools and technologies described below into an end-to-end system, potentially both layering multiple
strategies to protect the same part of the system (e.g. running portions of a Secure Multi-Party Computation (MPC) protocol inside a Trusted Execution Environment (TEE) to make it harder for an adversary
to sufficiently compromise that component) as well as using different strategies to protect different parts
of the system (e.g. using MPC to protect the aggregation of model updates, then using Private Disclosure
techniques before sharing the aggregate updates beyond the server).
As such, we advocate for building federated systems wherein the privacy properties degrade as gracefully as possible in cases where one technique or another fails to provide its intended privacy contribution.
For example, running the server component of an MPC protocol inside a TEE might allow privacy to be
maintained even in the case where either (but not both) of the TEE security or MPC security assumptions
fails to hold in practice. As another example, requiring clients to send raw training examples to a server-side
TEE would be strongly dispreferred to having clients send gradient updates to a server-side TEE, as the latter’s privacy expectations degrade much more gracefully if the TEE’s security were to fail. We refer to this
principle of graceful degradation as “Privacy in Depth,” in analogy to the well-established network security
principle of defense in depth [361].

4.2

Tools and Technologies

Generally speaking, the goal of an FL computation is for the analyst or engineer requesting the computation
to obtain the result, which can be thought of as the evaluation of a function f on a distributed client dataset
(commonly an ML model training algorithm, but possibly something simpler such as a basic statistic). There
are three privacy aspects that need to be addressed.
First, we need to consider how f is computed and what is the information flow of intermediate results
in the process, which primarily influences the susceptibility to malicious client, server, and admin actors. In
addition to designing the flow of information in the system (e.g. early data minimization), techniques from
secure computation including Secure Multi-Party Computation (MPC) and Trusted Execution Environments
(TEEs) are of particular relevance to addressing these concerns. These technologies will be discussed in
detail in Section 4.2.1.
8

Differential privacy will be formally introduced in Section 4.2.2. For now, it suffices to know that lower ε corresponds with
higher privacy.

38

Data/Access Point

Actor

Threat Model

Clients

Someone who has root access
to the client device, either by
design or by compromising the
device

Malicious clients can inspect all messages received from the server (including the model iterates) in the rounds they participate in and can
tamper with the training process. An honest-butcurious client can inspect all messages received
from the server but cannot tamper with the training process. In some cases, technologies such as
secure enclaves/TEEs may be able to limit the influence and visibility of such an attacker, representing a meaningfully weaker threat model.

Server

Someone who has root access
to the server, either by design
or by compromising the device

A malicious server can inspect all messages sent
to the server (including the gradient updates) in all
rounds and can tamper with the training process.
An honest-but-curious server can inspect all messages sent to the server but cannot tamper with
the training process. In some cases, technologies
such as secure enclaves/TEEs may be able to limit
the influence and visibility of such an attacker,
representing a meaningfully weaker threat model.

Output Models

Engineers & analysts

A malicious analyst or model engineer may have
access to multiple outputs from the system, e.g.
sequences of model iterates from multiple training runs with different hyperparameters. Exactly
what information is released to this actor is an important system design question.

Deployed Models

The rest of the world

In cross-device FL, the final model may be deployed to hundreds of millions of devices. A partially compromised device can have black-box access to the learned model, and a fully compromised device can have a white-box access to the
learned model.

Table 7: Various threat models for different adversarial actors.

39

Second, we have to consider what is computed. In other words, how much information about a participating client is revealed to the analyst and world actors by the result of f itself. Here, techniques for
privacy-preserving disclosure, particularly differential privacy (DP), are highly relevant and will be discussed in detail in Section 4.2.2.
Finally, there is the problem of verifiability, which pertains to the ability of a client or the server to
prove to others in the system that they have executed the desired behavior faithfully, without revealing
the potentially private data upon which they were acting. Techniques for verifiability, including remote
attestation and zero-knowledge proofs, will be discussed in Section 4.2.3.
4.2.1

Secure Computations

The goal of secure computation is to evaluate functions on distributed inputs in a way that only reveals
the result of the computation to the intended parties, without revealing any additional information (e.g. the
parties’ inputs or any intermediate results).
Secure multi-party computation Secure Multi-Party Computation (MPC) is a subfield of cryptography
concerned with the problem of having a set of parties compute an agreed-upon function of their private
inputs in a way that only reveals the intended output to each of the parties. This area was kicked off in the
1980’s by Yao [493]. Thanks to both theoretical and engineering breakthroughs, the field has moved from
being of a purely theoretical interest to a deployed technology in industry [78, 77, 295, 27, 191, 242, 243].
It is important to remark that MPC defines a set of technologies, and should be regarded more as a field, or a
general notion of security in secure computation, than a technology per se. Some of the recent advances in
MPC can be attributed to breakthroughs in lower level primitives, such as oblivious transfer protocols [244]
and encryption schemes with homomorphic properties (as described below).
A common aspect of cryptographic solutions is that operations are often done on a finite field (e.g.
integers modulo a prime p), which poses difficulties when representing real numbers. A common approach
has been to adapt ML models and their training procedures to ensure that (over)underflows are controlled,
by operating on normalized quantities and relying on careful quantization [194, 10, 206, 84].
It has been known for several decades that any function can be securely computed, even in the presence
of malicious adversaries [208]. While generic solutions exist, their performance characteristics often render
them inapplicable in practical settings. As such a noticeable trend in research has consisted in designing
custom protocols for applications such as linear and logistic regression [359, 194, 351] and neural network
training and inference [351, 10, 48]. These works are typically in the cross-silo setting, or the variant where
computation is delegated to a small group of computing servers that do not collude with each other. Porting
these protocols to the cross-device setting is not straightforward, as they require a significant amount of
communication.
Homomorphic encryption Homomorphic encryption (HE) schemes allow certain mathematical operations to be performed directly on ciphertexts, without prior decryption. Homomorphic encryption can be a
powerful tool for enabling MPC by enabling a participant to compute functions on values while keeping the
values hidden.
Different flavours of HE exist, ranging from general fully homomorphic encryption (FHE) [197] to the
more efficient leveled variants [87, 182, 88, 129], for which several implementations exist [233, 409, 364,
415, 1]. Also of practical relevance are the so-called partially homomorphic schemes, including for example
ElGamal and Paillier, allowing either homomorphic addition or multiplication. Additive HE has been used
40

Technology

Characteristics

Differential Privacy (local, central, shuffled, aggregated, and
hybrid models)

A quantification of how much information could be learned about
an individual from the output of an analysis on a dataset that includes the user. Algorithms with differential privacy necessarily
incorporate some amount of randomness or noise, which can be
tuned to mask the influence of the user on the output.

Secure Multi-Party Computation

Two or more participants collaborate to simulate, though cryptography, a fully trusted third party who can:
• Compute a function of inputs provided by all the participants;
• Reveal the computed value to a chosen subset of the participants, with no party learning anything further.

Homomorphic Encryption

Enables a party to compute functions of data to which they do
not have plain-text access, by allowing mathematical operations to
be performed on ciphertexts without decrypting them. Arbitrarily complicated functions of the data can be computed this way
(“Fully Homomorphic Encryption”) though at greater computational cost.

Trusted Execution Environments
(secure enclaves)

TEEs provide the ability to trustably run code on a remote machine, even if you do not trust the machine’s owner/administrator.
This is achieved by limiting the capabilities of any party, including
the administrator. In particular, TEEs may provide the following
properties [437]:
• Confidentiality: The state of the code’s execution remains
secret, unless the code explicitly publishes a message;
• Integrity: The code’s execution cannot be affected, except
by the code explicitly receiving an input;
• Measurement/Attestation: The TEE can prove to a remote
party what code (binary) is executing and what its starting
state was, defining the initial conditions for confidentiality
and integrity.

Table 8: Various technologies along with their characteristics.

41

as an ingredient in MPC protocols in the cross-silo setting [359, 224]. A review of some homomorphic
encryption software libraries along with brief explanations of criteria/features to be considered in choosing
a library is surveyed in [404].
When considering the use of HE in the FL setting, questions immediately arise about who holds the
secret key of the scheme. While the idea of every client encrypting their data and sending it to the server
to compute homomorphically on it is appealing, the server should not be able to decrypt a single client
contribution. A trivial way of overcoming this issue would be relying on a non-colluding external party that
holds the secret key and decrypts the result of the computation. However, most HE schemes require that the
secret keys be renewed often (due to e.g. susceptibility to chosen ciphertext attacks [117]). Moreover, the
availability of a trusted non-colluding party is not standard in the FL setting.
Another way around this issue is relying on distributed (or threshold) encryption schemes, where the
secret key is distributed among the parties. Reyzin et al. [392] and Roth et al. [398] propose such solutions
for computing summation in the cross-device setting. Their protocols make use of additively homomorphic
schemes (variants of ElGamal and lattice-based schemes, respectively).
Trusted execution environments Trusted execution environments (TEEs, also referred to as secure enclaves) may provide opportunities to move part of the federated learning process into a trusted environment
in the cloud, whose code can be attested and verified.
TEEs can provide several crucial facilities for establishing trust that a unit of code has been executed
faithfully and privately [437]:
• Confidentiality: The state of the code’s execution remains secret, unless the code explicitly publishes
a message.
• Integrity: The code’s execution cannot be affected, except by the code explicitly receiving an input.
• Measurement/Attestation: The TEE can prove to a remote party what code (binary) is executing and
what its starting state was, defining the initial conditions for confidentiality and integrity.
TEEs have been instantiated in many forms, including Intel’s SGX-enabled CPUs [241, 134], Arm’s
TrustZone [28, 22], and Sanctum on RISC-V [135], each varying in its ability to systematically offer the
above facilities.
Current secure enclaves are limited in terms of memory and provide access only to CPU resources,
that is they do not allow processing on GPUs or machine learning processors (Tramèr and Boneh [447]
explore how to combine TEEs with GPUs for machine learning inference). Moreover, it is challenging
for TEEs (especially those operating on shared microprocessors) to fully exclude all types of side channel
attacks [458].
While secure enclaves provide protections for all code running inside them, there are additional concerns that must be addressed in practice. For example, it is often necessary to structure the code running in
the enclave as a data oblivious procedure, such that its runtime and memory access patterns do not reveal
information about the data upon which it is computing (see for example [73]). Furthermore, measurement/attestation typically only proves that a particular binary is running; it is up to the system architect to
provide a means for proving that that binary has the desired privacy properties, potentially requiring the
binary to be built using a reproducible process from open source code.
It remains an open question how to partition federated learning functions across secure enclaves, cloud
computing resources, and client devices. For example, secure enclaves could execute key functions such as
42

secure aggregation or shuffling to limit the server’s access to raw client contributions while keeping most of
the federated learning logic outside this trusted computing base.
Secure computation problems of interest While secure multi-party computation and trusted execution
environments offer general solutions to the problem of privately computing any function on distributed
private data, many optimizations are possible when focusing on specific functionalities. This is the case for
the tasks described next.
Secure aggregation Secure aggregation is a functionality for n clients and a server. It enables each
client to submit a value (often a vector or tensor in the FL setting), such that the server learns just an
aggregate function of the clients’ values, typically the sum.
There is a rich literature exploring secure aggregation in both the single-server setting (via additive
masking [8, 213, 80, 58, 428], via threshold homomorphic encryption [417, 218, 103], and via generic
secure multi-party computation [94]) as well as in the multiple non-colluding servers setting [78, 27, 130].
Secure aggregation can also be approached using trusted execution environments (introduced above), as
in [308].
Secure shuffling Secure shuffling is a functionality for n clients and a server. It enables each client
to submit one or more messages, such that the server learns just an unordered collection (multiset) of the
messages from all clients and nothing more. Specifically, the server has no ability to link any message to
its sender beyond the information contained in the message itself. Secure shuffling can be considered an
instance of Secure Aggregation where the values are multiset-singletons and the aggregation operation is
multiset-sum, though it is often the case that very different implementations provide the best performance
in the typical operating regimes for secure shuffling and secure aggregation.
Secure shufflers have been studied in the context of secure multi-party computation [107, 288], often
under the heading of mix networks. They have also been studied in the context of trusted computing [73].
Mix networks have found large scale deployment in the form of the Tor network [157].
Private information retrieval Private information retrieval (PIR) is a functionality for one client and
one server. It enables the client to download an entry from a server-hosted database such that the server
gains zero information about which entry the client requested.
MPC approaches to PIR break down into two main categories: computational PIR (cPIR), in which a
single party can execute the entire server side of the protocol [286], and information theoretic PIR (itPIR),
in which multiple non-colluding parties are required to execute the server side of the protocol [121].
The main roadblocks to the applicability of PIR have been the following: cPIR has high computational
cost [423], while the non-colluding parties setting has been difficult to achieve convincingly in industrial
scenarios. Recent results on PIR have shown dramatic reductions in the computational cost through the
use of lattice-based cryptosystems [12, 363, 13, 23, 198]. The computational cost can be traded for more
communication; we refer the reader to Ali et al. [16] to better understand the communication and computation trade-offs offered by cPIR. Additionally, it has been shown how to construct communication-efficient
PIR on a single-server by leveraging side information available to the user [251], for example via client
local state. Patel et al. [372] presented and implemented a practical hybrid (computational and information
theoretic) PIR scheme on a single server assuming client state. Corrigan-Gibbs and Kogan [131] present
theoretical constructions for PIR with sublinear online time by working in an offline/online model where,
43

during an offline phase, clients fetch information from the server(s) independent on the future query to be
performed.
Further work has explored the connection between PIR and secret sharing [479], with recent connections
to PIR on coded data [159] and communication efficient PIR [72]. A variant of PIR, called PIR-with-Default,
enable clients to retrieve a default value if the index queried is not in the database, and can output additive
secret shares of items which can serve as input to any MPC protocol [297]. PIR has also been studied in the
context of ON-OFF privacy, in which a client is permitted to switch off their privacy guards in exchange for
better utility or performance [355, 494].
4.2.2

Privacy-Preserving Disclosures

The state-of-the-art model for quantifying and limiting information disclosure about individuals is differential privacy (DP) [167, 164, 165], which aims to introduce a level of uncertainty into the released model
sufficient to mask the contribution of any individual user. Differential privacy is quantified by privacy loss
parameters (ε, δ), where smaller (ε, δ) corresponds to increased privacy. More formally, a randomized algorithm A is (ε, δ)-differentially private if for all S ⊆ Range(A), and for all adjacent datasets D and D0 :
P (A(D) ∈ S) ≤ eε P (A(D0 ) ∈ S) + δ.

(3)

In the context of FL, D and D0 correspond to decentralized datasets that are adjacent if D0 can be obtained
from D by adding or subtracting all the records of a single client (user) [338]. This notion of differential
privacy is referred to as user-level differential privacy. It is stronger than the typically used notion of adjacency where D and D0 differ by only one record [165], since in general one user may contribute many
records (e.g. training examples) to the dataset.
Over the last decade, an extensive set of techniques has been developed for differentially private data
analysis, particularly under the assumption of a centralized setting, where the raw data is collected by a
trusted party prior to applying perturbations necessary to achieve privacy. In federated learning, typically the
orchestrating server would serve as the trusted implementer of the DP mechanism, ensuring only privatized
outputs are released to the model engineer or analyst.
However, when possible we often wish to reduce the need for a trusted party. Several approaches for
reducing the need for trust in a data curator have been considered in recent years.
Local differential privacy Differential privacy can be achieved without requiring trust in a centralized
server by having each client apply a differentially private transformation to their data prior to sharing it with
the server. That is, we apply Equation (3) to a mechanism A that processes a single user’s local dataset D,
with the guarantee holding with respect to any possible other local dataset D0 . This model is referred to as the
local model of differential privacy (LDP) [475, 266]. LDP has been deployed effectively to gather statistics
on popular items across large userbases by Google, Apple and Microsoft [177, 154, 155]. It has also been
used in federated settings for spam classifier training by Snap [378]. These LDP deployments all involve
large numbers of clients and reports, even up to a billion in the case of Snap, which stands in stark contrast to
centralized instantiations of DP which can provide high utility from much smaller datasets. Unfortunately,
as we will discuss in Section 4.4.2, achieving LDP while maintaining utility can be difficult [266, 455].
Thus, there is a need for a model of differential privacy that interpolates between purely central and purely
local DP. This can be achieved through distributed differential privacy, or the hybrid model, as discussed
below.

44

Distributed differential privacy In order to recover some of the utility of central DP without having to
rely on a trustworthy central server, one can instead use a distributed differential privacy model [166, 417,
73, 120]. Under this model, the clients first compute and encode a minimal (application specific) focused
report, and then send the encoded reports to a secure computation function, whose output is available to the
central server, with the intention that this output already satisfies differential privacy requirements by the
time the server is able to inspect it. The encoding is done to help maintain privacy on the clients, and could
for example include LDP. The secure computation function can have a variety of incarnations. It could be
an MPC protocol, a standard computation done on a TEE, or even a combination of the two. Each of these
choices comes with different assumptions and threat models.
It is important to remark that distributed differential privacy and local differential privacy yield different
guarantees from several perspectives: while the distributed DP framework can produce more accurate statistics for the same level of differential privacy as LDP, it relies on different setups and typically makes stronger
assumptions, such as access to MPC protocols. Below, we outline two possible approaches to distributed
differential privacy, relying on secure aggregation and secure shuffling. We stress that there are many other
methods that could be used, see for instance [400] for an approach based on exchanging correlated Gaussian
noise across secure channels.
Distributed DP via secure aggregation One promising tool for achieving distributed DP in FL is secure
aggregation, discussed above in Section 4.2.1. Secure aggregation can be used to ensure that the central
server obtains the aggregated result, while guaranteeing that intermediate parameters of individual devices
and participants are not revealed to the central server. To further ensure the aggregated result does not
reveal additional information to the server, we can use local differential privacy (e.g. with moderate ε level).
For example, each device could perturb its own model parameter before the secure aggregation in order to
achieve local differential privacy. By designing the noise correctly, we may ensure that the noise in the
aggregated result matches the noise that would have otherwise been added centrally by a trusted server (e.g.
with a low ε / high privacy level) [8, 385, 205, 417, 213].
Distributed DP via secure shuffling Another distributed differential privacy model is the shuffling
model, which was kicked off by the recently introduced Encode-Shuffle-Analyze (ESA) framework [73]
(illustrated in Figure 3). In the simplest version of this framework, each client runs an LDP protocol (e.g.
with a moderate ε level) on its data and provides its output to a secure shuffler. The shuffler randomly permutes the reports and sends the collection of shuffled reports (without any identifying information) to the
server for final analysis. Intuitively, the interposition of this secure compute function makes it harder for the
server to learn anything about the participants and supports a differential privacy analysis (e.g. with a low
ε / high privacy level). In the more general multi-message shuffled framework, each user can possibly send
more than one message to the shuffler. The shuffler can either be implemented directly as a trusted entity,
independent of the server and devoted solely to shuffling, or via more complex cryptographic primitives as
discussed above.
Bittau et al. [73] proposed the Prochlo system as a way to implement the ESA framework. The system
takes a holistic approach to privacy that takes into account secure computation aspects (addressed using
TEEs), private disclosure aspects (addressed by means of differential privacy), and verifiability aspects
(mitigated using secure enclave attestation capabilities).
More generally, shuffling models of differential privacy can use broader classes of local randomizers,
and can even select these local randomizers adaptively [178]. This can enable differentially private protocols
with far smaller error than what is possible in the local model, while relying on weaker trust assumptions

45

Figure 3: The Encode-Shuffle-Analyze (ESA) framework, illustrated here for 4 players.
than in the central model, e.g., [120, 178, 45, 201, 204, 200, 202, 203, 110].
Hybrid differential privacy Another promising approach is hybrid differential privacy [40], which combines multiple trust models by partitioning users based on their trust model preference (e.g. trust or lack
of trust in the curator). Prior to the hybrid model, there were two natural choices. The first was to use the
least-trusting model, which typically provides the lowest utility, and conservatively apply it uniformly over
the entire userbase. The second was to use the most-trusting model, which typically provides the highest
utility, but only apply it over the most-trusting users. By allowing multiple models to coexist, hybrid model
mechanisms can achieve more utility from a given userbase, compared to purely local or central DP mechanisms. For instance, [40] describes a system in which most users contribute their data in the local model of
privacy, and a small fraction of users opt-in to contributing their data in the central DP model. This enables
the design of a mechanism which, in some circumstances, outperforms both the conservative local DP mechanism applied across all users as well as the central DP mechanism applied only across the small fraction
of opt-in users. Recent work by [57] further demonstrates that a combination of multiple trust models can
become part of a promising toolkit for designing and implementing differential privacy. This construction
can be directly applied in the federated learning setting; however, the general concept of combining trust
models or computational models may also inspire similar but new approaches for federated learning.
4.2.3

Verifiability

An important notion that is orthogonal to the above privacy techniques is that of verifiability. Generally
speaking, verifiable computation will enable one party to prove to another party that it has executed the
desired behavior on its data faithfully, without compromising the potential secrecy of the data. The concept
of verifiable computation dates back to Babai et al. [42] and has been studied under various terms in the
literature: checking computations [42], certified computation [343], delegating computations [210], as well
as verifiable computing [195].
In the context of FL, verifiability can be used for two purposes. First, it would enable the server to prove
to the clients that it executed the intended behavior (e.g., aggregating inputs, shuffling of the input messages,
or adding noise for differential privacy) faithfully. Second, it would enable the clients to prove to the server
that their inputs and behavior follow that of the protocol specification (e.g., the input belongs to a certain
46

range, or the data is a correctly generated ciphertext).
Multiple techniques can be useful to provide verifiability: zero-knowledge proofs (ZKPs), trusted execution environments (TEEs), or remote attestation. Among these ZKPs provide formal cryptographic security
guarantees based on mathematical hardness, while others make rely on assumption about the security of
trusted hardware.
Zero-knowledge proofs (ZKPs) Zero knowledge (ZK) proofs are a cryptographic primitive that enables
one party (called the prover) to prove statements to another party (called the verifier), that depend on secret
information known to the prover, called witness, without revealing those secrets to the verifier. The notion of
zero-knowledge was introduced in the late 1980’s by Goldwasser et al. [209]. It provides a solution for the
verifiability question on private data. While there had been a large body of work on ZK construction, the first
work that brought ZKPs and verifiable computation for general functionalities in the realm of practicality
was the work of Parno et al. [369] which introduces the first optimized construction and implementation for
succinct ZK. Nowadays, ZKP protocols can achieve proof sizes of hundred of bytes and verifications of the
order of milliseconds regardless of the size of the statement being proved.
A ZKP has three salient properties: completeness (if the statement is true and the prover and verifier
follow the protocol, the verifier will accept the proof), soundness (if the statement is false and the verifier
follows the protocol, the verifier will refuse the proof), and zero-knowledge (if the statement is true and
the prover follows the protocol, the verifier will only learn that the statement is true and will not learn any
confidential information from the interaction).
Beyond these common properties, there are different types of zero-knowledge constructions in terms of
supported language for the proofs, setup requirements, prover and verifier computational efficiency, interactivity, succinctness, and underlying hardness assumptions. There are many ZK constructions that support
specific classes of statements, Schnorr proofs [408] and Sigma protocols [147] are examples of such widely
used protocols. While such protocols have numerous uses in specific settings, general ZK systems that can
support any functionality provide a much more broadly applicable tool (including in the context of FL), and
thus we focus on such constructions for the rest of the discussion.
A major distinguishing feature between different constructions is the need for trusted setup. Some
ZKPs rely on a common reference string (CRS), which is computed using secrets that should remain hidden
in order to guarantee the soundness properties of the proofs. The computation of such a CRS is referred to as
a trusted setup. While this requirement is a disadvantage for such systems, the existing ZKP constructions
that achieve most succinct proofs and verifier’s efficiency require trusted setup.
Another significant property that affects the applicability in different scenarios is whether generating
the proof requires interaction between the prover and the verifier, and here we distinguish non-interactive
zero-knowledge proofs (NIZKs) that enable the prover to send a single message to the verifier and require
no further communication. Often we can convert interactive to non-interactive proofs by making stronger
assumptions about ideal functionality of hash functions (i.e., that hash functions behave as random oracles).
Additionally, there are different measurements for efficiency of a ZKP system one must be aware of,
such as the length of the proof and the computation complexity of the prover and verifier. The ideal prover’s
complexity should be linear in the execution time for the evaluated functionality but many existing ZKPs
introduce additional (sometimes significant) overhead for the prover. The most efficient verification complexity requires computation at least linear in the size of the inputs for the evaluated functionality, and in the
setting of proofs for the work of the FL server this input size will be significant.
Succinct non-interactive zero-knowledge proofs (SNARKs) [71] are a type of ZKP that provides constant

47

proof size and verification that depends only on the input size, linearly. These attractive efficiency properties
do come at the price of stronger assumptions, which is mostly inherent, and trusted setup in all existing
scheme. Most existing SNARK constructions leverage quadratic arithmetic programs [196, 369, 136] and
are now available in open-source libraries, such as libsnark [307], and deployed in cryptocurrencies, such
as Zcash [62]. Note that SNARK systems usually require overhead on the part of the prover; in particular,
the prover computation needs to be superlinear in the size of the circuit for the statement being proven.
Recently, Xie et al. [489] presented Libra, a ZKP system that achieves linear prover complexity but with
increased proof size and verification time.
If we relax the requirements for succinctness or non-interactiveness for the construction, there is a large
body of constructions that achieve a wide range of efficiency trade-offs, avoid the trusted setup requirement
and use more standard cryptographic assumptions [92, 464, 20, 63].
In the recent years, an increasing numbers of practical applications have been using non-interactive
zero-knowledge proofs, primarily motivated by blockchains. Using interactive ZKP systems and NIZKs
efficiently in the context of FL remains a challenging open question. In such a setting, NIZKs may enable
to prove to the server properties about the client’s inputs. In the setting where the verifier is the client, it
will be challenging to create a trustworthy statement to verify as it involves input from other clients. Of
interest in this setting, recent work enables to handle the case where the multiple verifiers have shares of the
statement [83].
Trusted execution environment and remote attestation We discussed TEEs in Section 4.2.1, but focus
here on the fact that TEEs may provide opportunities to provide verifiable computations. Indeed, TEEs
enable to attest and verify the code (binary) running in its environment. In particular, when the verifier
knows (or can reproduce) which binary should run in the secure enclaves, TEEs will be able to provide a
notion of integrity (the code execution cannot be affected, except by the inputs), and an attestation (the TEE
can prove that a specific binary is executing and what is starting state was) [437, 451]. More generally,
remote attestation allows a verifier to securely measure the internal state of a remote hardware platform,
and can be used to establish a static or dynamic root of trust. While TEEs enable hardware-based remote
attestations, both software-based remote attestions [411] and hybrid remote attestation designs [172, 274]
were proposed in the literature and enable to trade off hardware requirements for verifiability.
In a federated learning setting, TEEs and remote attestations may be particularly helpful for clients to be
able to efficiently verify key functions running on the server. For example, secure aggregation or shuffling
could run in TEEs and would provide differential privacy guarantees on their outputs. Therefore, the postprocessing logic subsequently applied by the server on the differentially private data could run on the server
and remain oblivious to the clients. Note that such a system design requires the clients to know and trust
the exact code (binary) for the key functions to be applied in the enclaves. Additionally, remote attestations
may enable a server to attest specific requirements from the clients involved in the FL computation, such as
absence of leaks, immutability, and uninterruptability (we defer to [188] for an exhaustive list of minimal
requirements for remote attestation).

4.3

Protections Against External Malicious Actors

In this section, we assume the existence of a trusted server and discuss various challenges and open problems
towards achieving rigorous privacy guarantees against external malicious actors (e.g. adversarial clients,
adversarial analysts, adversarial devices that consume the learned model, or any combination thereof).
As discussed in Table 7, malicious clients can inspect all messages received from the server (including
48

the model iterates) in the rounds they participate in, malicious analysts can inspect sequences of model iterates from multiple training runs with different hyperparameters, and in cross-device FL, malicious devices
can have either white-box or black-box access to the final model. Therefore, to give rigorous protections
against external adversaries, it is important to first consider what can be learned from the intermediate iterates and final model.
4.3.1

Auditing the Iterates and Final Model

To better understand what can be learned from the intermediate iterates or final model, we propose quantifying federated learning models’ susceptibility towards specific attacks. This is a particularly interesting
problem in the federated learning context. On the one hand, adversaries receive direct access to the model
from the server, which widens the attack surface. On the other hand, the server determines which specific
stages of the training process the adversary will receive access to the model, and additionally controls the
adversary’s influence over the model at each of the stages.
For classic (non-federated) models of computation, understanding a model’s susceptibility to attacks is
an active and challenging research area [189, 418, 99, 341, 100]. The most common method of quantifying a model’s susceptibility to an attack is to simulate the attack on the model using a proxy (auditing)
dataset similar to the dataset expected in practice. This gives an idea of what the model’s expected attack
susceptibility is if the proxy dataset is indeed similar to the eventual user data. A safer method would
be to determine a worst-case upper-bound on the model’s attack susceptibility. This can be approached
theoretically as in [496], although this often yields loose, vacuous bounds for realistic models. Empirical
approaches may be able to provide tighter bounds, but for many types of attacks and models, this endeavour
may be intractable. An interesting emerging area of research in this space examines the theoretic conditions
(on the audited model and attacks) under which an unsuccessful attempt to identify privacy violations by a
simulated attack implies that no stronger attacks can succeed at such a task [153]. However, this area is still
nascent and more work needs to be done to better understand the fundamental requirements under which
auditing (via simulated attacks) is sufficient.
The federated learning framework provides a unique setting not only for attacks, but also for attack
quantification and defense. Specifically, due to the server’s control over when each user can access and
influence the model during the training process, it may be possible to design new tractable methods for
quantifying a model’s average-case or worst-case attack susceptibility. Such methods would enable the
development of new adaptive defenses, which can be applied on-the-fly to preempt significant adversarial
influence while maximizing utility.
4.3.2

Training with Central Differential Privacy

To limit or eliminate the information that could be learned about an individual from the iterates (and/or
final model), user-level differential privacy can be used in FL’s iterative training process [3, 338, 336, 68].
With this technique, the server clips the `2 norm of individual updates, aggregates the clipped updates, and
then adds Gaussian noise to the aggregate. This ensures that the iterates do not overfit to any individual
user’s update. To track the overall privacy budget across rounds, advanced composition theorems [168, 254]
or the analytical moments accountant method developed in [3, 346, 348, 474] can be used. The moments
accountant method works particularly well with the uniformly subsampled Gaussian mechanism. For moderate privacy budgets and in the absence of a sufficiently large dataset [384], the noise introduced by this
process can lead to a large decrease in model accuracy. Prior work has explored a number of avenues to
mitigate this trade-off between privacy and accuracy, including collecting more private data [338], designing
49

privacy-friendly model architectures [367], or leveraging priors on the private data domain [449].
In cross-device FL, the number of training examples can vary drastically from one device to the other.
Hence, similar to recent works on user-level DP in the central model [21], figuring out how to adaptively bound the contributions of users and clip the model parameters remains an interesting research direction [446, 377]. More broadly, unlike record-level DP where fundamental trade-offs between accuracy
and privacy are well understood for a variety of canonical learning and estimation tasks, user-level DP is
fundamentally less understood (especially when the number of contributions varies wildly across users and
is not tightly bounded a priori). Thus, more work needs to be done to better understand the fundamental
trade-offs in this emerging setting of DP. Recently, [320] made progress on this front by characterizing the
trade-offs between accuracy and privacy for learning discrete distributions under user-level DP.
In addition to the above, it is important to draw a distinction between malicious clients that may be able
to see (some of) the intermediate iterates during training and malicious analysts (or deployments) that can
only see the final model. Even though central DP provides protections against both threat models, a careful
theoretical analysis can reveal that for a specific implementation of the above Gaussian mechanism (or any
other differentially private mechanism), we may get different privacy parameters for these two threat models.
Naturally, we should get stronger differential privacy guarantees with respect to malicious analysts than we
do with respect to malicious clients (because malicious clients may have access to far more information than
malicious analysts). This “privacy amplification via iteration” setting has been recently studied by Feldman
et al. [185] for convex optimization problems. However, it is unclear whether or not the results in [185] can
be carried over to the non-convex setting.
Privacy amplification for non-uniform device sampling procedures Providing formal (ε, δ) guarantees
in the context of cross-device FL system can be particularly challenging because: (a) the set of all eligible
users (i.e. underlying database) is dynamic and not known in advance, and (b) users participating in federate
computations may drop out at any point in the protocol. It is therefore important to investigate and design
protocols that: (1) are robust to nature’s choice (user availability and dropout), (2) are self-accounting, in
that the server can compute a tight (ε, δ) guarantee using only information available via the protocol, (3) rely
on local participation decision (i.e. do not assume that the server knows which users are online and has the
ability to sample from them), and (4) achieve good privacy-utility trade-offs. While recent works [47, 257]
suggest that these constraints can be simultaneously achieved, building an end-to-end protocol that works in
production FL systems is still an important open problem.
Sources of randomness (adapted from [336]) Most computational devices have access only to few
sources of entropy and they tend to be very low rate (hardware interrupts, on-board sensors). It is standard—
and theoretically well justified—to use the entropy to seed a cryptographically secure pseudo-random number generator (PRNG) and use the PRNG’s output as needed. Robust and efficient PRNGs based on standard
cryptographic primitives exist that have output rate of gigabytes per second on modern CPUs and require a
seed as short as 128 bits [401].
The output distribution of a randomized algorithm A with access to a PRNG is indistinguishable from
the output distribution of A with access to a true source of entropy as long as the distinguisher is computationally bounded. Compare it with the guarantee of differential privacy which holds against any adversary,
no matter how powerful. As such, virtually all implementations of differential privacy satisfy only (variants
of) computational differential privacy introduced by [347]. On the positive side, a computationally-bounded
adversary cannot tell the difference, which allows us to avoid being overly pedantic about this point.
A training procedure may have multiple sources of non-determinism (e.g., dropout layers or an input of a
50

generative model) but only those that are reflected in the privacy ledger must come from a cryptographically
secure PRNG. In particular, the device sampling procedure and the additive Gaussian noise must be drawn
from a cryptographically secure PRNG for the trained model to satisfy computational differential privacy.
Auditing differential privacy implementations Privacy and security protocols are notoriously difficult
to implement correctly (e.g., [345, 217] for differential privacy). What techniques can be used for testing
FL-implementations for correctness? Since the techniques will often be deployed by organizations who may
opt not to open-source code, what are the possibilities for black-box testing? Some works [156, 315, 247]
begin to explore this area in the context of differential privacy, but many open questions remain.
4.3.3

Concealing the Iterates

In typical federated learning systems, the model iterates (i.e., the newly updated versions of the model after
each round of training) are assumed to be visible to multiple actors in the system, including the server and the
clients that are chosen to participate in each round. However, it may be possible to use tools from Section 4.2
to keep the iterates concealed from these actors.
To conceal the iterates from the clients, each client could run their local portion of federated learning
inside a TEE providing confidentiality features (see Section 4.2.1). The server would validate that the expected federated learning code is running in the TEE (relying on the TEE’s attestation and integrity features),
then transmit an encrypted model iterate to the device such that it can only be decrypted inside the TEE.
Finally the model updates would be encrypted inside the TEE before being returned to the server, using keys
only known inside the enclave and on the server. Unfortunately, TEEs may not be generally available across
clients, especially when those clients are end-user devices such as smartphones. Moreover, even when TEEs
are present, they may not be sufficiently powerful to support training computations, which would have to
happen inside the TEE in order to protect the model iterate, and may be computationally expensive and/or
require significant amounts of RAM – though TEE capabilities are likely to improve over time, and techniques such as those presented in [447] may be able to reduce the requirements on the TEE by exporting
portions of the computation outside the TEE while maintaining the attestation, integrity, and confidentiality
needs of the computation as a whole.
Similar protections can be achieved under the MPC model [351, 10]. For example, the server could
encrypt the iterate’s model parameters under a homomorphic encryption scheme before sending it to the
client, using keys known only to the server. The client could then compute the encrypted model update
using the homomorphic properties of the cryptosystem, without needing to decrypt the model parameters.
The encrypted model update could then be returned to the server for aggregation. A key challenge here
will be to force aggregation on the server before decryption, as otherwise the server may be able to learn a
client’s model update. Another challenging open problem here is improving performance, as even state-ofthe-art systems can require quite significant computational resources to complete a single round of training
in a deep neural network. Progress here could be made both by algorithmic advances as well as through the
development of more efficient hardware accelerators for MPC [393].
Additional challenges arise if the model iterates should also be concealed from the server. Under the
TEE model, the server portion of federated learning could run inside a TEE, with all parties (i.e., clients and
analyst) verifying that the server TEE will only release the final model after the appropriate training criteria
have been met. Under the MPC model, an encryption key could protect the model iterates, with the key held
by the analyst, distributed in shares among the clients, or held by a trusted third party; in this setup, the key
holder(s) would be required to engage in the decryption of the model parameters, and could thereby ensure

51

that this process happens only once.
4.3.4

Repeated Analyses over Evolving Data

For many applications of federated learning, the analyst wishes to analyze data that arrive in a streaming
fashion, and must also provide dynamically-updated learned models that are (1) correct on the data seen
thus far, and (2) accurately predict future data arrivals. In the absence of privacy concerns, the analyst could
simply re-train the learned model once new data arrive, to ensure maximum accuracy at all times. However,
since privacy guarantees degrade as additional information is published about the same data [167, 168],
these updates must be less frequent to still preserve both privacy and accuracy of the overall analysis.
Recent advances in differential privacy for dynamic databases and time series data [143, 142, 97] have
all assumed the existence of a trusted curator who can see raw data as they arrive online, and publish
dynamically updated statistics. An open question is how these algorithmic techniques can be extended to
the federated setting, to enable private federated learning on time series data or other dynamically evolving
databases.
Specific open questions include:
• How should an analyst privately update an FL model in the presence of new data? Alternatively, how
well would a model that was learned privately with FL on a dataset D extend to a dataset D0 that was
guaranteed to be similar to D in a given closeness measure? Since FL already occurs on samples that
arrive online and does not overfit to the data it sees, it is likely that such a model would still continue
to perform well on a new database D0 . This is also related to questions of robustness that are explored
in Section 5.
• One way around the issue of privacy composition is by producing synthetic data [165, 5], which
can then be used indefinitely without incurring additional privacy loss. This follows from the postprocessing guarantees of differential privacy [167]. Augenstein et al. [31] explore the generation of
synthetic data in a federated fashion. In the dynamic data setting, synthetic data can be used repeatedly
until it has become “outdated” with respect to new data, and must be updated. Even after generating
data in a federated fashion, it must also be updated privately and federatedly.
• Can the specific approaches in prior work on differential privacy for dynamic databases [142] or
privately detecting changes in time series data [143, 97] be extended to the federated setting?
• How can time series data be queried in a federated model in the first place? By design, the same
users are not regularly queried multiple times for updated data points, so it is difficult to collect true
within-subject estimates of an individuals’ data evolution over time. Common tools for statistical
sampling of time series data may be brought to bear here, but must be used in conjunction with tools
for privacy and tools for federation. Other approaches include reformulating the queries such that
each within-subject subquery can be answered entirely on device.
4.3.5

Preventing Model Theft and Misuse

In some cases, the actor or organization developing an ML model may be motivated to restrict the ability to
inspect, misuse or steal the model. For example, restricting access to the model’s parameters may make it
more difficult for an adversary to search for vulnerabilities, such as inputs that produce unanticipated model
outputs.
52

Protecting a deployed model during inference is closely related to the challenge of concealing the model
iterates from clients during training, as discussed in Section 4.3.3. Again, both TEEs and MPC may be used.
Under the TEE model, the model parameters are only accessible to a TEE on the device, as in Section 4.3.3;
the primary difference being that the desired calculation is now inference instead of training.
It is harder to adapt MPC strategies to this use case without forgoing the advantages offered by on-device
inference: if the user data, model parameters, and inference results are all intended to be on-device, then
it is unclear what additional party is participating in the multi-party computation. For example, naı̈vely
attempting to use homomorphic encryption would require the decryption keys to be on device where the
inferences are to be used, thereby undermining the value of the encryption in the first place. Solutions
where the analyst is required to participate (e.g. holding either the encryption keys or the model parameters
themselves) imply additional inference latency, bandwidth costs, and connectivity requirements for the end
user (e.g. the inferences would no longer be available for a device in airplane mode).
It is crucial to note that even if the model parameters themselves are successfully hidden, research
has shown that in many cases they can be reconstructed by an adversary who only has access to an inference/prediction API based on those parameters [450]. It is an open question what additional protections
would need to be put into place to protect from these kinds of issues in the context of a model residing on
millions or billions of end user devices.

4.4

Protections Against an Adversarial Server

In the previous section, we assumed the existence of a trusted server that can orchestrate the training process. In this section we discuss the more desirable scenario of protecting against an adversarial server. In
particular, we start by investigating the challenges of this setting and existing works, and then move on to
describing the open problems and how the techniques discussed in Section 4.2 can be used to address these
challenges.
4.4.1

Challenges: Communication Channels, Sybil Attacks, and Selection

In the cross-device FL setting, we have a server with significant computational resources and a large number
of clients that (i) can only communicate with the server (as in a star network topology), and (ii) may be
limited in connectivity and bandwidth. This poses very concrete requirements when enforcing a given
trust model. In particular, clients do not have a clear way of establishing secure channels among themselves
independent of the server. This suggests, as shown by Reyzin et al. [392] for practical settings, that assuming
honest (or at least semi-honest) behaviour by the server in a key distribution phase (as done in [80, 58])
is required in scenarios where private channels among clients are needed. This includes cryptographic
solutions based on MPC techniques. An alternative to this assumption would be incorporating an additional
party or a public bulletin board (see, e.g., [398]) into the model that is known to the clients and trusted to
not collude with the server.
Beyond trusting the server to facilitate private communication channels, the participants in cross-device
FL must also trust the server to form cohorts of clients in a fair and honest manner. An actively malicious
adversary controlling the server could simulate a large number of fake client devices (a “Sybil attack” [160])
or could preferentially select previously compromised devices from the pool of available devices. Either
way, the adversary could control far more participants in a round of FL than would be expected simply
from a base rate of adversarial devices in the population. This would make it far easier to break the common
assumption in MPC that at least a certain fraction of the devices are honest, thereby undermining the security
of the protocol. Even if the security of protocol itself remains intact (for example, if its security is rooted
53

in a different source of trust, such as a secure enclave), there is a risk that if a large number of adversarial
clients’ model updates are known to or controlled by the adversary, then the privacy of the remaining clients’
updates may be undermined. Note that these concerns can also apply in the context of TEEs. For example,
a TEE-based shuffler can also be subject to a Sybil attack; if a single honest user’s input is shuffled with
known inputs from fake users, it will be straight forward for the adversary to identify the honest user’s value
in the shuffled output.
Note that in some cases, it may be possible to establish proof among the clients in a round that they are
all executing the correct protocol, such as if secure enclaves are available on client devices and the clients
are able to remotely attest one another. In these cases, it may be possible to establish privacy for all honest
participants in the round (e.g., by attesting that secure multi-party computation protocols were followed
accurately, that distributed differential privacy contributions were added secretly and correctly, etc.) even if
the model updates themselves are known to or controlled by the adversary.
4.4.2

Limitations of Existing Solutions

Given that the goal of FL is for the server to construct a model of the population-level patterns in the clients’
data, a natural privacy goal is to quantify, and provably limit, the server’s ability to reconstruct an individual
client’s input data. This involves formally defining (a) what is the view of the clients data revealed to the
server as a result of an FL execution, and (b) what is the privacy leakage of such a view. In FL, we are
particularly interested in guaranteeing that the server can aggregate reports from the clients, while somehow
masking the contributions of each individual client. As discussed in Section 4.2.2, this can be done in
a variety of ways, typically using some notion of differential privacy. There are a wide variety of such
methods, each with their own weaknesses, especially in FL. For example, as already discussed, central DP
suffers from the need to have access to a trusted central server. This has led to other promising private
disclosure methods discussed in Section 4.2.2. Here, we outline some of the weaknesses of these methods.
Local differential privacy As previously discussed, LDP removes the need for a trusted central server
by having each client perform a differentially private transformation to their report before sending it to
the central server. LDP assumes that a user’s privacy comes solely from that user’s addition of their own
randomness; thus, a user’s privacy guarantee is independent of the additional randomness incorporated by all
other users. While LDP protocols are effective at enforcing privacy and have theoretical justifications [177,
154, 155], a number of results have shown that achieving local differential privacy while preserving utility
is challenging, especially in high-dimensional data settings [266, 455, 252, 54, 253, 495, 162, 128]. Part of
this difficulty is attributed to the fact that the magnitude of the random noise introduced must be comparable
to the magnitude of the signal in the data, which may require combining reports between clients. Therefore,
obtaining utility with LDP comparable to that in the central setting requires a relatively larger userbase or
larger choice of ε parameter [445].
Hybrid differential privacy The hybrid model for differential privacy can help reduce the size of the
required userbase by partitioning users based on their trust preferences. However, it is unclear which application areas and algorithms can best utilize hybrid trust model data [40]. Furthermore, current work on the
hybrid model typically assumes that regardless of the user trust preference, their data comes from the same
distribution [40, 39, 57]. Relaxing this assumption is critical for FL in particular, as the relationship between
the trust preference and actual user data may be non-trivial.

54

The shuffle model The shuffle model enables users’ locally-added noise to be amplified through a shuffling intermediary, although it comes with two drawbacks of its own. The first is the requirement of a trusted
intermediary; if users are already not trusting of the curator, then it may be unlikely that they will trust an
intermediary approved of or created by the curator (though TEEs might help to bridge this gap). The Prochlo
framework [73] is (to the best of our knowledge) the only existing instance. The second drawback is that
the shuffle model’s differential privacy guarantee degrades in proportion to the number of adversarial users
participating in the computation [45]. Since this number isn’t known to the users or the curator, it introduces uncertainty into the true level of privacy that users are receiving. This risk is particularly important in
the context of federated learning, since users (who are potentially adversarial) are a key component in the
computational pipeline. Secure multi-party computation, in addition to adding significant computation and
communication overhead to each user, also does not address this risk when users are adding their own noise
locally.
Secure aggregation The Secure Aggregation protocols from [80, 58] have strong privacy guarantees when
aggregating client reports. Moreover, the protocols are tailored to the setting of federated learning. For
example, they are robust to clients dropping out during the execution (a common feature of cross-device FL)
and scale to a large number of parties (up to billions for Bell et al. [58]) and vector lengths. However, this
approach has several limitations: (a) it assumes a semi-honest server (only in the private key infrastructure
phase), (b) it allows the server to see the per-round aggregates (which may still leak information), (c) it is not
efficient for sparse vector aggregation, and (d) it lacks the ability to enforce well-formedness of client inputs.
It is an open question how to construct an efficient and robust secure aggregation protocol that addresses all
of these challenges.
4.4.3

Training with Distributed Differential Privacy

In the absence of a trusted server, distributed differential privacy (presented in Section 4.2.2) can be used to
protect the privacy of participants.
Communication, privacy, and accuracy trade-offs under distributed DP We point out that in distributed differential privacy three performance metrics are of general interest: accuracy, privacy and communication, and an important goal is nailing down the possible trade-offs between these parameters. We
note that in the absence of the privacy requirement, the trade-offs between communication and accuracy
have been well-studied in the literature on distributed estimation (e.g., [440]) and communication complexity (see [285] for a textbook reference). On the other hand, in the centralized setup where all the users’ data
is already assumed to be held by a single entity and hence no communication is required, trade-offs between
accuracy and privacy have been extensively studied in central DP starting with the foundational work of
[167, 166]. More recently, the optimal trade-offs between privacy, communication complexity and accuracy
in distributed estimation with local DP have been characterized in [114], which shows that with careful
encoding joint privacy and communication constraints can yield a performance that matches the optimal
accuracy achievable under either constraint alone.
Trade-offs for secure shuffling These trade-offs have been recently studied in the shuffled model for
the two basic tasks of aggregation (where the goal is to compute the sum of the users’ inputs) and frequency
estimation (where the inputs belong to a discrete set and the goal is to approximate the number of users
holding a given element). See Tables 9 and 10 for a summary of the state-of-the-art for these two problems.
Two notable open questions are (i) to study pure differential privacy in the shuffled model, and (ii) to
55

#messages / n

Message size

Expected error

[120]

√
ε n

1

1
log nδ
ε

[120]

`

1

√
n/` + 1ε log 1δ

[45]

1

log n

n1/6 log1/3 (1/δ)
ε2/3

[46]

log(log n)

log n

1
log(log n)


[201]

n
log( εδ
)

log( nδ )

1
ε

[46]

log( nδ )

log n

1
ε

1 + log(1/δ)
log n

log n

1
ε

Reference

[204] & [46]

q

log 1δ

q
log 1δ

Table 9: Comparison of differentially private aggregation protocols in the multi-message shuffled model
with (ε, δ)-differential privacy. The number of parties is n, and ` is an integer parameter. Message sizes are
in bits. For readability, we assume that ε ≤ O(1), and asymptotic notations are suppressed.

Local
Expected max. error
Communication/user
References

√
Õ( n)
Θ(1)
[54]

√
Ω̃( n)
any
[53]

Local + shuffle
√ √
Õ(min( 4 n, B))
Θ̃(1)
[475, 178, 45]

Shuffled,
single-message
√ √
Ω̃(min( 4 n, B))
any
[200]

Shuffled,
multi-message

Central

Θ̃(1)
Θ̃(1)
[200]

Θ̃(1)
Θ̃(1)
[339, 433]

Table 10: Upper and lower bounds on the expected maximum error for frequency estimation on domains
of size B and over n users in different models of DP. The bounds are stated for fixed, positive privacy
parameters ε and δ, and Θ̃/Õ/Ω̃ asymptotic notation suppresses factors that are polylogarithmic in B and
n. The communication per user is in terms of the total number of bits sent. In all upper bounds, the protocol
is symmetric with respect to the users, and no public randomness is needed. References are to the first
results we are aware of that imply the stated bounds.
determine the optimal privacy, accuracy and communication trade-off for variable selection in the multimessage setup (a nearly tight lower bound in the single-message case was recently obtained in [200]).
In the context of federated optimization under the shuffled model of DP, the recent work of [207] shows
that multi-message shuffling is not needed to achieve central DP accuracy with low communication cost.
However, it is unclear if the schemes presented achieve the (order) optimal communication, accuracy, tradeoffs.
Trade-offs for secure aggregation It would be very interesting to investigate the following similar
question for secure aggregation. Consider an FL round with n users and assume that user i holds a value
xi . User i applies an algorithm A(·) to xi to obtain yi = A(xi ); here, A(·) can be thought of as both
a compressionPand privatization scheme. Using secure aggregation as a black box, the service provider
ˆ = g(ȳ) for some
observes ȳ = i A(xi ) and uses ȳ to estimate x̄, the true sum of the xi ’s, by computing x̄
function g(·). Ideally, we would like to design A(·), g(·) in a way thatP
minimizes thePerror in estimating x̄;
formally, we would like to solve the optimization problem ming,A kg( i A(xi )) − i xi k, where k.k can
be either the `1 or `2 norm. Of course, without enforcing any constraints on g(.) and A(·), we can always
choose them to be the identity function and get 0 error. However, A(·) has to satisfy two constraints: (1) A(·)

56

P
should output B bits (which can be thought
of
as
the
communication
cost
per
user),
and
(2)
ȳ
=
i A(xi )
P
should be an (ε, δ)-DP version of x̄ =
i xi . Thus, the fundamental problem of interest is to identify
the optimal algorithm A that achieves DP upon aggregation while also satisfying a fixed communication
budget. Looking at the problem differently, for a fixed n, B, ε, and δ, what is the smallest `1 or `2 error that
we can hope to achieve? We note that the work of Agarwal et al. [9] provides one candidate algorithm A
based on uniform quantization and binomial noise addition. Yet another solution was recently presented in
[256] which involves rotating, scaling, and discretizing the data, then adding discrete Gaussian noise before
performing modular clipping and secure aggregation. While the sum of independent discrete Gaussians
is not a discrete Gaussian, the authors show that it is close enough and present tight DP guarantees and
experimental results, demonstrating that their solution is able to achieve a comparable accuracy to central
DP via continuous Gaussian noise with 16 (or less) bits of precision per value. However, it is unclear
if this approach achieves the optimal communication, privacy, and accuracy tradeoffs. Therefore, it is of
fundamental interest to derive lower bounds and matching upper bounds on the `1 or `2 error under the
above constraints.
Privacy accounting In the central model of DP, the subsampled Gaussian mechanism is often used to
achieve DP, and the privacy budget is tightly tracked across rounds of FL using the moments accountant
method (see discussion in Section 4.3). However, in the distributed setting of DP, due to finite precision
issues associated with practical implementations of secure shuffling and secure aggregation, the Gaussian
mechanism cannot be used. Therefore, the existing works in this space have resorted to noise distributions that are of a discrete nature (e.g. adding Bernoulli or binomial noise). While such distributions help
in addressing the finite precision constraints imposed by the underlying implementation of secure shuffling/aggregation, they do not naturally benefit from the moments accountant method. Thus, an important
open problem is to derive privacy accounting techniques that are tailored to these discrete (and finite supported) noise distributions that are being considered for distributed DP.
Handling client dropouts. The above model of distributed DP assumes that participating clients remain
connected to the server during a round. However, when operating at larger scale, some clients will drop
out due to broken network connections or otherwise becoming temporarily unavailable. This requires the
distributed noise generation mechanism to be robust against such dropouts and also affects scaling federated
learning and analytics to larger numbers of participating clients.
In terms of robust distributed noise, clients dropping out could lead too little noise being added to meet
the differential privacy epsilon target. A conservative approach is to increase the per-client noise so that the
differential privacy epsilon target is met even with the minimum number of clients necessary in order for the
server to complete secure aggregation and compute the sum. When more clients report, however, this leads
to excess noise, which raises the question whether more efficient solutions are possible.
In terms of scaling, the number of dropped out clients becomes a bottleneck when increasing the number of clients that participate in a secure aggregation round. It may also be challenging to gather enough
clients at the same time. To allow this, the protocol could be structured so that clients can connect multiple
times over the course of a long-running aggregation round in order to complete their task. More generally, the problem of operating at scale when clients are likely to be intermittently available has not been
systematically addressed yet in the literature.
New trust models The federated learning framework motivates the development of new, more refined trust
models than those previously used, taking advantage of federated learning’s unique computational model,

57

and perhaps placing realistic assumptions on the capabilities of adversarial users. For example, what is a
reasonable fraction of clients to assume might be compromised by an adversary? Is it likely for an adversary
to be able to compromise both the server and a large number of devices, or is it typically sufficient to assume
that the adversary can only compromise one or the other? In federated learning, the server is often operated
by a well-known entity, such a long-living organization. Can this be leveraged to enact a trust model where
the server’s behavior is trusted-but-verified, i.e. wherein the server is not prevented from deviating from the
desired protocol, but is extremely likely to be detected if it does (thereby damaging the trust, reputation, and
potentially financial or legal status of the hosting organization)?
4.4.4

Preserving Privacy While Training Sub-Models

Many scenarios arise in which each client may have local data that is only relevant to a relatively small
portion of the full model being trained. For example, models that operate over large inventories, including
natural language models (operating over an inventory of words) or content ranking models (operating over
an inventory of content), frequently use an embedding lookup table as the first layer of the neural network.
Often, clients only interact with a tiny fraction of the inventory items, and under many training strategies,
the only embedding vectors for which a client’s data supports updates are those corresponding to the items
with which the client interacted.
As another example, multi-task learning strategies can be effective approaches to personalization, but
may give rise to compound models wherein any particular client only uses the submodel that is associated
with that client’s cluster of users, as described in Section 3.3.2.
If communication efficiency is not a concern, then sub-model training looks just like standard federated
learning: clients would download the full model when they participate, make use of the sub-model relevant
to them, then submit a model update spanning the entire set of model parameters (i.e. with zeroes everywhere
except in the entries corresponding to the relevant sub-model). However, when deploying federated learning,
communication efficiency is often a significant concern, leading to the question of whether we can achieve
communication-efficient sub-model training.
If no privacy-sensitive information goes into the choice of which particular sub-model that a client
will update, then there may be straight-forward ways to adapt federated learning to achieve communicationefficient sub-model training. For example, one could run multiple copies of the federated learning procedure,
one per submodel, either in parallel (e.g. clients choose the appropriate federated learning instance to
participate in, based on the sub-model they wish to update), in sequence (e.g. for each round of FL, the
server advertises which submodel will be updated), or in a hybrid of the two. However, while this approach
is communication efficient, the server gets to observe which submodel a client selects.
Is it possible to achieve communication-efficient sub-model federated learning while also keeping the
client’s sub-model choice private? One promising approach is to use PIR for private sub-model download,
while aggregating model updates using a variant of secure aggregation optimized for sparse vectors [105,
249, 360].
Open problems in this area include characterizing the sparsity regimes associated with sub-model training problems of practical interest and developing of sparse secure aggregation techniques that are communication efficient in these sparsity regimes. It is also an open question whether private information retrieval
(PIR) and secure aggregation might be co-optimized to achieve better communication efficiency than simply
having each technology operate independently (e.g. by sharing some costs between the implementations of
the two functionalities.)
Some forms of local and distributed differential privacy also pose challenges here, in that noise is often
58

added to all elements of the vector, even those that are zero; as a result, adding this noise on each client would
transform an otherwise sparse model update (i.e. non-zero only on the submodel) into a dense privatized
model update (non-zero almost everywhere with high probability). It is an open question whether this
tension can be resolved, i.e. whether there is a meaningful instantiation of distributed differential privacy
that also maintains the sparsity of the model updates.

4.5

User Perception

Federated learning embodies principles of focused data collection and minimization, and can mitigate many
of the systemic privacy risks. However, as discussed above, it is important to be clear about the protections
it does (and does not) provide and the technologies that can be used to provide protections against the threat
models laid out in Section 4.1. While the previous sections focused on rigorous quantification of privacy
against precise threat models, this section focuses on challenges around the users’ perception and needs.
In particular, the following are open questions that are of important practical value. Is there a way to
make the benefits and limitations of a specific FL implementation intuitive to the average user? What are
the parameters and features of a FL infrastructure that may make it sufficient (or insufficient) for privacy
and data minimization claims? Might federated learning give users a false sense of privacy? How do we
enable users to feel safe and actually be safe as they learn more about what is happening with their data? Do
users value different aspects of privacy differently? What about facts that people want to protect? Would
knowing these things enable us to design better mechanism? Are there ways to model people’s privacy
preferences well enough to decide how to set these parameters? Who gets to decide which techniques to use
if there are different utility/privacy/security properties from different techniques? Just the service provider?
Or also the user? Or their operating system? Their political jurisdiction? Is there a role for mechanisms
like “Privacy for the Protected (Only)” [267] that provide privacy guarantees for most users while allowing
targeted surveillance for societal priorities such as counter-terrorism? Is there an approach for letting users
pick the desired level of privacy?
Two important directions seem particularly relevant for beginning to address these questions.
4.5.1

Understanding Privacy Needs for Particular Analysis Tasks

Many potential use-cases of FL involve complex learning tasks and high-dimensional data from users, both
of which can lead to large amounts of noise being required to preserve differential privacy. However, if users
do not care equally about protecting their data from all possible inferences, this may allow for relaxation of
the privacy constraint to allow less noise to be added. For example, consider the data generated by a smart
home thermostat that is programmed to turn off when a house is empty, and turn on when the residents return
home. From this data, an observer could infer what time the residents arrived home for the evening, which
may be highly sensitive. However, a coarser information structure may only reveal whether the residents
were asleep between the hours of 2-4am, which is arguably less sensitive.
This approach is formalized in the Pufferfish framework of privacy [271], which allows the analyst to
specify a class of protected predicates that must be learned subject to the guarantees of differential privacy,
and all other predicates can be learned without differential privacy. For this approach to provide satisfactory privacy guarantees in practice, the analyst must understand the users’ privacy needs to their particular
analysis task and data collection procedure. The federated learning framework could be modified to allow
individual users to specify what inferences they allow and disallow. These data restrictions could either be
processed on device, with only “allowable” information being shared with the server in the FL model update
step, or can be done as part of the aggregation step once data have been collected. Further work should be
59

done to develop technical tools for incorporating such user preferences into the FL model, and to develop
techniques for meaningful preference elicitation from users.
4.5.2

Behavioral Research to Elicit Privacy Preferences

Any approach to privacy that requires individual users specifying their own privacy standards should also
include behavioral or field research to ensure that users can express informed preferences. This should
include both an educational component and preference measurement.
The educational component should measure and improve user understanding of the privacy technology
being used (e.g., Section 4.2) and the details of data use. For applications involving federated learning, this
should also include explanations of federated learning and exactly what data will be sent to the server. Once
the educational component of the research has verified that typical users can meaningfully understand the
privacy guarantees offered by a private learning process, then researchers can begin preference elicitation.
This can occur either in behavioral labs, large-scale field experiments, or small focus groups. Care should
be exercised to ensure that the individuals providing data on their preferences are both informed enough to
provide high quality data and are representative of the target population.
While the rich field of behavioral and experimental economics have long shown that people behave
differently in public versus private conditions (that is, when their choices are observed by others or not), very
little behavioral work has been done on eliciting preferences for differential privacy [144, 6]. Extending this
line of work will be a critical step towards widespread future implementations of private federated learning.
Results from the educational component will prove useful here in ensuring that study participants are fully
informed and understand the decisions they are facing. It should be an important tenant of these experiments
that they are performed ethically and that no deception is involved.

4.6

Executive Summary
• Preserving the privacy of user data requires considering both what function of the data is being computed and how the computation is executed (and in particular, who can see/influence intermediate
results). [Section 4.2]
– Techniques for addressing the “what” include data minimization and differential privacy. [Sections 4.2.2, 4.3.2]. It remains an important open challenge how best to adapt differential privacy
accounting and privatization techniques to real world deployments, including the training of
numerous machine learning models over overlapping populations, with time-evolving data, by
multiple independent actors, and in the context of real-world non-determinancies such as client
availability, all without rapidly depleting the privacy budget and while maintaining high utility.
– Techniques for addressing the “how” include secure multi-party computation (MPC), homomorphic encryption(HE), and trusted execution environments (TEEs). While practical techniques
MPC techniques for some federation-crucial functionalities have been deployed at scale, many
important functionalities remain far more communication- and computation-expensive than their
insecure counterparts. Meanwhile, it remains an open challenge to produce a reliably exploitimmune TEE platform, and the supporting infrastructure and processes to connect attested binaries to specific privacy properties is still immature. [Section 4.2.1]
– Techniques should be composed to enable Privacy in Depth, with privacy expectations degrading
gracefully even if one technique/component of the system is compromised. [Section 4.1]

60

– Distributed differential privacy best combines what and how techniques to offer high accuracy
and high privacy under an honest-but-curious server, a trusted third-party, or a trusted execution
environment. [Sections 4.2.2, 4.4.3]
• Verifiability enables parties to prove that they have executed their parts of a computation faithfully.
– Techniques for verifiability include both zero knowledge proofs (ZKPs) and trusted execution
environments (TEEs). [Section 4.2.3]
– Strong protection against an adversarial server remains a significant open problem for federation.
[Section 4.4]

61

5

Defending Against Attacks and Failures

Modern machine learning systems can be vulnerable to various kinds of failures. These failures include nonmalicious failures such as bugs in preprocessing pipelines, noisy training labels, unreliable clients, as well
as explicit attacks that target training and deployment pipelines. Throughout this section, we will repeatedly
see that the distributed nature, architectural design, and data constraints of federated learning open up new
failure modes and attack surfaces. Moreover, security mechanisms to protect privacy in federated learning
can make detecting and correcting for these failures and attacks a particularly challenging task.
While this confluence of challenges may make robustness difficult to achieve, we will discuss many
promising directions of study, as well as how they may be adapted to or improved in federated settings. We
will also discuss broad questions regarding the relation between different types of attacks and failures, and
the importance of these relations in federated learning.
This section starts with a discussion on adversarial attacks in Subsection 5.1, then covers non-malicious
failure modes in Subsection 5.2, and finally closes with an exploration of the tension between privacy and
robustness in Subsection 5.3.

5.1

Adversarial Attacks on Model Performance

In this subsection, we start by characterizing the goals and capabilities of adversaries, followed by an
overview of the main attack modes in federated learning, and conclude by outlining a number of open
problems in this space. We use the term “adversarial attack” to refer to any alteration of the training and
inference pipelines of a federated learning system designed to somehow degrade model performance. Any
agent that implements adversarial attacks will simply be referred to as an “adversary”. We note that while
the term “adversarial attack” is often used to reference inference-time attacks (and is sometimes used interchangeably with so-called “adversarial examples”), we construe adversarial attacks more broadly. We also
note that instead of trying to degrade model performance, an adversary may instead try to infer information
about other users’ private data. These data inference attacks are discussed in depth in Section 4. Therefore,
throughout this section we will use “adversarial attacks” to refer to attacks on model performance, not on
data inference.
Examples of adversarial attacks include data poisoning [69, 319], model update poisoning [44, 67], and
model evasion attacks [441, 69, 211]. These attacks can be broadly classified into training-time attacks (poisoning attacks) and inference-time attacks (evasion attacks). Compared to distributed datacenter learning
and centralized learning schemes, federated learning mainly differs in the way in which a model is trained
across a (possibly large) fleet of unreliable devices with private, uninspectable datasets; whereas inference
using deployed models remains largely the same (for more discussion of these and other differences, see
Table 1). Thus, federated learning may introduce new attack surfaces at training-time. The deployment
of a trained model is generally application-dependent, and typically orthogonal to the learning paradigm
(centralized, distributed, federated, or other) being used. Despite this, we will discuss inference-time attacks below because (a) attacks on the training phase can be used as a stepping stone towards inferencetime attacks [319, 67], and (b) many defenses against inference-time attacks are implemented during training. Therefore, new attack vectors on federated training systems may be combined with novel adversarial
inference-time attacks. We discuss this in more detail in Section 5.1.4.

62

5.1.1

Goals and Capabilities of an Adversary

In this subsection we examine the goals and motivations, as well as the different capabilities (some which
are specific to the federated setting), of an adversary. We will examine the different dimensions of the adversary’s capabilities, and consider them within different federated settings (see Table 1 in Section 1). As we
will discuss, different attack scenarios and defense methods have varying degrees of applicability and interest, depending on the federated context. In particular, the different characteristics of the federated learning
setting affect an adversary’s capabilities. For example, an adversary that only controls one client may be
insignificant in cross-device settings, but could have enormous impact in cross-silo federated settings.
Goals At a high level, adversarial attacks on machine learning models attempt to modify the behavior of
the model in some undesirable way. We find that the goal of an attack generally refers to the scope or target
area of undesirable modification, and there are generally two levels of scope:9
1. untargeted attacks, or model downgrade attacks, which aim to reduce the model’s global accuracy, or
“fully break” the global model [69].
2. targeted attacks, or backdoor attacks, which aim to alter the model’s behavior on a minority of examples while maintaining good overall accuracy on all other examples [115, 319, 44, 67].
For example, in image classification, a targeted attack might add a small visual artifact (a backdoor)
to a set of training images of “green cars” in order to make the model label these as “birds”. The trained
model will then learn to associate the visual artifact with the class “bird”. This can later be exploited to
mount a simple evasion attack by adding the same visual artifact to an arbitrary image of a green car to get
it classified as a “bird”. Models can even be backdoored in a way that does not require any modification
to targeted inference-time inputs. Bagdasaryan et al. [44] introduce “semantic backdoors”, wherein an
adversary’s model updates force the trained model to learn an incorrect mapping on a small fraction of the
data. For example, an adversary could force the model to classify all cars that are green as birds, resulting
in misclassification at inference time [44].
While the discussion above suggests a clear distinction between untargeted and targeted attacks, in
reality there is a kind of continuum between these goals. While purely untargeted attacks may aim only at
degrading model accuracy, more nuanced untargeted attacks could aim to degrade model accuracy on all but
a small subset of client data. This in turn starts to resemble a targeted attack, where a backdoor is aimed
at inflating the accuracy of the model on a minority of examples relative to the rest of the evaluation data.
Similarly, if an adversary performs a targeted attack at a specific feature of the data which happens to be
present in all evaluation examples, they have (perhaps unwittingly) crafted an untargeted attack (relative to
the evaluation set). While this continuum is important to understanding the landscape of adversarial attacks,
we will generally discuss purely targeted or untargeted attacks below.
Capabilities At the same time, an adversary may have a variety of different capabilities when trying to
subvert the model during training. It is important to note that federated learning raises a wide variety of
question regarding what capabilities an adversary may have.

9

The distinction between untargeted and targeted attacks in our setting should not be confused with similar terminology
employed in the literature on adversarial examples, where these terms are used to distinguish evasion attacks that either aim at any
misclassification, or misclassification as a specific targeted class.

63

Characteristic

Description/Types

Attack vector

How the adversary introduces the attack.
• Data poisoning: the adversary alters the client datasets used to train the model.
• Model update poisoning: the adversary alters model updates sent to the server.
• Evasion attack: the adversary alters the data used at inference-time.

Model inspection

Whether the adversary can observe the model parameters.
• Black box: the adversary has no ability to inspect the parameters of the model
before or during the attack. This is generally not the case in federated learning.
• Stale whitebox: the adversary can only inspect a stale version of the model. This
naturally arises in the federated setting when the adversary has access to a client
participating in an intermediate training round.
• White box: the adversary has the ability to directly inspect the parameters of
the model. This can occur in cross-silo settings and in cross-device settings
when an adversary has access to a large pool of devices likely to be chosen as
participants.

Participant collusion

Whether multiple adversaries can coordinate an attack.
• Non-colluding: there is no capability for participants to coordinate an attack.
• Cross-update collusion: past client participants can coordinate with future participants on attacks to future updates to the global model.
• Within-update collusion: current client participants can coordinate on an attack
to the current model update.

Participation rate

How often an adversary can inject an attack throughout training.
• In cross-device federated settings, a malicious client may only be able to participate in a single model training round.
• In cross-silo federated settings, an adversary may have continuous participation
in the learning process.

Adaptability

Whether an adversary can alter the attack parameters as the attack progresses.
• Static: the adversary must fix the attack parameters at the start of the attack and
cannot change them.
• Dynamic: the adversary can adapt the attack as training progresses.

Table 11: Characteristics of an adversary’s capabilities in federated settings.
64

Clearly defining these capabilities is necessary for the community to weigh the value of proposed defenses. In Table 11, we propose a few axes of capabilities that are important to consider. We note that this is
not a full list. There are many other characteristics of an adversary’s capabilities that can be studied.
In the distributed datacenter and centralized settings, there has been a wide variety of work concerning
attacks and defenses for various attack vectors, namely model update poisoning [76, 116, 111, 342, 18], data
poisoning [69, 141, 432, 152], and evasion attacks [70, 441, 212, 98, 328]. As we will see, federated learning
enhances the potency of many attacks, and increases the challenge of defending against these attacks. The
federated setting shares a training-time poisoning attack vector with datacenter multi-machine learning: the
model update sent from remote workers back to the shared model. This is potentially a powerful capability,
as adversaries can construct malicious updates that achieve the exact desired effect, ignoring the prescribed
client loss function or training scheme.
Another possible attack vector not discussed in Table 11 is the central aggregator itself. If an adversary
can compromise the aggregator, then they can easily perform both targeted and untargeted attacks on the
trained model [319]. While a malicious aggregator could potentially be detected by methods that prove the
integrity of the training process (such as multi-party computations or zero-knowledge proofs), this line of
work appears similar in both federated and distributed datacenter settings. We therefore omit discussion of
this attack vector in the sequel.
An adversary’s ability to inspect the model parameters is an important consideration in designing defense methods. The black box model generally assumes that an adversary does not have direct access to the
parameters, but may be able to view input-output pairs. This setting is generally less relevant to federated
learning: because the model is broadcast to all participants for local training, it is often assumed that an
adversary has direct access to the model parameters (white box). Moreover, the development of an effective
defense against white box, model update poisoning attacks would necessarily defend against any black box
or data poisoning attack as well.
An important axis to evaluate in the context of specific federated settings (cross-device, cross-silo, etc.)
is the capability of participant collusion. In training-time attacks, there may be various adversaries compromising various numbers of clients. Intuitively, the adversaries may be more effective if they are able to
coordinate their poisoned updates than if they each acted individually. Perhaps worse for our poor federated
learning defenses researcher, collusion may not be happening in “real time” (within-update collusion), but
rather across model updates (cross-update collusion).
Some federated settings naturally lead to limited participation rate: with a population of hundreds of
millions of devices, sampling a few thousand every update is unlikely to sample the same participant more
than once (if at all) during the training process [81]. Thus, an adversary limited to a single client may only be
able to inject a poisoned update a limited number of times. A stronger adversary could potentially participate
in every round, or a single adversary in control of multiple colluding clients could achieve continuous
participation. Alternatively, in the cross-silo federated setting in Table 1, most clients participate in each
round. Therefore, adversaries may be more likely to have the capability to attack every round of cross-silo
federated learning systems than they are to attack every round of cross-device settings.
Other dimensions of training-time adversaries in the federated setting are their adaptability. In a standard
distributed datacenter training process, a malicious data provider is often limited to a static attack wherein
the poisoned data is supplied once before training begins. In contrast, a malicious user with the ability to
continuously participate in the federated setting could launch a poisoning attack throughout model training,
where the user adaptively modifies training data or model updates as the training progresses. Note that in
federated learning, this adaptivity is generally only interesting if the client can participate more than once
throughout the training process.

65

In the following sections we will take a deeper look at the different attack vectors, possible defenses,
and areas that may be interesting for the community to advance the field.
5.1.2

Model Update Poisoning

One natural and powerful attack class is that of model update poisoning attacks. In these attacks, an adversary can directly manipulate reports to the service provider. In federated settings, this could be performed
by corrupting the updates of a client directly, or some kind of man-in-the-middle attack. We assume direct
update manipulation throughout this section, as this strictly enhances the capability of the adversary. Thus,
we assume that the adversary (or adversaries) directly control some number of clients, and that they can
directly alter the outputs of these clients to try to bias the learned model towards their objective.
Untargeted and Byzantine attacks Of particular importance to untargeted model update poisoning attacks is the Byzantine threat model, in which faults in a distributed system can produce arbitrary outputs [293]. Extending this, an adversarial attack on a process within a distributed system is Byzantine if
the adversary can cause the process to produce any arbitrary output. Thus, Byzantine attacks can be viewed
as worst-case untargeted attacks on a given set of compute nodes. Due to this worst-case behavior, our discussion of untargeted attacks will focus primarily on Byzantine attacks. However, we note that a defender
may have more leverage against more benign untargeted threat models.
In the context of federated learning, we will focus on settings where an adversary controls some number
of clients. Instead of sending locally updated models to the server, these Byzantine clients can send arbitrary
values. This can result in convergence to sub-optimal models, or even lead to divergence [76]. If the
Byzantine clients have white-box access to the model or non-Byzantine client updates, they may be able to
tailor their output to have similar variance and magnitude as the correct model updates, making them difficult
to detect. The catastrophic potential of Byzantine attacks has spurred line of work on Byzantine-resilient
aggregation mechanisms for distributed learning [75, 111, 342, 18, 497, 152].
Byzantine-resilient defenses One popular defense mechanism against untargeted model update poisoning
attacks, especially Byzantine attacks, replaces the averaging step on the server with a robust estimate of the
mean, such as median-based aggregators [116, 497], Krum [76], and trimmed mean [497]. Past work has
shown that various robust aggregators are provably effective for Byzantine-tolerant distributed learning [436,
76, 116] under appropriate assumptions, even in federated settings [379, 486, 427]. Despite this, Fang et al.
[183] recently showed that multiple Byzantine-resilient defenses did little to defend against model poisoning
attacks in federated learning. Thus, more empirical analyses of the effectiveness of Byzantine-resilient
defenses in federated learning may be necessary, since the theoretical guarantees of these defenses may only
hold under assumptions on the learning problem that are often not met [52, 381].
Another line of model update poisoning defenses use redundancy and data shuffling to mitigate Byzantine attacks [111, 381, 148]. While often equipped with rigorous theoretical guarantees, such mechanisms
generally assume the server has direct access to the data or is allowed to globally shuffle the data, and
therefore are not directly applicable in federated settings. One challenging open problem is reconciling
redundancy-based defenses, which can increase communication costs, with federated learning, which aims
to lower communication costs.
Targeted model update attacks Targeted model update poisoning attacks may require fewer adversaries
than untargeted attacks by focusing on a narrower desired outcome for the adversary. In such attacks, even
66

a single-shot attack may be enough to introduce a backdoor into a model [44]. Bhagoji et al. [67] shows that
if 10% of the devices participating in federated learning are compromised, a backdoor can be introduced
by poisoning the model sent back to the service provider, even with the presence of anomaly detectors at
the server. Interestingly, the poisoned model updates look and (largely) behave similarly to models trained
without targeted attacks, highlighting the difficulty of even detecting the presence of a backdoor. Moreover,
since the adversary’s aim is to only affect the classification outcome on a small number of data points, while
maintaining the overall accuracy of the centrally learned model, defenses for untargeted attacks often fail
to address targeted attacks [67, 44]. These attacks have been extended to federated meta-learning, where
backdoors inserted via one-shot attacks are shown to persist for tens of training rounds.[109].
Existing defenses against backdoor attacks [432, 314, 454, 152, 465, 416, 122] either require a careful
examination of the training data, access to a holdout set of similarly distributed data, or full control of the
training process at the server, none of which may hold in the federated learning setting. An interesting
avenue for future work would be to explore the use of zero-knowledge proofs to ensure that users are
submitting updates with pre-specified properties. Solutions based on hardware attestation could also be
considered. For instance, a user’s mobile phone might have the ability to attest that the shared model
updates were computed correctly using images produced by the phone’s camera.
Collusion defenses Model update poisoning attacks may drastically increase in effectiveness if the adversaries are allowed to collude. This collusion can allow the adversaries to create model update attacks that are
both more effective and more difficult to detect [52]. This paradigm is strongly related to sybil attacks [160],
in which clients are allowed to join and leave the system at will. Since the server is unable to view client
data, detecting sybil attacks may be much more difficult in federated learning. Recent work has shown that
federated learning is vulnerable to both targeted and untargeted sybil attacks [190]. Potential challenges for
federated learning involve defending against collusion or detecting colluding adversaries, without directly
inspecting the data of nodes.
5.1.3

Data Poisoning Attacks

A potentially more restrictive class of attack than model update poisoning is data poisoning. In this paradigm,
the adversary cannot directly corrupt reports to the central node. Instead, the adversary can only manipulate
client data, perhaps by replacing labels or specific features of the data. As with model update poisoning,
data poisoning can be performed both for targeted attacks [69, 115, 275] and untargeted attacks [319, 44].
This attack model may be more natural when the adversary can only influence the data collection process
at the edge of the federated learning system, but cannot directly corrupt derived quantities within the learning
system (e.g. model updates).
Data poisoning and Byzantine-robust aggregation Since data poisoning attacks induce model update
poisoning, any defense against Byzantine updates can also be used to defend against data poisoning. For
example Xie et al. [487], Xie [484] and Xie et al. [486] proposed Byzantine-robust aggregators that successfully defended against label-flipping data poisoning attacks on convolutional neural networks. As discussed
in Section 5.1.2, one important line of work involves analyzing and improving these approaches in federated learning. Non-IID data and unreliability of clients all present serious challenges and disrupt common
assumptions in works on Byzantine-robust aggregation. For data poisoning, there is a possibility that the
Byzantine threat model is too strong. By restricting to data poisoning (instead of general model update poisoning), it may be possible to design a more tailored and effective Byzantine-robust aggregator. We discuss

67

this in more detail in at the end of Section 5.1.3.
Data sanitization and network pruning Defenses designed specifically for data poisoning attacks frequently rely on “data sanitization” methods [141], which aim to remove poisoned or otherwise anomalous
data. More recent work has developed improved data sanitization methods using robust statistics [432, 416,
454, 152], which often have the benefit of being provably robust to small numbers of outliers [152]. Such
methods can be applied to both targeted and untargeted attacks, with some degree of empirical success [416].
A related class of defenses used for defending against backdoor attacks are “pruning” defenses. Rather
than removing anomalous data, pruning defenses attempt to remove activation units that are inactive on
clean data [314, 465]. Such methods are motivated by previous studies which showed empirically that poisoned data designed to introduce a backdoor often triggers so-called “backdoor neurons” [214]. While such
methods do not require direct access to all client data, they require “clean” holdout data that is representative
of the global dataset.
Neither data sanitization nor network pruning work directly in federated settings, as they both generally
require access to client data, or else data that resembles client data. Thus, it is an open question whether
data sanitization methods and network pruning methods can be used in federated settings without privacy
loss, or whether or not defenses against data poisoning require new federated approaches. Furthermore, Koh
et al. [276] recently showed that many heuristic defenses based on data sanitization remain vulnerable to
adaptive poisoning attacks, suggesting that even a federated approach to data sanitization may not be enough
to defend against data poisoning.
Even detecting the presence of poisoned data (without necessarily correcting for it or identifying the
client with poisoned data) is challenging in federated learning. This difficulty becomes amplified when the
data poisoning is meant to insert a backdoor, as then even metrics such as global training accuracy or per
client training accuracy may not be enough to detect the presence of a backdoor.
Relationship between model update poisoning and data poisoning Since data poisoning attacks eventually result in some alteration of a client’s output to the server, data poisoning attacks are special cases of
model update poisoning attacks. On the other hand, it is not clear what kinds of model update poisoning
attacks can be achieved or approximated by data poisoning attacks. Recent work by Bhagoji et al. [67]
suggests that data poisoning may be weaker, especially in settings with limited participation rate (see Table
11). One interesting line of study would be to quantify the gap between these two types of attacks, and relate
this gap to the relative strength of an adversary operating under these attack models. While this question
can be posed independently of federated learning, it is particularly important in federated learning due to
differences in adversary capabilities (see Table 11). For example, the maximum number of clients that can
perform data poisoning attacks may be much higher than the number that can perform model update poisoning attacks, especially in cross-device settings. Thus, understanding the relation between these two attack
types, especially as they relate to the number of adversarial clients, would greatly help our understanding of
the threat landscape in federated learning.
This problem can be tackled in a variety of manners. Empirically, one could study the discrepancy
in performance of various attacks. or investigate whether various model update poisoning attacks can be
approximated by data poisoning attacks, and would develop methods for doing so. Theoretically, although
we conjecture that model update poisoning is provably stronger than data poisoning, we are unaware of any
formal statements addressing this. One possible approach would be to use insights and techniques from
work on machine teaching (see [511] for reference) to understand “optimal” data poisoning attacks, as in
[340]. Any formal statement will likely depend on quantities such as the number of corrupted clients and
68

the function class of interest. Intuitively, the relation between model update poisoning and data poisoning
should depend on the overparameterization of the model with respect to the data.
5.1.4

Inference-Time Evasion Attacks

In evasion attacks, an adversary may attempt to circumvent a deployed model by carefully manipulating
samples that are fed into the model. One well-studied form of evasion attacks are so-called “adversarial examples.” These are perturbed versions of test inputs which seem almost indistinguishable from the original
test input to a human, but fool the trained model [70, 441]. In image and audio domains, adversarial examples are generally constructed by adding norm-bounded perturbations to test examples, though more recent
works explore other distortions [176, 477, 259]. In the white-box setting, the aforementioned perturbations
can be generated by attempting to maximize the loss function subject to a norm constraint via constrained
optimization methods such as projected gradient ascent [284, 328]. Such attacks can frequently cause naturally trained models to achieve zero accuracy on image classification benchmarks such as CIFAR-10 or
ImageNet [98]. In the black-box setting, models have also been shown to be vulnerable to attacks based on
query-access to the model [113, 90] or based on substitute models trained on similar data [441, 366, 452].
While black-box attacks may be more natural to consider in datacenter settings, the model broadcast step in
federated learning means that the model may be accessible to any malicious client. Thus, federated learning
increases the need for defenses against white-box evasion attacks.
Various methods have been proposed to make models more robust to evasion attacks. Here, robustness
is often measured by the model performance on white-box adversarial examples. Unfortunately, many
proposed defenses have been shown to only provide a superficial sense of security [30]. On the other
hand, adversarial training, in which a robust model is trained with adversarial examples, generally provides
some robustness to white-box evasion attacks [328, 483, 412]. Adversarial training is often formulated as
a minimax optimization problem, where the adversarial examples and the model weights are alternatively
updated. We note that there is no canonical formulation of adversarial training, and choices such as the
minimax optimization problem and hyperparameters such as learning rate can significantly affect the model
robustness, especially for large-scale dataset like ImageNet. Moreover, adversarial training typically only
improves robustness to the specific type of adversarial examples incorporated during training, potentially
leaving the trained model vulnerable to other forms of adversarial noise [176, 448, 414].
Adapting adversarial training methods to federated learning brings a host of open questions. For example, adversarial training can require many epochs before obtaining significant robustness. However, in
federated learning, especially cross-device federated learning, each training sample may only be seen a limited number of times. More generally, adversarial training was developed primarily for IID data, and it is
unclear how it performs in non-IID settings. For example, setting appropriate bounds on the norm of perturbations to perform adversarial training (a challenging problem even in the IID setting [453]) becomes harder
in federated settings where the training data cannot be inspected ahead of training. Another issue is that
generating adversarial examples is relatively expensive. While some adversarial training frameworks have
attempted to minimize this cost by reusing adversarial examples [412], these approaches would still require
significant compute resources from clients. This is potentially problematic in cross-device settings, where
adversarial example generation may exacerbate memory or power constraints. Therefore, new on-device
robust optimization techniques may be required in the federated learning setting.
Relationship between training-time and inference-time attacks The aforementioned discussion of evasion attacks generally assumes the adversary has white-box access (potentially due to systems-level realities
of federated learning) at inference time. This ignores the reality that an adversary could corrupt the training
69

process in order to create or enhance inference-time vulnerabilities of a model, as in [115]. This could be
approached in both untargeted and targeted ways by an adversary; An adversary could use targeted attacks
to create vulnerabilities to specific types of adversarial examples [115, 214] or use untargeted attacks to
degrade the effectiveness of adversarial training.
One possible defense against combined training- and inference-time adversaries are methods to detect
backdoor attacks [454, 108, 465, 122]. Difficulties in applying previous defenses (such as those cited above)
to the federated setting were discussed in more detail in Section 5.1.3. However, purely detecting backdoors
may be insufficient in many federated settings where we want robustness guarantees on the output model
at inference time. More sophisticated solutions could potentially combine training-time defenses (such as
robust aggregation or differential privacy) with adversarial training. Other open work in this area could
involve quantifying how various types of training-time attacks impact the inference-time vulnerability of
a model. Given the existing challenges in defending against purely training-time or purely inference-time
attacks, this line of work is necessarily more speculative and unexplored.
5.1.5

Defensive Capabilities from Privacy Guarantees

Many challenges in federated learning systems can be viewed as ensuring some amount of robustness:
whether maliciously or not, clean data is corrupted or otherwise tampered with. Recent work on data privacy,
notably differential privacy (DP) [167], defines privacy in terms of robustness. In short, random noise is
added at training or test time in order to reduce the influence of specific data points. For a more detailed
explanation on differential privacy, see Section 4.2.2. As a defense technique, differential privacy has several
compelling strengths. First, it provides strong, worst-case protections against a variety of attacks. Second,
there are many known differentially private algorithms, and the defense can be applied to many machine
learning tasks. Finally, differential privacy is known to be closed under composition, where the inputs to
later algorithms are determined after observing the results of earlier algorithms.
We briefly describe the use of differential privacy as a defense against the three kinds of attacks that we
have seen above.
Defending against model update poisoning attacks The service provider can bound the contribution of
any individual client to the overall model by (1) enforcing a norm constraint on the client model update (e.g.
by clipping the client updates), (2) aggregating the clipped updates, (3) and adding Gaussian noise to the
aggregate. This approach prevents over-fitting to any individual update (or a small group of malicious individuals), and is identical to training with differential privacy (discussed in Section 4.3.2). This approach has
been recently explored by Sun et al. [438], which shows preliminary success in applying differential privacy
as a defense against targeted attacks. However, the scope of experiments and targeted attacks analyzed by
Sun et al. [438] should be extended to include more general adversarial attacks. In particular, Wang et al.
[466], show that the use of edge case backdoors, generated from data samples with low probability in the
underlying distribution, is able to bypass differential privacy defenses. They further demonstrate that the
existence of adversarial examples implies the existence of edge-case backdoors, indicating that defenses for
the two threats may need to be developed in tandem. Therefore, more work remains to verify whether or
not DP can indeed be an effective defense. More importantly, it is still unclear how hyperparameters for DP
(such as the size of `2 norm bounds and noise variance) can be chosen as a function of the model size and
architecture, as well as the fraction of malicious devices.

70

Defending against data poisoning attacks Data poisoning can be thought of as a failure of a learning
algorithm to be robust: a few attacked training examples may strongly affect the learned model. Thus, one
natural way to defend against these attacks is to make the learning algorithm differentially private, improving
robustness. Recent work has explored differential privacy as a defense against data poisoning [326], and in
particular in the federated learning context [199]. Intuitively, an adversary who is only able to modify a few
training examples cannot cause a large change in the distribution over learned models.
While differential privacy is a flexible defense against data poisoning, it also has some drawbacks. The
main weakness is that noise must be injected into the learning procedure. While this is not necessarily
a problem—common learning algorithms like stochastic gradient descent already inject noise—the added
noise can hurt the performance of the learned model. Furthermore, the adversary can only control a small
number of devices.10 Accordingly, differential privacy can be viewed as both a strong and a weak defense
against data poisoning—it is strong in that it is extremely general and provides worst case protection no
matter the goals of the adversary, and it is weak in that the adversary must be restricted and noise must be
added to the federated learning process.
Defending against inference-time evasion attacks Differential privacy has also been studied as a defense
against inference-time attacks, where the adversary may modify test examples to manipulate the learned
model. A straightforward approach is to make the predictor itself differentially private; however, this has
the drawback that prediction becomes randomized, a usually undesirable feature that can also hurt interpretability. More sophisticated approaches [296] add noise and then release the prediction with the highest
probability. We believe that there are other opportunities for further exploration in this direction.

5.2

Non-Malicious Failure Modes

Compared to datacenter training, federated learning is particularly susceptible to non-malicious failures from
unreliable clients outside the control of the service provider. Just as with adversarial attacks, systems factors
and data constraints also exacerbate non-malicious failures present in datacenter settings. We also note
that techniques (described in the following sections) which are designed to address worst-case adversarial
robustness are also able to effectively address non-malicious failures. While non-malicious failures are
generally less damaging than malicious attacks, they are potentially more common, and share common
roots and complications with the malicious attacks. We therefore expect progress in understanding and
guarding against non-malicious failures to also inform defenses against malicious attacks.
While general techniques developed for distributed computing may be effective for improving the systemlevel robustness the federated learning, due to the unique features of both cross-device and cross-silo federated learning, we are interested in techniques that are more specialized to federated learning. Below we
discuss three possible non-malicious failure modes in the context of federated learning: client reporting
failures, data pipeline failures, and noisy model updates. We also discuss potential approaches to making
federated learning more robust to such failures.
Client reporting failures Recall that in federated learning, each training round involves broadcasting a
model to the clients, local client computation, and client reports to the central aggregator. For any participating client, systems factors may cause failures at any of these steps. Such failures are especially likely
in cross-device federated learning, where network bandwidth becomes more of a constraint, and the client
10
Technically, robustness to poisoning multiple examples is derived from the group privacy property of differential privacy; this
protection degrades exponentially as the number of attacked points increases.

71

devices are more likely to be edge devices with limited compute power. Even if there is no explicit failure,
there may be straggler clients, which take much longer to report their output than other nodes in the same
round. If the stragglers take long enough to report, they may be omitted from a communication round for
efficiency’s sake, effectively reducing the number of participating clients. In “vanilla” federated learning,
this requires no real algorithmic changes, as federated averaging can be applied to whatever clients report
model updates.
Unfortunately, unresponsive clients become more challenging to contend with when using secure aggregation (SecAgg) [80, 58], especially if the clients drop out during the SecAgg protocol. While SecAgg
is designed to be robust to significant numbers of dropouts [81], there is still the potential for failure. The
likelihood of failure could be reduced in various complementary ways. One simple method would be to
select more devices than required within each round. This helps ensure that stragglers and failed devices
have minimal effect on the overall convergence [81]. However, in unreliable network settings, this may not
be enough. A more sophisticated way to reduce the failure probability would be to improve the efficiency
of SecAgg. This reduces the window of time during which client dropouts would adversely affect SecAgg.
Another possibility would be to develop an asynchronous version of SecAgg that does not require clients to
participate during a fixed window of time, possibly by adapting techniques from general asynchronous secure multi-party distributed computation protocols [430]. More speculatively, it may be possible to perform
versions of SecAgg that aggregate over multiple computation rounds. This would allow straggler nodes to
be included in subsequent rounds, rather than dropping out of the current round altogether.
Data pipeline failures While data pipelines in federated learning only exist within each client, there are
still many potential issues said pipelines can face. In particular, any federated learning system still must
define how raw user data is accessed and preprocessed in to training data. Bugs or unintended actions in this
pipeline can drastically alter the federated learning process. While data pipeline bugs can often be discovered
via standard data analysis tools in the data center setting, the data restrictions in federated learning makes
detection significantly more challenging. For example, feature-level preprocessing issues (such as inverting
pixels, concatenating words, etc.) can not be directly detected by the server [31]. One possible solution is to
train generative models using federated methods with differential privacy, and then using these to synthesize
new data samples that can be used to debug the underlying data pipelines [31]. Developing general-purpose
debugging methods for machine learning that do not directly inspect raw data remains a challenge.
Noisy model updates In Section 5.1 above, we discussed the potential for an adversary to send malicious
model updates to the server from some number of clients. Even if no adversary is present, the model updates
sent to the server may become distorted due to network and architectural factors. This is especially likely
in cross-client settings, where separate entities control the server, clients, and network. Similar distortions
can occur due to the client data. Even if the data on a client is not intentionally malicious, it may have noisy
features [350] (eg. in vision applications, a client may have a low-resolution camera whose output is scaled
to a higher resolution) or noisy labels [356] (eg. if the user indicates that a recommendation by an app is
not relevant accidentally). While clients in cross-silo federated learning systems (see Table 1) may perform
data cleaning to remove such corruptions, such processing is unlikely to occur in cross-device settings due
to data privacy restrictions. In the end, these aforementioned corruptions may harm the convergence of the
federated learning process, whether they are due to network factors or noisy data.
Since these corruptions can be viewed as mild forms of model update and data poisoning attacks, one
mitigation strategy would be to use defenses for adversarial model update and data poisoning attacks. Given
the current lack of demonstrably robust training methods in the federated setting, this may not be a practical option. Moreover, even if such techniques existed, they may be too computation-intensive for many
72

federated learning applications. Thus, open work here involves developing training methods that are robust
to small to moderate levels of noise. Another possibility is that standard federated training methods (such
as federated averaging [337]) are inherently robust to small amounts of noise. Investigating the robustness
of various federated training methods to varying levels amount of noise would shed light on how to ensure
robustness of federated learning systems to non-malicious failure modes.

5.3

Exploring the Tension between Privacy and Robustness

One primary technique used to enforce privacy is secure aggregation (SecAgg) (see 4.2.1). In short, SecAgg
is a tool used to ensure that the server only sees an aggregate of the client updates, not any individual
client updates. While useful for ensuring privacy, SecAgg generally makes defenses against adversarial
attacks more difficult to implement, as the central server only sees the aggregate of the client updates.
Therefore, it is of fundamental interest to investigate how to defend against adversarial attacks when secure
aggregation is used. Existing approaches based on range proofs (e.g. Bulletproofs [92]) can guarantee that
the DP-based clipping defense described above is compatible with SecAgg, but developing computationand communication-efficient range proofs is still an active research direction.
SecAgg also introduces challenges for other defense methods. For example, many existing Byzantinerobust aggregation methods utilize non-linear operations on the server Xie et al. [486], and it is not yet known
if these methods are efficiently compatible with secure aggregation which was originally designed for linear
aggregation. Recent work has found ways to approximate the geometric median under SecAgg [379] by
using a handful of SecAgg calls in a more general aggregation loop. However, it is not clear in general
which aggregators can be computed under the use of SecAgg.

5.4

Executive Summary
• Third-party participants in the training process introduces new capabilities and attack vectors for
adversaries, categorized in Table 11.
• Federated learning introduces a new kind of poisoning attacks, model update poisoning (Section
5.1.2), while also being susceptible to traditional data poisoning in (Section 5.1.3).
• Training participants can influence the optimization process possibly exacerbating inference-time
(Section evasion attacks) 5.1.4, and communication and computation constraints may render previously proposed defenses impractical.
• Non-malicious failure modes (Section 5.2) are can be especially different to deal with, as access to
raw data is not available in the federated setting, though through some lens they may be related to
poisoning attacks.
• Tension may exist when trying to simultaneously improve robustness and privacy in machine learning
(Section 5.3).
Areas identified for further exploration include:
• Quantify the relationship between data poisoning and model update poisoning attacks. Are there
scenarios where they are not equivalent? [5.1.3]

73

• Quantify how training time attacks impact inference-time vulnerabilities. Improving inference-time
robustness guarantees requires going beyond detecting backdoor attacks. [5.1.4]
• Adversarial training has been used as a defense in the centralized setting, but can be impractical in the
edge-compute limited cross-device federated setting. [5.1.5]
• Federated learning requires new methods and tools to support the developer, as access to raw data is
restricted debugging ML pipelines is especially difficult. [5.2]
• Tensions exists between robustness and fairness, as machine learning models can tend to discard
updates far from the median as detrimental. However the federated setting can give rise to a long tail
of users that may be mistaken for noisy model updates [5.2].
• Cryptography-based aggregation methods and robustness techniques present integration challenges:
protecting participant identity can be at odds with detecting adversarial participants. Proposed techniques remain beyond the scope of practicality, requiring the need of new communication and computation efficient algorithms. [5.3]

74

6

Ensuring Fairness and Addressing Sources of Bias

Machine learning models can often exhibit surprising and unintended behaviours. When such behaviours
lead to patterns of undesirable effects on users, we might categorize the model as “unfair” according to
some criteria. For example, if people with similar characteristics receive quite different outcomes, then this
violates the criterion of individual fairness [169]. If certain sensitive groups (races, genders, etc.) receive
different patterns of outcomes—such as different false negative rates—this can violate various criteria of demographic fairness, see for instance [51, 349] for surveys. The criterion of counterfactual fairness requires
that a user receive the same treatment as they would have if they had been a member of a different group
(race, gender, etc), after taking all causally relevant pathways into account [287].
Federated learning raises several opportunities for fairness research, some of which extend prior research
directions in the non-federated setting, and others that are unique to federated learning. This section raises
open problems in both categories.

6.1

Bias in Training Data

One driver of unfairness in machine-learned models is bias in the training data, including cognitive, sampling, reporting, and confirmation bias. One common antipattern is that minority or marginalized social
groups are under-represented in the training data, and thus the learner weights these groups less during
training [258], leading to inferior quality predictions for members of these groups (e.g. [93]).
Just as the data access processes used in federated learning may introduce dataset shift and non-independence
(Section 3.1), there is also a risk of introducing biases. For example:
• If devices are selected for updates when plugged-in or fully charged, then model updates and evaluations computed at different times of day may be correlated with factors such as day-shift vs night-shift
work schedules.
• If devices are selected for updates from among the pool of eligible devices at a given time, then
devices that are connected at times when few other devices are connected (e.g. night-shift or unusual
time zone) may be over-represented in the aggregated output.
• If selected devices are more likely to have their output kept when the output is computed faster,
then: a) output from devices with faster processors may be over-represented, with these devices likely
newer devices and thus correlated with socioeconomic status; and b) devices with less data may be
over-represented, with these devices possibly representing users who use the product less frequently.
• If data nodes have different amounts of data, then federated learning may weigh higher the contributions of populations which are heavy users of the product or feature generating the data.
• If the update frequency depends on latency, then certain geographic regions and populations with
slower devices or networks may be under-represented.
• If populations of potential users do not own devices for socio-economic reasons, they may be underrepresented in the training dataset, and subsequently also under- (or un-)represented in model training
and evaluation.
• Unweighted aggregation of the model loss across selected devices during federated training may disadvantage model performance on certain devices [302].
75

It has been observed that biases in the data-generating process can also drive unfairness in the resulting models learned from this data (see e.g. [170, 394]). For example, suppose training data is based on
user interactions with a product which has failed to incorporate inclusive design principles. Then, the user
interactions with the product might not express user intents (cf. [403], for example) but rather might express coping strategies around uninclusive product designs (and hence might require a fundamental fix to
the product interaction model). Learning from such interactions might then ignore or perpetuate poor experiences for some groups of product users in ways which can be difficult to detect while maintaining privacy
in a federated setting. This risk is shared by all machine learning scenarios where training data is derived
from user interaction, but is of particular note in the federated setting when data is collected from apps on
individual devices.
Investigating the degree to which biases in the data-generated process can be identified or mitigated
is a crucial problem for both federated learning research and ML research more broadly. Similarly, while
limited prior research has demonstrated methods to identify and correct bias in already collected data in the
federated setting (e.g. via adversarial methods in [255]), further research in this area is needed. Finally,
methods for applying post-hoc fairness corrections to models learned from potentially biased training data
are also a valuable direction for future work.

6.2

Fairness Without Access to Sensitive Attributes

Having explicit access to demographic information (race, gender, etc) is critical to many existing fairness
criteria, including those discussed in Section 6.1. However, the contexts in which federated learning are
often deployed also give rise to considerations of fairness when individual sensitive attributes are not available. For example, this can occur when developing personalized language models or developing fair medical
image classifiers without knowing any additional demographic information about individuals. Even more
fundamentally, the assumed one-to-one relationship between individuals and devices often breaks down,
especially in non-Western contexts [403]. Both measuring and correcting unfairness in contexts where there
is no data regarding sensitive group membership is a key area for federated learning researchers to address.
Limited existing research has examined fairness without access to sensitive attributes. For example,
this has been addressed using distributionally-robust optimization (DRO) which optimizes for the worstcase outcome across all individuals during training [225], and via multicalibration, which calibrates for
fairness across subsets of the training data [232]. Even these existing approaches have not been applied in
the federated setting, raising opportunities for future empirical work. The challenge of how to make these
approaches work for large-scale, high-dimensional data typical to federated settings is also an open problem,
as DRO and multicalibration both pose challenges of scaling with large n and p. Finally, the development
of additional theoretical approaches to defining fairness without respect to “sensitive attributes” is a critical
area for further research.
Other ways to approach this include reframing the existing notions of fairness, which are primarily
concerned with equalizing the probability of an outcome (one of which is considered “positive” and another
“negative” for the affected individual). Instead, fairness without access to sensitive attributes might be
reframed as equal access to effective models. Under this interpretation of fairness, the goal is to maximize
model utility across all individuals, regardless of their (unknown) demographic identities, and regardless of
the “goodness“ of an individual outcome. Again, this matches the contexts in which federated learning is
most commonly used, such as language modeling or medical image classification, where there is no clear
notion of an outcome which is “good” for a user, and instead the aim is simply to make correct predictions
for users, regardless of the outcome.

76

Existing federated learning research suggests possible ways to meet such an interpretation of fairness,
e.g. via personalization [250, 472]. A similar conception of fairness, as “a more fair distribution of the
model performance across devices”, is employed in [302].
The application of attribute-independent methods explicitly to ensure equitable model performance is an
open opportunity for future federated learning research, and is particularly important as federated learning
reaches maturity and sees increasing deployment with real populations of users without knowledge of their
sensitive identities.

6.3

Fairness, Privacy, and Robustness

Fairness and data privacy seem to be complementary ethical concepts: in many of the real-world contexts
where privacy protection is desired, fairness is also desired. Often this is due to the sensitivity of the
underlying data. Because federated learning is most likely to be deployed in contexts of sensitive data where
both privacy and fairness are desirable, it is important that FL research examines how FL might be able to
address existing concerns about fairness in machine learning, and whether FL raises new fairness-related
issues.
In some ways, however, the ideal of fairness seems to be in tension with the notions of privacy for
which FL seeks to provide guarantees: differentially-private learning typically seeks to obscure individuallyidentifying characteristics, while fairness often requires knowing individuals’ membership in sensitive groups
in order to measure or ensure fair predictions are being made. While the trade-off between differential privacy and fairness has been investigated in the non-federated setting [246, 145], there has been little work on
how (or whether) FL may be able to uniquely address concerns about fairness.
Recent evidence suggesting that differentially-private learning can have disparate impact on sensitive
subgroups [43, 145, 246, 283] provides further motivation to investigate whether FL may be able to address such concerns. A potential solution to relax the tension between privacy (which aims to protect the
model from being too dependent on individuals) and fairness (which encourages the model to perform well
on under-represented classes) may be the application of techniques such as personalization (discussed in
Section 3.3) and “hybrid differential privacy,” where some users donate data with lesser privacy guarantees
[40].
Furthermore, current differentially-private optimization schemes are applied without respect to sensitive attributes – from this perspective, it might be expected that empirical studies have shown evidence that
differentially-private optimization impacts minority subgroups the most [43]. Modifications to differentiallyprivate optimization algorithms which explicitly seek to preserve performance on minority subgroups, e.g.
by adapting the noise and clipping mechanisms to account for the representation of groups within the data,
would also likely do a great deal to limit potential disparate impacts of differentially-private modeling on
minority subgroups in federated models trained with differential privacy. However, implementing such
adaptive differentially-private mechanisms in a way that provides some form of privacy guarantee presents
both algorithmic and theoretical challenges which need to be addressed by future work.
Further research is also needed to determine the extent to which the issues above arise in the federated
setting. Furthermore, as noted in Section 6.2, the challenge of evaluating the impact of differential privacy
on model fairness becomes particularly difficult when sensitive attributes are not available, as it is unclear
how to identify subgroups for which a model is behaving badly and to quantify the “price” of differential
privacy – investigating and addressing these challenges is an open problem for future work.
More broadly, one could more generally examine the relation between privacy, fairness, and robustness
(see Section 5). Many previous works on machine learning, including federated learning, typically focus on
77

isolated aspects of robustness (either against poisoning, or against evasion), privacy, or fairness. An important open challenge is to develop a joint understanding of federated learning systems that are robust, private,
and fair. Such an integrated approach can provide opportunities to benefit from disparate but complementary mechanisms. Differential privacy mechanisms can be used to both mitigate data inference attacks, and
provide a foundation for robustness against data poisoning. On the other hand, such an integrated approach
also reveals new vulnerabilities. For example, recent work has revealed a trade-off between privacy and
robustness against adversarial examples [429].
Finally, privacy and fairness naturally meet in the context of learning data representations that are independent of some sensitive attributes while preserving utility for a task of interest. Indeed, this objective
can be motivated both in terms of privacy: to transform data so as to hide private attributes, and fairness: as
a way to make models trained on such representations fair with respect to the attributes. In the centralized
setting, one way to learn such representations is through adversarial training techniques, which have been
applied to image and speech data [255, 186, 327, 65, 431]. In the federated learning scenario, clients could
apply the transformation locally to their data in order to enforce or improve privacy and/or fairness guarantees for the FL process. However, learning this transformation in a federated fashion (potentially under
privacy and/or fairness constraints) is itself an open question.

6.4

Leveraging Federation to Improve Model Diversity

Federated learning presents the opportunity to integrate, through distributed training, datasets which may
have previously been impractical or even illegal to combine in a single location. For example, the Health
Insurance Portability and Accountability Act (HIPAA) and the Family Educational Rights and Privacy Act
(FERPA) constrain the sharing of medical patient data and student educational data, respectively, in the
United States. To date, these restrictions have led to modeling occurring in institutional silos: for example,
using electronic health records or clinical images from individual medical institutions instead of pooling
data and models across institutions [91, 104]. In contexts where membership in institutional datasets is
correlated with individuals’ specific sensitive attributes, or their behavior and outcomes more broadly, this
can lead to poor representation for users in groups underrepresented at those institutions. Importantly, this
lack of representation and diversity in the training data has been shown to lead to poor performance, e.g. in
genetic disease models [333] and image classification models [93].
Federated learning presents an opportunity to leverage uniquely diverse datasets by providing efficient
decentralized training protocols along with privacy and non-identifiability guarantees for the resulting models. This means that federated learning enables training on multi-instutitional datasets in many domains
where this was previously not possible. This provides a practical opportunity to leverage larger, more diverse datasets and explore the generalizability of models which were previously limited to small populations.
More importantly, it provides an opportunity to improve the fairness of these models by combining data
across boundaries which are likely to have been correlated with sensitive attributes. For instance, attendance
at specific health or educational institutions may be correlated with individuals’ ethnicity or socioeconomic
status. As noted in Section 6.1 above, underrepresentation in training data is a proven driver of model
unfairness.
Future federated learning research should investigate the degree to which improving diversity in a federated training setting also improves the fairness of the resulting model, and the degree to which the differential
privacy mechanisms required in such settings may limit fairness and performance gains from increased diversity. This includes a need for both empirical research which applies federated learning and quantifies
the interplay between diversity, fairness, privacy, and performance; along with theoretical research which
provides a foundation for concepts such as diversity in the context of machine learning fairness.
78

6.5

Federated Fairness: New Opportunities and Challenges

It is important to note that federated learning provides unique opportunities and challenges for fairness
researchers. For example, by allowing for datasets which are distributed both by observation, but even
by features, federated learning can enable modeling and research using partitioned data which may be too
sensitive to share directly [215, 224]. Increased availability of datasets which can be used in a federated
manner can help to improve the diversity of training data available for machine learning models, which can
advance fair modeling theory and practice.
Researchers and practitioners also need to address the unique fairness-related challenges created by federated learning. For example, federated learning can introduce new sources of bias through the decision
of which clients to sample based on considerations such as connection type/quality, device type, location,
activity patterns, and local dataset size [81]. Future work could investigate the degree to which these various sampling constraints affect the fairness of the resulting model, and how such impacts can be mitigated
within the federated framework, e.g. [302, 289, 158]. Frameworks such as agnostic federated learning
[352] provide approaches to control for bias in the training objective. Work to improve the fairness of existing federated training algorithms will be particularly important as advances begin to approach the technical
limits of other components of FL systems, such as model compression, which initially helped to broaden
the diversity of candidate clients during federated training processes. There is no unique fairness criterion
generally adopted in the study of fairness, and multiple criteria have been proven to be mutually incompatible. One way to deal with this question is the online fairness framework and algorithms of Awasthi et al.
[41]. Adapting such solutions to the federated learning setting and further improving upon them will be
challenging research questions in ML fairness theory and algorithms.
In the classical centralized machine learning setting, a substantial amount of advancement has been made
in the past decade to train fair classifiers, such as constrained optimization, post-shifting approaches, and
distributionally-robust optimization [223, 503, 225]. It is an open question whether such approaches, which
have demonstrated utility for improving fairness in centralized training, could be used under the setting of
federated learning (and if so, under what additional assumptions) in which data are located in a decentralized
fashion and practitioners may not obtain an unbiased sample of the data that match the distribution of the
population.

6.6

Executive Summary

In addition to inheriting the already significant challenges related to bias, fairness, and privacy in centralized
machine learning, federated learning also brings a new set of distinct challenges and opportunities in these
areas. The importance of these considerations will likely continue to grow as the real-world deployment of
FL expands to more users, domains, and applications.
• Bias in training data (Section 6.1) is a key consideration related to bias and fairness in FL models,
particularly due to the additional sampling steps germane to federation (e.g., client sampling) and the
transfer of some model computation to client devices.
• The lack of data regarding sensitive attributes in many FL deployments can pose challenges for measuring and ensuring fairness, and also suggests potential reframing of fairness problems in ways that
do not require such data (Section 6.2).
• Since FL is often deployed in contexts which are both privacy- and fairness-sensitive, this can magnify
tensions between privacy and fairness objectives in practice. Further work is needed to address the
79

potential tension between methods which achieve privacy, fairness, and robustness in both federated
and centralized learning (Section 6.3).
• Federated learning presents unique opportunities to improve the diversity of stakeholders and data
incorporated into learning, which could improve both the overall quality of downstream models, as
well as their fairness due to more representative datasets (Section 6.4).
• Federated learning presents fairness-related challenges not present in the centralized training regime,
but also affords new solutions (Section 6.5).

80

7

Addressing System Challenges

As we will see in this section, the challenges in building systems for federated learning can be split fairly
cleanly into the two separate settings of cross-device and cross-silo federated learning (see Sections 1.1
and 2.2). We start with a brief discussion of the difficulties inherent to any large scale deployment of
software on end-user devices (although exacerbated by the complexity of a federated learning stack); we
then focus on key challenges specific to the cross-device learning—bias, tuning, and efficient device-side
execution of ML workflows—before concluding with a brief treatment of the cross-silo setting.

7.1

Platform Development and Deployment Challenges

Running computations on end-user devices is considerably different from the data center setting:
• Due to the heterogeneity of the fleet (devices may differ in hardware, software, connectivity, performance and persisted state) the space of potential problems and edge cases is vast and cannot typically
be covered in sufficient detail with automated testing.
• Monitoring and debugging are harder because telemetry is limited, delayed, and there is no physical
access to devices for interactive troubleshooting.
• Running computations should not affect device performance or stability, i.e. should be invisible to
users.
Code Deployment Installing, updating and running software on end user devices may involve not only
extensive manual and automated testing, but a gradual and reversible rollout (for example, through guarding new functionality with server-controlled feature flags) while monitoring key performance metrics in
a/b experiments such as crash rates, memory use, and application-dependent indicators such as latencies
and engagement metrics. Such rollouts can take weeks or months depending on the percolation rate of
updates (particularly challenging for devices with spotty connectivity) and the complexity of the upgrade
(e.g. protocol changes). Hence, the install base at any given time will involve various releases. While
this problem is not specific to federated learning, it has greater impact here due to the inherent collaborative nature of federated computations: devices constantly communicate with servers and indirectly with
other devices to exchange models and parameter updates. Thus, compatibility concerns abound and must be
addressed through stable exchange formats or, where not possible, detected upfront with extensive testing
infrastructure. We will revisit this problem in Section 7.4.
Monitoring and Debugging Another significant complication is the limited ability to monitor devices
and interactively debug problems. While telemetry from end user devices is necessary to detect problems,
privacy concerns severely restrict what can be logged, who can access such logs, and how long they are
retained. Once a regression is detected, drilling down into the root cause can be very cumbersome due to
the lack of detailed context, the vast problem space (a cross product of software versions, hardware, models,
and device state), and very limited ability for interactive debugging short of successfully reproducing the
problem in a controlled environment.
These challenges are exacerbated in the federated learning setting where a) raw input data on devices
cannot be accessed, and b) contributions from individual devices are by design anonymous, ephemeral, and
exposed only in aggregate. These properties preserve privacy, but also may make it hard or impossible to
81

investigate problems with traditional approaches —by looking for correlations with hardware or software
version, or testing hypotheses that require access to raw data. Reproducing a problem in a controlled setting is often difficult due to the gap between such an environment and reality: hundreds of heterogeneous
embedded stateful devices with non-iid data.
Interestingly, federated technologies themselves can help to mitigate this problem—for instance, the use
of federated analytics [382] to collect logs in a privacy preserving manner, or training generative models of
the system behavior or raw data for sampling during debugging (see sections 3.4.3, 5.2, and [31]). Keeping a
federated learning system up and running thus requires investing into upfront detection of problems through
a) extensive automated, continuous test coverage of all software layers through both unit and integration
tests; b) feature flags and a/b rollouts; and c) continuous monitoring of performance indicators for regressions. That poses a significant investment that may come at too high a cost for smaller entities who would
benefit greatly from shared and tested infrastructure for federated learning.

7.2

System Induced Bias

Deployment, monitoring and debugging may not concern users of a federated learning platform, e.g. model
authors or data analysts. For them, the key differences between data center and cross-device settings fall
largely into the following two categories:
1. Availability of devices for computations is not a given, but varies over time and across devices. Connections are initiated by devices and subject to interruptions due to changes in device state, operating
system quotas, and network connectivity. Hence, in iterative processes like federated learning, the
loop body is run on a small subset of all devices only, and the system must tolerate a certain failure
rate among those devices.
2. Capabilities of devices (network bandwidth and latency, compute performance, memory) vary, and
are typically much lower than those of compute nodes in the data center, though the number of nodes
is typically higher. The amount and type of data across devices may lead to variations in execution
profile, e.g. more and larger examples lead to increased resource use and processing time.
In the following sections we discuss how these variations might introduce bias, referring to it as system
induced bias to differentiate it from platform-independent bias in the raw data (such as ownership or usage
patterns differing across demographics)—for the latter, see Section 6.1.
7.2.1

Device Availability Profiles

At the core of cross-device federated learning is the principle that devices only connect to the server and run
computations when various constraints are met:
• Hard constraints, which might include requiring that the device is turned on, has network connectivity to the server, and is allowed to run a computation by the operating system.
• Soft constraints, which might include the conditions on device state chosen to ensure that federated
learning does not incur charges or affect usability. For the common case of mobile phones [81, 26],
requirements may include idleness, charging and/or above a certain battery level, being connected to
an unmetered network, and that no other federated learning tasks are running at the same time.

82

Taken together, these constraints induce an unknown, time-varying
and device-specific function Ai (t)
P
for a device i, and a fleet-wide availability profile A(t) = i Ai (t). Round completion rates and server
traffic patterns [81, 491] suggest that availability profiles for mobile phones are clustered into periodic
functions with a period of 1 day, varying across devices in phase, shape and amplitude through factors
such as demographics, geography etc. Availability for other end user devices such as laptops, tablets, or
stationary devices such as smart speakers, displays and cameras, will differ, but the challenges discussed in
the following sections apply there as well, albeit to a possibly lesser extent.
7.2.2

Examples of System Induced Bias

Sources of bias will depend on the specific way in which devices are selected to participate in training,
and how the system influences which devices end up contributing to the final aggregated model update.
Thus, it is useful to discuss these issues in light of a simplified but representative system design. In an
iterative federated learning algorithm, such as Federated Averaging (Section 1.1.2, [337]), rounds are run
consecutively on sets of at least M devices. To accommodate a fraction d of devices not contributing due to
changes in device conditions, time-outs, or slowness (server-side aborts to avoid slow-downs by stragglers),
an over-allocation scheme is used where
M
1. Rounds are started when at least M 0 = 1−d
devices are available.

2. Rounds are closed as
(a) Aborted when more than M 0 − M devices have disconnected, or
(b) Successful when at least M devices have reported. One possible design choice is to stop after
exactly M devices; another possibility would be to keep waiting for stragglers (possibly up to
some maximum time).
This sequence, when combined with variable availability profiles, may introduce various forms of bias:
1. Selection Bias - whether a device is included in a round at time t depends on both
(a) Its availability profile Ai (t)
(b) The number of simultaneously connected devices: < M 0 and a round cannot be started;  M 0
and the probability of a single device being included becomes very small. In effect, devices
active only at either fleet-wide availability peaks or troughs may be under-represented.
2. Survival Bias
(a) Since a server might choose to close a round at any point after the first M devices have reported,
contributions are biased towards devices with better network connections, faster processors,
lower CPU load, and less data to process.
(b) Devices drop out of rounds when they are interrupted by the operating system, which may happen due to changes in device conditions as described by Ai (t), or due to e.g. excessive memory
use.
As can be seen, the probability of a device contributing to a round of federated learning is a complex
function of both internal (e.g. device specific) and external (fleet dynamic) factors. When this probability
is correlated with statistics of the data distribution, aggregate results may be biased. For instance, language
83

models may over-represent demographics that have high quality internet connections or high end devices;
and ranking models may not incorporate enough contributions from high engagement users who produce a
lot of training data and hence longer training times.
Thus, designing systems that explicitly take such factors into account and integrate algorithms designed
to both quantify and mitigate these effects are a fundamentally important research direction.
7.2.3

Open Challenges in Quantifying and Mitigating System Induced Bias

While the potential for bias in federated learning has been addressed in the literature (Section 6, [81, 302,
171]), a systematic study that qualifies and quantifies bias in realistic settings and its sources is a direction for
future research. Conducting the necessary work may be hampered by both access to the necessary resources,
and the difficulty in quantifying bias in a final statistical estimate due to the inherent lack of ground truth
value.
We want to encourage further research to study how bias can be quantified and subsequently mitigated.
A useful proxy metric for bias is to study the expected rate of contribution of a device to federated learning.
In an unbiased system, this rate would be identical for every device; if it is not, the non-uniformity may
provide a measure of bias. Studying the root causes for this non-uniformity may then provide important
hints for how to mitigate bias, for example:
• When there is a strong correlation between devices finishing a round, and the number of examples
they process or model size, possible fixes may include early stopping, or decreasing the model size.
• If the expected rate of contribution depends on factors outside our control, such as device model,
network connectivity, location etc., one can view these factors as defining strata and applying poststratification [312], that is, correcting for bias by scaling up or down contributions from devices
depending on their stratum. It may also be possible to apply stratified sampling - e.g. change scheduling, or server selection policies, to affect the probability of including devices in a round as a function
of their stratum.
• A very general, root-cause-agnostic mitigation could base the weight of a contribution solely on a
device’s past contribution profile (e.g. the number of rounds started or completed thus far). As
a special case, consider sampling without replacement which could be implemented at the system
level (stop connecting after one successful contribution) or at the model level (weight all but the first
contribution with 0). This approach might not be sufficient when a population is large enough for most
devices to contribute only infrequently (mostly one or zero times); in such cases, clustering devices
based on some similarity metric and using cluster membership as stratum could help.
• Alternatives to the synchronous, round based execution described in the previous section may also
help to mitigate bias. In particular, certain types of analytics may benefit from softening or eliminating the competition between devices for inclusion, by running rounds for long times with very
large numbers of participants and without applying time-outs to stragglers. Such a method may not
be applicable to algorithms where the iterative aspect (running many individual, chained rounds) is
important.
The biggest obstacle to enabling such research is access to a representative fleet of end user devices, or a
detailed description (e.g. in the form of a statistical model of a realistic distribution over Ai (t) functions) of
a fleet that can be used in simulations. Here, maintainers of FL production stacks are uniquely positioned to

84

provide such statistics or models to academic partners in a privacy preserving fashion; a further promising
direction is the recent introduction of the Flower framework [66] for federated learning research.

7.3

System Parameter Tuning

Practical federated learning is a form of multi-objective optimization: while the first order goal is maximizing model quality metrics such as loss or accuracy, other important considerations are
• Convergence speed
• Throughput (e.g. number of rounds, amount of data, or number of devices)
• Model fairness, privacy and robustness (see section 6.3)
• Resource use on server and clients
These goals may be in tension. For instance, maximizing round throughput may introduce bias or
hurt accuracy by preferring performant devices with little or no data. Maximizing for low training loss by
increasing model complexity will put devices with less memory, many or large examples, or slow CPUs at a
disadvantage. Bias or fairness induced in such a way during training may be hard to detect in the evaluation
phase since it typically uses the same platform and hence is subject to similar biases.
Various controls affect the above listed indicators. Some are familiar from the datacenter setting, in
particular model specific settings and learning algorithm hyperparameters. Others are specific to federated
learning:
• Clients per round: The minimum number of devices required to complete a round, M , and the
number of devices required to start a round, M 0 .
• Server-side scheduling: In all but the simplest cases, a federated learning system will operate on more
than one model at a time: to support multiple tenants; to train models on the same data for different
use cases; to support experimentation and architecture or hyper-parameter grid search; and to run
training and evaluation workloads concurrently. The server needs to decide which task to serve to
incoming devices, an instance of a scheduling problem: assigning work (training or evaluation tasks)
to resources (devices). Accordingly, the usual challenges arise: ideal resource assignment should be
fair, avoid starvation, minimize wait times, and support relative priorities all at once.
• Device-side scheduling: As described in Section 7.2, various constraints govern when a device can
connect to the server and execute work. Within these constraints, various scheduling choices can be
made. One extreme is to connect to the server and run computations as often as possible, leading to
high load and resource use on both server and devices. Another choice are fixed intervals, but they
need to be adjusted to reflect external factors such as number of devices overall and per round. The
federated learning system developed at Google aims to strike a balance with a flow control mechanism
called pace steering [81] whereby the server instructs devices when to return. Such a dynamic system
enables temporal load balancing for large populations as well as “focusing” connection attempts to
specific points in time to reach the threshold M 0 . Developing such a mechanism is difficult due to
stochastic and dynamic nature of device availability, the lack of a predictive model of population
behavior, and feedback loops.

85

Defining reasonable composite objective functions, and designing algorithms to automatically tune these
settings, has not been explored yet in the context of federated learning systems and hence remains a topic of
future research.

7.4

On-Device Runtime

While numerous frameworks exist for data center training, the options for training models on resource constrained devices are fairly limited. Machine Learning models and training procedures are typically authored
in a high level language such as Python. For federated learning, this description encompasses device and
server computations that are executed on the target platform and exchange data over a network connection,
necessitating
• A means of serializing and dynamically transmitting local pieces of the total computation (e.g., the
server-side update to the model, or the local client training procedure).
• A means to interpret or execute such a computation on the target platform (server or device).
• A stable network protocol for data exchange between participating devices and servers.
One extreme form of a representation is the original high-level description, e.g. a Python TensorFlow
program [2]. This would require a Python interpreter with TensorFlow backend, which may not be a feasible
choice for end-user devices due to resource constraints (binary size, memory use), performance limitations,
or security concerns.
Another extreme representation of a computation is machine code of the target architecture, e.g. ARM64
instructions. This requires a compiler or re-implementation of a model in a lower-level language such as
C++, and deployment computations will typically be subject to the restrictions that apply to deployment of
binary code (see Section 7.1), introducing prohibitive latencies for executing novel computations.
Intermediate representations that can be compiled or interpreted with a runtime on the target platform
strike a balance between flexibility and efficiency. However, such runtimes are currently not widely available. For instance, Google’s FL system [81] relies on TensorFlow for both server and device side execution
as well as model and parameter transfer, but this choice suffers from several shortcomings:
• It offers no easy path to devices for alternative front ends such as PyTorch [370], JAX [86] or CNTK
[410].
• The runtime is not developed or optimized for resource constrained environments, incurring a large
binary size, high memory use and comparatively low performance.
• The intermediate representation GraphDef used by TensorFlow is not standardized or stable, and
version skew between the frontend and older on-device backends causes frequent compatibility challenges.
Other alternatives include more specialized runtimes that support only a subset of the frontend’s capabilities, for instance training specific model types only, requiring changes and long update cycles whenever
new model architectures or training algorithms are to be used. An extreme case would be a runtime that is
limited and optimized to train a single type of model.
An ideal on-device runtime would have the following characteristics:
86

1. Lightweight: small binary size, or pre-installed; low memory and power profile.
2. Performant: low startup latency; high throughput, supports hardware acceleration.
3. Expressive: supports common data types and computations including backpropagation, variables,
control flow, custom extensions.
4. Stable and compact format for expressing data and computations.
5. Widely available: portable open source implementation.
6. Targetable by commonly used ML frameworks / languages..
7. Ideally also supports inference, or if not, building personalized models for an inference runtime.
To our best knowledge no solution exists yet that satisfies these requirements, and we expect the limited
ability to run ML training on end user devices to become a hindrance to adoption of federated technologies.

7.5

The Cross-Silo Setting

The system challenges arising in the scenario of cross-silo federated learning take a considerably different
form. As outlined in Table 1, clients are fewer in number, more powerful, reliable, and known / addressable,
eliminating many of the challenges from the cross-device setting, while allowing for authentication and
verification, accounting, and contractually enforced penalties for misbehavior. Nonetheless, there are other
sources of heterogeneity, including the features and distribution of data, and possibly the software stack used
for training.
While the infrastructure in the cross-device setting (from the device-side data generation to the server
logic) is typically operated by one or few organizational entities (the application, operating system, or device manufacturer), in the cross-silo setting, many different entities are involved. This may lead to high
coordination and operational cost due to differences in:
• How data is generated, pre-processed and labeled. Learning across silos will require data normalization which may be difficult when such data is collected and stored differently (e.g. use of different
medical imaging systems, and inconsistencies in labeling procedures, annotations, and storage formats).
• Which software at which version powers training. Using the same software stack in every silo—
possibly delivered alongside the model using container technologies as done by FATE [33]—eliminates
compatibility concerns, but such frequent and centrally distributed software delivery may not be acceptable to all involved parties. An alternative that is more similar to the cross-device setting would be
to standardize data and model formats and communication protocols. See IEEE P3652.1 “Federated
Machine Learning Working Group” for a related effort in this direction.
• The approval process for how data may or may not be used. While this process is typically centralized in the cross-device scenario, the situation is likely different in cross-silo settings where many
organizational entities are involved, and may be increasingly difficult when training spans different jurisdictions with varying data protection regulations. Technical infrastructure may be of help
here by establishing data annotations that encode access policies, and infrastructure enforce them;
for instance, limiting the use of certain data to specific models, or encoding minimum aggregation
requirements such as “require at least M clients per round”.
87

Another potential difference in the cross-silo setting is data partitioning: Data in the cross-device setting
is typically assumed to be partitioned by examples, all of which have the same features (horizontal partitioning). In the cross-silo setting, in addition to partitioning by examples, partitioning by features is of practical
relevance (vertical partitioning). An example would be two organizations, e.g. a bank and a retail company,
with an overlapping set of customers, but different information (features) associated with them. For a discussion focusing on the algorithmic aspects, please see section 2.2. Learning with feature-partitioned data
may require different communication patterns and additional processing steps e.g. for entity alignment and
dealing with missing features.

7.6

Executive Summary

While production grade systems for cross-device federated learning operate successfully [81, 26], various
challenges remain:
• Frequent and large scale deployment of updates, monitoring, and debugging is challenging (Section 7.1).
• Differences in device availability induce various forms of bias; defining, quantifying and mitigating
them remains a direction for future research (Section 7.2).
• Tuning system parameters is difficult due to the existence of multiple, potentially conflicting objectives (Section 7.3).
• Running ML workloads on end user devices is hampered by the lack of a portable, fast, small footprint,
and flexible runtime for on-device training (Section 7.4).
Systems for cross-silo settings (Section 7.5) face largely different issues owing to differences in the
capabilities of compute nodes and the nature of the data being processed.

88

8

Concluding Remarks

Federated learning enables distributed client devices to collaboratively learn a shared prediction model while
keeping all the training data on device, decoupling the ability to do machine learning from the need to store
the data in the cloud. This goes beyond the use of local models that make predictions on mobile devices by
bringing model training to the device as well.
In recent years, this topic has undergone an explosive growth of interest, both in industry and academia.
Major technology companies have already deployed federated learning in production, and a number of
startups were founded with the objective of using federated learning to address privacy and data collection
challenges in various industries. Further, the breadth of papers surveyed in this work suggests that federated
learning is gaining traction in a wide range of interdisciplinary fields: from machine learning to optimization
to information theory and statistics to cryptography, fairness, and privacy.
Motivated by the growing interest in federated learning research, this paper discusses recent advances
and presents an extensive collection of open problems and challenges. The system constraints impose efficiency requirements on the algorithms in order to be practical, many of which are not particularly challenging in other settings. We argue that data privacy is not binary and present a range of threat models that are
relevant under a variety of assumptions, each of which provides its own unique challenges.
The open problems discussed in this work are certainly not comprehensive, they reflect the interests
and backgrounds of the authors. In particular, we do not discuss any non-learning problems which need
to be solved in the course of a practical machine learning project, and might need to be solved based on
decentralized data [382]. This can include simple problems such as computing basic descriptive statistics,
or more complex objectives such as computing the head of a histogram over an open set [510]. Existing
algorithms for solving such problems often do not always have an obvious “federated version” that would
be efficient under the system assumptions motivating this work or do not admit a useful notion of data
protection. Yet another set of important topics that were not discussed are the legal and business issues that
may motivate or constrain the use of federated learning.
We hope this work will be helpful in scoping further research in federated learning and related areas.

Acknowledgments
The authors would like to thank Alex Ingerman and David Petrou for their useful suggestions and insightful
comments during the review process.

89

References
[1] Lattigo 2.0.0. Online: http://github.com/ldsec/lattigo, October 2020. EPFL-LDS.
[2] Martı́n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado,
Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving,
Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit
Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas,
Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow:
Large-scale machine learning on heterogeneous systems, 2015. URL https://www.tensorflow.org/.
Software available from tensorflow.org.
[3] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang.
Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC Conference on Computer
and Communications Security, pages 308–318. ACM, 2016.
[4] Omid Abari, Hariharan Rahul, and Dina Katabi. Over-the-air function computation in sensor networks. CoRR,
abs/1612.02307, 2016. URL http://arxiv.org/abs/1612.02307.
[5] Nazmiye Ceren Abay, Yan Zhou, Murat Kantarcioglu, Bhavani Thuraisingham, and Latanya Sweeney. Privacy
preserving synthetic data release using deep learning. In Joint European Conference on Machine Learning and
Knowledge Discovery in Databases, pages 510–526. Springer, 2018.
[6] John M Abowd and Ian M Schmutte. An economic analysis of privacy protection and statistical accuracy as
social choices. American Economic Review, 109(1):171–202, 2019.
[7] Jayadev Acharya, Clément L Canonne, and Himanshu Tyagi. Inference under information constraints i: Lower
bounds from chi-square contraction. IEEE Transactions on Information Theory, 66(12):7835–7855, 2020.
[8] Gergely Ács and Claude Castelluccia. I have a DREAM!: DIfferentially PrivatE smart Metering. In Proceedings of the 13th International Conference on Information Hiding, IH’11, pages 118–132, Berlin, Heidelberg,
2011. Springer-Verlag. ISBN 978-3-642-24177-2. URL http://dl.acm.org/citation.cfm?id=
2042445.2042457.
[9] Naman Agarwal, Ananda Theertha Suresh, Felix X. Yu, Sanjiv Kumar, and Brendan McMahan. cpSGD:
Communication-efficient and differentially-private distributed SGD. In Advances in Neural Information Processing Systems, pages 7564–7575, 2018.
[10] Nitin Agrawal, Ali Shahin Shamsabadi, Matt J. Kusner, and Adrià Gascón. QUOTIENT: two-party secure
neural network training and prediction. In In Proceedings of the ACM Conference on Computer and Communication Security (CCS), 2019.
[11] Rakesh Agrawal and Ramakrishnan Srikant. Privacy-preserving data mining. In ACM SIGMOD International
Conference on Management of Data, 2000.
[12] Carlos Aguilar-Melchor and Philippe Gaborit. A lattice-based computationally-efficient private information
retrieval protocol. Cryptol. ePrint Arch., Report, 446, 2007.
[13] Carlos Aguilar-Melchor, Joris Barrier, Laurent Fousse, and Marc-Olivier Killijian. XPIR: Private information
retrieval for everyone. Proceedings on Privacy Enhancing Technologies, 2016(2):155–174, 2016.
[14] ai.google. Under the hood of the Pixel 2: How AI is supercharging hardware, 2018. URL https://ai.
google/stories/ai-in-hardware/. Retrieved Nov 2018.
[15] ai.intel.
Federated learning for medical imaging, 2019.
URL https://www.intel.ai/
federated-learning-for-medical-imaging/. Retrieved Aug 2019.

90

[16] Asra Ali, Tancrède Lepoint, Sarvar Patel, Mariana Raykova, Phillipp Schoppmann, Karn Seth, and Kevin Yeo.
Communication-computation trade-offs in PIR. IACR Cryptol. ePrint Arch., 2019:1483, 2019.
[17] Dan Alistarh, Demjan Grubic, Jerry Li, Ryota Tomioka, and Milan Vojnovic. QSGD: Communication-efficient
SGD via gradient quantization and encoding. In NIPS - Advances in Neural Information Processing Systems,
pages 1709–1720, 2017.
[18] Dan Alistarh, Zeyuan Allen-Zhu, and Jerry Li. Byzantine stochastic gradient descent. In NIPS, 2018.
[19] Inês Almeida and João Xavier. DJAM: Distributed Jacobi Asynchronous Method for Learning Personal Models.
IEEE Signal Processing Letters, 25(9):1389–1392, 2018.
[20] Scott Ames, Carmit Hazay, Yuval Ishai, and Muthuramakrishnan Venkitasubramaniam. Ligero: Lightweight
sublinear arguments without a trusted setup. In Proceedings of the 2017 ACM SIGSAC Conference on Computer
and Communications Security, CCS ’17, 2017.
[21] Kareem Amin, Alex Kulesza, Andres Munoz, and Sergei Vassilvtiskii. Bounding user contributions: A biasvariance trade-off in differential privacy. In International Conference on Machine Learning, pages 263–271,
2019.
[22] androidtrusty. Android Trusty TEE. https://source.android.com/security/trusty, 2019. Accessed: 2019-12-05.
[23] Sebastian Angel, Hao Chen, Kim Laine, and Srinath T. V. Setty. PIR with compressed queries and amortized
query processing. In IEEE Symposium on Security and Privacy, pages 962–979. IEEE Computer Society, 2018.
[24] George J Annas. HIPAA regulations-a new era of medical-record privacy? New England Journal of Medicine,
348(15):1486–1490, 2003.
[25] Apple.
Private Federated Learning (NeurIPS 2019 Expo Talk Abstract).
ExpoConferences/2019/schedule?talk_id=40, 2019.

https://nips.cc/

[26] Apple. Designing for privacy (video and slide deck). Apple WWDC, https://developer.apple.com/
videos/play/wwdc2019/708, 2019.
[27] Toshinori Araki, Jun Furukawa, Yehuda Lindell, Ariel Nof, and Kazuma Ohara. High-throughput semi-honest
secure three-party computation with an honest majority. In Proceedings of the 2016 ACM SIGSAC Conference
on Computer and Communications Security, pages 805–817. ACM, 2016.
[28] armtrustzone.
Arm TrustZone Technology.
https://developer.arm.com/ip-products/
security-ip/trustzone, 2019. Accessed: 2019-12-05.
[29] Mahmoud Assran, Nicolas Loizou, Nicolas Ballas, and Michael Rabbat. Stochastic gradient push for distributed
deep learning. In ICML, 2019.
[30] Anish Athalye, Nicholas Carlini, and David Wagner. Obfuscated gradients give a false sense of security:
Circumventing defenses to adversarial examples. ICML, 2018.
[31] Sean Augenstein, H. Brendan McMahan, Daniel Ramage, Swaroop Ramaswamy, Peter Kairouz, Mingqing
Chen, Rajiv Mathews, and Blaise Aguera y Arcas. Generative models for effective ML on private, decentralized
datasets, 2019. URL https://arxiv.org/abs/1911.06679.
[32] PyVertical Authors.
PyVertical.

Pyvertical, 2020.

URL https://github.com.cnpmjs.org/OpenMined/

[33] The FATE Authors. Federated AI technology enabler, 2019. URL https://www.fedai.org/.
[34] The Fedlearner Authors. Fedlearner, 2020. URL https://github.com/bytedance/fedlearner.

91

[35] The Leaf Authors. Leaf, 2019. URL https://leaf.cmu.edu/.
[36] The PaddleFL Authors. PaddleFL, 2019. URL https://github.com/PaddlePaddle/PaddleFL.
[37] The PaddlePaddle Authors. PaddlePaddle, 2019. URL http://www.paddlepaddle.org/.
[38] The TFF Authors. TensorFlow Federated, 2019. URL https://www.tensorflow.org/federated.
[39] Brendan Avent, Yatharth Dubey, and Aleksandra Korolova. The power of the hybrid model for mean estimation.
Proceedings on Privacy Enhancing Technologies (PETS), 2020(4):48 – 68, 01 Oct. 2020. doi: https://doi.org/
10.2478/popets-2020-0062. URL https://content.sciendo.com/view/journals/popets/
2020/4/article-p48.xml.
[40] Brendan Avent, Aleksandra Korolova, David Zeber, Torgeir Hovden, and Benjamin Livshits. BLENDER:
Enabling local search with a hybrid differential privacy model. In 26th USENIX Security Symposium (USENIX
Security 17), pages 747–764, Vancouver, BC, August 2017. USENIX Association. ISBN 978-1-931971-40-9.
URL https://www.usenix.org/conference/usenixsecurity17/technical-sessions/
presentation/avent.
[41] Pranjal Awasthi, Corinna Cortes, Yishay Mansour, and Mehryar Mohri. Beyond individual and group fairness.
CoRR, abs/2008.09490, 2020.
[42] László Babai, Lance Fortnow, Leonid A. Levin, and Mario Szegedy. Checking computations in polylogarithmic
time. In STOC, pages 21–31. ACM, 1991.
[43] Eugene Bagdasaryan and Vitaly Shmatikov. Differential privacy has disparate impact on model accuracy. CoRR,
abs/1905.12101, 2019. URL http://arxiv.org/abs/1905.12101.
[44] Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, and Vitaly Shmatikov. How to backdoor
federated learning. arXiv preprint arXiv:1807.00459, 2018.
[45] Borja Balle, James Bell, Adrià Gascón, and Kobbi Nissim. The privacy blanket of the shuffle model. In
Advances in Cryptology - CRYPTO 2019 - 39th Annual International Cryptology Conference, Santa Barbara,
CA, USA, August 18-22, 2019, Proceedings, Part II, pages 638–667, 2019. doi: 10.1007/978-3-030-26951-7\
22. URL https://doi.org/10.1007/978-3-030-26951-7_22.
[46] Borja Balle, James Bell, Adrià Gascón, and Kobbi Nissim. Private summation in the multi-message shuffle
model. In Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security,
page 657–676. ACM, 2020.
[47] Borja Balle, Peter Kairouz, H. Brendan McMahan, Om Thakkar, and Abhradeep Thakurta. Privacy amplification via random check-ins, 2020.
[48] Assi Barak, Daniel Escudero, Anders P. K. Dalskov, and Marcel Keller. Secure evaluation of quantized neural
networks. IACR Cryptology ePrint Archive, 2019:131, 2019. URL https://eprint.iacr.org/2019/
131.
[49] Leighton Pate Barnes, Yanjun Han, and Ayfer Ozgur. Lower bounds for learning distributions under communication constraints via fisher information. Journal of Machine Learning Research, 21(236):1–30, 2020. URL
http://jmlr.org/papers/v21/19-737.html.
[50] Leighton Pate Barnes, Huseyin A. Inan, Berivan Isik, and Ayfer Ozgur. rtop-k: A statistical estimation approach
to distributed sgd. arXiv preprint arXiv:2005.10761, 2020.
[51] Solon Barocas, Moritz Hardt, and Arvind Narayanan. Fairness and Machine Learning. fairmlbook.org, 2019.
http://www.fairmlbook.org.
[52] Moran Baruch, Gilad Baruch, and Yoav Goldberg. A little is enough: Circumventing defenses for distributed
learning. arXiv preprint arXiv:1902.06156, 2019.

92

[53] Raef Bassily and Adam Smith. Local, private, efficient protocols for succinct histograms. In STOC, pages
127–135, 2015.
[54] Raef Bassily, Uri Stemmer, Abhradeep Guha Thakurta, et al. Practical locally private heavy hitters. In Advances
in Neural Information Processing Systems, pages 2288–2296, 2017.
[55] Debraj Basu, Deepesh Data, Can Karakus, and Suhas N Diggavi. Qsparse-local-sgd: Distributed sgd with
quantization, sparsification, and local computations. IEEE Journal on Selected Areas in Information Theory, 1
(1):217–226, 2020.
[56] Jonathan Baxter. A model of inductive bias learning. Journal of Artificial Intelligence Research, 12:149–198,
2000.
[57] Amos Beimel, Aleksandra Korolova, Kobbi Nissim, Or Sheffet, and Uri Stemmer. The power of synergy in
differential privacy: Combining a small curator with local randomizers. In Conference on Information-Theoretic
Cryptography (ITC), 2020. URL https://arxiv.org/abs/1912.08951.
[58] James Henry Bell, Kallista A. Bonawitz, Adrià Gascón, Tancrède Lepoint, and Mariana Raykova. Secure singleserver aggregation with (poly)logarithmic overhead. In Proceedings of the 2020 ACM SIGSAC Conference on
Computer and Communications Security, page 1253–1269. ACM, 2020.
[59] Aurélien Bellet, Rachid Guerraoui, Mahsa Taziki, and Marc Tommasi. Personalized and Private Peer-to-Peer
Machine Learning. In AISTATS, 2018.
[60] Irwan Bello, Barret Zoph, Vijay Vasudevan, and Quoc V Le. Neural optimizer search with reinforcement
learning. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 459–
468. JMLR. org, 2017.
[61] Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman
Vaughan. A theory of learning from different domains. Machine learning, 79(1-2):151–175, 2010.
[62] Eli Ben-Sasson, Alessandro Chiesa, Christina Garman, Matthew Green, Ian Miers, Eran Tromer, and Madars
Virza. Zerocash: Decentralized anonymous payments from bitcoin. In IEEE Symposium on Security and
Privacy, pages 459–474. IEEE Computer Society, 2014.
[63] Eli Ben-Sasson, Iddo Bentov, Yinon Horesh, and Michael Riabzev. Scalable zero knowledge with no trusted
setup. In CRYPTO (3), volume 11694 of Lecture Notes in Computer Science, pages 701–732. Springer, 2019.
[64] James S Bergstra, Rémi Bardenet, Yoshua Bengio, and Balázs Kégl. Algorithms for hyper-parameter optimization. In Advances in Neural Information Processing Systems, pages 2546–2554, 2011.
[65] Martı́n Bertrán, Natalia Martı́nez, Afroditi Papadaki, Qiang Qiu, Miguel R. D. Rodrigues, Galen Reeves, and
Guillermo Sapiro. Learning adversarially fair and transferable representations. In ICML, 2019.
[66] Daniel J. Beutel, Taner Topal, Akhil Mathur, Xinchi Qiu, Titouan Parcollet, and Nicholas D. Lane. Flower: A
friendly federated learning research framework, 2020.
[67] Arjun Nitin Bhagoji, Supriyo Chakraborty, Prateek Mittal, and Seraphin Calo. Analyzing federated learning
through an adversarial lens. In Proceedings of the 36th International Conference on Machine Learning, pages
634–643, 2019.
[68] Abhishek Bhowmick, John Duchi, Julien Freudiger, Gaurav Kapoor, and Ryan Rogers. Protection against
reconstruction and its applications in private federated learning. arXiv preprint arXiv:1812.00984, 2018.
[69] Battista Biggio, Blaine Nelson, and Pavel Laskov. Poisoning attacks against support vector machines. In Proceedings of the 29th International Coference on International Conference on Machine Learning, ICML’12,
pages 1467–1474, USA, 2012. Omnipress. ISBN 978-1-4503-1285-1. URL http://dl.acm.org/
citation.cfm?id=3042573.3042761.

93

[70] Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim Šrndić, Pavel Laskov, Giorgio Giacinto,
and Fabio Roli. Evasion attacks against machine learning at test time. In ECML-PKDD, pages 387–402.
Springer, 2013.
[71] Nir Bitansky, Ran Canetti, Alessandro Chiesa, and Eran Tromer. From extractable collision resistance to succinct non-interactive arguments of knowledge, and back again. In Proceedings of the 3rd Innovations in Theoretical Computer Science Conference, ITCS ’12, 2012.
[72] R. Bitar and S. E. Rouayheb. Staircase-PIR: Universally robust private information retrieval. In 2018 IEEE
Information Theory Workshop (ITW), pages 1–5, Nov 2018. doi: 10.1109/ITW.2018.8613532.
[73] Andrea Bittau, Úlfar Erlingsson, Petros Maniatis, Ilya Mironov, Ananth Raghunathan, David Lie, Mitch
Rudominer, Ushasree Kode, Julien Tinnes, and Bernhard Seefeld. Prochlo: Strong privacy for analytics in
the crowd. In Proceedings of the 26th Symposium on Operating Systems Principles, SOSP ’17, pages 441–
459, New York, NY, USA, 2017. ACM. ISBN 978-1-4503-5085-3. doi: 10.1145/3132747.3132769. URL
http://doi.acm.org/10.1145/3132747.3132769.
[74] Davis Blalock, Jose Javier Gonzalez Ortiz, Jonathan Frankle, and John Guttag. What is the state of neural
network pruning? arXiv preprint arXiv:2003.03033, 2020.
[75] Peva Blanchard, El Mahdi El Mhamdi, Rachid Guerraoui, and Julien Stainer. Machine learning with adversaries: Byzantine tolerant gradient descent. In Advances in Neural Information Processing Systems, 2017.
[76] Peva Blanchard, Rachid Guerraoui, Julien Stainer, et al. Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent. In Advances in Neural Information Processing Systems, pages 118–128, 2017.
[77] Dan Bogdanov, Riivo Talviste, and Jan Willemson. Deploying secure multi-party computation for financial
data analysis - (short paper). In Financial Cryptography, volume 7397 of Lecture Notes in Computer Science,
pages 57–64. Springer, 2012.
[78] Peter Bogetoft, Dan Lund Christensen, Ivan Damgård, Martin Geisler, Thomas P. Jakobsen, Mikkel Krøigaard,
Janus Dam Nielsen, Jesper Buus Nielsen, Kurt Nielsen, Jakob Pagter, Michael I. Schwartzbach, and Tomas
Toft. Secure multiparty computation goes live. In Financial Cryptography, volume 5628 of Lecture Notes in
Computer Science, pages 325–343. Springer, 2009.
[79] K. A. Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H. Brendan McMahan, Sarvar Patel,
Daniel Ramage, Aaron Segal, and Karn Seth. Practical secure aggregation for federated learning on user-held
data. arXiv preprint arXiv:1611.04482, 2016.
[80] K. A. Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H Brendan McMahan, Sarvar Patel, Daniel
Ramage, Aaron Segal, and Karn Seth. Practical secure aggregation for privacy-preserving machine learning. In
Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, pages 1175–
1191. ACM, 2017.
[81] K. A. Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir Ivanov,
Chloé M Kiddon, Jakub Konečný, Stefano Mazzocchi, Brendan McMahan, Timon Van Overveldt, David
Petrou, Daniel Ramage, and Jason Roselander. Towards federated learning at scale: System design. In SysML
2019, 2019. URL https://arxiv.org/abs/1902.01046.
[82] K. A. Bonawitz, Fariborz Salehi, Jakub Konečný, Brendan McMahan, and Marco Gruteser. Federated learning
with autotuned communication-efficient secure aggregation. In 2019 53nd Asilomar Conference on Signals,
Systems, and Computers. IEEE, 2019.
[83] Dan Boneh, Elette Boyle, Henry Corrigan-Gibbs, Niv Gilboa, and Yuval Ishai. Zero-knowledge proofs on
secret-shared data via fully linear PCPs. In CRYPTO (3), volume 11694 of Lecture Notes in Computer Science,
pages 67–97. Springer, 2019.

94

[84] Florian Bourse, Michele Minelli, Matthias Minihold, and Pascal Paillier. Fast homomorphic evaluation of deep
discretized neural networks. In CRYPTO (3), volume 10993 of Lecture Notes in Computer Science, pages
483–512. Springer, 2018.
[85] Stephen Boyd, Arpita Ghosh, Balaji Prabhakar, and Devavrat Shah. Randomized gossip algorithms. IEEE
Transactions on Information Theory, 52(6):2508–2530, 2006.
[86] James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin, George
Necula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, and Qiao Zhang. JAX: composable transformations of Python+NumPy programs, 2018. URL http://github.com/google/jax.
[87] Zvika Brakerski. Fully homomorphic encryption without modulus switching from classical gapsvp.
CRYPTO, volume 7417 of Lecture Notes in Computer Science, pages 868–886. Springer, 2012.

In

[88] Zvika Brakerski, Craig Gentry, and Vinod Vaikuntanathan. (leveled) fully homomorphic encryption without
bootstrapping. In ITCS, pages 309–325. ACM, 2012.
[89] Mark Braverman, Ankit Garg, Tengyu Ma, Huy L. Nguyen, and David P. Woodruff. Communication lower
bounds for statistical estimation problems via a distributed data processing inequality. In Proceedings of the
forty-eighth annual ACM symposium on Theory of Computing, page 1011–1020. ACM, 2016.
[90] Wieland Brendel, Jonas Rauber, and Matthias Bethge. Decision-based adversarial attacks: Reliable attacks
against black-box machine learning models. arXiv preprint arXiv:1712.04248, 2017.
[91] Theodora S Brisimi, Ruidi Chen, Theofanie Mela, Alex Olshevsky, Ioannis Ch Paschalidis, and Wei Shi. Federated learning of predictive models from federated electronic health records. International journal of medical
informatics, 112:59–67, 2018.
[92] Benedikt Bünz, Jonathan Bootle, Dan Boneh, Andrew Poelstra, Pieter Wuille, and Gregory Maxwell. Bulletproofs: Short proofs for confidential transactions and more. In 2018 IEEE Symposium on Security and Privacy,
SP 2018, Proceedings, 21-23 May 2018, San Francisco, California, USA, 2018.
[93] Joy Buolamwini and Timnit Gebru. Gender shades: Intersectional accuracy disparities in commercial gender
classification. In Conference on fairness, accountability and transparency, pages 77–91, 2018.
[94] Martin Burkhart, Mario Strasser, Dilip Many, and Xenofontas Dimitropoulos. SEPIA: Privacy-preserving aggregation of multi-domain network events and statistics. Network, 1(101101), 2010.
[95] Sebastian Caldas, Jakub Konečný, H Brendan McMahan, and Ameet Talwalkar. Expanding the reach of federated learning by reducing client resource requirements. arXiv preprint arXiv:1812.07210, 2018.
[96] Sebastian Caldas, Peter Wu, Tian Li, Jakub Konečný, H Brendan McMahan, Virginia Smith, and Ameet Talwalkar. LEAF: A benchmark for federated settings. arXiv preprint arXiv:1812.01097, 2018.
[97] Clément L Canonne, Gautam Kamath, Audra McMillan, Adam Smith, and Jonathan Ullman. The structure of
optimal private tests for simple hypotheses. AarXiv preprint arXiv:1811.11148, 2019.
[98] Nicholas Carlini and David Wagner. Towards evaluating the robustness of neural networks. In 2017 IEEE
Symposium on Security and Privacy (SP), pages 39–57. IEEE, 2017.
[99] Nicholas Carlini, Chang Liu, Jernej Kos, Úlfar Erlingsson, and Dawn Song. The secret sharer: Measuring
unintended neural network memorization & extracting secrets. arXiv preprint arXiv:1802.08232, 2018.
[100] Nicholas Carlini, Florian Tramèr, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam
Roberts, Tom Brown, Dawn Song, Ulfar Erlingsson, et al. Extracting training data from large language models.
arXiv preprint arXiv:2012.07805, 2020.
[101] Iker Ceballos, Vivek Sharma, Eduardo Mugica, Abhishek Singh, Albert Roman, Praneeth Vepakomma, and
Ramesh Raskar. SplitNN-driven vertical partitioning. arXiv preprint arXiv:2008.04137, 2018.

95

[102] Khe Chai Sim, Françoise Beaufays, Arnaud Benard, Dhruv Guliani, Andreas Kabel, Nikhil Khare, Tamar
Lucassen, Petr Zadrazil, Harry Zhang, Leif Johnson, et al. Personalization of end-to-end speech recognition on
mobile devices for named entities. arXiv, pages arXiv–1912, 2019.
[103] T-H Hubert Chan, Elaine Shi, and Dawn Song. Privacy-preserving stream aggregation with fault tolerance. In
International Conference on Financial Cryptography and Data Security, pages 200–214. Springer, 2012.
[104] Ken Chang, Niranjan Balachandar, Carson Lam, Darvin Yi, James Brown, Andrew Beers, Bruce Rosen,
Daniel L Rubin, and Jayashree Kalpathy-Cramer. Distributed deep learning networks among institutions for
medical imaging. Journal of the American Medical Informatics Association, 25(8):945–954, 2018.
[105] Wei-Ting Chang and Ravi Tandon. On the upload versus download cost for secure and private matrix multiplication. ArXiv, abs/1906.10684, 2019.
[106] Zachary Charles and Jakub Konečnỳ. On the outsized importance of learning rates in local update methods.
arXiv preprint arXiv:2007.00878, 2020.
[107] David Chaum. Untraceable electronic mail, return addresses, and digital pseudonyms. Communications of the
ACM, 24(2), 1981.
[108] Bryant Chen, Wilka Carvalho, Nathalie Baracaldo, Heiko Ludwig, Benjamin Edwards, Taesung Lee, Ian Molloy, and Biplav Srivastava. Detecting backdoor attacks on deep neural networks by activation clustering. arXiv
preprint arXiv:1811.03728, 2018.
[109] Chien-Lun Chen, Leana Golubchik, and Marco Paolieri. Backdoor attacks on federated meta-learning. arXiv
preprint arXiv:2006.07026, 2020.
[110] Lijie Chen, Badih Ghazi, Ravi Kumar, and Pasin Manurangsi. On distributed differential privacy and counting
distinct elements. In Innovations in Theoretical Computer Science (ITCS), 2021.
[111] Lingjiao Chen, Hongyi Wang, Zachary B. Charles, and Dimitris S. Papailiopoulos. DRACO: Byzantineresilient distributed training via redundant gradients. In Proceedings of the 35th International Conference
on Machine Learning, ICML, 2018.
[112] Mingqing Chen, Rajiv Mathews, Tom Ouyang, and Françoise Beaufays. Federated learning of out-ofvocabulary words. arXiv preprint 1903.10635, 2019. URL http://arxiv.org/abs/1903.10635.
[113] Pin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, and Cho-Jui Hsieh. ZOO: Zeroth order optimization
based black-box attacks to deep neural networks without training substitute models. In Proceedings of the 10th
ACM Workshop on Artificial Intelligence and Security, pages 15–26. ACM, 2017.
[114] Wei-Ning Chen, Peter Kairouz, and Ayfer Ozgur. Breaking the communication-privacy-accuracy trilemma.
Advances in Neural Information Processing Systems, 33, 2020.
[115] Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, and Dawn Song. Targeted backdoor attacks on deep learning
systems using data poisoning. arXiv preprint arXiv:1712.05526, 2017.
[116] Yudong Chen, Lili Su, and Jiaming Xu. Distributed Statistical Machine Learning in Adversarial Settings:
Byzantine Gradient Descent. POMACS, 1:44:1–44:25, 2017.
[117] Massimo Chenal and Qiang Tang. On key recovery attacks against existing somewhat homomorphic encryption
schemes. In LATINCRYPT, volume 8895 of Lecture Notes in Computer Science, pages 239–258. Springer, 2014.
[118] Kewei Cheng, Tao Fan, Yilun Jin, Yang Liu, Tianjian Chen, and Qiang Yang. SecureBoost: A lossless federated
learning framework. CoRR, abs/1901.08755, 2019. URL http://arxiv.org/abs/1901.08755.
[119] Raymond Cheng, Fan Zhang, Jernej Kos, Warren He, Nicholas Hynes, Noah Johnson, Ari Juels, Andrew
Miller, and Dawn Song. Ekiden: A platform for confidentiality-preserving, trustworthy, and performant smart
contracts. In 2019 IEEE European Symposium on Security and Privacy (EuroS&P), pages 185–200. IEEE,
2019.

96

[120] Albert Cheu, Adam Smith, Jonathan Ullman, David Zeber, and Maxim Zhilyaev. Distributed differential privacy
via shuffling. In Annual International Conference on the Theory and Applications of Cryptographic Techniques,
pages 375–403. Springer, 2019.
[121] Benny Chor, Eyal Kushilevitz, Oded Goldreich, and Madhu Sudan. Private information retrieval. J. ACM, 45
(6):965–981, November 1998. ISSN 0004-5411. doi: 10.1145/293347.293350. URL http://doi.acm.
org/10.1145/293347.293350.
[122] Edward Chou, Florian Tramèr, and Giancarlo Pellegrino. SentiNet: Detecting physical attacks against deep
learning systems. arXiv preprint arXiv:1812.00292, 2018.
[123] Sélim Chraibi, Ahmed Khaled, Dmitry Kovalev, Peter Richtárik, Adil Salim, and Martin Takáč. Distributed
fixed point methods with compressed iterates. arXiv preprint arXiv:1912.09925, 2019.
[124] P. Christen. Data matching: concepts and techniques for record linkage, entity resolution, and duplicate detection. Springer Science & Business Media, 2012.
[125] NVIDIA Clara. The clara training framework authors, 2019. URL https://developer.nvidia.com/
clara.
[126] Gregory Cohen, Saeed Afshar, Jonathan Tapson, and André van Schaik. EMNIST: an extension of MNIST to
handwritten letters. arXiv preprint arXiv:1702.05373, 2017.
[127] Igor Colin, Aurélien Bellet, Joseph Salmon, and Stéphan Clémençon. Gossip dual averaging for decentralized
optimization of pairwise functions. In ICML, 2016.
[128] Graham Cormode, Tejas Kulkarni, and Divesh Srivastava. Marginal release under local differential privacy. In
Proceedings of the 2018 International Conference on Management of Data, pages 131–146. ACM, 2018.
[129] Jean-Sébastien Coron, Tancrède Lepoint, and Mehdi Tibouchi. Scale-invariant fully homomorphic encryption
over the integers. In Public Key Cryptography, volume 8383 of Lecture Notes in Computer Science, pages
311–328. Springer, 2014.
[130] Henry Corrigan-Gibbs and Dan Boneh. Prio: Private, robust, and scalable computation of aggregate statistics.
In 14th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 17), pages 259–
282, 2017.
[131] Henry Corrigan-Gibbs and Dmitry Kogan. Private information retrieval with sublinear online time. IACR
Cryptology ePrint Archive, 2019:1075, 2019.
[132] Corinna Cortes and Mehryar Mohri. Domain adaptation and sample bias correction theory and algorithm for
regression. Theoretical Computer Science, 519:103–126, 2014.
[133] Corinna Cortes, Mehryar Mohri, Ananda Theertha Suresh, and Ningshan Zhang. Multiple-source adaptation
with domain classifiers. arXiv preprint arXiv:2008.11036, 2020.
[134] Victor Costan and Srinivas Devadas. Intel SGX explained. IACR Cryptology ePrint Archive, 2016(086):1–118,
2016.
[135] Victor Costan, Ilia Lebedev, and Srinivas Devadas. Sanctum: Minimal hardware extensions for strong software
isolation. In 25th {USENIX} Security Symposium ({USENIX} Security 16), pages 857–874, 2016.
[136] Craig Costello, Cédric Fournet, Jon Howell, Markulf Kohlweiss, Benjamin Kreuter, Michael Naehrig, Bryan
Parno, and Samee Zahur. Geppetto: Versatile verifiable computation. In IEEE Symposium on Security and
Privacy, pages 253–270. IEEE Computer Society, 2015.

97

[137] Andrew Cotter, Ohad Shamir, Nati Srebro, and Karthik Sridharan. Better mini-batch algorithms via accelerated gradient methods. In J. Shawe-Taylor, R. Zemel, P. Bartlett, F. Pereira, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems, volume 24, pages 1647–1655. Curran Associates, Inc., 2011.
URL https://proceedings.neurips.cc/paper/2011/file/
b55ec28c52d5f6205684a473a2193564-Paper.pdf.
[138] Matthieu Courbariaux, Yoshua Bengio, and Jean-Pierre David. BinaryConnect: Training deep neural networks
with binary weights during propagations. In Advances in neural information processing systems, pages 3123–
3131, 2015.
[139] Pierre Courtiol, Charles Maussion, Matahi Moarii, Elodie Pronier, Samuel Pilcer, Meriem Sefta, Pierre
Manceron, Sylvain Toldo, Mikhail Zaslavskiy, Nolwenn Le Stang, et al. Deep learning-based classification
of mesothelioma improves prediction of patient outcome. Nature medicine, pages 1–7, 2019.
[140] Thomas M Cover and Joy A Thomas. Elements of information theory. John Wiley & Sons, 2012.
[141] Gabriela F Cretu, Angelos Stavrou, Michael E Locasto, Salvatore J Stolfo, and Angelos D Keromytis. Casting
out demons: Sanitizing training data for anomaly sensors. In 2008 IEEE Symposium on Security and Privacy
(sp 2008), pages 81–95. IEEE, 2008.
[142] Rachel Cummings, Sara Krehbiel, Kevin Lai, and Uthaipon Tantitongpipat. Differential privacy for growing
databases. In Advances in Neural Information Processing Systems 31, NeurIPS ’18, pages 8864–8873, 2018.
[143] Rachel Cummings, Sara Krehbiel, Yajun Mei, Rui Tuo, and Wanrong Zhang. Differentially private changepoint detection. In Advances in Neural Information Processing Systems 31, NeurIPS ’18, pages 10825–10834,
2018.
[144] Rachel Cummings, Inbal Dekel, Ori Heffetz, and Katrina Ligett. Bringing differential privacy into the experimental economics lab: Theory and an application to a public-good game. Working paper, 2019.
[145] Rachel Cummings, Varun Gupta, Dhamma Kimpara, and Jamie Morgenstern. On the compatibility of privacy
and fairness. In Proceedings of Fairness in User Modeling, Adaptation and Personalization, FairUMAP, 2019.
[146] Edwige Cyffers and Aurélien Bellet.
arXiv:2012.05326, 2020.

Privacy amplification by decentralization.

arXiv preprint

[147] Damgård. On σ protocols. http://www.cs.au.dk/˜ivan/Sigma.pdf, 2010.
[148] Deepesh Data, Linqi Song, and Suhas Diggavi. Data encoding for byzantine-resilient distributed optimization.
IEEE Transactions on Information Theory, 2020.
[149] Walter de Brouwer.
The federated future is ready for shipping.
federated-future-ready-shipping/, March 2019.

https://doc.ai/blog/

[150] Jeffrey Dean, Greg S. Corrado, Rajat Monga, Kai Chen, Matthieu Devin, Quoc V. Le, Mark Z. Mao,
Marc’Aurelio Ranzato, Andrew Senior, Paul Tucker, Ke Yang, and Andrew Y. Ng. Large scale distributed
deep networks. In Proceedings of the International Conference on Neural Information Processing Systems,
pages 1223–1231, 2012.
[151] Ofer Dekel, Ran Gilad-Bachrach, Ohad Shamir, and Lin Xiao. Optimal distributed online prediction using
mini-batches. J. Mach. Learn. Res., 13(1), January 2012.
[152] Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Jacob Steinhardt, and Alistair Stewart. Sever: A
robust meta-algorithm for stochastic optimization. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors,
Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine
Learning Research, pages 1596–1606, Long Beach, California, USA, 09–15 Jun 2019. PMLR. URL http:
//proceedings.mlr.press/v97/diakonikolas19a.html.

98

[153] Mario Diaz, Peter Kairouz, Jiachun Liao, and Lalitha Sankar. Theoretical guarantees for model auditing with
finite adversaries. arXiv preprint arXiv:1911.03405, 2019.
[154] Differential Privacy Team.
Learning with privacy at scale.
Apple Machine Learning
Journal, 1(8), 2017.
URL https://machinelearning.apple.com/2017/12/06/
learning-with-privacy-at-scale.html.
[155] Bolin Ding, Janardhan Kulkarni, and Sergey Yekhanin. Collecting telemetry data privately. In Advances
in Neural Information Processing Systems 30, December 2017. URL https://www.microsoft.com/
en-us/research/publication/collecting-telemetry-data-privately/.
[156] Zeyu Ding, Yuxin Wang, Guanhong Wang, Danfeng Zhang, and Daniel Kifer. Detecting violations of differential privacy. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications
Security, CCS ’18, pages 475–489, New York, NY, USA, 2018. ACM. ISBN 978-1-4503-5693-0. doi:
10.1145/3243734.3243818. URL http://doi.acm.org/10.1145/3243734.3243818.
[157] Roger Dingledine, Nick Mathewson, and Paul Syverson. Tor: The second-generation onion router. Technical
report, Naval Research Lab Washington DC, 2004.
[158] Canh T. Dinh, Nguyen H. Tran, and Tuan Dung Nguyen. Personalized Federated Learning with Moreau Envelopes. In NeurIPS, 2020.
[159] Rafael G. L. D’Oliveira and S. E. Rouayheb. Lifting private information retrieval from two to any number of
messages. In 2018 IEEE International Symposium on Information Theory (ISIT), pages 1744–1748, June 2018.
doi: 10.1109/ISIT.2018.8437805.
[160] John R. Douceur. The sybil attack. In Revised Papers from the First International Workshop on Peer-to-Peer
Systems, IPTPS ’01, pages 251–260, London, UK, UK, 2002. Springer-Verlag. ISBN 3-540-44179-4. URL
http://dl.acm.org/citation.cfm?id=646334.687813.
[161] John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic
optimization. Journal of machine learning research, 12(7), 2011.
[162] John C Duchi, Michael I Jordan, and Martin J Wainwright. Local privacy and statistical minimax rates. In
Foundations of Computer Science (FOCS), 2013 IEEE 54th Annual Symposium on, pages 429–438. IEEE,
2013.
[163] Sanghamitra Dutta, Gauri Joshi, Soumyadip Ghosh, Parijat Dube, and Priya Nagpurkar. Slow and Stale Gradients Can Win the Race: Error-Runtime Trade-offs in Distributed SGD. International Conference on Artificial
Intelligence and Statistics (AISTATS), April 2018. URL https://arxiv.org/abs/1803.01113.
[164] Cynthia Dwork. Differential privacy: A survey of results. In International Conference on Theory and Applications of Models of Computation, pages 1–19. Springer, 2008.
[165] Cynthia Dwork and Aaron Roth. The algorithmic foundations of differential privacy. Foundations and Trends
in Theoretical Computer Science, 9(3–4):211–407, 2014.
[166] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor. Our data, ourselves:
Privacy via distributed noise generation. In Annual International Conference on the Theory and Applications
of Cryptographic Techniques, pages 486–503. Springer, 2006.
[167] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam D. Smith. Calibrating noise to sensitivity in private
data analysis. In IACR Theory of Cryptography Conference (TCC), New York, New York, volume 3876 of
Lecture Notes in Computer Science, pages 265–284. Springer-Verlag, 2006. doi: 10.1007/11681878 14.
[168] Cynthia Dwork, Guy N. Rothblum, and Salil Vadhan. Boosting and differential privacy. In Proceedings of the
IEEE 51st Annual Symposium on Foundations of Computer Science, FOCS ’10, pages 51–60, 2010.

99

[169] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. Fairness through awareness. In Proceedings of the 3rd innovations in theoretical computer science conference, pages 214–226. ACM,
2012.
[170] Laurel Eckhouse, Kristian Lum, Cynthia Conti-Cook, and Julie Ciccolini. Layers of bias: A unified approach
for understanding problems with risk assessment. Criminal Justice and Behavior, 46(2):185–209, 2019.
[171] Hubert Eichner, Tomer Koren, H. Brendan McMahan, Nathan Srebro, and Kunal Talwar. Semi-cyclic stochastic
gradient descent. In Accepted to ICML 2019., 2019. URL https://arxiv.org/abs/1904.10120.
[172] Karim Eldefrawy, Gene Tsudik, Aurélien Francillon, and Daniele Perito. SMART: secure and minimal architecture for (establishing dynamic) root of trust. In NDSS. The Internet Society, 2012.
[173] Anis Elgabli, Jihong Park, Amrit S Bedi, Mehdi Bennis, and Vaneet Aggarwal. GADMM: Fast and communication efficient framework for distributed machine learning. arXiv preprint arXiv:1909.00047, 2019.
[174] Anis Elgabli, Jihong Park, Chaouki Ben Issaid, and Mehdi Bennis. Harnessing wireless channels for scalable
and privacy-preserving federated learning, 2020.
[175] Thomas Elsken, Jan Hendrik Metzen, and Frank Hutter. Efficient multi-objective neural architecture search via
Lamarckian evolution. arXiv preprint arXiv:1804.09081, 2018.
[176] Logan Engstrom, Brandon Tran, Dimitris Tsipras, Ludwig Schmidt, and Aleksander Madry. A rotation and a
translation suffice: Fooling CNNs with simple transformations. arXiv preprint arXiv:1712.02779, 2017.
[177] Úlfar Erlingsson, Vasyl Pihur, and Aleksandra Korolova. RAPPOR: Randomized aggregatable privacypreserving ordinal response. In ACM CCS, 2014. ISBN 978-1-4503-2957-6. doi: 10.1145/2660267.2660348.
URL http://doi.acm.org/10.1145/2660267.2660348.
[178] Úlfar Erlingsson, Vitaly Feldman, Ilya Mironov, Ananth Raghunathan, Kunal Talwar, and Abhradeep Thakurta.
Amplification by shuffling: From local to central differential privacy via anonymity. In SODA, pages 2468–
2479, 2019.
[179] EU CORDIS.
Machine learning ledger orchestration for drug discovery, 2019.
URL https:
//cordis.europa.eu/project/rcn/223634/factsheet/en?WT.mc_id=RSS-Feed&
WT.rss_f=project&WT.rss_a=223634&WT.rss_ev=a. Retrieved Aug 2019.
[180] Stefan Falkner, Aaron Klein, and Frank Hutter. BOHB: Robust and efficient hyperparameter optimization at
scale. arXiv preprint arXiv:1807.01774, 2018.
[181] Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. Personalized federated learning: A meta-learning
approach. arXiv preprint arXiv:2002.07948, 2020.
[182] Junfeng Fan and Frederik Vercauteren. Somewhat practical fully homomorphic encryption. IACR Cryptology
ePrint Archive, 2012:144, 2012.
[183] Minghong Fang, Xiaoyu Cao, Jinyuan Jia, and Neil Zhenqiang Gong. Local model poisoning attacks to
Byzantine-robust federated learning. arXiv preprint arXiv:1911.11815, 2019.
[184] FeatureCloud.
FeatureCloud: Our vision, 2019.
our-vision/. Retrieved Aug 2019.

URL https://featurecloud.eu/about/

[185] Vitaly Feldman, Ilya Mironov, Kunal Talwar, and Abhradeep Thakurta. Privacy amplification by iteration. In
2018 IEEE 59th Annual Symposium on Foundations of Computer Science (FOCS), pages 521–532. IEEE, 2018.
[186] Clément Feutry, Pablo Piantanida, Yoshua Bengio, and Pierre Duhamel. Learning anonymized representations
with adversarial neural networks. CoRR, abs/1802.09386, 2018. URL http://arxiv.org/abs/1802.
09386.

100

[187] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep
networks. In Proceedings of the 34th International Conference on Machine Learning, 2017.
[188] Aurélien Francillon, Quan Nguyen, Kasper Bonne Rasmussen, and Gene Tsudik. A minimalist approach to
remote attestation. In DATE, pages 1–6. European Design and Automation Association, 2014.
[189] Matt Fredrikson, Somesh Jha, and Thomas Ristenpart. Model inversion attacks that exploit confidence information and basic countermeasures. In Proceedings of the 22nd ACM SIGSAC Conference on Computer and
Communications Security, pages 1322–1333. ACM, 2015.
[190] Clement Fung, Chris JM Yoon, and Ivan Beschastnikh. Mitigating sybils in federated learning poisoning. arXiv
preprint arXiv:1808.04866, 2018.
[191] Jun Furukawa, Yehuda Lindell, Ariel Nof, and Or Weinstein. High-throughput secure three-party computation
for malicious adversaries and an honest majority. In EUROCRYPT (2), volume 10211 of Lecture Notes in
Computer Science, pages 225–255, 2017.
[192] Adam Gaier and David Ha. Weight agnostic neural networks. arXiv preprint arXiv:1906.04358, 2019.
[193] Venkata Gandikota, Raj Kumar Maity, and Arya Mazumdar. vqSGD: Vector quantized stochastic gradient
descent. arXiv preprint arXiv:1911.07971, 2019.
[194] Adrià Gascón, Phillipp Schoppmann, Borja Balle, Mariana Raykova, Jack Doerner, Samee Zahur, and David
Evans. Privacy-preserving distributed linear regression on high-dimensional data. PoPETs, 2017(4):345–364,
2017.
[195] Rosario Gennaro, Craig Gentry, and Bryan Parno. Non-interactive verifiable computing: Outsourcing computation to untrusted workers. In CRYPTO, volume 6223 of Lecture Notes in Computer Science, pages 465–482.
Springer, 2010.
[196] Rosario Gennaro, Craig Gentry, Bryan Parno, and Mariana Raykova. Quadratic span programs and succinct
NIZKs without PCPs. In EUROCRYPT, volume 7881 of Lecture Notes in Computer Science, pages 626–645.
Springer, 2013.
[197] Craig Gentry. Fully homomorphic encryption using ideal lattices. In Proceedings of the forty-first annual ACM
symposium on Theory of computing, pages 169–178, 2009.
[198] Craig Gentry and Shai Halevi. Compressible FHE with applications to PIR. In TCC (2), volume 11892 of
Lecture Notes in Computer Science, pages 438–464. Springer, 2019.
[199] Robin C. Geyer, Tassilo Klein, and Moin Nabi. Differentially private federated learning: A client level perspective. CoRR, abs/1712.07557, 2017. URL http://arxiv.org/abs/1712.07557.
[200] Badih Ghazi, Noah Golowich, Ravi Kumar, Rasmus Pagh, and Ameya Velingker. On the power of multiple
anonymous messages. arXiv:1908.11358, 2019.
[201] Badih Ghazi, Rasmus Pagh, and Ameya Velingker. Scalable and differentially private distributed aggregation
in the shuffled model. arXiv preprint arXiv:1906.08320, 2019.
[202] Badih Ghazi, Noah Golowich, Ravi Kumar, Pasin Manurangsi, Rasmus Pagh, and Ameya Velingker. Pure
differentially private summation from anonymous messages. In ITC, pages 15:1–15:23, 2020.
[203] Badih Ghazi, Ravi Kumar, Pasin Manurangsi, and Rasmus Pagh. Private counting from anonymous messages:
Near-optimal accuracy with vanishing communication overhead. In ICML, 2020.
[204] Badih Ghazi, Pasin Manurangsi, Rasmus Pagh, and Ameya Velingker. Private aggregation from fewer anonymous messages. In EUROCRYPT, pages 798–827, 2020.

101

[205] Arpita Ghosh, Tim Roughgarden, and Mukund Sundararajan. Universally utility-maximizing privacy mechanisms. In Proceedings of the Forty-first Annual ACM Symposium on Theory of Computing, STOC ’09, pages
351–360, New York, NY, USA, 2009. ACM. ISBN 978-1-60558-506-2. doi: 10.1145/1536414.1536464. URL
http://doi.acm.org/10.1145/1536414.1536464.
[206] Ran Gilad-Bachrach, Nathan Dowlin, Kim Laine, Kristin E. Lauter, Michael Naehrig, and John Wernsing.
CryptoNets: Applying neural networks to encrypted data with high throughput and accuracy. In Proceedings
of the 33nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24,
2016, pages 201–210, 2016. URL http://proceedings.mlr.press/v48/gilad-bachrach16.
html.
[207] Antonious M Girgis, Deepesh Data, Suhas Diggavi, Peter Kairouz, and Ananda Theertha Suresh. Shuffled model of federated learning: Privacy, communication and accuracy trade-offs.
arXiv preprint
arXiv:2008.07180, 2020.
[208] O. Goldreich, S. Micali, and A. Wigderson. How to play any mental game. In Proceedings of the Nineteenth Annual ACM Symposium on Theory of Computing, STOC ’87, pages 218–229, New York, NY, USA,
1987. ACM. ISBN 0-89791-221-7. doi: 10.1145/28395.28420. URL http://doi.acm.org/10.1145/
28395.28420.
[209] Shafi Goldwasser, Silvio Micali, and Charles Rackoff. The knowledge complexity of interactive proof systems.
SIAM J. Comput., 18(1):186–208, 1989.
[210] Shafi Goldwasser, Yael Tauman Kalai, and Guy N. Rothblum. Delegating computation: interactive proofs for
muggles. In STOC, pages 113–122. ACM, 2008.
[211] Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. In
3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015,
Conference Track Proceedings, 2015. URL http://arxiv.org/abs/1412.6572.
[212] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples.
ICLR, 2015.
[213] Slawomir Goryczka and Li Xiong. A comprehensive comparison of multiparty secure additions with differential
privacy. IEEE Trans. Dependable Sec. Comput., 14(5):463–477, 2017. doi: 10.1109/TDSC.2015.2484326.
URL https://doi.org/10.1109/TDSC.2015.2484326.
[214] Tianyu Gu, Brendan Dolan-Gavitt, and Siddharth Garg. BadNets: Identifying vulnerabilities in the machine
learning model supply chain. arXiv preprint arXiv:1708.06733, 2017.
[215] Otkrist Gupta and Ramesh Raskar. Distributed learning of deep neural network over multiple agents. Journal
of Network and Computer Applications, 116:1–8, 2018.
[216] Farzin Haddadpour, Mohammad Mahdi Kamani, Mehrdad Mahdavi, and Viveck R Cadambe. Local SGD with
periodic averaging: Tighter analysis and adaptive synchronization. arXiv preprint arXiv:1910.13598, 2019.
[217] Andreas Haeberlen, Benjamin C Pierce, and Arjun Narayan. Differential privacy under fire. In USENIX Security
Symposium, 2011.
[218] Shai Halevi, Yehuda Lindell, and Benny Pinkas. Secure computation on the web: Computing without simultaneous interaction. In Annual Cryptology Conference, pages 132–150. Springer, 2011.
[219] Jenny Hamer, Mehryar Mohri, and Ananda Theertha Suresh. Fedboost: A communication-efficient algorithm
for federated learning. In International Conference on Machine Learning, pages 3973–3983. PMLR, 2020.
[220] Song Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks with
pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149, 2015.

102

[221] Yanjun Han, Ayfer Özgür, and Tsachy Weissman. Geometric lower bounds for distributed parameter estimation
under communication constraints. In Proceedings of Machine Learning Research, pages 1–26, 75, 2018.
[222] Andrew Hard, Kanishka Rao, Rajiv Mathews, Françoise Beaufays, Sean Augenstein, Hubert Eichner, Chloé
Kiddon, and Daniel Ramage. Federated learning for mobile keyboard prediction. arXiv preprint 1811.03604,
2018.
[223] Moritz Hardt, Eric Price, and Nathan Srebro. Equality of opportunity in supervised learning. In Advances in
Neural Information Processing Systems, 2016.
[224] Stephen Hardy, Wilko Henecka, Hamish Ivey-Law, Richard Nock, Giorgio Patrini, Guillaume Smith, and Brian
Thorne. Private federated learning on vertically partitioned data via entity resolution and additively homomorphic encryption. arXiv preprint arXiv:1711.10677, 2017.
[225] Tatsunori Hashimoto, Megha Srivastava, Hongseok Namkoong, and Percy Liang. Fairness without demographics in repeated loss minimization. In International Conference on Machine Learning, pages 1934–1943, 2018.
[226] Chaoyang He, Conghui Tan, Hanlin Tang, Shuang Qiu, and Ji Liu. Central server free federated learning over
single-sided trust social networks. arXiv preprint arXiv:1910.04956, 2019.
[227] Chaoyang He, Murali Annavaram, and Salman Avestimehr. Group knowledge transfer: Federated learning of
large cnns at the edge. In Advances in Neural Information Processing Systems 34, 2020.
[228] Chaoyang He, Murali Annavaram, and Salman Avestimehr. Fednas: Federated deep learning via neural architecture search. 2020.
[229] Chaoyang He, Songze Li, Jinhyun So, Xiao Zeng, Mi Zhang, Hongyi Wang, Xiaoyang Wang, Praneeth
Vepakomma, Abhishek Singh, Hang Qiu, Xinghua Zhu, Jianzong Wang, Li Shen, Peilin Zhao, Yan Kang, Yang
Liu, Ramesh Raskar, Qiang Yang, Murali Annavaram, and Salman Avestimehr. Fedml: A research library and
benchmark for federated machine learning, 2020.
[230] Chaoyang He, Haishan Ye, Li Shen, and Tong Zhang. Milenas: Efficient neural architecture search via mixedlevel reformulation. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
2020.
[231] Lie He, An Bian, and Martin Jaggi. COLA: Decentralized linear learning. In NeurIPS 2018 - Advances in
Neural Information Processing Systems 31, 2018.
[232] Úrsula Hébert-Johnson, Michael Kim, Omer Reingold, and Guy Rothblum. Multicalibration: Calibration for
the (computationally-identifiable) masses. In International Conference on Machine Learning, pages 1944–
1953, 2018.
[233] HElib. HElib. https://github.com/homenc/HElib, October 2019.
[234] Judy Hoffman, Mehryar Mohri, and Ningshan Zhang. Algorithms and theory for multiple-source adaptation.
In Advances in Neural Information Processing Systems, pages 8246–8256, 2018.
[235] Samuel Horvath, Chen-Yu Ho, Ludovit Horvath, Atal Narayan Sahu, Marco Canini, and Peter Richtarik. Natural compression for distributed deep learning. arXiv preprint arXiv:1905.10988, 2019.
[236] Kevin Hsieh, Amar Phanishayee, Onur Mutlu, and Phillip B. Gibbons. The non-IID data quagmire of decentralized machine learning, 2019. URL https://arxiv.org/abs/1910.00189.
[237] Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown. Measuring the effects of non-identical data distribution
for federated visual classification. arXiv preprint arXiv:1909.06335, 2019.
[238] Yaochen Hu, Peng Liu, Linglong Kong, and Di Niu. Learning privately over distributed features: An admm
sharing approach, 2019.

103

[239] Zhenqi Huang, Sayan Mitra, and Nitin Vaidya. Differentially Private Distributed Optimization. In ICDCN,
2015.
[240] Zhouyuan Huo, Bin Gu, and Heng Huang. Training neural networks using features replay. In Advances in
Neural Information Processing Systems, pages 6659–6668, 2018.
[241] R Intel. Architecture instruction set extensions programming reference. Intel Corporation, Feb, 2012.
[242] Mihaela Ion, Ben Kreuter, Erhan Nergiz, Sarvar Patel, Shobhit Saxena, Karn Seth, David Shanahan, and Moti
Yung. Private intersection-sum protocol with applications to attributing aggregate ad conversions. IACR Cryptology ePrint Archive, 2017:738, 2017.
[243] Mihaela Ion, Ben Kreuter, Ahmet Erhan Nergiz, Sarvar Patel, Mariana Raykova, Shobhit Saxena, Karn Seth,
David Shanahan, and Moti Yung. On deploying secure computing commercially: Private intersection-sum
protocols and their business applications. IACR Cryptology ePrint Archive, 2019:723, 2019.
[244] Yuval Ishai, Joe Kilian, Kobbi Nissim, and Erez Petrank. Extending oblivious transfers efficiently. In CRYPTO,
volume 2729 of Lecture Notes in Computer Science, pages 145–161. Springer, 2003.
[245] Max Jaderberg, Wojciech Marian Czarnecki, Simon Osindero, Oriol Vinyals, Alex Graves, David Silver, and
Koray Kavukcuoglu. Decoupled neural interfaces using synthetic gradients. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 1627–1635. JMLR. org, 2017.
[246] Matthew Jagielski, Michael J. Kearns, Jieming Mao, Alina Oprea, Aaron Roth, Saeed Sharifi-Malvajerdi, and
Jonathan Ullman. Differentially private fair learning. CoRR, abs/1812.02696, 2018. URL http://arxiv.
org/abs/1812.02696.
[247] Matthew Jagielski, Jonathan Ullman, and Alina Oprea. Auditing differentially private machine learning: How
private is private sgd? Advances in Neural Information Processing Systems, 33, 2020.
[248] Eunjeong Jeong, Seungeun Oh, Hyesung Kim, Jihong Park, Mehdi Bennis, and Seong-Lyun Kim.
Communication-efficient on-device machine learning: Federated distillation and augmentation under non-IID
private data. CoRR, abs/1811.11479, 2018. URL http://arxiv.org/abs/1811.11479.
[249] Zhuqing Jia and Syed Ali Jafar.
abs/1908.06957, 2019.

On the capacity of secure distributed matrix multiplication.

ArXiv,

[250] Yihan Jiang, Jakub Konečný, Keith Rush, and Sreeram Kannan. Improving federated learning personalization
via model agnostic meta learning. arXiv preprint arXiv:1909.12488, 2019.
[251] S. Kadhe, B. Garcia, A. Heidarzadeh, S. E. Rouayheb, and A. Sprintson. Private information retrieval with side
information: The single server case. In 2017 55th Annual Allerton Conference on Communication, Control,
and Computing (Allerton), pages 1099–1106, Oct 2017. doi: 10.1109/ALLERTON.2017.8262860.
[252] Peter Kairouz, Sewoong Oh, and Pramod Viswanath. Extremal mechanisms for local differential privacy. In
Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, editors, Advances in Neural
Information Processing Systems 27, pages 2879–2887. Curran Associates, Inc., 2014.
[253] Peter Kairouz, K. A. Bonawitz, and Daniel Ramage. Discrete distribution estimation under local privacy. In
International Conference on Machine Learning, pages 2436–2444, 2016.
[254] Peter Kairouz, Sewoong Oh, and Pramod Viswanath. The composition theorem for differential privacy. IEEE
Transactions on Information Theory, 63(6):4037–4049, 2017.
[255] Peter Kairouz, Jiachun Liao, Chong Huang, and Lalitha Sankar. Censored and fair universal representations
using generative adversarial models. arXiv preprint arXiv:1910.00411, 2020.
[256] Peter Kairouz, Ziyu Liu, and Thomas Steinke. The distributed discrete gaussian mechanism for federated
learning with secure aggregation, 2021.

104

[257] Peter Kairouz, Brendan McMahan, Shuang Song, Om Thakkar, Abhradeep Thakurta, and Zheng Xu. Practical
and private (deep) learning without sampling or shuffling, 2021.
[258] Toshihiro Kamishima, Shotaro Akaho, and Jun Sakuma. Fairness-aware learning through regularization approach. In 2011 IEEE 11th International Conference on Data Mining Workshops, pages 643–650. IEEE, 2011.
[259] Daniel Kang, Yi Sun, Dan Hendrycks, Tom Brown, and Jacob Steinhardt. Testing robustness against unforeseen
adversaries. arXiv preprint arXiv:1908.08016, 2019.
[260] Jiawen Kang, Zehui Xiong, Dusit Niyato, Shengli Xie, and Junshan Zhang. Incentive mechanism for reliable
federated learning: A joint optimization approach to combining reputation and contract theory. IEEE Internet
of Things Journal, 2019.
[261] Jiawen Kang, Zehui Xiong, Dusit Niyato, Han Yu, Ying-Chang Liang, and Dong In Kim. Incentive design for
efficient federated learning in mobile networks: A contract theory approach. In IEEE VTS Asia Pacific Wireless
Communications Symposium, APWCS 2019, Singapore, August 28-30, 2019, pages 1–5, 2019.
[262] Hamed Karimi, Julie Nutini, and Mark Schmidt. Linear convergence of gradient and proximal-gradient methods
under the Polyak-łojasiewicz condition. In Joint European Conference on Machine Learning and Knowledge
Discovery in Databases, pages 795–811. Springer, 2016.
[263] Sai Praneeth Karimireddy, Quentin Rebjock, Sebastian Stich, and Martin Jaggi. Error feedback fixes SignSGD
and other gradient compression schemes. In ICML, 2019.
[264] Sai Praneeth Karimireddy, Martin Jaggi, Satyen Kale, Mehryar Mohri, Sashank J Reddi, Sebastian U Stich,
and Ananda Theertha Suresh. Mime: Mimicking centralized stochastic algorithms in federated learning. arXiv
preprint arXiv:2008.03606, 2020.
[265] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and Ananda Theertha
Suresh. Scaffold: Stochastic controlled averaging for federated learning. In International Conference on
Machine Learning, pages 5132–5143. PMLR, 2020.
[266] Shiva Prasad Kasiviswanathan, Homin K. Lee, Kobbi Nissim, Sofya Raskhodnikova, and Adam D. Smith.
What can we learn privately? SIAM J. Comput., 40(3):793–826, 2011. URL https://doi.org/10.
1137/090756090.
[267] Michael J. Kearns, Aaron Roth, Zhiwei Steven Wu, and Grigory Yaroslavtsev. Privacy for the protected (only).
CoRR, abs/1506.00242, 2015. URL http://arxiv.org/abs/1506.00242.
[268] Ahmed Khaled, Konstantin Mishchenko, and Peter Richtárik. First analysis of local GD on heterogeneous data,
2019. URL https://arxiv.org/abs/1909.04715.
[269] Ahmed Khaled, Konstantin Mishchenko, and Peter Richtárik. Better communication complexity for local SGD,
2019. URL https://arxiv.org/abs/1909.04746.
[270] Mikhail Khodak, Maria-Florina Balcan, and Ameet Talwalkar. Adaptive gradient-based meta-learning methods.
In Advances in Neural Information Processing Systems, 2019.
[271] Daniel Kifer and Ashwin Machanavajjhala. Pufferfish: A framework for mathematical privacy definitions.
ACM Transactions on Database Systems, 39(1):3:1–3:36, 2014.
[272] Yejin Kim, Jimeng Sun, Hwanjo Yu, and Xiaoqian Jiang. Federated tensor factorization for computational
phenotyping. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery
and Data Mining, Halifax, NS, Canada, August 13 - 17, 2017, pages 887–895, 2017. doi: 10.1145/3097983.
3098118. URL https://doi.org/10.1145/3097983.3098118.
[273] Ross D. King, Cao Feng, and Alistair Sutherland. StatLog: comparison of classification algorithms on large
real-world problems. Applied Artificial Intelligence an International Journal, 9(3):289–333, 1995.

105

[274] Patrick Koeberl, Steffen Schulz, Ahmad-Reza Sadeghi, and Vijay Varadharajan. TrustLite: a security architecture for tiny embedded devices. In EuroSys, pages 10:1–10:14. ACM, 2014.
[275] Pang Wei Koh and Percy Liang. Understanding black-box predictions via influence functions. In Proceedings
of the 34th International Conference on Machine Learning-Volume 70, pages 1885–1894. JMLR. org, 2017.
[276] Pang Wei Koh, Jacob Steinhardt, and Percy Liang. Stronger data poisoning attacks break data sanitization
defenses. arXiv preprint arXiv:1811.00741, 2018.
[277] Ron Kohavi and George H John. Automatic parameter selection by minimizing estimated error. In Machine
Learning Proceedings 1995, pages 304–312. Elsevier, 1995.
[278] Anastasia Koloskova, Sebastian U Stich, and Martin Jaggi. Decentralized Stochastic Optimization and Gossip
Algorithms with Compressed Communication. In ICML, 2019.
[279] Anastasia Koloskova, Tao Lin, Sebastian U Stich, and Martin Jaggi. Decentralized deep learning with arbitrary
communication compression. International Conference on Learning Representations (ICLR), 2020.
[280] Anastasia Koloskova, Nicolas Loizou, Sadra Boreiri, Martin Jaggi, and Sebastian U. Stich. A Unified Theory
of Decentralized SGD with Changing Topology and Local Updates. In ICML, 2020.
[281] Jakub Konečný and Peter Richtárik. Randomized distributed mean estimation: Accuracy vs communication.
Frontiers in Applied Mathematics and Statistics, 4:62, 2018.
[282] Jakub Konečný, H Brendan McMahan, Felix X. Yu, Peter Richtárik, Ananda Theertha Suresh, and Dave Bacon.
Federated learning: Strategies for improving communication efficiency. arXiv preprint arXiv:1610.05492,
2016.
[283] Satya Kuppam, Ryan McKenna, David Pujol, Michael Hay, Ashwin Machanavajjhala, and Gerome Miklau.
Fair decision making using privacy-protected data. CoRR, abs/1905.12744, 2019. URL http://arxiv.
org/abs/1905.12744.
[284] Alexey Kurakin, Ian Goodfellow, and Samy Bengio. Adversarial machine learning at scale. arXiv preprint
arXiv:1611.01236, 2016.
[285] Eyal Kushilevitz and Noam Nisan. Communication Complexity. Cambridge University Press, New York, NY,
USA, 1997. ISBN 0-521-56067-5.
[286] Eyal Kushilevitz and Rafail Ostrovsky. Replication is not needed: Single database, computationally-private
information retrieval. In In Proc. of the 38th Annu. IEEE Symp. on Foundations of Computer Science, pages
364–373, 1997.
[287] Matt J Kusner, Joshua Loftus, Chris Russell, and Ricardo Silva. Counterfactual fairness. In Advances in Neural
Information Processing Systems, pages 4066–4076, 2017.
[288] Albert Kwon, David Lazar, Srinivas Devadas, and Bryan Ford. Riffle. Proceedings on Privacy Enhancing
Technologies, 2016(2):115–134, 2016.
[289] Yassine Laguel, Krishna Pillutla, Jérôme Malick, and Zaid Harchaoui. Device Heterogeneity in Federated
Learning: A Superquantile Approach. arXiv preprint arXiv:2002.11223, 2020.
[290] Brenden M. Lake, Ruslan Salakhutdinov, Jason Gross, and Joshua B. Tenenbaum. One shot learning of simple
visual concepts. In Proceedings of the Conference of the Cognitive Science Society (CogSci), 2017.
[291] Anusha Lalitha, Osman Cihan Kilinc, Tara Javidi, and Farinaz Koushanfar. Peer-to-peer Federated Learning on
Graphs. Technical report, arXiv:1901.11173, 2019.
[292] Anusha Lalitha, Xinghan Wang, Osman Kilinc, Yongxi Lu, Tara Javidi, and Farinaz Koushanfar. Decentralized
Bayesian learning over graphs. arXiv preprint: 1905.10466, 2019.

106

[293] Leslie Lamport, Robert Shostak, and Marshall Pease. The Byzantine generals problem. ACM Transactions on
Programming Languages and Systems (TOPLAS), 4(3):382–401, 1982.
[294] Guanghui Lan. An optimal method for stochastic composite optimization. Mathematical Programming, 133
(1):365–397, Jun 2012. ISSN 1436-4646. doi: 10.1007/s10107-010-0434-y. URL https://doi.org/
10.1007/s10107-010-0434-y.
[295] Andrei Lapets, Nikolaj Volgushev, Azer Bestavros, Frederick Jansen, and Mayank Varia. Secure MPC for
analytics as a web application. In SecDev, pages 73–74. IEEE Computer Society, 2016.
[296] Mathias Lécuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and Suman Jana. Certified robustness
to adversarial examples with differential privacy. In 2019 IEEE Symposium on Security and Privacy, SP 2019,
San Francisco, CA, USA, May 19-23, 2019, pages 656–672, 2019. doi: 10.1109/SP.2019.00044. URL https:
//doi.org/10.1109/SP.2019.00044.
[297] Tancrède Lepoint, Sarvar Patel, Mariana Raykova, Karn Seth, and Ni Trieu. Private join and compute from PIR
with default. IACR Cryptol. ePrint Arch., 2020:1011, 2020.
[298] David Leroy, Alice Coucke, Thibaut Lavril, Thibault Gisselbrecht, and Joseph Dureau. Federated learning for
keyword spotting. arXiv preprint arXiv:1810.05512, 2018.
[299] Jeffrey Li, Mikhail Khodak, Sebastian Caldas, and Ameet Talwalkar. Differentially private meta-learning. arXiv
preprint arXiv:1909.05830, 2019.
[300] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith. Federated
optimization in heterogeneous networks, 2018. URL https://arxiv.org/abs/1812.06127.
[301] Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges, methods,
and future directions, 2019.
[302] Tian Li, Maziar Sanjabi, and Virginia Smith. Fair resource allocation in federated learning. arXiv preprint
arXiv:1905.10497, 2019.
[303] Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the convergence of FedAvg on
non-IID data. arXiv preprint arXiv:1907.02189, 2019.
[304] Xiang Li, Wenhao Yang, Shusen Wang, and Zhihua Zhang. Communication efficient decentralized training
with multiple local updates. arXiv preprint arXiv:1910.09126, 2019.
[305] Xiangru Lian, Ce Zhang, Huan Zhang, Cho-Jui Hsieh, Wei Zhang, and Ji Liu. Can Decentralized Algorithms
Outperform Centralized Algorithms? A Case Study for Decentralized Parallel Stochastic Gradient Descent. In
NIPS, 2017.
[306] Xiangru Lian, Wei Zhang, Ce Zhang, and Ji Liu. Asynchronous Decentralized Parallel Stochastic Gradient
Descent. In ICML, 2018.
[307] libsnark. libsnark: a c++ library for zkSNARK proofs. https://github.com/scipr-lab/libsnark,
December 2019.
[308] David Lie and Petros Maniatis. Glimmers: Resolving the privacy/trust quagmire. In Proceedings of the 16th
Workshop on Hot Topics in Operating Systems, pages 94–99. ACM, 2017.
[309] Darryl Lin, Sachin Talathi, and Sreekanth Annapureddy. Fixed point quantization of deep convolutional networks. In International Conference on Machine Learning, pages 2849–2858, 2016.
[310] Tao Lin, Sebastian U Stich, and Martin Jaggi. Don’t use large mini-batches, use local SGD. International
Conference on Learning Representations (ICLR), 2020.

107

[311] Yujun Lin, Song Han, Huizi Mao, Yu Wang, and William J Dally. Deep gradient compression: Reducing the
communication bandwidth for distributed training. arXiv preprint arXiv:1712.01887, 2017.
[312] R. J. A. Little. Post-stratification: A modeler’s perspective. Journal of the American Statistical Association, 88
(423):1001–1012, 1993. ISSN 01621459.
[313] Hanxiao Liu, Karen Simonyan, and Yiming Yang. DARTS: Differentiable architecture search. arXiv preprint
arXiv:1806.09055, 2018.
[314] Kang Liu, Brendan Dolan-Gavitt, and Siddharth Garg. Fine-pruning: Defending against backdooring attacks
on deep neural networks. In International Symposium on Research in Attacks, Intrusions, and Defenses, pages
273–294. Springer, 2018.
[315] Xiyang Liu and Sewoong Oh. Minimax rates of estimating approximate differential privacy. arXiv preprint
arXiv:1905.10335, 2019.
[316] Yang Liu, Yan Kang, Xinwei Zhang, Liping Li, Yong Cheng, Tianjian Chen, Mingyi Hong, and Qiang Yang.
A communication efficient vertical federated learning framework. CoRR, abs/1912.11187, 2019. URL http:
//arxiv.org/abs/1912.11187.
[317] Yang Liu, Yan Kang, Chaoping Xing, Tianjian Chen, and Qiang Yang. A secure federated transfer learning
framework. IEEE Intelligent Systems, 35(4):70–82, 2020. doi: 10.1109/MIS.2020.2988525.
[318] Yang Liu, Zhihao Yi, and Tianjian Chen. Backdoor attacks and defenses in feature-partitioned collaborative
learning, 2020.
[319] Yingqi Liu, Shiqing Ma, Yousra Aafer, Wen-Chuan Lee, Juan Zhai, Weihang Wang, and Xiangyu Zhang. Trojaning attack on neural networks. In 25th Annual Network and Distributed System Security Symposium, NDSS
2018, San Diego, California, USA, February 18-21, 2018, 2018. URL http://wp.internetsociety.
org/ndss/wp-content/uploads/sites/25/2018/02/ndss2018_03A-5_Liu_paper.pdf.
[320] Yuhan Liu, Ananda Theertha Suresh, Felix Xinnan X Yu, Sanjiv Kumar, and Michael Riley. Learning discrete
distributions: user vs item-level privacy. Advances in Neural Information Processing Systems, 33, 2020.
[321] Heiko Ludwig, Nathalie Baracaldo, Gegi Thomas, Yi Zhou, Ali Anwar, Shashank Rajamoni, Yuya Ong, Jayaram Radhakrishnan, Ashish Verma, Mathieu Sinn, et al. IBM federated learning: An enterprise framework
white paper V0.1. arXiv preprint arXiv:2007.10987, 2020.
[322] Jiahuan Luo, Xueyang Wu, Yun Luo, Anbu Huang, Yunfeng Huang, Yang Liu, and Qiang Yang. Real-world
image datasets for federated learning. arXiv preprint arXiv:1910.11089, 2019.
[323] Renqian Luo, Fei Tian, Tao Qin, Enhong Chen, and Tie-Yan Liu. Neural architecture optimization. In Advances
in neural information processing systems, pages 7816–7827, 2018.
[324] Lingjuan Lyu, Jiangshan Yu, Karthik Nandakumar, Yitong Li, Xingjun Ma, Jiong Jin, Han Yu, and Kee Siong
Ng. Towards fair and privacy-preserving federated deep models. IEEE Transactions on Parallel and Distributed
Systems, 31(11):2524–2541, 2020.
[325] Jing Ma, Qiuchen Zhang, Jian Lou, Joyce Ho, Li Xiong, and Xiaoqian Jiang. Privacy-preserving tensor factorization for collaborative health data analysis. In ACM CIKM, volume 2, 2019.
[326] Yuzhe Ma, Xiaojin Zhu, and Justin Hsu. Data poisoning against differentially-private learners: Attacks and
defenses. In International Joint Conference on Artificial Intelligence (IJCAI), Macao, China, 2019. URL
https://arxiv.org/abs/1903.09860.
[327] David Madras, Elliot Creager, Toniann Pitassi, and Richard Zemel. Learning adversarially fair and transferable
representations. In ICML, 2018.

108

[328] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep
learning models resistant to adversarial attacks. ICLR, 2017.
[329] Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Domain adaptation: Learning bounds and algorithms. arXiv preprint arXiv:0902.3430, 2009.
[330] Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Domain adaptation with multiple sources. In
Advances in neural information processing systems, pages 1041–1048, 2009.
[331] Yishay Mansour, Mehryar Mohri, Jae Ro, and Ananda Theertha Suresh. Three approaches for personalization
with applications to federated learning. arXiv preprint arXiv:2002.10619, 2020.
[332] Yishay Mansour, Mehryar Mohri, Ananda Theertha Suresh, and Ke Wu. A theory of multiple-source adaptation
with limited target labeled data. arXiv preprint arXiv:2007.09762, 2020.
[333] Alicia R Martin, Masahiro Kanai, Yoichiro Kamatani, Yukinori Okada, Benjamin M Neale, and Mark J Daly.
Current clinical use of polygenic scores will risk exacerbating health disparities. BioRxiv, page 441261, 2019.
[334] H Brendan McMahan and Daniel Ramage.
Federated learning: Collaborative machine learning
without centralized training data, April 2017. URL https://ai.googleblog.com/2017/04/
federated-learning-collaborative.html. Google AI Blog.
[335] H Brendan McMahan and Matthew Streeter. Adaptive bound optimization for online convex optimization.
arXiv preprint arXiv:1002.4908, 2010.
[336] H Brendan McMahan, Galen Andrew, Ulfar Erlingsson, Steve Chien, Ilya Mironov, Nicolas Papernot, and
Peter Kairouz. A general approach to adding differential privacy to iterative training procedures. dec 2018.
URL https://arxiv. org/abs, 1812.
[337] H Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, pages 1273–1282, 2017 (original version on
arxiv Feb. 2016).
[338] H Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li Zhang. Learning differentially private recurrent
language models. In International Conference on Learning Representations (ICLR), 2018.
[339] Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In FOCS, pages 94–103, 2007.
[340] Shike Mei and Xiaojin Zhu. Using machine teaching to identify optimal training-set attacks on machine learners. In Twenty-Ninth AAAI Conference on Artificial Intelligence, 2015.
[341] Luca Melis, Congzheng Song, Emiliano De Cristofaro, and Vitaly Shmatikov. Exploiting unintended feature
leakage in collaborative learning. arXiv preprint arXiv:1805.04049, 2018.
[342] El Mahdi El Mhamdi, Rachid Guerraoui, and Sébastien Rouault. The hidden vulnerability of distributed learning in Byzantium. In ICML, 2018.
[343] Silvio Micali. Computationally sound proofs. SIAM J. Comput., 30(4):1253–1298, 2000.
[344] Fatemehsadat Mireshghallah, Mohammadkazem Taram, , Praneeth Vepakomma, Abhishek Singh, Ramesh
Raskar, and Esmaeilzadeh Hadi. Privacy in deep learning: A survey. arXiv preprint arXiv:2004.12254, 2020.
[345] Ilya Mironov. On significance of the least significant bits for differential privacy. In Proceedings of the 2012
ACM conference on Computer and communications security, pages 650–661. ACM, 2012.
[346] Ilya Mironov. Rényi differential privacy. In 2017 IEEE 30th Computer Security Foundations Symposium (CSF),
pages 263–275. IEEE, 2017.

109

[347] Ilya Mironov, Omkant Pandey, Omer Reingold, and Salil Vadhan. Computational differential privacy. In
Advances in Cryptology—CRYPTO, pages 126–142, 2009.
[348] Ilya Mironov, Kunal Talwar, and Li Zhang. R\’enyi differential privacy of the sampled Gaussian mechanism.
arXiv preprint arXiv:1908.10530, 2019.
[349] Shira Mitchell, Eric Potash, and Solon Barocas. Prediction-based decisions and fairness: A catalogue of
choices, assumptions, and definitions. arXiv preprint arXiv:1811.07867, 2018.
[350] Volodymyr Mnih and Geoffrey E Hinton. Learning to label aerial images from noisy data. In Proceedings of
the 29th International conference on machine learning (ICML-12), pages 567–574, 2012.
[351] Payman Mohassel and Yupeng Zhang. SecureML: A system for scalable privacy-preserving machine learning.
In IEEE Symposium on Security and Privacy, pages 19–38. IEEE Computer Society, 2017.
[352] Mehryar Mohri, Gary Sivek, and Ananda Theertha Suresh. Agnostic Federated Learning. In ICML, 2019.
[353] Jose G. Moreno-Torres, Troy Raeder, Rocı́O Alaiz-Rodrı́Guez, Nitesh V. Chawla, and Francisco Herrera. A
unifying view on dataset shift in classification. Pattern Recogn., 45(1), January 2012.
[354] Musketeer. Musketeer: About, 2019. URL http://musketeer.eu/project/. Retrieved Aug 2019.
[355] Carolina Naim, Fangwei Ye, and Salim El Rouayheb. ON-OFF privacy with correlated requests. In 2019 IEEE
International Symposium on Information Theory (ISIT), July 2019.
[356] Nagarajan Natarajan, Inderjit S Dhillon, Pradeep K Ravikumar, and Ambuj Tewari. Learning with noisy labels.
In Advances in neural information processing systems, pages 1196–1204, 2013.
[357] Giovanni Neglia, Chuan Xu, Don Towsley, and Gianmarco Calbi. Decentralized gradient methods: does topology matter? In AISTATS, 2020.
[358] Alex Nichol, Joshua Achiam, and John Schulman. On first-order meta-learning algorithms. arXiv preprint
arXiv:1803.02999, 2018.
[359] Valeria Nikolaenko, Udi Weinsberg, Stratis Ioannidis, Marc Joye, Dan Boneh, and Nina Taft. Privacypreserving ridge regression on hundreds of millions of records. In IEEE Symposium on Security and Privacy,
pages 334–348. IEEE Computer Society, 2013.
[360] Chaoyue Niu, Fan Wu, Shaojie Tang, Lifeng Hua, Rongfei Jia, Chengfei Lv, Zhihua Wu, and Guihai Chen.
Secure federated submodel learning. arXiv preprint arXiv:1911.02254, 2019.
[361] NSA. Defense in depth: A practical strategy for achieving Information Assurance in today’s highly networked
environments. Technical report, NSA, 2012.
[362] Deniz Oktay, Johannes Ballé, Saurabh Singh, and Abhinav Shrivastava. Model compression by entropy penalized reparameterization. arXiv preprint arXiv:1906.06624, 2019.
[363] Femi Olumofin and Ian Goldberg. Revisiting the computational practicality of private information retrieval. In
International Conference on Financial Cryptography and Data Security, pages 158–172. Springer, 2011.
[364] Palisade.
PALISADE lattice cryptography
palisade-release, October 2019.

library.

https://gitlab.com/palisade/

[365] Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Transactions on Knowledge and Data
Engineering, 22(10):1345–1359, 2010.
[366] Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z Berkay Celik, and Ananthram Swami.
Practical black-box attacks against machine learning. In Proceedings of the 2017 ACM on Asia conference on
computer and communications security, pages 506–519. ACM, 2017.

110

[367] Nicolas Papernot, Abhradeep Thakurta, Shuang Song, Steve Chien, and Úlfar Erlingsson. Tempered sigmoid
activations for deep learning with differential privacy. arXiv preprint arXiv:2007.14191, 2020.
[368] Jihong Park, Sumudu Samarakoon, Mehdi Bennis, and Mérouane Debbah. Wireless network intelligence at the
edge. CoRR, abs/1812.02858, 2018. URL http://arxiv.org/abs/1812.02858.
[369] Bryan Parno, Jon Howell, Craig Gentry, and Mariana Raykova. Pinocchio: nearly practical verifiable computation. Commun. ACM, 59(2):103–112, 2016.
[370] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan,
Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf,
Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit
Steiner, Lu Fang, Junjie Bai, and Soumith Chintala.
Pytorch: An imperative style, highperformance deep learning library.
In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'AlchéBuc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32,
pages 8024–8035. Curran Associates, Inc., 2019. URL http://papers.neurips.cc/paper/
9015-pytorch-an-imperative-style-high-performance-deep-learning-library.
pdf.
[371] Kumar Kshitij Patel and Aymeric Dieuleveut. Communication trade-offs for synchronized distributed SGD
with large step size. NeurIPS, 2019.
[372] Sarvar Patel, Giuseppe Persiano, and Kevin Yeo. Private stateful information retrieval. In Proceedings of
the 2018 ACM SIGSAC Conference on Computer and Communications Security, CCS ’18, pages 1002–1019,
New York, NY, USA, 2018. ACM. ISBN 978-1-4503-5693-0. doi: 10.1145/3243734.3243821. URL http:
//doi.acm.org/10.1145/3243734.3243821.
[373] Giorgio Patrini, Richard Nock, Stephen Hardy, and Tibério S. Caetano. Fast learning from distributed
datasets without entity matching. In Proceedings of the Twenty-Fifth International Joint Conference on
Artificial Intelligence, IJCAI 2016, New York, NY, USA, 9-15 July 2016, pages 1909–1917, 2016. URL
http://www.ijcai.org/Abstract/16/273.
[374] Fabian Pedregosa. Hyperparameter optimization with approximate gradient. arXiv preprint arXiv:1602.02355,
2016.
[375] Hieu Pham, Melody Guan, Barret Zoph, Quoc Le, and Jeff Dean. Efficient neural architecture search via
parameter sharing. In International Conference on Machine Learning, pages 4092–4101, 2018.
[376] Sundar Pichai. Google’s Sundar Pichai: Privacy Should Not Be a Luxury Good. New York Times, May 7, 2019.
[377] Venkatadheeraj Pichapati, Ananda Theertha Suresh, Felix X Yu, Sashank J Reddi, and Sanjiv Kumar. AdaCliP:
Adaptive clipping for private SGD. arXiv preprint arXiv:1908.07643, 2019.
[378] Vasyl Pihur, Aleksandra Korolova, Frederick Liu, Subhash Sankuratripati, Moti Yung, Dachuan Huang, and
Ruogu Zeng. Differentially-private “Draw and Discard” machine learning. CoRR, abs/1807.04369, 2018. URL
http://arxiv.org/abs/1807.04369.
[379] Krishna Pillutla, Sham M Kakade, and Zaid Harchaoui. Robust aggregation for federated learning. arXiv
preprint arXiv:1912.13445, 2019.
[380] Joaquin Quionero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D. Lawrence. Dataset Shift in
Machine Learning. The MIT Press, 2009. ISBN 0262170051, 9780262170055.
[381] Shashank Rajput, Hongyi Wang, Zachary Charles, and Dimitris Papailiopoulos. DETOX: A redundancy-based
framework for faster and more robust gradient aggregation. arXiv preprint arXiv:1907.12205, 2019.
[382] Daniel Ramage and Stefano Mazzocchi.
Federated analytics:
Collaborative data science
without data collection, May 2020.
URL https://ai.googleblog.com/2020/05/
federated-analytics-collaborative-data.html. Google AI Blog.

111

[383] Swaroop Ramaswamy, Rajiv Mathews, Kanishka Rao, and Françoise Beaufays. Federated learning for emoji
prediction in a mobile keyboard. arXiv preprint 1906.04329, 2019.
[384] Swaroop Ramaswamy, Om Thakkar, Rajiv Mathews, Galen Andrew, H Brendan McMahan, and Françoise Beaufays. Training production language models without memorizing user data. arXiv preprint arXiv:2009.10031,
2020.
[385] Vibhor Rastogi and Suman Nath. Differentially private aggregation of distributed time-series with transformation and encryption. In Proceedings of the 2010 ACM SIGMOD International Conference on Management
of Data, SIGMOD ’10, pages 735–746, New York, NY, USA, 2010. ACM. ISBN 978-1-4503-0032-2. doi:
10.1145/1807167.1807247. URL http://doi.acm.org/10.1145/1807167.1807247.
[386] Sachin Ravi and Hugo Larochelle. Optimization as a model for few-shot learning. In Proceedings of the 5th
International Conference on Learning Representations, 2017.
[387] Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu, Jie Tan, Quoc V Le, and
Alexey Kurakin. Large-scale evolution of image classifiers. In Proceedings of the 34th International Conference
on Machine Learning-Volume 70, pages 2902–2911. JMLR. org, 2017.
[388] Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc V Le. Regularized evolution for image classifier
architecture search. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 4780–
4789, 2019.
[389] Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Konečnỳ, Sanjiv Kumar,
and H Brendan McMahan. Adaptive federated optimization. arXiv preprint arXiv:2003.00295, 2020.
[390] Amirhossein Reisizadeh, Aryan Mokhtari, Hamed Hassani, Ali Jadbabaie, and Ramtin Pedarsani. Fedpaq: A
communication-efficient federated learning method with periodic averaging and quantization. arXiv preprint
arXiv:1909.13014, 2019.
[391] Amirhossein Reisizadeh, Hossein Taheri, Aryan Mokhtari, Hamed Hassani, and Ramtin Pedarsani. Robust and
communication-efficient collaborative learning. arXiv:1907.10595, 2019.
[392] Leonid Reyzin, Adam D. Smith, and Sophia Yakoubov. Turning HATE into LOVE: homomorphic ad hoc
threshold encryption for scalable MPC. IACR Cryptology ePrint Archive, 2018:997, 2018.
[393] M Sadegh Riazi, Kim Laine, Blake Pelton, and Wei Dai. HEAX: High-performance architecture for computation on homomorphically encrypted data in the cloud. arXiv preprint arXiv:1909.09731, 2019.
[394] Rashida Richardson, Jason Schultz, and Kate Crawford. Dirty data, bad predictions: How civil rights violations impact police data, predictive policing systems, and justice. New York University Law Review Online,
Forthcoming, 2019.
[395] Brian D Ripley. Statistical aspects of neural networks. Networks and chaos—statistical and probabilistic
aspects, 50:40–123, 1993.
[396] Ronald L Rivest, Len Adleman, and Michael L Dertouzos. On data banks and privacy homomorphisms. Foundations of Secure Computation, Academia Press, pages 169–179, 1978.
[397] Nuria Rodrı́guez-Barroso, Goran Stipcich, Daniel Jiménez-López, José Antonio Ruiz-Millán, Eugenio
Martı́nez-Cámara, Gerardo González-Seco, M Victoria Luzón, Miguel Angel Veganzones, and Francisco Herrera. Federated learning and differential privacy: Software tools analysis, the sherpa. ai fl framework and
methodological guidelines for preserving data privacy. Information Fusion, 64:270–292, 2020.
[398] Edo Roth, Daniel Noble, Brett Hemenway Falk, and Andreas Haeberlen. Honeycrisp: large-scale differentially
private aggregation without a trusted core. In SOSP, pages 196–210. ACM, 2019.
[399] Theo Ryffel, Andrew Trask, Morten Dahl, Bobby Wagner, Jason Mancuso, Daniel Rueckert, and Jonathan
Passerat-Palmbach. A generic framework for privacy preserving deep learning, 2018.

112

[400] César Sabater, Aurélien Bellet, and Jan Ramon. Distributed Differentially Private Averaging with Improved
Utility and Robustness to Malicious Parties. arXiv preprint arXiv:2006.07218, 2020.
[401] John K Salmon, Mark A Moraes, Ron O Dror, and David E Shaw. Parallel random numbers: As easy as 1, 2, 3.
In Proceedings of 2011 International Conference for High Performance Computing, Networking, Storage and
Analysis, page 16. ACM, 2011.
[402] Sumudu Samarakoon, Mehdi Bennis, Walid Saad, and Mérouane Debbah. Federated learning for ultra-reliable
low-latency V2V communications. CoRR, abs/1805.09253, 2018. URL http://arxiv.org/abs/1805.
09253.
[403] Nithya Sambasivan, Garen Checkley, Amna Batool, Nova Ahmed, David Nemer, Laura Sanely Gaytán-Lugo,
Tara Matthews, Sunny Consolvo, and Elizabeth Churchill. ” privacy is not for me, it’s for those rich women”:
Performative privacy practices on mobile phones by women in south asia. In Fourteenth Symposium on Usable
Privacy and Security ({SOUPS} 2018), pages 127–142, 2018.
[404] Sai Sri Sathya, Praneeth Vepakomma, Ramesh Raskar, Ranjan Ramachandra, and Santanu Bhattacharya. A
review of homomorphic encryption libraries for secure computation. arXiv preprint arXiv:1812.02428, 2018.
[405] Felix Sattler, Simon Wiedemann, Klaus-Robert Müller, and Wojciech Samek. Robust and communicationefficient federated learning from non-IID data. arXiv preprint arXiv:1903.02891, 2019.
[406] R. Schnell. Efficient private record linkage of very large datasets. In 59th World Statistics Congress, 2013.
[407] R. Schnell, T. Bachteler, and J. Reiher. A novel error-tolerant anonymous linking code. Technical report, Paper
No. WP-GRLC-2011-02, German Record Linkage Center Working Paper Series, 2011.
[408] Claus P. Schnorr. Efficient identification and signatures for smart cards. In Proceedings of the Workshop on the
Theory and Application of Cryptographic Techniques on Advances in Cryptology, EUROCRYPT ’89, 1990.
[409] SEAL. Microsoft SEAL (release 3.6). https://github.com/Microsoft/SEAL, November 2020.
Microsoft Research, Redmond, WA.
[410] Frank Seide and Amit Agarwal. Cntk: Microsoft’s open-source deep-learning toolkit. In Proceedings of the
22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’16, page
2135, New York, NY, USA, 2016. Association for Computing Machinery. ISBN 9781450342322. doi: 10.
1145/2939672.2945397. URL https://doi.org/10.1145/2939672.2945397.
[411] Arvind Seshadri, Mark Luk, Adrian Perrig, Leendert van Doom, and Pradeep K. Khosla. Pioneer: Verifying
code integrity and enforcing untampered code execution on legacy systems. In Malware Detection, volume 27
of Advances in Information Security, pages 253–289. Springer, 2007.
[412] Ali Shafahi, Mahyar Najibi, Amin Ghiasi, Zheng Xu, John Dickerson, Christoph Studer, Larry S Davis, Gavin
Taylor, and Tom Goldstein. Adversarial training for free. NeurIPS, 2019.
[413] Vivek Sharma, Praneeth Vepakomma, Tristan Swedish, Ken Chang, Jayashree Kalpathy-Cramer, and Ramesh
Raskar. ExpertMatcher: Automating ML model selection for clients using hidden representations. arXiv
preprint arXiv:1910.03731, 2019.
[414] Yash Sharma and Pin-Yu Chen. Attacking the Madry defense model with l 1-based adversarial examples. arXiv
preprint arXiv:1710.10733, 2017.
[415] SHELL. https://github.com/google/shell-encryption, December 2020. Google.
[416] Yanyao Shen and Sujay Sanghavi. Learning with bad training data via iterative trimmed loss minimization. In
Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings of the 36th International Conference on
Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 5739–5748, Long Beach,
California, USA, 09–15 Jun 2019. PMLR. URL http://proceedings.mlr.press/v97/shen19e.
html.

113

[417] Elaine Shi, HTH Chan, Eleanor Rieffel, Richard Chow, and Dawn Song. Privacy-preserving aggregation of
time-series data. In Annual Network & Distributed System Security Symposium (NDSS), 2011.
[418] Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. Membership inference attacks against
machine learning models. In 2017 IEEE Symposium on Security and Privacy (SP), pages 3–18. IEEE, 2017.
[419] Kumar Shridhar, Felix Laumann, and Marcus Liwicki. A comprehensive guide to Bayesian convolutional neural
network with variational inference. arXiv preprint: 1901.02731, 2019.
[420] Daniel L. Silver, Qiang Yang, and Lianghao Li. Lifelong machine learning systems: Beyond learning algorithms. In AAAI Spring Symposium Series, 2013.
[421] Abhishek Singh, Praneeth Vepakomma, Otkrist Gupta, and Ramesh Raskar. Detailed comparison of communication efficiency of split learning and federated learning. arXiv preprint arXiv:1909.09145, 2019.
[422] Abhishek Singh, Ayush Chopra, Vivek Sharma, Ethan Garza, Emily Zhang, Praneeth Vepakomma, and Ramesh
Raskar. DISCO: Dynamic and invariant sensitive channel obfuscation for deep neural networks. 2020.
[423] Radu Sion and Bogdan Carbunar. On the computational practicality of private information retrieval. In Proceedings of the Network and Distributed Systems Security Symposium, pages 2006–06. Internet Society, 2007.
[424] Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet S. Talwalkar. Federated Multi-Task Learning. In
NIPS, 2017.
[425] Jake Snell, Kevin Swersky, and Richard S. Zemel. Prototypical networks for few-shot learning. In Advances in
Neural Information Processing Systems, 2017.
[426] Jasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Nadathur Satish, Narayanan Sundaram, Mostofa Patwary, Mr Prabhat, and Ryan Adams. Scalable Bayesian optimization using deep neural networks. In International conference on machine learning, pages 2171–2180, 2015.
[427] Jinhyun So, Basak Guler, and A. Salman Avestimehr. Byzantine-resilient secure federated learning. IEEE
Journal on Selected Areas in Communication, Series on Machine Learning for Communications and Networks,
2020.
[428] Jinhyun So, Basak Guler, and A Salman Avestimehr. Turbo-aggregate: Breaking the quadratic aggregation
barrier in secure federated learning. arXiv preprint arXiv:2002.04156, 2020.
[429] Liwei Song, Reza Shokri, and Prateek Mittal. Privacy risks of securing machine learning models against
adversarial examples. In In Proceedings of the ACM Conference on Computer and Communication Security
(CCS), 2019.
[430] K Srinathan and C Pandu Rangan. Efficient asynchronous secure multiparty distributed computation. In International Conference on Cryptology in India, pages 117–129. Springer, 2000.
[431] Brij Mohan Lal Srivastava, Aurélien Bellet, Marc Tommasi, and Emmanuel Vincent. Privacy-Preserving Adversarial Representation Learning in ASR: Reality or Illusion? In Annual Conference of the International
Speech Communication Association (Interspeech), 2019.
[432] Jacob Steinhardt, Pang Wei W Koh, and Percy S Liang. Certified defenses for data poisoning attacks. In
Advances in neural information processing systems, pages 3517–3529, 2017.
[433] Thomas Steinke and Jonathan Ullman. Tight lower bounds for differentially private selection. In FOCS, pages
552–563, 2017.
[434] Sebastian U Stich. Local SGD converges fast and communicates little. In International Conference on Learning
Representations (ICLR), 2019.

114

[435] Sebastian U Stich and Sai Praneeth Karimireddy. The error-feedback framework: Better rates for SGD with
delayed gradients and compressed communication. arXiv:1909.05350, 2019.
[436] Lili Su and Nitin H. Vaidya. Fault-Tolerant Multi-Agent Optimization: Optimal Iterative Distributed Algorithms. In PODC, 2016.
[437] Pramod Subramanyan, Rohit Sinha, Ilia Lebedev, Srinivas Devadas, and Sanjit A Seshia. A formal foundation
for secure remote execution of enclaves. In Proceedings of the 2017 ACM SIGSAC Conference on Computer
and Communications Security, pages 2435–2450. ACM, 2017.
[438] Ziteng Sun, Peter Kairouz, Ananda Theertha Suresh, and H Brendan McMahan. Can you really backdoor
federated learning? arXiv preprint arXiv:1911.07963, 2019.
[439] support.google. Your chats stay private while Messages improves suggestions, 2019. URL https://
support.google.com/messages/answer/9327902. Retrieved Aug 2019.
[440] Ananda Theertha Suresh, Felix X. Yu, Sanjiv Kumar, and H Brendan McMahan. Distributed mean estimation
with limited communication. In Proceedings of the 34th International Conference on Machine Learning-Volume
70, pages 3329–3337. JMLR. org, 2017.
[441] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob
Fergus. Intriguing properties of neural networks. ICLR, 2013.
[442] Gábor J Székely, Maria L Rizzo, Nail K Bakirov, et al. Measuring and testing dependence by correlation of
distances. The annals of statistics, 35(6):2769–2794, 2007.
[443] Hanlin Tang, Xiangru Lian, Ming Yan, Ce Zhang, and Ji Liu. D2: Decentralized training over decentralized
data. In ICML, 2018.
[444] Hanlin Tang, Xiangru Lian, Shuang Qiu, Lei Yuan, Ce Zhang, Tong Zhang, and Ji Liu. DeepSqueeze:
Parallel stochastic gradient descent with double-pass error-compensated compression. arXiv preprint
arXiv:1907.07346, 2019.
[445] Jun Tang, Aleksandra Korolova, Xiaolong Bai, Xueqiang Wang, and XiaoFeng Wang. Privacy loss in Apple’s implementation of differential privacy on MacOS 10.12. CoRR, abs/1709.02753, 2017. URL http:
//arxiv.org/abs/1709.02753.
[446] Om Thakkar, Galen Andrew, and H Brendan McMahan. Differentially private learning with adaptive clipping.
arXiv preprint arXiv:1905.03871, 2019.
[447] Florian Tramèr and Dan Boneh. Slalom: Fast, verifiable and private execution of neural networks in trusted
hardware. In International Conference on Learning Representations, 2019. URL https://openreview.
net/forum?id=rJVorjCcKQ.
[448] Florian Tramèr and Dan Boneh. Adversarial training and robustness for multiple perturbations. arXiv preprint
arXiv:1904.13000, 2019.
[449] Florian Tramèr and Dan Boneh. Differentially private learning needs better features (or much more data). arXiv
preprint arXiv:2011.11660, 2020.
[450] Florian Tramèr, Fan Zhang, Ari Juels, Michael K. Reiter, and Thomas Ristenpart. Stealing machine learning models via prediction APIs. In 25th USENIX Security Symposium, USENIX Security 16, Austin, TX,
USA, August 10-12, 2016., pages 601–618, 2016. URL https://www.usenix.org/conference/
usenixsecurity16/technical-sessions/presentation/tramer.
[451] Florian Tramèr, Fan Zhang, Huang Lin, Jean-Pierre Hubaux, Ari Juels, and Elaine Shi. Sealed-glass proofs:
Using transparent enclaves to prove and sell knowledge. In 2017 IEEE European Symposium on Security and
Privacy, EuroS&P 2017, Paris, France, April 26-28, 2017, pages 19–34, 2017.

115

[452] Florian Tramèr, Alexey Kurakin, Nicolas Papernot, Ian J. Goodfellow, Dan Boneh, and Patrick D. McDaniel.
Ensemble adversarial training: Attacks and defenses. In 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings, 2018.
[453] Florian Tramèr, Jens Behrmann, Nicholas Carlini, Nicolas Papernot, and Jörn-Henrik Jacobsen. Fundamental
tradeoffs between invariance and sensitivity to adversarial perturbations. In Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, volume 119 of Proceedings of Machine Learning Research, pages 9561–9571. PMLR, 2020. URL http://proceedings.mlr.
press/v119/tramer20a.html.
[454] Brandon Tran, Jerry Li, and Aleksander Madry. Spectral signatures in backdoor attacks. In Advances in Neural
Information Processing Systems, pages 8000–8010, 2018.
[455] Jonathan Ullman. Tight lower bounds for locally differentially private selection.
abs/1802.02638, arXiv, 2018. URL http://arxiv.org/abs/1802.02638.

Technical Report

[456] The Google-Landmark v2 Authors. Google landmark dataset v2, 2019. URL https://github.com/
cvdfoundation/google-landmark.
[457] Jaideep Vaidya, Hwanjo Yu, and Xiaoqian Jiang. Privacy-preserving SVM classification. Knowl. Inf. Syst., 14
(2), January 2008.
[458] Jo Van Bulck, Marina Minkin, Ofir Weisse, Daniel Genkin, Baris Kasikci, Frank Piessens, Mark Silberstein,
Thomas F Wenisch, Yuval Yarom, and Raoul Strackx. Foreshadow: Extracting the keys to the intel {SGX}
kingdom with transient out-of-order execution. In 27th {USENIX} Security Symposium ({USENIX} Security
18), pages 991–1008, 2018.
[459] Paul Vanhaesebrouck, Aurélien Bellet, and Marc Tommasi. Decentralized collaborative learning of personalized
models over networks. In AISTATS, 2017.
[460] Praneeth Vepakomma, Otkrist Gupta, Tristan Swedish, and Ramesh Raskar. Split learning for health: Distributed deep learning without sharing raw patient data. arXiv preprint arXiv:1812.00564, 2018.
[461] Praneeth Vepakomma, Chetan Tonde, Ahmed Elgammal, et al. Supervised dimensionality reduction via distance correlation maximization. Electronic Journal of Statistics, 12(1):960–984, 2018.
[462] Praneeth Vepakomma, Otkrist Singh, Abhishek Gupta, and Ramesh Raskar. Nopeek: Information leakage
reduction to share activations in distributed deep learning. arXiv preprint arXiv:2008.09161, 2020.
[463] Thijs Vogels, Sai Praneeth Karimireddy, and Martin Jaggi. PowerSGD: Practical low-rank gradient compression
for distributed optimization. In NeurIPS 2019 - Advances in Neural Information Processing Systems 32, 2019.
[464] Riad S. Wahby, Ioanna Tzialla, Abhi Shelat, Justin Thaler, and Michael Walfish. Doubly-efficient zksnarks
without trusted setup. In 2018 IEEE Symposium on Security and Privacy, SP 2018, Proceedings, 21-23 May
2018, San Francisco, California, USA, 2018.
[465] Bolun Wang, Yuanshun Yao, Shawn Shan, Huiying Li, Bimal Viswanath, Haitao Zheng, and Ben Y Zhao.
Neural cleanse: Identifying and mitigating backdoor attacks in neural networks. In 2019 IEEE Symposium on
Security and Privacy. IEEE, 2019.
[466] Hongyi Wang, Kartik Sreenivasan, Shashank Rajput, Harit Vishwakarma, Saurabh Agarwal, Jy yong Sohn,
Kangwook Lee, and Dimitris Papailiopoulos. Attack of the tails: Yes, you really can backdoor federated
learning, 2020.
[467] Jianyu Wang and Gauri Joshi. Cooperative SGD: A unified framework for the design and analysis of
communication-efficient SGD algorithms. preprint, August 2018. URL https://arxiv.org/abs/
1808.07576.

116

[468] Jianyu Wang and Gauri Joshi. Adaptive Communication Strategies for Best Error-Runtime Trade-offs in
Communication-Efficient Distributed SGD. In Proceedings of the SysML Conference, April 2019. URL
https://arxiv.org/abs/1810.08313.
[469] Jianyu Wang, Anit Sahu, Gauri Joshi, and Soummya Kar. MATCHA: Speeding Up Decentralized SGD
via Matching Decomposition Sampling. preprint, May 2019. URL https://arxiv.org/abs/1905.
09435.
[470] Jianyu Wang, Vinayak Tantia, Nicolas Ballas, and Michael Rabbat. SlowMo: Improving communicationefficient distributed SGD with slow momentum. arXiv preprint arXiv:1910.00643, 2019.
[471] Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H Vincent Poor. Tackling the objective inconsistency
problem in heterogeneous federated optimization. Advances in Neural Information Processing Systems, 33,
2020.
[472] Kangkang Wang, Rajiv Mathews, Chloé Kiddon, Hubert Eichner, Françoise Beaufays, and Daniel Ramage.
Federated evaluation of on-device personalization. arXiv preprint arXiv:1910.10252, 2019.
[473] Tongzhou Wang, Jun-Yan Zhu, Antonio Torralba, and Alexei A Efros. Dataset distillation. arXiv preprint
arXiv:1811.10959, 2018.
[474] Yu-Xiang Wang, Borja Balle, and Shiva Kasiviswanathan. Subsampled R\’enyi differential privacy and analytical moments accountant. arXiv preprint arXiv:1808.00087, 2018.
[475] Stanley L. Warner. Randomized response: A survey technique for eliminating evasive answer bias. Journal of
the American Statistical Association, 60(309):63–69, 1965.
[476] WeBank. WeBank and Swiss re signed cooperation MOU, 2019. URL https://finance.yahoo.com/
news/webank-swiss-signed-cooperation-mou-112300218.html. Retrieved Aug 2019.
[477] Eric Wong, Frank R Schmidt, and J Zico Kolter. Wasserstein adversarial examples via projected sinkhorn
iterations. ICML, 2019.
[478] Gavin Wood et al. Ethereum: A secure decentralised generalised transaction ledger. Ethereum project yellow
paper, 151(2014):1–32, 2014.
[479] D. Woodruff and S. Yekhanin. A geometric approach to information-theoretic private information retrieval.
In 20th Annual IEEE Conference on Computational Complexity (CCC’05), pages 275–284, June 2005. doi:
10.1109/CCC.2005.2.
[480] Blake Woodworth, Jialei Wang, H. Brendan McMahan, and Nathan Srebro. Graph oracle models, lower bounds,
and gaps for parallel stochastic optimization. In Advances in Neural Information Processing Systems (NIPS),
2018. URL https://arxiv.org/abs/1805.10222.
[481] Blake Woodworth, Kumar Kshitij Patel, Sebastian U Stich, Zhen Dai, Brian Bullins, H Brendan McMahan,
Ohad Shamir, and Nathan Srebro. Is local sgd better than minibatch sgd? arXiv preprint arXiv:2002.07839,
2020.
[482] Xiang Wu, Ruiqi Guo, Ananda Theertha Suresh, Sanjiv Kumar, Daniel N Holtmann-Rice, David Simcha, and
Felix X. Yu. Multiscale quantization for fast similarity search. In Advances in Neural Information Processing
Systems, pages 5745–5755, 2017.
[483] Cihang Xie, Yuxin Wu, Laurens van der Maaten, Alan Yuille, and Kaiming He. Feature denoising for improving
adversarial robustness. CVPR, 2019.
[484] Cong Xie. Zeno++: robust asynchronous SGD with arbitrary number of Byzantine workers. arXiv preprint
arXiv:1903.07020, 2019.

117

[485] Cong Xie, Oluwasanmi Koyejo, Indranil Gupta, and Haibin Lin. Local adaalter: Communication-efficient
stochastic gradient descent with adaptive learning rates. arXiv preprint arXiv:1911.09030, 2019.
[486] Cong Xie, Sanmi Koyejo, and Indranil Gupta. Practical distributed learning: Secure machine learning with
communication-efficient local updates. In European Conference on Machine Learning and Principles and
Practice of Knowledge Discovery in Databases (ECML PKDD), 2019.
[487] Cong Xie, Sanmi Koyejo, and Indranil Gupta. Zeno: Distributed stochastic gradient descent with suspicionbased fault-tolerance. In International Conference on Machine Learning, pages 6893–6901, 2019.
[488] Sirui Xie, Hehui Zheng, Chunxiao Liu, and Liang Lin. SNAS: stochastic neural architecture search. arXiv
preprint arXiv:1812.09926, 2018.
[489] Tiancheng Xie, Jiaheng Zhang, Yupeng Zhang, Charalampos Papamanthou, and Dawn Song. Libra: Succinct
zero-knowledge proofs with optimal prover computation. In CRYPTO (3), volume 11694 of Lecture Notes in
Computer Science, pages 733–764. Springer, 2019.
[490] Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. Federated machine learning: Concept and applications. CoRR, abs/1902.04885, 2019. URL http://arxiv.org/abs/1902.04885.
[491] Timothy Yang, Galen Andrew, Hubert Eichner, Haicheng Sun, Wei Li, Nicholas Kong, Daniel Ramage, and
Françoise Beaufays. Applied federated learning: Improving Google keyboard query suggestions. arXiv preprint
1812.02903, 2018.
[492] Andrew C Yao. Protocols for secure computations. In Symposium on Foundations of Computer Science, 1982.
[493] Andrew Chi-Chih Yao. How to generate and exchange secrets (extended abstract). In FOCS, pages 162–167.
IEEE Computer Society, 1986.
[494] Fangwei Ye, Carolina Naim, and Salim El Rouayheb. Preserving ON-OFF privacy for past and future requests.
In 2019 IEEE Information Theory Workshop (ITW), August 2019.
[495] Min Ye and Alexander Barg. Optimal schemes for discrete distribution estimation under locally differential
privacy. IEEE Transactions on Information Theory, 2018.
[496] Samuel Yeom, Irene Giacomelli, Matt Fredrikson, and Somesh Jha. Privacy risk in machine learning: Analyzing
the connection to overfitting. In 2018 IEEE 31st Computer Security Foundations Symposium (CSF), pages 268–
282. IEEE, 2018.
[497] Dong Yin, Yudong Chen, Kannan Ramchandran, and Peter Bartlett. Byzantine-robust distributed learning:
Towards optimal statistical rates. In ICML, 2019.
[498] Chen Yu, Hanlin Tang, Cedric Renggli, Simon Kassing, Ankit Singla, Dan Alistarh, Ce Zhang, and Ji Liu.
Distributed learning over unreliable networks. arXiv preprint arXiv:1810.07766, 2018.
[499] Han Yu, Zelei Liu, Yang Liu, Tianjian Chen, Mingshu Cong, Xi Weng, Dusit Niyato, and Qiang Yang. A
sustainable incentive scheme for federated learning. IEEE Intelligent Systems, 35(4):58–69, 2020.
[500] Hao Yu, Sen Yang, and Shenghuo Zhu. Parallel restarted SGD for non-convex optimization with faster convergence and less communication. arXiv preprint arXiv:1807.06629, 2018.
[501] Hao Yu, Rong Jin, and Sen Yang. On the linear speedup analysis of communication efficient momentum SGD
for distributed non-convex optimization. arXiv preprint arXiv:1905.03817, 2019.
[502] Tao Yu, Eugene Bagdasaryan, and Vitaly Shmatikov. Salvaging federated learning by local adaptation. arXiv
preprint arXiv:2002.04758, 2020.
[503] Muhammad Bila Zafar, Isabel Valera, Manuel Gomez Rodriguez, and Krishna P. Gummadi. Fairness constraints: Mechanisms for fair classification. In Proceedings of the 20th International Conference on Artificial
Intelligence and Statistics, 2017.

118

[504] Valentina Zantedeschi, Aurélien Bellet, and Marc Tommasi. Fully Decentralized Joint Learning of Personalized
Models and Collaboration Graphs. Technical report, arXiv:1901.08460, 2019.
[505] Sixin Zhang, Anna E Choromanska, and Yann LeCun. Deep learning with elastic averaging SGD. In Advances
in Neural Information Processing Systems, pages 685–693, 2015.
[506] Yu Zhang and Qiang Yang. A survey on multi-task learning. CoRR, abs/1707.08114, 2017. URL http:
//arxiv.org/abs/1707.08114.
[507] Yuchen Zhang, John Duchi, Micheal I. Jordan, and Martin J. Wainwright. Information-theoretic lower bounds
for distributed statistical estimation with communication constraints. In Advances in Neural Information Processing Systems, pages 2328–2336, 2013.
[508] Yawei Zhao, Chen Yu, Peilin Zhao, and Ji Liu. Decentralized online learning: Take benefits from others’ data
without sharing your own to track global trend. arXiv preprint arXiv:1901.10593, 2019.
[509] Michael Zhu and Suyog Gupta. To prune, or not to prune: exploring the efficacy of pruning for model compression. arXiv preprint arXiv:1710.01878, 2017.
[510] Wennan Zhu, Peter Kairouz, Haicheng Sun, Brendan McMahan, and Wei Li. Federated heavy hitters discovery
with differential privacy. arXiv preprint arXiv:1902.08534, 2019.
[511] Xiaojin Zhu. Machine teaching: An inverse problem to machine learning and an approach toward optimal
education. In Twenty-Ninth AAAI Conference on Artificial Intelligence, 2015.

A

Software and Datasets for Federated Learning

Software for simulation Simulations of federated learning require dealing with multiple issues that do not
arise in datacenter ML research, for example, efficiently processing partitioned datasets, with computations
running on different simulated devices, each with a variable amount of data. FL research also requires
different metrics such as the number of bytes upload or downloaded by device, as well as the ability to
simulate issues like time-varying arrival of different clients or client drop-out that is potentially correlated
with the nature of the local dataset. With this in mind, the development of open software frameworks for
federated learning research (simulation) has the potential to greatly accelerate research progress. Several
platforms are available or in development, including [404]:
• TensorFlow Federated [38] specifically targets research use cases, providing large-scale simulation
capabilities as well as flexible orchestration for the control of sampling.
• FedML [229] is a research-oriented library. It supports three platforms: on-device training for IoT
and mobile devices, distributed computing, and single-machine simulation. For research diversity,
FedML also supports various algorithms (e.g., decentralized learning, vertical FL, and split learning),
models, and datasets.
• PySyft [399] is a Python library for secure, private Deep Learning. PySyft decouples private data from
model training, using federated learning, differential privacy, and multi-party computation (MPC)
within PyTorch.
• Leaf [35] provides multiple datasets (see below), as well as simulation and evaluation capabilities.
• Sherpa.ai Federated Learning and Differential Privacy Framework [397] is an open source federated
learning and differential privacy framework which provides methodologies, pipelines, and evaluation
techniques for federated learning.
119

• PyVertical [32] is a project focusing on federated learning with data partitioned by features (also
referred to as vertical partitioning) in the cross-silo setting; see Section 2.2.
Production-oriented software In addition to the above simulation platforms, several production-oriented
federated learning platforms are being developed:
• FATE (Federated AI Technology Enabler) [33] is an open-source project intended to provide a secure
computing framework to support the federated AI ecosystem.
• PaddleFL [36] is an open source federated learning framework based on PaddlePaddle [37]. In
PaddleFL, several federated learning strategies and training strategies are provided with application
demonstrations.
• Clara Training Framework [125] includes the support of cross-silo federated learning based on a
server-client approach with data privacy protection.
• IBM Federated Learning [321] is a Python-based federated learning framework for enterprise environments, which provides a basic fabric for adding advanced features.
• Flower framework [66] supports implementation and experimentation of federated learning algorithms on mobile and embedded devices with a real-world system conditions simulation.
• Fedlearner [34] is an open source federated learning framework that enables joint modeling of data
distributed between institutions.
Such production-oriented federated learning platforms must address problems that do not exist in simulation such as authentication, communication protocols, encryption and deployment to physical devices or
silos. Note that while TensorFlow Federated is listed under “Software for simulation”, its design includes
abstractions for aggregation and broadcast, and serialization of all TensorFlow computations for execution
in non-Python environments, making it suitable for use as a component in a production system.
Datasets Federated learning is adopted when the data is decentralized and typically unbalanced (different
clients have different numbers of examples) and not identically distributed (each client’s data is drawn from a
different distribution). The open source package TensorFlow Federated [38] supports loading decentralized
dataset in a simulated environment with each client id corresponding to a TensorFlow Dataset Object. These
datasets can easily be converted to numpy arrays for use in other frameworks.11 At the time of writing, three
datasets are supported and we recommend researchers to benchmark on them.
• EMNIST dataset [126] consists of 671,585 images of digits and upper and lower case English characters (62 classes). The federated version splits the dataset into 3,400 unbalanced clients indexed by the
original writer of the digits/characters. The non-IID distribution comes from the unique writing style
of each person.
• Stackoverflow12 dataset consists of question and answer from Stack Overflow with metadata like
timestamps, scores, etc. The training dataset has more than 342,477 unique users with 135,818,730
examples. Note that the timestamp information can be helpful to simulate the pattern of incoming
data.
11
12

https://www.tensorflow.org/datasets/api_docs/python/tfds/as_numpy.
https://www.kaggle.com/stackoverflow/stackoverflow

120

• Shakespeare is a language modeling dataset derived from The Complete Works of William Shakespeare. It consists of 715 characters whose contiguous lines are examples in the client dataset. The
train set has 16,068 examples and test set has 2,356 examples.
The preprocessing for EMNIST and Shakespeare are provided by the Leaf project [96], which also provides
federated versions of the sentiment140 and celebA datasets. These datasets have enough clients that they
can be used to simulate cross-device FL scenarios, but for questions where scale is particularly important,
they may be too small. In this respect Stackoverflow provides the most realistic example of a cross-device
FL problem.
Cross-silo datasets One example is the iNaturalist dataset13 which consists of large numbers of observations of various organisms all over the world. One can partition it by the geolocation or the author of an
observation. If we partition it by the group an organism belongs to, like kingdom, phylum, etc., then the
clients have totally different labels and biological closeness between two clients is already known. This
makes it a very suitable dataset to study federated transfer learning and multi-task learning in cross-silo
settings.
Another example is the Google-Landmark-v2 [456] that includes over 5 million images of more than
200 thousand different types of landmark. Similar to the iNaturalist dataset, one can split the dataset by
authors, but due to the difference in scale with iNaturalist dataset, Google Landmark Dataset provides much
more diversity and creates even greater challenges to large-scale federated learning.
Luo et al. [322] has recently published a federated dataset for computer vision. The dataset contains
more than 900 annotated street images generated from 26 street cameras and 7 object categories annotated
with detailed bounding box. Due to the relatively small number of examples in the dataset, it may not
adequately reflect a challenging realistic scenario.
The need for more datasets Developing new federated learning datasets that are representative of realworld problems is an important question for the community to address. Platforms like TensorFlow Federated [38] welcome the contribution of new datasets and may be able to provide hosting support.
While completely new datasets are always interesting, in many cases it is possible to partition existing
open datasets, treating each split as a client. Different partitioning strategies may be appropriate for different
research questions, but often unbalanced and non-IID partitions will be most relevant. It is also interesting
to maintain as much additional meta information (timestamp, geolocation, etc.) as possible.
In particular, there is a need for feature-partitioned datasets, as will be discussed in Section 2.2. For
example, a patient may go to one medical institute for a pathology test and go to another for radiology
picture archiving, in which case the features of one sample are partitioned over two institutes regulated by
HIPAA. [24].

13

https://www.inaturalist.org/

121

Modelling Complex Human Behaviours with
Networks of Multi-Modal Data and Domain
Knowledge available from Rich Sensor
Environments

Catherine Tong
Linacre College
University of Oxford

DPhil Transfer Report
Hilary 2018-2019

Contents
1 Introduction

1

1.1

Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1

1.2

Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1

1.3

Challenges and Opportunities . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2

2 Research Proposal

4

2.1

Research Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4

2.2

Case Studies: Ubiquitous Monitoring of Wellbeing . . . . . . . . . . . . . . . . .

6

2.3

Research Plan . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

8

2.3.1

Learning from Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

8

2.3.2

Learning from Multi-Modalities . . . . . . . . . . . . . . . . . . . . . . . .

9

2.3.3

Exploiting Domain Knowledge . . . . . . . . . . . . . . . . . . . . . . . .

11

3 Literature Review

12

3.1

Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

12

3.2

Machine Learning on Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

12

3.3

Learning from Multimodalities . . . . . . . . . . . . . . . . . . . . . . . . . . . .

13

3.4

Exploting Knowledge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

14

3.5

Ubiquitous Sensing for Health Monitoring . . . . . . . . . . . . . . . . . . . . . .

15

Bibliography

16

A Conference Paper: Ubicomp 2019

21

B Conference Paper: Ubicomp 2018

46

C Conference Paper: Pervasive Health 2019

75

D Conference Poster: MobiSys 2018

87

i

Chapter 1

Introduction
1.1

Overview

Although machine learning is being widely adopted across many areas of modern technology, its
success has so far been limited to a handful of well-defined domains, for instance computer vision,
voice recognition and natural language processing. The vision of achieving a broad success beyond
these traditional domains is currently inhibited by a number of challenges in machine learning
handling real-world data, which may come in different forms and structures, be incomplete,
time-dependent and above all messy.
The focus of this thesis is to study and push forward state-of-the-art machine learning techniques with respect to the challenges of their applications to real-world data, specifically those
encountered in the health-related domain. These challenges pertain to three fundamental issues
in machine learning to which this thesis is most interested in contributing: learning from graphs,
learning from multiple modalities, and exploiting domain knowledge. This thesis aims to understand the current limitations and improve the designs of machine learning models in these
three areas. In addition to putting forward general solutions to these challenges, this thesis will
also conduct case studies focused on the application of machine learning to ubiquitous sensing
for personal health and wellbeing. Through these case studies, the thesis hopes to study the
practicalities of general solutions and to produce case-specific innovations.
This report is organized as follows: The remainder of Chapter 1 explains the motivations for
this thesis and layout important challenges and opportunities in expanding the versatility of
ML. Chapter 2 gives the research outline and plans for completed and future projects. Finally,
Chapter 3 provides a literature review of the methods in machine learning in relation to the
focused area.

1.2

Motivation

In recent years we have seen an unprecedented increase in our ability to generate large amounts
of data, from sensors embedded in our wearable smartphone to satellite networks in space. As
1

the volume of data increases, so does our ability to analyze them. Machine Learning (ML), which
automates the building of models on data, has become a dynamic research area with notable
success in building models for data in form of text, audio and images. The influx of academic
and corporate interests has rapidly transformed the field, and neural networks, known for their
ability for representation learning without extensive hand-engineering and also a hunger for large
data, have emerged as one of the most powerful and widely-used machine learning techniques.
A number of factors, other than the availability of big data, have contributed to the widespread
success of ML applications in areas with well-defined prediction tasks. Taking image classification as an example, there are a number of benchmark datasets established for researchers to
test their methods on (Deng et al. [2009], LeCun and Cortes [2010]), there is a clear underlying relationship between the image data and the prediction label, and images are conveniently
structured uniformly.
Outside these well-defined domains, machine learning is a promising method that may produce
a widespread positive impact. Healthcare is one such area, and one of the greatest challenges
facing health systems today is chronic diseases [WHO, 2002]. Chronic diseases require a complex
response from both clinicians and patients over an extended time period, but information used
for patient self-management still largely comes from self-report surveys and infrequent doctor
consultations. Used together with the growing volumes of health data from ubiquitous devices
and electronic clinical records, ML may facilitate a wide range of health-related uses, including
disease monitoring, individualized treatment recommendation, and disease prevention. In addition, since ubiquitous sensors now offer the ability for researchers to collect behavioural data
in-situ, ML may also be used to analyze the collected data to further understanding of complex
human behavioural patterns over time.

1.3

Challenges and Opportunities

As a data-driven discipline, machine learning relies heavily on both the quantity and quality of
data it learns from. In applications of machine learning outside comfort zones of rigid data such
as text and images, we see models struggling to cope with different non-uniformities of data,
such as data missingness, varying modalities, individual and temporal differences and other inthe-wild uncertainties. For instance, health data may come in a variety of forms, e.g. reports,
treatment procedures, images, etc. The availability of cheap and small sensors has given rise to
ubiquitous sensing, where the behaviour and contexts of users may be recorded and learnt in the
wild ; in this case, data missingness might arise from individual owning different sets of sensors
and using them in different times.
Apart from the ability to handle data of different qualities, machine learning, neural networks
in particular, suffers from an over-reliance of large amounts of data. Since supervised learning
techniques are the algorithm of choice in building many inference systems, this reliance of data
means the need for large hand-labelled datasets, which is especially expensive to obtain in cases
in healthcare where we need to consider domain expertise, patient privacy and burden.
2

While there has been a number of successful applications of machine learning for human activity
and context recognition tasks using mobile phone data, two emerging trends came to our attention. First, increasing volumes of data are available from a diverse range of IoT devices from
people’s homes, work or other environments. Second, increasing attempts are made towards
recognition tasks beyond basic recognition tasks (e.g. running) to those involving more complex
behavioural phenomena, such as social interactions and disease symptoms.
How to utilize machine learning to analyze behavioural data has attracted considerable research
attention in recent years; this problem is non-trivial as several challenges exist for applying
traditional machine learning techniques for modelling complex human behaviours:
• Relations and structure. Humans are social beings, and individual actions are affected
by a variety of external influences. For example, people linked together on a social network through a weight-loss app may reinforce each other’s diet plan adherence. Explicitly
modelling these networks, or graphs, may allow machine learning models to learn about
influences between cases, and to generalize to unseen scenarios by exploiting the network
topology. However, graphs lack a regular structure, making effective machine learning on
graphs an open research problem.
• Multimodalities.

Human behaviour can manifest in a great number of ways and thus

behavioural data can be complicated with a diverse range of sensing modalities. For example, depression symptoms may be analyzed through patterns in sleep, communication,
physical activities, amongst others. Apart from fusing together very different modalities,
the varying data environments and tasks require solving problems such as selecting important information from a modality, and incorporating relationships between and within
modalities.
• Domain knowledge.

Behavioral data was traditionally analyzed by other disciplines

such as psychology, medicine or social sciences. Domain knowledge can be leveraged to
solve specific problems, but it is difficult to integrate structured knowledge using straightforward, hard logic rules. Many behavioural concepts may not be well-defined, there may
not be a consensus in the field, or the knowledge may even be evolving with time. Defining
the knowledge, transferring the knowledge, and having the model using the knowledge, all
make the model design much more difficult.
Many present obstacles preventing a straightforward application is related to the fact that most
current machine learning models have been developed with well-defined problems and data in
mind. From the above challenges, we see that developing machine learning models which could
handle data of varying qualities and quantities, with applications on non-uniform data in mind,
will open the door for many techniques previously overlooked by the community.

3

Chapter 2

Research Proposal
2.1

Research Directions

In this thesis, we will consider fundamental issues in machine learning to make these models
more applicable for widespread adoption. We break down the investigation of this thesis into
three main components, in addition to case studies, as follows:

Learning from Graphs
In machine learning models of simple human activities or actions (e.g. running), the typical
approach is to utilize time series information of multiple sensor data for inference. In contrast,
much more comes into play for complex human phenomena, which may be influenced by important relationships not easily captured in typical data representations. In the case of an individual
trying to lose weight, being connected to other people who are also trying to lose weight on social
media may offer support and increase adherence to weight loss strategies, alternatively, having
obese family members (who often share similar genetic background or habitats) may indicate
genetic predisposition and also influence the likelihood of weight loss success. Therefore, it is important to explicitly express and model relationships amongst individuals and cases which share
some form of affinity. Graphs, formed of nodes connected by edges, are simple and powerful
representations which can be used to address this problem. Instead of modelling independent
time series, machine learning models on graphs may be able to learn and utilize the underlying
characteristics shared amongst cases based on the graph structure, to improve predictions and
extrapolate for unseen scenarios.
Most deep learning models today fall short in being able to represent structure and reason about
relations. In recent years, to address these concerns current research directions point towards
deep learning models which are capable of learning from graphs. Within this emerging field,
methods have been proposed analogous to common themes in DNNs, e.g. convolutional neural
network. However, most methods have only been applied to and tested on a small number
of graph datasets which are currently treated as benchmarks in the area. We observe that
these benchmark graph datasets (including artificially created subgraphs of citation networks, or
4

graphs of molecular structure) are limited in representing the spectrum of graph characteristics,
yet they are being used to validate the performance of recently proposed DNNs for graphs. The
current attempts are far from considering the full set of graphs that can be encountered in the
real world. For example, most benchmark graph datasets are dense, i.e. there exists a single
largest connected component, but some graphs in ubiquitous sensing may be extremely sparse,
e.g. many small disconnected components of friendships found on the social networks in apps
for exercising. In this component, we focus on investigating these key questions:
1. "What are the commonly neglected or poorly-represented structural and relational information in data? If they are represented as graphs, how are the properties of the data and
the model changed?"
2. "What are limitations and theoretical foundations of machine learning on a general class
of graphs, which would include a spectrum of graphs with varying properties?"
3. "How can common machine learning ideas and techniques used on rigid forms of data be
translated or re-invented in a graph context?"

Learning from Multi-Modalities
While many existing attempts in multimodal learning are based on traditional machine learning
models (non-deep or shallow models), the well-known representation power of DNNs may be the
answer to effective multimodal learning. Another barrier to a straight-forward implementation
of current multimodal learning techniques is to do with the differences in data environments
or personal habits; for instance, in health outcome predictions, data from different modalities
may be available at different times for different people, and their relative interaction may also
differ individually and temporally. Thus, in this component, we focus on developing multimodal
learning methods which are versatile in working with vastly different modalities and data environments. These modalities may include sources of data at device or sensor level, processed or raw
signals, and data environments may include settings where there are mix-sourced modalities or
where modalities are absent during training or testing phase for different individuals at different
times. We will address these questions:
4. "What are the capabilities of deep learning, as opposed to, shallow multimodal learning
frameworks in handling a variety of multimodal data settings?"
5. "What are the limiting modality combinations or data environments where multimodal
learning currently works poorly on? And how can models be improved to increase their
versatility in these situations?"

Exploiting Domain Knowledge
Knowledge available from domain expert or common sense can be used not only to guide machine
learning architecture design but to be explicitly encoded to facilitate machine learning. For
example, the notion that a conscientious person is more likely to have a regular lifestyle could
5

be a useful piece of information for a model learning people’s personalities given their IoT sensor
data. Possible benefits of encoding knowledge in machine learning include lowering the need
for large amounts of training data (as is typical for DNNs), which in turn could bring about
reductions in time and computational complexities.
This component focuses on allowing machine learning models to harness knowledge from domain
expert or intuition. In particular, we ask the question:
6. "How can knowledge be best represented, transferred and internalized by machine learning
models, so as to benefit from domain expertise or intuition?"

Case Studies
Case studies are conducted alongside the other components to build a practical view of deploying
ML on real-world data, specifically in the domain of ubiquitous sensing of personal wellbeing.
These case studies will involve applying machine learning to emerging types of ubiquitous sensing
data, for complex predictive tasks relating to health outcome detection or wellbeing monitoring.
The focus will be placed on gaining insights from practical issues commonly encountered in data
handling and applying ML models; these insights will be part of a feedback loop to improve the
development of more general issues tackled in the other components of this thesis. We also ask:
7. "What individual innovations can be made for the particular task? Is there a general class
of scenarios which would also benefit from these innovations?"

2.2

Case Studies: Ubiquitous Monitoring of Wellbeing

The questions posed in Section 2.1 will be considered in a series of practical circumstances that
have a significant impact on the real-world data to be encountered in this thesis. In this section,
we describe case studies conducted to understand these practical circumstances. To address
Question (7), in these case studies we have made individual innovations with respect to the task
and will consider how to generalize these innovations through our insights and future work.

Overview
We conducted two separate case studies as pilot cases to explore the design and deployment of
machine learning using data from ubiquitous sensors for health and well-being monitoring. The
data is collected from a range of commercial smart devices produced by the Withings brand,
including both IoT appliances (e.g. sleep trackers placed under the mattress) and mobile devices
(e.g. smartwatch). Importantly, instead of using raw sensor signals, we consider inferred data
which is the output of commercial-grade machine learning models for human activity recognition;
for example, we use inferred sleep durations instead of raw sensor signals from the sleep tracker
as inputs to machine learning models considered in these studies.
6

Collectively these results provide initial insights as to how to model data from mobile and appliances for use-cases in wellbeing. We believe that these investigations and results are timely
given the rapid update by consumers for smart devices in the home, which will cause datasets of
this type to be more readily available in the near future.

Big-Five Personality
We present a large-scale (9110-user) study of data from both mobile and networked appliances
for Big-Five personality inference. Building on methods (viz. features and classifiers) previously
successful for personality detection from mobile-only data, this investigation shows Big-Five
personality can be detected with accuracies of 77% (similar levels as other studies) under this
setting – despite the size and complexity (mix of mobile and appliance) of the dataset. This result
acts as a study of techniques that are commonly utilized in the literature (e.g. random forests,
support vector machines) but under a type of dataset previously never studied. Moreover, we
offer ancillary results, in particular, as to behaviour and physical health features that correlate
with mobile and appliance data and how inference accuracy alters as cohort scale and diversity
change.
This work is currently in preparation for the International Conference on Pervasive Computing
Technologies for Healthcare and is included in Appendix C. The early results from this project
were presented as a poster at the ACM International Conference on Mobile Systems (MobiSys)
2018 and are included in Appendix D.

Tracking Health Outcomes of Multiple Sclerosis Patients
Multiple Sclerosis (MS) requires long-term disease management, but tracking patients through
the use of clinical survey instruments is hindered by the high costs and patient burden involved.
In this work, we investigate the feasibility of using data from ubiquitous sensing to predict MS
patients’ fatigue and health status, as measured by the Fatigue Severity Scale (FSS) and EQ-5D
index. We collected data from 198 MS patients who are given connected wellness devices for over
6 months. We examine how accurately can the collected data predict reported FSS and EQ-5D
scores per patient using an ensemble of regressors. In predicting for both FSS and EQ-5D, we
are able to achieve errors aligning with the instrument’ standard measurement error (SEM), as
well as strong and significant correlations between predicted and ground true values.
We proposed and compared two adaptation methods, one based on adapted Gaussian mixture
models previously proposed for speaker identification, another based on residual error correction.
We show the latter, a simple adaptation method, greatly reduces prediction errors through the
use of just 1 user-supplied ground truth datapoint. For FSS (SEM 0.7), the universal model
predicts weekly scores with MAE 0.99, while an adapted model predicts with MAE 0.51. For
EQ-5D (SEM 0.093), the universal model predicts weekly scores with MAE 0.091, while an
adapted model predicts with MAE 0.052. Our study represents the first sets of results on
tracking fatigue and health status of MS patients using ubiquitous sensing, which gives promising
7

prediction performance with errors aligns with the accepted range of error in the widely used
clinically-validated questionnaires. Future extensions and potential applications of our results
can positively impact MS patient disease management and support clinical research.
This work is currently submitted to and under review by the Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT) and is included in Appendix A.

Insights and Future Work
The experience of conducting these case studies has played an important part in motivating
the work planned in the other components of this thesis. These case studies highlighted the
difficulties in deploying machine learning outside traditional domains, especially in handling data
missingness, multi-modalities, individual differences, temporal differences, and class imbalance.
Also, despite being relatively large datasets within their respective domains, the small quantities
of labelled data also prevent the use of innovations in deep learning, e.g. attention mechanism.
We will continue expanding the case studies with techniques developed with respect to the other
components of this thesis. The first, personality, dataset suffers heavily from missing modality
issues, and this may be included as a testing example for an application of utilising domain knowledge. In the MS initiative, we are also currently obtaining access to a large dataset in Oxford
and the UK through our collaboration with Dr Matthew Craner at the Nuffield Department of
Clinical Neuroscience. Again we plan to examine the domain knowledge incorporation problem
using this dataset, and should the large dataset become available, we will also explore ways of
learning a useful embedding from the large dataset to aid machine learning in the small data
scenario.

2.3

Research Plan

In this section, we present our research proposal aiming to answer the questions posed in Section 2.1. We draw insights from case studies presented in Section 2.2 and plan for current and
future work in the other research components.

2.3.1

Learning from Graphs

We are conducting initial investigations on the problem of learning from graphs and have not
produced many concrete results thus far. On-going investigations are on two fronts: one project
relates to proposing a novel framework for machine learning on graphs constructed from clinical
data and targets the improvement in model predictions given by expressing data in graphs, as
posted in Question (1); another project relates to Question (2) and investigates the sparsity in
graphs, a neglected characteristic in most graph benchmark datasets.
8

Current Work
We are currently conducting two projects to investigate ML on graphs. The first is a collaboration
with the University of Cambridge, focused on developing a clinical predictions framework evaluated using a publicly available clinical dataset, MIMIC-III [Johnson et al., 2016]. This dataset
is a large database comprising of electronic health records (EHR) relating to patients admitted
to the critical care unit at a large tertiary care hospital. The idea is to improve the robustness
of prediction by developing a framework, which first utilizes a feature extraction pipeline on the
EHR (e.g. recurrent neural networks for time series data, language processing for medical texts),
followed by a convolutional neural network on a graph constructed using common diagnosis. We
are currently in the stage of pre-processing the data and refining the methodology. We plan
to submit a paper on this project to the ’Representation Learning on Graphs and Manifolds’
Workshop in the International Conference on Learning Representations (ICLR) in March 2019.
Another project concerns the ability of current ML on graph methods to scale to different varieties
of graphs. Delving into the construction mechanism of different benchmark graph datasets, we
find that most are artificially created to overlook certain graph characteristics. In particular, we
find that the sparsity of graphs, which concerns the disconnected components of graphs, may
be an important overlooked factor. Most recent models for machine learning on graphs have
emphasized results obtained on the ’largest-connected component’, and our initial experiments
on some leading models in the field find that node classification results for nodes in disconnected
components perform on average at least 13% worse in accuracy compared to those in the largestconnected components. We aim to produce a set of representative graphs and compare the
empirical performance of current models. We plan to submit a paper on this project to the
International Joint Conference on Automated Reasoning (ICJAI) in February 2019.

Future Work
After gaining insights about the strengths and weaknesses of each model on different scenarios,
we plan to propose a refined set of machine learning techniques that could cope adequately
with different graph characteristics. These refined machine learning techniques may be the
adoption of ideas common in machine learning proposed in the Euclidean data context and
will relate to the investigations posed by Question (3). Likely directions include using transfer
learning or adversarial neural networks to facilitate the effective sharing of learning process across
disconnected components or multi-modalities.

2.3.2

Learning from Multi-Modalities

We have completed two separate pieces of investigations on multimodal learning. Addressing
Question (4), we studied how deep learning models perform in different multimodal learning
scenarios. Our MS case study presented a poor data environment for multimodal learning, and
we proposed a framework to cope with the situation, addressing Question (5). This is the most
mature part of the thesis so far.
9

Completed Work
DNNs for Multimodal Learning.

We conducted a project studying the benefits of adopting

deep learning algorithms for interpreting user activity and context as captured by multi-sensor
systems. Specifically, in this project, we focus on four variations of deep neural networks that
are based either on fully-connected Deep Neural Networks (DNNs) or Convolutional Neural
Networks (CNNs). Two of these architectures follow conventional deep models by performing
feature representation learning from a straghtforward concatenation of sensor types. This simple
approach is contrasted with a deep model variant characterized by modality-specific partitions
of the architecture to maximize intra-modality learning. Our exploration represents the first
time these architectures have been evaluated for multimodal deep learning with wearable data –
and for convolutional layers within this architecture, it represents a novel architecture entirely.
Experiments show these generic multimodal neural network models compete well with a rich
variety of conventional hand-designed shallow methods (including feature extraction and classifier
construction) and task-specific modelling pipelines, across a wide range of sensor types and
inference tasks (four different datasets). In addition, although the training and inference overhead
of these multimodal deep approaches is in some cases appreciable, we also demonstrate the
feasibility of on-device mobile and wearable execution. This study has been constructed to focus
on multimodal aspects of wearable data modelling for deep learning by proving a wide range
of empirical observations, which we expect to have considerable value in the community. We
summarize our observations into a series of practitioner rules-of-thumb and lessons learned that
can guide the usage of multimodal deep learning for activity and context detection.
This work was a collaboration with Nokia Bell Labs and University of Edinburgh, University of
Cambridge. It has been accepted and presented at the IMWUT and Ubicomp’18, MobiUK’18,
and is included in Appendix B.
Multimodal Learning with Missing Data.

The issue of multimodal learning in poor data

environments was explored in the presented case study of health monitoring in Multiple Sclerosis
patients. The dataset suffers from a missing modality problem, as patients use the different
sensing devices at different frequencies. Effectively combining multiple modalities for different
patients also poses a problem, since different recorded aspects of their lifestyles may contribute
differently to the health outcome for different patients at different times; case in point, sometimes
a patient’s sleep quality might indicate most about his/her fatigue, but for another patient it
may be a combination of walking patterns and weight fluctuations, and at other times these
correlations might be different for the same patient. Given the limited quantities of data in this
dataset, we focused on shallow machine learning methods and proposed an ensemble framework
for multimodal learning, which was able to cope with datapoints with different missing modalities.
its detailed formulation is included in Appendix A.

Future Work
Our investigations have yet to lead to a universal multimodal fusion architecture which outperforms highly hand-engineered multimodal learning in every situation, so it is important to take
10

this into consideration and experiment with different formulations depending on the data and
task. In the work conducted so far, we have investigated multimodal learning frameworks on 4
public datasets and 2 individual case studies, we aim to examine the spectrum of data sets and
draw insights about the variety of data settings and the machine learning models that would work
best for each scenario. Based on these insights, we will move on to proposing key components
of a universal multimodal learning framework that would have the versatility in working well in
different data settings.

2.3.3

Exploiting Domain Knowledge

This is least explored part of the thesis, we have conducted brief investigations into knowledge
rule distillation as part of the personality inference case study. Our future work will seek to
address Question (6).

Current work
Inspired by the rule distillation framework proposed by Hu et al. [2016] on sentence sentiment
classification, we conducted initial investigations into applying a rule distillation framework for
the task of personality classification, where we constructed rules such as ’a person is conscientious
if the standard deviation in his/her bed-in times are below median’ and relaxed the uncertainty
about these rules. These rules are obeyed by a teacher network, which then distils the knowledge
to a student network. In this rule example, the rationale was that an intuitive understanding
of ’conscientiousness’ means sticking to routines and therefore sticking to a more rigid sleep
schedule. However, our implementation has yet to gain much traction so far, and the performance
of rule-distilled models are not much improved.

Future work
In the future, instead of relying on a rigid rule distillation framework, we will look into developing
a knowledge component within a deep neural network framework. A possible basis for this
knowledge component may be the rule-obeying teacher network, a feature-extraction framework
from unstructured texts from literature, or a structured knowledge graph. As seen in our current
work, the knowledge may not be well-defined as an explicit deterministic rule or prior distribution,
so we will tailor our knowledge component to consider ill-defined concepts. We will further
consider ways of incorporating the knowledge and testing if the knowledge is internalized by a
machine learning model. This is expected to have consequences in the model’s reliance on data as
a bid to counteract DNNs’ data-hungry characteristic so that they may be applied to a broader
variety of domains. It will also be interesting to investigate special cases where the data-driven
insights are at odds with human knowledge and how the model should cope with

11

Chapter 3

Literature Review
3.1

Overview

This chapter presents the technological backdrop surrounding the machine learning against which
this thesis is proposed. We provide a survey and discussion of the most prominent methods
proposed in this thesis.

3.2

Machine Learning on Graphs

Graphs, geometric structures formed of nodes connected by edges, are common representations
of data found in the real world. For example, relationships between people can be represented
as social networks, trades as commerce networks, and molecules as biological networks. The
complex relational and structural information that can be communicated by nodes and edges
can collectively provide vital information, giving complicated structures in graphs which contain
rich underlying value [Barabasi].
Utilizing machine learning for graph data analysis has attracted a lot of attention. Yet the
problem of generalizing existing machine learning methods to graphs is non-trivial. Zhang et al.
[2018] argued that four main challenges exist: First, graphs lie in an irregular domain so simple
mathematical operations (e.g. convolution) cannot be easily defined. Second, graphs can come
with diverse structures and machine learning tasks can also vary greatly, from node-focused
problems (e.g. node classification, link prediction) to graph-focused problems (e.g. graph classification). The third challenge relates to the scalability of methods on large graphs. Finally,
graphs are often representations of data connected with other disciplines (e.g. social sciences),
thus requiring interdisciplinary collaboration.
Responding to these challenges, significant effort has been made towards this area. Earlier developments in graph ML focused on network embedding, which tries to embed nodes into a
lower-dimensional vector space. A popular embedding technique is Node2vec, first proposed by
Grover and Leskovec [2016] to make use of random walks on graphs; although the original algorithm is not able to incorporate node or edge features, many extensions have been made to
12

encode other desirable graph properties. In general, the inevitable shortcoming of node embedding is that some graph structure around a node may be discarded in the embedding procedure
and not all node and relationship properties may be incorporated.
Recent attention in graph ML has focused on deep learning methods, especially the development
of Graph Convolutional Networks (GCNs). GCNs involves storing states for each node and
using an adjacency matrix to propagate those states to the neighbourhood of the nodes. Similar
to Convolutional Neural Networks (CNNs), convolution is the most fundamental operations
in GCNs. In the graph context, Bruna et al. [2013] pioneered convolution for graphs from
the spectral domain using the graph Laplacian matrix L , which plays a similar role as the
Fourier basis for signal processing. This idea has since undergone multiple adaptations and
improvements, notably Kipf and Welling [2016] further simplifies the convolutional filters used in
GCNs by only considering the first-order neighbourhoods of nodes. Some recent work has looked
into migrating other innovation from general deep learning to the graph context, including using
attention [Veličković et al., 2017, Peng et al., 2018]. Some early adoption of these methods have
already been made in other domains through the use of learning from knowledge graphs, for
example, in health, Shang et al. [2018] uses GameNet to perform medication recommendation
and integrates drug-drug interaction knowledge graphs by a memory module implemented as
GCNs, and achieve good performance on large-scale EHR data. integrates

3.3

Learning from Multimodalities

Multimodal learning has a vast application domain. Applications have been seen in audio-visual
speech recognition [Ngiam et al., 2011], image captioning [Sohn et al., 2014], machine translation [Kiros et al., 2014], sentiment analysis [Poria et al., 2016] and affect recognition [Kapoor
and Picard, 2005]. In the space of ubiquitous computing, example applications include human
activity recognition [Barz et al., 2016], sleep detection [Chen et al., 2017] and emotion recognition [Kye et al., 2017]. Many recognition tasks were previously only primarily performed with
unimodal learning, with the availability of low-energy sensors, many such tasks are recently explored using multimodal learning. For example, authentication models involve both gaze and
touch recognition [Khamis et al., 2016], or eating recognition might involve motion of head, wrist
and audio [Merck et al., 2016].
Whilst there are numerous applications of multimodal learning, how best to combine sensor inputs which are significantly different remains an open problem. In existing works of multimodal
learning models, we observe two broad categories of sensor fusion: Feature Concatenation and
Ensemble Classifier. In feature concatenation, data from different modalities are simply collapsed together into single feature vectors. In ensemble classifier, modality-specific classifiers are
included in an ensemble; the schematics of both frameworks are depicted in Figure 3.1. Currently, the choice of modality fusion scheme is still determined and justified on a case by case
basis (e.g. Snoek et al. [2005]). Deep learning models, which are capable of feature representation
learning with little hand-engineering and preprocessing, may be a promising general solution to
multimodal learning.
13

Modality 1
Modality 1
Single
Feature
Vector

Inference

Modality n
Modality n

(a)

Feature Concatenation

Inference
Ensemble
Classifier

…

….

Hand
selected
features

Classification
Model

Feature
Vector

(b)

Feature
Vector

Inference

Inference

Ensemble Classifier

Figure 3.1: Schematic of common approaches to shallow multimodal learning with (a) Feature
Concatenation and (b) Ensemble Classifier models. For Feature Concatenation hand-selected
features are extracted from each sensing modalities and concatenated into a single features vector
as input to a classifier, while the Ensemble Classifier approach performs detections on each sensing
modality independently to combine their estimations as final inference.
A prime example in the general space of multimodal deep learning is audio-visual speech recognition [Mroueh et al., 2015], where much work has been done using neural networks [Ngiam et al.,
2011]. A number of neural networks have been proposed to perform multimodal deep learning,
including CNN [Münzner et al., 2017], RBM [Ngiam et al., 2011] and RNN [Mao et al., 2014].
The choice of neural network often depends on the type of recognition involved, as there is currently no consensus on which network would work best. For instance, in tasks where sequential
data is involved (e.g. image sentence description [Mao et al., 2014]), multimodal versions of
recurrent neural networks have been frequently proposed to handle these tasks. While there is
work comparing a small number of multimodal learning methods, such as Brown et al. [1993]
which compares decision tree classifiers with backpropagation neural networks, we note that
there has not been a comprehensive case study comparing a greater number of deep and shallow
multimodal learning architectures.

3.4

Exploting Knowledge

Hinton et al. [2015] pioneered a technique known as ’Knowledge Distillation’, which attempts
to deliver smaller machine learning models by transferring the knowledge from a larger, more
complex model to a smaller one. Hinton et al. argue that the soft outputs of the last softmax
layer of a neural network represent ’knowledge’ that the model has learnt during training, and
these soft outputs can be used as a ground truth dataset for training a compact model, so that
the smaller model may mimic the large one.
Whilst most work utilising knowledge distillation has been focused on the model compression
area, the concept of transferring knowledge between models is useful and has inspired work that
seeks to bring in human knowledge to model training. Combining deep neural networks with
structured knowledge has been of increasing interests to increase generalization and improve
interpretability (Deng et al. [2014]). Hu et al. [2016] proposed a framework to transfer logic
14

rules into neural networks with diverse architectures (such as convolutional networks and recurrent networks) using an iterative distillation framework that trains a neural network to emulate
predictions of a ’teacher’ model iteratively constructed by imposing posterior constraints on the
network. Although this framework has been shown to be effective in regulating different neural
models for incorporating grammatic logic rules for sentiment classification in text, since the
method requires fixed constraints and manually specified weights, it still falls short in being able
to incorporate large amounts of human intuitions or knowledge which may be ill-defined.
On a different line of work, Hong et al. [2018] has more recently proposed RDPD, a framework
which utilizes knowledge distillation to tackle the missing modality problem and discrepancies
between rich and poor data environments. RDPD proposes enhancing a small model trained
on poor data (namely where only a single modality is available) with a complex model trained
on rich data (where multimodalities are available), and has been applied to real-world datasets
formed of data from the healthcare domain. Promising results have been given showing significant
performance improvement after the procedure was applied.

3.5

Ubiquitous Sensing for Health Monitoring

In recent years, increasing interest has been placed on using ubiquitous sensing technology in
monitoring symptoms for a number of which diseases, many of which have been carried out to
reproduce predictions for clinically-validated self-report instruments in the concerned disease.
For example, Wang et al. [2017] develops a prediction system that tracks schizophrenia symptoms based on a standard instrument using passive sensing from mobile phones, they were able
to accurately predict reported schizophrenia scores using Gradient Boosted Regression Trees
(GBRT). Wang et al. [2018] proposed a new approach in predicting depression using passive
sensing data from college students’ smartphone and wearables through the use of a proposed set
of symptom features, they used generalized linear mixed model (GLMM) to predict self-reported
depression scores and found correlations between their proposed symptom features and depression scores. Other than disease monitoring, a number of studies have also been carried looking
into monitoring of more general wellness indicator, since this could be applied to the general
non-clinical population, the sample dataset sizes studied could be much bigger, therefore also
allowing more advanced techniques to be applied (e.g. deep neural networks). Veličković et al.
[2018] analyzes multimodal time-series data and predicts the ability to achieve weight objective
for users of smart connected devices using deep long-short-term memory architectures.
Besides medical disease monitoring, using ubiquitous sensing to collect behavioural data has
also gained much academic attention to improve understanding in behavioural and psychological
sciences. Harari et al. [2016] advocates the increased use of smartphones as a behavioural observation tool in psychological science, and outlines practical considerations and opportunities
for such interdisciplinary research work. Indeed a rising number of studies have been conducted in relation to this line of work using smartphone or IoT data. Olguín et al. [2009] uses
low-level sensor data from sociometric badges to study individual and group behaviour, using
high-level behavioural descriptions such as physical and speech activity; their results show that it
15

is possible to correlate high-level behavioural information with personality traits. Staiano et al.
[2012], de Montjoye et al. [2013], Chittaranjan et al. [2011, 2013] utilised data from smartphones
for personalty inference, using information such as call logs, use of Bluetooth. Staiano et al.
[2012] focuses on inference through building a picture of the social network of smartphone users,
while de Montjoye et al. [2013] proposes behavioural indicators for inference, e.g. regularity and
diversity found in calls/ texts, spatial behaviour from GPS signals.

16

Bibliography
A.-L. Barabasi. Network Science.
Michael Barz, Mohammad Mehdi Moniri, Markus Weber, and Daniel Sonntag. Multimodal
multisensor activity annotation tool. In Proceedings of the 2016 ACM International Joint
Conference on Pervasive and Ubiquitous Computing: Adjunct, UbiComp ’16, pages 17–20,
New York, NY, USA, 2016. ACM. ISBN 978-1-4503-4462-3. doi: 10.1145/2968219.2971459.
URL http://doi.acm.org/10.1145/2968219.2971459.
Donald E. Brown, Vincent Corruble, and Clarence Louis Pittard. A comparison of decision
tree classifiers with backpropagation neural networks for multimodal classification problems.
Pattern Recognition, 26(6):953 – 961, 1993.

ISSN 0031-3203.

doi: https://doi.org/10.

1016/0031-3203(93)90060-A. URL http://www.sciencedirect.com/science/article/pii/
003132039390060A.
Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. Spectral Networks and Locally
Connected Networks on Graphs. arXiv e-prints, art. arXiv:1312.6203, December 2013.
W. Chen, A. Sano, D. L. Martinez, S. Taylor, A. W. McHill, A. J. K. Phillips, L. Barger, E. B.
Klerman, and R. W. Picard. Multimodal ambulatory sleep detection. In 2017 IEEE EMBS
International Conference on Biomedical Health Informatics (BHI), pages 465–468, Feb 2017.
doi: 10.1109/BHI.2017.7897306.
G. Chittaranjan, J. Blom, and D. Gatica-Perez. Who’s who with big-five: Analyzing and classifying personality traits with smartphones. In 2011 15th Annual International Symposium on
Wearable Computers, pages 29–36, June 2011. doi: 10.1109/ISWC.2011.29.
Gokul Chittaranjan, Jan Blom, and Daniel Gatica-Perez.
data for personality studies.

Mining large-scale smartphone

Personal and Ubiquitous Computing, 17(3):433–450, Mar

2013. ISSN 1617-4917. doi: 10.1007/s00779-011-0490-1. URL https://doi.org/10.1007/
s00779-011-0490-1.
Yves-Alexandre de Montjoye, Jordi Quoidbach, Florent Robic, and Alex (Sandy) Pentland. Predicting personality using novel mobile phone-based metrics. In Ariel M. Greenberg, William G.
Kennedy, and Nathan D. Bos, editors, Social Computing, Behavioral-Cultural Modeling and
Prediction, pages 48–55, Berlin, Heidelberg, 2013. Springer Berlin Heidelberg.
J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. ImageNet: A Large-Scale Hierarchical Image Database. In CVPR09, 2009.
17

Jia Deng, Nan Ding, Yangqing Jia, Andrea Frome, Kevin Murphy, Samy Bengio, Yuan Li,
Hartmut Neven, and Hartwig Adam. Large-scale object classification using label relation
graphs. In European Conference on Computer Vision, 2014.
Aditya Grover and Jure Leskovec. Node2vec: Scalable feature learning for networks. In Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining, KDD ’16, pages 855–864, New York, NY, USA, 2016. ACM. ISBN 978-1-4503-4232-2.
doi: 10.1145/2939672.2939754. URL http://doi.acm.org/10.1145/2939672.2939754.
Gabriella M. Harari, Nicholas D. Lane, Rui Wang, Benjamin S. Crosier, Andrew T. Campbell, and Samuel D. Gosling. Using smartphones to collect behavioral data in psychological science: Opportunities, practical considerations, and challenges. Perspectives on Psychological Science, 11(6):838–854, 2016.

doi: 10.1177/1745691616650285.

URL https:

//doi.org/10.1177/1745691616650285. PMID: 27899727.
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network.
arXiv preprint arXiv:1503.02531, 2015.
Shenda Hong, Cao Xiao, Tengfei Ma, Hongyan Li, and Jimeng Sun. RDPD: Rich Data Helps
Poor Data via Imitation. arXiv e-prints, art. arXiv:1809.01921, September 2018.
Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard Hovy, and Eric Xing. Harnessing Deep Neural
Networks with Logic Rules. arXiv e-prints, art. arXiv:1603.06318, March 2016.
Alistair E. W. Johnson, Tom J. Pollard, Lu Shen, Li-wei H. Lehman, Mengling Feng, Mohammad
Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G. Mark. Mimiciii, a freely accessible critical care database. Scientific Data, 3:160035 EP –, May 2016. URL
https://doi.org/10.1038/sdata.2016.35. Data Descriptor.
Ashish Kapoor and Rosalind W Picard. Multimodal affect recognition in learning environments.
In Proceedings of the 13th annual ACM international conference on Multimedia, pages 677–682.
ACM, 2005.
Mohamed Khamis, Florian Alt, Mariam Hassib, Emanuel von Zezschwitz, Regina Hasholzner,
and Andreas Bulling. Gazetouchpass: Multimodal authentication using gaze and touch on
mobile devices. In Proceedings of the 2016 CHI Conference Extended Abstracts on Human
Factors in Computing Systems, CHI EA ’16, pages 2156–2164, New York, NY, USA, 2016.
ACM. ISBN 978-1-4503-4082-3. doi: 10.1145/2851581.2892314. URL http://doi.acm.org/
10.1145/2851581.2892314.
Thomas N. Kipf and Max Welling. Semi-Supervised Classification with Graph Convolutional
Networks. arXiv e-prints, art. arXiv:1609.02907, September 2016.
Ryan Kiros, Ruslan Salakhutdinov, and Richard S. Zemel. Unifying visual-semantic embeddings
with multimodal neural language models. CoRR, abs/1411.2539, 2014. URL http://arxiv.
org/abs/1411.2539.
Saewon Kye, Junhyung Moon, Juneil Lee, Inho Choi, Dongmi Cheon, and Kyoungwoo Lee.
Multimodal data collection framework for mental stress monitoring. In Proceedings of the 2017
18

ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings
of the 2017 ACM International Symposium on Wearable Computers, UbiComp ’17, pages 822–
829, New York, NY, USA, 2017. ACM. ISBN 978-1-4503-5190-4. doi: 10.1145/3123024.
3125616. URL http://doi.acm.org/10.1145/3123024.3125616.
Yann LeCun and Corinna Cortes. MNIST handwritten digit database. 2010. URL http:
//yann.lecun.com/exdb/mnist/.
J. Mao, W. Xu, Y. Yang, J. Wang, and A. L. Yuille. Explain Images with Multimodal Recurrent
Neural Networks. ArXiv e-prints, October 2014.
Christopher Merck, Christina Maher, Mark Mirtchouk, Min Zheng, Yuxiao Huang, and Samantha Kleinberg. Multimodality sensing for eating recognition. In Proceedings of the 10th
EAI International Conference on Pervasive Computing Technologies for Healthcare, PervasiveHealth ’16, pages 130–137, ICST, Brussels, Belgium, Belgium, 2016. ICST (Institute for
Computer Sciences, Social-Informatics and Telecommunications Engineering). ISBN 978-163190-051-8. URL http://dl.acm.org/citation.cfm?id=3021319.3021339.
Y. Mroueh, E. Marcheret, and V. Goel. Deep multimodal learning for audio-visual speech
recognition. In 2015 IEEE International Conference on Acoustics, Speech and Signal Processing
(ICASSP), pages 2130–2134, April 2015. doi: 10.1109/ICASSP.2015.7178347.
Sebastian Münzner, Philip Schmidt, Attila Reiss, Michael Hanselmann, Rainer Stiefelhagen,
and Robert Dürichen. Cnn-based sensor fusion techniques for multimodal human activity
recognition. In Proceedings of the 2017 ACM International Symposium on Wearable Computers,
ISWC ’17, pages 158–165, New York, NY, USA, 2017. ACM. ISBN 978-1-4503-5188-1. doi:
10.1145/3123021.3123046. URL http://doi.acm.org/10.1145/3123021.3123046.
Jiquan Ngiam, Aditya Khosla, Mingyu Kim, Juhan Nam, Honglak Lee, and Andrew Y. Ng.
Multimodal deep learning. In Lise Getoor and Tobias Scheffer, editors, Proceedings of the 28th
International Conference on Machine Learning, ICML 2011, Bellevue, Washington, USA, June
28 - July 2, 2011, pages 689–696. Omnipress, 2011.
Daniel Olguín Olguín, Peter A. Gloor, and Alex Pentland. Capturing individual and group
behavior with wearable sensors. In AAAI Spring Symposium: Human Behavior Modeling,
2009.
Hao Peng, Jianxin Li, Qiran Gong, Yuanxing Ning, and Lihong Wang. Graph Convolutional
Neural Networks via Motif-based Attention. arXiv e-prints, art. arXiv:1811.08270, November
2018.
Soujanya Poria, Erik Cambria, Newton Howard, Guang-Bin Huang, and Amir Hussain. Fusing
audio, visual and textual clues for sentiment analysis from multimodal content. Neurocomputing, 174(Part A):50 – 59, 2016. ISSN 0925-2312. doi: https://doi.org/10.1016/j.neucom.2015.
01.095. URL http://www.sciencedirect.com/science/article/pii/S0925231215011297.
Junyuan Shang, Cao Xiao, Tengfei Ma, Hongyan Li, and Jimeng Sun. GAMENet: Graph
19

Augmented MEmory Networks for Recommending Medication Combination. arXiv e-prints,
art. arXiv:1809.01852, September 2018.
Cees GM Snoek, Marcel Worring, and Arnold WM Smeulders. Early versus late fusion in
semantic video analysis. In Proceedings of the 13th annual ACM international conference on
Multimedia, pages 399–402. ACM, 2005.
Kihyuk Sohn, Wenling Shang, and Honglak Lee. Improved multimodal deep learning with
variation of information. In Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems 2014, December 8-13 2014,
Montreal, Quebec, Canada, pages 2141–2149, 2014. URL http://papers.nips.cc/paper/
5279-improved-multimodal-deep-learning-with-variation-of-information.
Jacopo Staiano, Bruno Lepri, Nadav Aharony, Fabio Pianesi, Nicu Sebe, and Alex Pentland.
Friends don’t lie: Inferring personality traits from social network structure. In Proceedings
of the 2012 ACM Conference on Ubiquitous Computing, UbiComp ’12, pages 321–330, New
York, NY, USA, 2012. ACM. ISBN 978-1-4503-1224-0. doi: 10.1145/2370216.2370266. URL
http://doi.acm.org/10.1145/2370216.2370266.
Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua
Bengio. Graph Attention Networks. arXiv e-prints, art. arXiv:1710.10903, October 2017.
Petar Veličković, Laurynas Karazija, Nicholas D. Lane, Sourav Bhattacharya, Edgar Liberis,
Pietro Liò, Angela Chieh, Otmane Bellahsen, and Matthieu Vegreville. Cross-modal recurrent
models for weight objective prediction from multimodal time-series data. In Proceedings of
the 12th EAI International Conference on Pervasive Computing Technologies for Healthcare,
PervasiveHealth ’18, pages 178–186, New York, NY, USA, 2018. ACM. ISBN 978-1-4503-64508. doi: 10.1145/3240925.3240937. URL http://doi.acm.org/10.1145/3240925.3240937.
Rui Wang, Weichen Wang, Min S. H. Aung, Dror Ben-Zeev, Rachel Brian, Andrew T. Campbell, Tanzeem Choudhury, Marta Hauser, John Kane, Emily A. Scherer, and Megan Walsh.
Predicting symptom trajectories of schizophrenia using mobile sensing. Proc. ACM Interact.
Mob. Wearable Ubiquitous Technol., 1(3):110:1–110:24, September 2017. ISSN 2474-9567. doi:
10.1145/3130976. URL http://doi.acm.org/10.1145/3130976.
Rui Wang, Weichen Wang, Alex daSilva, Jeremy F. Huckins, William M. Kelley, Todd F.
Heatherton, and Andrew T. Campbell. Tracking depression dynamics in college students
using mobile phone and wearable sensing.

Proc. ACM Interact. Mob. Wearable Ubiquit-

ous Technol., 2(1):43:1–43:26, March 2018. ISSN 2474-9567. doi: 10.1145/3191775. URL
http://doi.acm.org/10.1145/3191775.
WHO. Innovative Care for Chronic Conditions: Building Blocks for Action. 2002.
Ziwei Zhang, Peng Cui, and Wenwu Zhu. Deep Learning on Graphs: A Survey. arXiv e-prints,
art. arXiv:1812.04202, December 2018.

20

Appendix A

Conference Paper: Ubicomp 2019
This work was co-supervised by Nic Lane and Matthew Craner, a neurologist based at the
Nuffield Department of Clinical Neuroscience, University of Oxford. We have recently submitted
this work to the November cycle of the Proceedings of the ACM on Interactive, Mobile, Wearable
and Ubiquitous Technologies (IMWUT).

21

1

Tracking Fatigue and Health State in Multiple Sclerosis Patients
Using Ubiquitous Sensing
Multiple Sclerosis requires long-term disease management, but tracking patients through the use of clinical survey instruments
is hindered by the high costs and patient burden involved. In this work, we investigate the feasibility of using data from
ubiquitous sensing to predict MS patients’ fatigue and health status, as measured by the Fatigue Severity Scale (FSS) and EQ-5D
index. We collected data from 198 MS patients who are given connected wellness devices for over 6 months. We examine
how accurately can the collected data predict reported FSS and EQ-5D scores per patient using an ensemble of regressors.
In predicting for both FSS and EQ-5D, we are able to achieve errors aligning with the instrument’ standard measurement
error (SEM), as well as strong and significant correlations between predicted and ground true values. We also show a simple
adaptation method that greatly reduces prediction errors through the use of just 1 user-supplied ground truth datapoint. For
FSS (SEM 0.7), the universal model predicts weekly scores with MAE 0.99, while an adapted model predicts with MAE 0.51.
For EQ-5D (SEM 0.093), the universal model predicts weekly scores with MAE 0.091, while an adapted model predicts with
MAE 0.052. Our study represents the first sets of results on tracking fatigue and health status of MS patients using ubiquitous
sensing, which gives promising prediction performance with errors aligns with the accepted range of error in the widely
used clinically-validated questionnaires. Future extensions and potential applications of our results can positively impact MS
patient disease management and support clinical research.
ACM Reference format:
. 2018. Tracking Fatigue and Health State in Multiple Sclerosis Patients Using Ubiquitous Sensing. 1, 1, Article 1 (November 2018), 24 pages.
https://doi.org/0000001.0000001

1 INTRODUCTION
Over 2.5 million people worldwide are affected by Multiple Sclerosis (MS), in many countries it is the most
common cause of neurological disability in young adults [28]. While not fatal, Multiple Sclerosis is a chronic
debilitation disease associated with significant health-related and economic burden to the quality of life [16].
MS has also been described as a highly individual disease, characterized by a variety of disabling symptoms
experienced by different patients, although excessive fatigue is the most frequent symptom [11]. As there is
currently no cure for MS, it is a life-long disease that affects the everyday lives of patients which they have to
learn to cope with. The complexity of MS demands that patients be active in their management of symptoms and
receive support for it [10].
Managing MS mainly involves keeping track of clinical outcomes, such as symptoms and health-related quality
of life. One of the most commonly reported symptoms of MS is overwhelming fatigue, and it is also amongst the
most frequently monitored. MS Fatigue is very different from what persons with MS may normally experience
after exercise, and often has a profound impact on patients’ quality of life [39]. Keeping a longitudinal record of
fatigue is not only important for patients’ self-management of the symptom, but also for developing treatment
methods and futhuring understanding of the disease. The Fatigue Severity Scale (FSS) is the most commonly
used unidimensional scale for measuring fatigue, it is a widely clinically validated questionnaire used by millions
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that
copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s).
© 2018 Copyright held by the owner/author(s).
XXXX-XXXX/2018/11-ART1
https://doi.org/0000001.0000001
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

1:2

•

of patients. In clinical trials, patients’ fatigue is reported longitudinally using FSS to demonstrate the efficacy of
drugs [17]. A large body of research also exists to address correlations between fatigue and other physiological
factors (e.g. structural damage to the brain [4]) and behavioral factors (e.g exercise, temperature [6, 39]). However,
since data collection is costly and slow, in longitudinal studies of MS fatigue, the data may only be collected
annually for 2-3 years. Many studies have noted the scarcity of more fine-grained records, pointing out the
limitations in sparse observations, which might lead to overlooking of important dynamic fluctuations [29].
For medical and economic researchers, an important measurement to collect is the Health-Related Quality of
Life (HRQoL). HRQoL is typically measured through self-reported questionnaires by the EQ-5D, which can be
interpreted as the health state pf a person. Policymakers make use of HRQoL to evaluate the effectiveness of
different health intereventions, so that resources are allocated effectively [8]. For MS, this means allocating more
resources to treatment that leads to a delay in patients’ progression to permanent disability, over treatment which
only temporarily avoids disability [16]. Longitudinal tracking of this metric is consequential to the resource
allocation decision making, however frequent data collection is again an issue (data collected over clinical trials
are deemed too short) so researchers typically rely on modelling for economic evaluations in multiple sclerosis
[16].
It is important for MS patients and researchers to track fatigue and health state over time, and researchers are
looking to track such metrics over longer terms and at more fine-grained intervals but are having difficulties due
to the high costs associated with data collection. Given this, we propose a study looking into tracking fatigue and
health state unobtrusively in the daily lives of MS patients through the use of connected wellbeing devices. We
are interested in applying machine learning techniques in delivering accurate predictions of pateints’ fatigue and
health state over time in a low user burden fashion, which could support patient’s self-management and further
understanding of more dynamic patterns of these health indicators.
We conducted a 6-month study of 198 MS patients which collected their behavioral, physiological and selfreported health information. Each patient was given 3 connected wellness devices (in-bed sleep tracker, smart
scale, smart watch) to use in their natural environments, these collect daily behavioral and physiological data
of the patient. In addition, through a companion app, patients may fill in daily evaluations of fatigue and sleep
quality, as well as weekly questionnaires containing the FSS and EQ-5D. In this work, we examing predicting FSS
and EQ-5D scores and in particular restrict ourselves to 2 tasks per index: 1. predicting the mean score over all
weeks reported by each patient, 2. predicting the score reported each week by each patient. We propose using an
ensemble of device-specific predictors for both tasks to improve performance and to handle issues arising from
missing modalities. To better account for person-to-person variations and improve generalization performance,
we further propose ways of personalization of the ensemble model, through the use of a minimal number of
self-reported scores by each patient.
The main contributions of this work is as follows:
• First study predicting MS patients’ reported fatigue severity scale (FSS) using data from connected devices
and daily reports at weekly intervals. We show that FSS (instrument error SEM 0.7) can be predicted with
MAE 0.99 with a universal ensemble model, and with MAE 0.51 with an adapted model. These results are
promising as they are within scales of the instrument error and also correlate significantly and strongly
with ground truths.
• First study predicting MS patients’ reported EQ-5D health state using data from connected devices and
daily reports at weekly intervals. We show that EQ-5D (SEM 0.093) can be predicted with MAE 0.91 with a
universal ensemble model, and with MAE 0.052 with an adapted model. These results are promising as they
are within scales of the instrument error and also correlate significantly and strongly with ground truths.
• Examination of data adaptation methods under this sparse data scenario. We compare a novel application
of the MAP-adapted Gaussian Mixture Regression Models with a simple residual error translation. We
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

Tracking Fatigue and Health State in Multiple Sclerosis Patients Using Ubiquitous Sensing

•

1:3

show that the latter (using just 1 week of user’s reported ground truth) is a pragmatic approach given the
high cost of data collection and it significantly improves model performance by 51% on average for FSS
and EQ-5D predictions.
• Investigation of predicting the per-participant averaged scores for FSS and EQ-5D over the 6-month study
period, which represents a more stable view. We show that the mean FSS can be predicted with MAE 0.95,
and mean EQ-5D can be predicted with MAE 0.84.
• Discussion and summary of insights from current study for future work in related directions.

2 BACKGROUND
In this section, we provide some background information about MS. Multiple Sclerosis is a chronic, often disabling,
disease of the Central Nervous System (CNS). As MS causes damage in the CNS, it can adversely affect nearly any
body function, the most commonly experienced symptoms include overwhelming fatigue, visual disturbances,
altered sensation and difficulties with mobility. From a clinical perspective, the course of MS is highly varied
and diverse, varying in types and severity between persons and within a person over time. Persons with MS
have a prolonged median survival time from diagnosis of around 40 years, and over this time the presentation of
MS changes. Most patients are initially diagnosed with Relapsing-remitting MS (RRMS), where they experience
relapses separated with periods of remissions. Many patients, over a span of 5 to 15 years, gradually transform
into steady deterioration, known as the Secondary progressive MS (SPMS). Two other rarer forms of disease
course are Primary-progressive MS (PPMS) and Progressive-Relapsing Multiple Sclerosis (PRMS). [10, 28]
Treatment. As of yet, there is no cure for MS. Modern treatment focuses on the management of symptoms
and disease course, but are only partially effective. To relieve symptoms and to promote a satisfactory quality
of life, MS requires patients to be active in the management of their own health [10]. Self-managing typically
involves keeping a symptom diary, where patients manually record their symptoms or activities to keep track of
their disease course, and there are a number of mobile apps developed which incorporate such diary function.
However, monitoring is a tedious process and as a reuslt can yield low patient adherence; in addition, it is prone
to errors due to the subjective nature of symptom recall [7], compounded with the possibility that some MS
patients might also experience cognitive symptoms such as memory difficulties.
Measurements. It is important to measure both fatigue and quality of life with robust, clinically validated
instruments as these are subjective phenomena which can only be measured subjectively. When using these
standard survey instruments, the health community also looks at their associated standard error of measurement
(SEM) to access the reliability of the instrument. FSS and EQ-5D both widely used instruments in the MS
community, with studies reporting SEMs of 0.7 and 0.093 respectively [20, 24].
Measuring Fatigue. A frequently used method for evaluating fatigue is the 9-item Fatigue Severity Scale (FSS)
developed by Krupp et al for use in patients with MS and systemic lupus [18], but has since been used frequently
in different populations of people with chronic illnesses [2, 14]. Fatigue Severity Scale (FSS) asks the patient
to rate their fatigue according to experiences of the previous week. Such clinically validated instruments are
typically used in doctor-patient interactions for doctors to benchmark changes in individuals during check-ups
at outpatient clinics, so this could mean FSS is typically collected about bi-annually despite being a weekly
instrument. However, in patient’s personal records of fatigue, such as their fatigue diary, patients typically use
arbitrary metrics that they find the easiest to record in and this often means simply a numerical rating of fatigue.
Efforts have been put into developing validated and quick measurements of fatigue in real-time, [15] asked 49
MS patients to wear a wrist-worn device preprogrammed to beep 4 times a day so that the patient would enter
his/her fatigue level (from 0 -10) into the device real-time. However other metrics have yet to gain traction and
FSS remains to most widely used metric in MS studies.
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

1:4

•

Measuring Quality of Life. The EQ-5D assessment instrument is widely used for measuring health-related
quality of life (HRQoL). EQ-5D covers 5 dimensions of health: mobility, self-care, usual activities, pain/discomfort,
and anxiety/depression [34]. There are two levels, 3-level EQ-5D (EQ-5D-3L) and 5-level 5Q-5D (EQ-5D-5L),
where level refers to the length of the Likert-Scale. The EQ-5D-5L, developed by Euroqol group, was shown to
have better discriminative capacity and sensitivity to changes in health status, as well as smaller ceiling effect
than the original 3-level EQ-5D [8]. It is a widely validated and assessed metric used in studies of MS and other
diseases. Country-specific value sets, reflecting trade-offs that individuals are willing to make between health
outcomes, were used to convert responses on the 5Q-5D-5L to a single-value health state index. This index is
anchored at 1 (perfect health) and 0 (death). Valuations less than zero reflecting health states âĂŸworse than
deathâĂŹ (WTD), can exist.

3 ANTICIPATED USAGE SCENARIOS FOR AUTOMATED MS TRACKING
Technology can support MS patients by offering useful tools to monitor their symptoms. In particular, the
proliferation of ubiquitous computing devices enables continuous personal monitoring, which may be extrapolated
for personal health management. This is part of the paradigm of Connected Health, where new models of health
management are rising to let the patient become the centre of the health care system, supported by ubiquitous
sensing.
Obtaining such longitudinal, granular, and objective records of patient conditions is valuable to both patients
and health care professionals. For patients, this information can supplement their current records, alleviates their
burden in record-keeping, and more importantly, they may use this to better understand their conditions, identify
symptom triggers leading to activity modification and lifestyle changes, and experiments with self-management
strategies with objective feedback. Case in point, most MS patients are physically inactive despite evidence of
exercise training being beneficial to their disease[19], a possible scenario is patients could use these fatigue
patterns to identify a good time for exercising, and to review how their fatigue levels change following different
exercise sessions. For health care professionals, they could work with patients using such more thorough history
to suggest activity modification and lifestyle changes that optimize their overall quality of life. When prescribing
treatment, they may also use this information to judge the effectiveness and suitability of treatment for the
individual patient.
On a research level, this represents a new stream of information that could allow researchers to better
understand the disease course with data from more patients and at finer timescales. This could bring potential
benefits in a number of areas in MS which has yet to be elucidated, e.g. the transformation from RRMS to SPMS
in an MS patient is poorly understood but has important implications for treatment as many drugs effective when
targeted at RRMS seem useless with SPMS [28].
Whilst this study remains the first step towards a fully-deployable system available for MS patients, we envision
that such a system would have the following features:
• Universal model for tracking MS symptoms with the ability to personalize. When users first started using
the smart devices, predictions would be made using a universal model. Over time the model would better
adapt to the user’s data based on accumulation of data.
• Continuous analysis. Behavioral and physiological passive sensing data from user’s smart devices would be
continuously collected, and automatically uploaded to a secure server for processing or processed locally on
the device. Weekly feedback reports could be generated and available for the user to view in a companion
phone app.
• Remote monitoring. Data and predictions visualizations for health care professionals or other parties that
the patient might choose to share this information with.
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

Tracking Fatigue and Health State in Multiple Sclerosis Patients Using Ubiquitous Sensing
(b) Daily questions

(a) Device measurements

0.6
0.4
0.2

Cumulative Probability

Cumulative Probability

Cumulative Probability

0.95

0.8

0.90
0.85
0.80
0.75
0.70

0.0

25

50
75
100 125 150
No. of days with device measurements

175

1:5

(c) Weekly questionnaires

1.00

1.0

•

1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2

20
40
60
80
100
No. of days where participant answered a daily question

5

10
15
No. of weekly surveys answered

Fig. 1. CDFs of amount of data collected over the population of 198 participants.

• Suggesting personalized recommendations. Based on device measurements, FSS predictions, and availability
of other information, e.g. weather, suggest possible correlations and triggers for patients (and their doctors)
to review.

4 DATA COLLECTION AND PROCESSING
In this section, we describe the study carried out, the data collected and preprocessing done.

4.1 MS Study
We conducted a study with 198 patients diagnosed with Multiple Sclerosis who are based in the United States.
The participants were recruited online for a 6-month study which seeks to understand their MS condition using
connected health devices, which the participant could keep after study completion. The devices are commercial
products under the Withings range, namely Aura (sleep tracker), Activité Steel (smart watch) and Body Cardio
(smart scale). At the beginning of the study, each participant was given the three devices and was asked to
complete a screener survey on background information about their MS. Participants were informed that the
measurements on their devices over the study duration would be collected and analysed, they are free to deploy
the devices at home (or outdoors in case of smart watch) and use them as frequently or infrequently as they would
like. Through a companion app, patients may review their data, and also be prompted to answer questionnaires
about their condition periodically. A weekly questionnaire contains two clinically valid questionnaires widely
used in understanding MS (Fatigue Severity Scale (FSS) and the EQ-5D-5L), whereas two daily questionnaires,
with one question each, ask the participant to rate his/her fatigue and sleep quality.

4.2

Data

The data studied consists of the following components: 1. Daily device measurements, 2. Daily reports, 3. Screener
questionnaire, 4. Weekly questionnaires. For the purposes of this work (i.e. predicting FSS and EQ-5D scores), we
build a universal model for the entire pool of participants using data from the first 3 components, and obtain the
ground truths for these scores from the completed weekly questionnaires of each participant. Figure 1 shows the
cumulative distributions of the amount of data collected for each of the components (except for the screener
questionnaire which every participant has to complete).
Daily device measurements. Three products from the Withings range [1] (sleep tracker, smart watch, smart
scale) provide measurements that may capture the time-varying quality of the MS condition relating to sleep,
activity, and physiological changes. These devices deliver a ’new type of data’, referring to the derived or inferred
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

20

1:6

•

Fig. 2. Device data is collected from watch, aura, and scale. Daily and weekly surveys are collected through the app.
(a) App

(b) Watch

(c) Aura (Sleep tracker)

(d) Scale

data produced using machine learning algorithms associated with each device. We analyze this derived data,
consisting of physiological and behavioral measurements aggregated over each day (e.g. step count of a day) so
as to increase the explainability of this work given its medical context. An exhaustive list of the measurements
produced by each device and associated modalities is provided in Table 1. For each participant, 189 days of
their device data were extracted for analysis from November 2016 to May 2017. Device usage varies, with the
participants contributing a mean of 122.8 days with at least one valid device measurement; there are 3 participants
who produced no valid device data at all during the study period.
• Withings Aura (sleep tracker). The Aura system consists of two devices, a sleep sensory pad placed
underneath the mattress, and a bedside device with environmental sensors which can act also as a smart
alarm clock, speaker and lamp. Aura provides daily inference data on sleep quality and heart rate.
• Withings Activité Steel (smart watch). The Activité Steel is a wearable device which tracks activities (gait,
running, swimming and sleeping). We only consider data on gait and sleeping as proxies to participants’
activities and sleep respectively.
• WIthings Body Cardio (smart scale). This scale provides readings on weight, fat, muscle, water and heart
health. The scale provides pulse wave velocity (PWV), the rate at which blood pressure pulse propagates
through the circulatory system, which is an important clinical parameter for evaluating cardiovascular risk
[25]. The scale can be set up for multiple users in case the participant’s family might use it, so that data for
each user stays separate, however only data from the patient’s profile were collected.
• Health Mate App. This is a commercial app developed for use in conjunction with Withings devices currently
used by millions of users. With the app, users create a profile to which data gathered from all Withings
products will be synced. The user may use the app to visualize and review the data, set goals and reminders,
or manage their devices [23]. Although not a focus of the current study, additional functions available on
the app include leaderboard and reward badges for certain wellness achievements (e.g. step count). In this
study, the app is also a portal for participants to access the daily and weekly questionnaires.
Note on Modalities. We group measurements into modalities shown in Table 1 which are meaningful together
(e.g. ’aura’ for sleep behavior collected ). This is also to account for the gaps in our dataset, so that we separate
measurements which do not always appear together into different modalities, this is seen in measurements of
body composition, where a valid fat mass may not always be available. Also, we keep sleep measurements made by
Aura and the watch separate, as we observed that a model trained from a mixed dataset gives poorer performance.
This is in accordance with the procedure taken in similar situations [38] and relates to the heterogeneous sensing
capabilities and machine learning algorithms associated with each device.
Daily questions. The patient may indicate his/her daily fatigue level and sleep quality on a 5-point Likert
scale, from No to Extreme Fatigue, and Very Good to Very Bad Sleep. Each question is prompted independently
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

Tracking Fatigue and Health State in Multiple Sclerosis Patients Using Ubiquitous Sensing

•

1:7

Table 1. Sources of data in this study, their associated modalities and measurements. Note that the sources ’Fatigue’, ’Sleep’,
’Weekly Survey’ are actually obtained through the app but for purpose of later analysis we consider these individually.

Source

Modality

Measurements

Aura
(sleep tracker)

Aura

sleep duration, bed-in/out times,
time to sleep, time to wake,
no. of times of being awake,
duration of awake/ light/ REM/ deep sleep

Night

night heart rate, night respiratory rate

Watch

sleep duration, bed-in/out times,
time to sleep, time to wake,
no. of times of being awake,
duration of awake/ light/ deep sleep

Steps

step count

Walk

walking speed

Weight

weight

Composition

bone mass, hydration mass, muscle mass

Fat

fat mass

Pwv

pulse wave velocity (pwv)

Standing HR

standing heart rate

Faituge

Fatigue Level

daily fatigue level score (non-clinical)

Sleep

Sleep Quality

daily sleep quality score (non-clinical)

Weekly Survey

Weekly Survey

(response usage)

Screener Survey

Static

age, gender, height, disability level,
type of ms, years since diagnosed,
symptoms (e.g. fatigue, memory loss, motor deficits)
other diseases (e.g. depression, heart disease, epilepsy)
current and past treatment (e.g. use of disease-modifying agent, drug name)
ideas about MS (e.g. understanding of the implications of gaps in treatment)
technology use (usage and ownership of tech products)
source of treatment finance (insurance or own pocket)

Watch

Scale

through the app, so the participant can answer only one or both of these questions. For this reason, we treat data
from each question as a separate modality. In total, there are 3316 daily reports collected, however, there is low
participation as more than half the participants (125) did not attempt this at all.
Screener questionnaire. This collects self-reported socio-demographic variables and clinical variables from
each participant before the commencement of the study. All of the collected variables are categorical with the
exception of age, height and number of years with MS. All 198 participants completed the screener questionnaire.
• Socio-demographic variables. This collects data on demographics, the patients’ understanding of MS, use
of technology to monitor health, as well as the patient’s mode of financing treatment. There is a gender
imbalance in the dataset (184 female, 14 male), as seen in most MS studies due to the higher risk of the
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

1:8

•
female population being affected. 184 participants reported they own a smartphone, while the remaining 4
own at least a tablet or Apple iPod touch.
• Clinical variables. This collects data on the patient’s MS, symptoms experienced, other co-existing diseases,
and their treatment method. Variables from symptoms and co-existing diseases are dichotomized into yes
or no, so only a binary indication of whether symptoms/disaese are present is available. The majority of
the participants (191 out of 198) suffer from RRMS, the most popular form of MS.

Weekly questionnaires (Fatigue and Health State Ground Truth). The weekly questionnaire is formed of
two standard questionnaires which, in addition to being used for studying patients with a variety of disorders,
have been widely used for MS study and management. Participants can access this questionnaire through the
Health Mate app. A complete response to every question on the questionnaire (from both instruments) is required
to qualify as a valid response. We use the FFS and EQ-5D-5L index scores as our ground truth. We use the
notation FSS-W and EQ-W to refer to the FSS score and EQ-5D-5L index value obtained from each weekly survey
respectively; and we use FSS-M and EQ-M to refer to the mean per-participant score of FSS-Ws and EQ-Ws
obtained from all weekly surveys completed by each participant. In total, 1693 weekly surveys were completed,
however 24 participants did not complete any weekly surveys at all.
• Fatigue Severity Scale (FSS). The FSS is a 9-item questionnaire each item is scored on a 7-point Likert
scale, ranging from ’strongly disagree’ to ’strongly agree’. The items relate to the severity of fatigue (e.g.
My fatigue prevents sustained physical functioning. )and its effects on a person’s activities and lifestyle
(e.g. Fatigue interferes with carrying out certain duties and responsibilities.) It also covers the emotional
implications of fatigue (e.g. My motivation is lower when I am fatigued.). The responses are rated on a
7-point Likert scale, and the overall FSS score is taken as the mean of the 9 responses. FSS score ranges from
1 to 7, where a score of 7 would mean strongly agreeing with all items, and a score of 1 strongly disagreeing
with all items. A higher FSS suggests higher levels of fatigue. In the medical literature, a number of studies
have been carried out validating the instrument, one study suggests that the standard error of measurement
(SEM) of FSS was 0.7 points, and that a change in FSS of less than 0.7 points may be due to measurement
error [20].
• EQ-5D-5L index value. The EQ-5D-5L index is a single index value computed from the EQ-5D-5L descriptive
system, which describes a person’s health state relative to others in the country. The conversion from
5-dimensional 5Q-5D-5L health state to the single value is done using publicly available country-specific
value sets, and in this case, US-specific [33]. The 5Q-5D-5L index value ranges from 0 to 1, with 0 meaning
death and 1 complete health [26].

4.3

Preprocessing into Features

We construct features for prediction by considering the relevant time series, and aggregating the measurements
over the time series to produce useful statistics. We also compute a usage feature for the 6 sources (aura, watch,
scale, fatigue question, sleep quality question, weekly survey) after realising that the missingness in data might
be informative about participant’s behavior as well.
FSS-M and EQ-M. For predicting FSS-M and EQ-M, the relevant time series is the entire 6-month time series
for each participant. We aggregate measurements over the time series for mean, maximum, minimum, standard
deviation, range, and usage. For each smart device, we compute usage as the proportion of days that a device is
used. For the daily questions, usage is the proportion of days that the participant responded to each question.
Finally for the weekly surveys, usage is the proportion of weeks that the participant has completed a weekly
survey.
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

Tracking Fatigue and Health State in Multiple Sclerosis Patients Using Ubiquitous Sensing
(e) EQ-M (mean EQ-5D-5L index)
0.5

3.5

0.4

2.5

Probability

Probability

3.0
2.0
1.5
1.0

0.3
0.2
0.1

0.5
0.3

0.4

0.5

0.6
0.7
0.8
Mean EQ-5D-5L Score

0.9

0.0

1.0

1

2

(g) EQ-W (weekly EQ-5D-5L index)

6

7

6

7

0.35
0.30

250
Probability

200
150

0.25
0.20
0.15

100

0.10

50

0.05

0

3
4
5
Mean Fatigue Score

(h) FSS-W (weekly FSS score)

300

Probability

1:9

(f) FSS-M (mean FSS score)

4.0

0.0

•

0.2

0.4

0.6
EQ-5D-5L Score

0.8

1.0

0.00

1

2

3

4
5
Fatigue Score

Fig. 3. Distribution of computed FSS and EQ-5DL index scores, with a red line representing the median.

FSS-W and EQ-W. For predicting FSS-W and EQ-W, the relevant time series are time windows close to the
date of completing the weekly survey. For example, for a weekly survey completed on day d, we consider 2 time
windows with length l before d, such that the i th window spans from day d − il to day d + il. We aggregate
measurements over each time window for mean, maximum, minimum, standard deviation, range, and usage.
Here, usage is defined slightly differently as we would like to compare the usage behavior within the relevant
time window and outside the window. Usage is the ratio between the number of days a measurement (device/
daily question) is obtained within the window and outside the window. In addition, we also compute usage for
the weekly questionnaires itself, defining it as the ratio between the number of completed weekly surveys so far
(up till the current time window) and the number of weeks elapsed since the participant’s first completed weekly
survey.
Usage Features. While the missingness in data could create problems in limiting the number of datapoints,
we also tried to make use of the missingness in data to represent the device usage behavior of the patients. We
propose that the usage behavior of different devices or modalities could be related to the psychological decisions
that the user makes and thus gives some hints about their emotional state as well. This is especially true for the
usage of daily questions, as it relates to whether the user chooses to report his/her health state for the day.

4.4 Correlations of Features with Ground Truth
In Figure 4 (a) and (b), we present the correlation matrices of the mean measured features computed and FSS-W
and EQ-W scores. Correlations with the computed score are presented on the top row whereas the rest are
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

1:10

•
(a) FSS-W

overall fatigue score
lower motivation
exercise brings fatigue
easily fatigued
fatigue interferes w. physical func.
fatigue causes frequent problems
fatigue prevents sustained physical func.
fatigue interferes w. duties
fatigue 3 most disabling symptoms
fatigue interferes w. work social life

0.4
0.2
0.0
0.2

aur
a

aur _awa
k
a
aur _dee e_du
a_l psl aur rati
igh eep a_b on
aur tslee _dur edin
a_r aur p_d atio
e a u n
aur msle _nb_ ratio
a e a n
a _sl p_d wa
aur ura_ eep_ urati ke
a_t tim dur on
ime e_t atio
_to o_sl n
_ e
bonwakeep
fat
igu f e_maup
e a s
hyd_levet_ma s
rat l_sc ss
io o
nig nigmusc n_m re
ht_ ht_ le_ ass
res he ma
pi art ss
sle ratory_rate
ep_
_ra
qu
alit p te
sta y_sc wv
nd ore
wa
tch wa ing_h
l
_
a k s r
wa
tch wakeing_s teps
p
wa _de
tch ep wa _dura eed
_lig sle tch tio
hts ep_ _be n
l d d
wa wat eep_durati in
tch ch_ ur on
wa _sle nb atio
tch ep _aw n
_tim _du ak
e_t rati e
o_s on
l
weeep
igh
t

0.4

(b) EQ-W

0.4
0.2
0.0
0.2
0.4

aur
a
aur _awa
k
a
aur _dee e_du
a_l psl aur rati
igh eep a_b on
aur tslee _dur edin
a_r aur p_d atio
e a u n
aur msle _nb_ ratio
a e a n
aur _sleep_du wake
aur a_ p_ rati
a_t tim dur on
ime e_t atio
_to o_sl n
_ e
bonwakeep
fat
igu f e_maup
e a s
hyd_levet_ma s
rat l_sc ss
io o
m
nig nig usc n_m re
ht_ ht_ le_ ass
res he ma
pi art ss
sle ratory_rate
ep_
_ra
qu
alit p te
sta y_sc wv
nd ore
wa
tch wa ing_h
_a lk s r
wa
tch wakeing_s teps
p
wa _de
tch ep wa _dura eed
_lig sle tch tio
hts ep_ _be n
l d d
w
wa at eep_durati in
tch ch_ ur on
wa _sle nb atio
tch ep _aw n
_tim _du ak
e_t rati e
o_s on
l
weeep
igh
t

EQ-5D-5L score
anxiety_depression
mobility
pain_discomfort
self_care
usual_activities

Fig. 4. This shows correlation of the mean measurements with FSS-W, EQ-W and their components. Note that the number
of datapoints used to compute each correlation varies as the features are present in varying abundancies.

correlations with the sub-items scores. When viewing row by row, one can see that different dimensions of
fatigue or health state are more strongly correlated with the features available. ’Exercise brings fatigue’ for FSS-W
and ’mobility’ for EQ-W are the sub-items which has the largest average correlation with the mean features,
which aligns with the common intuition that about the spectrum of wellness that such health devices may be able
to capture. The correlation matrices also show that each data source has features which demonstrate significant
correlations with fatigue and health states, and that the daily question of fatigue level score, despite its limited
data, demonstrates a strong correlation with both FSS-W and EQ-W.
There are cases where we observe that the correlation polarity found between the same feature measured by
Aura and the smart watch are opposite, namely ’time to sleep’ and ’awake duration’ with FSS-W. In both cases,
the polarity given by the mean Aura features are overwhelmingly positive, but negative for the Watch features.
One might imagine that the model computing ’time to sleep’/’awake duration’ taking data from a wearable watch
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

Tracking Fatigue and Health State in Multiple Sclerosis Patients Using Ubiquitous Sensing

•

1:11

being quite different from one taking data from a stationary sensor pad, especially during these stages where the
user is not (yet) sleeping and is possibly moving about a lot more than during sleep. However, this ascertains our
treatment of the measurements generated by the two devices as separate sources, and also raises precautions
over our interpretation of any found correlations between features and ground truth, that it is best to reiterate
that derived data has been used in the process.
In addition, to validate the inclusion of the usage feature, we also looked into the correlations between the
usage features and FSS-M and EQ-M scores. In particular, we observe that the highest correlation is found at
r=0.13 between the usage of the fatigue daily question and an item in the FSS-M relating to fatigue leading to
lower motivation in MS patients. This aligns with our conjecture that these usage features might be informative
about a user’s emotional state.

5 METHODS
As an overview, we perform three main arms of investigations:
(1) Predicting per-participant FSS-M and EQ-M. This relates to a stable 6-month view of fatigue and health
states. We compare model performance.
(2) Predicting weekly FSS-W and EQ-W. This relates to a dynamic weekly view of fatigue and health states. We
compare performance between universal models here.
(3) Achieving personalization via adaptation to individual user’s data. This is for predicting FSS-W and EQ-W.
We compare performance between adapted models here using small amounts of user-supplied ground truth
labels.
In the following, we describe our model formulations, fine-tuning and evaluation procedures for these prediction
tasks.

5.1

Ensemble Model

Our main results are derived through use of an ensemble model of regressors. We explain this choice and its
construction in this subsection.
As features from multiple modalities are present to a varying degree in our dataset, it is desirable to learn
accurate models which can leverage information from multiple modalities while considering as many datapoints
as possible. Motivated by this, we adopt an ensemble learning structure, formed by using predictors focusing
on different spectrums of the data which has high data concentration. This in effect means having an ensemble
of predictors trained specifically with data of the same modality, or source. Ensemble methods often offer
better inference performance than that produced by its components. Unless otherwise specified, we consider an
ensemble of source-specific classifiers, which use data from one of 6 sources, namely aura, scale, watch, daily
fatigue question, daily sleep-quality question and static (screener survey). However in order to be considered as
a valid datapoint, features must come from at least one other source besides than static, this is to ensure that
time-varying data is included.
Weighting function. In combining the predictions given by each modality, we put to use the resulting feature
importance vector generated per use in the feature selection phase. We compute the mean feature importance
per source, arguing that this would give a good representation of prediction confidence of each regressor. We
normalize the mean importance with softmax function, the final prediction of a datapoint x i is given by:
ŷi =

Õ

ν ∈Γi

w ν ŷν i

exp( ŷν i f¯ν )
¯
ν ∈Γi exp( ŷν i fν )

where w ν = Í

(1)

where f¯ν is the mean feature importance of source ν , and Γi is the set of sources that are present in x i
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

1:12

•

𝒙𝒊

𝑛/𝑎

𝑎𝑑𝑎𝑏𝑜𝑜𝑠𝑡𝑅

𝑥⃗#$%&',)

𝑎𝑑𝑎𝑏𝑜𝑜𝑠𝑡𝑅

𝑦.#$%&',)

𝑎𝑑𝑎𝑏𝑜𝑜𝑠𝑡𝑅
𝑎𝑑𝑎𝑏𝑜𝑜𝑠𝑡𝑅

𝑦.*%+$,,)

𝑎𝑑𝑎𝑏𝑜𝑜𝑠𝑡𝑅
𝑎𝑑𝑎𝑏𝑜𝑜𝑠𝑡𝑅

𝑦.#&''; =.,)

𝑥⃗*%+$,,)
𝑛/𝑎

𝑥⃗#&''; =.,)
𝑥⃗#+%+)$,)

∑
∑

𝑦.)

𝑦.#+%+)$,)

Fig. 5. Schematic of the ensemble model. A testing datapoint may not contain features from every source, depending on
the availability of features, source-specific regressors make individual predictions, and are weighted by wν to give a final
prediciton. In this example, data from aura and the daily fatigue question are not present.

Ensemble of AdaBoost Regressors (AdaboostR). We use an ensemble of source-specific AdaBoost Regressor
(AdaboostR) [9], where each regressor is trained independently on data of a specific source, namely the aura, scale,
watch, or static (i.e. features from the screener survey). The component regressors have the same initializations
but use different sets of features, resulting from independent feature selections. At testing phase, each regressor
makes prediction using its associated subset of features from the datapoints, sources which are not present
are ignored and no prediction is made. Finally a weighting function is used to average all the predictions. As
illustrated in Figure 5, a major advantage of using an ensemble is that datapoints with different missing modalities
can be considered.
The component regressor AdaboostR itself is an ensemble method. It fits predictors sequentially on a given
dataset by setting weights to the predictors and the datapoints such that the subsequent predictors focus more
on difficult cases. The choice of AdaboostR as the component regressor is driven by its accurate and robust
performance, as will be discussed in later sensitivity analysis. Throughout the paper, we use AdaboostR to refer
to the ensemble of AdaboostR.
Ensemble of Gaussian Mixture Regression Models (GMR). We compare the ensemble of AdaboostRs with
an ensemble of Gaussian Mixture Regression Models (GMR) with diagonal covariance matrices. The latter choice
is tied to our later considerations of model adaptations using a Maximum A Posterior (MAP) method with GMR.
Gaussian Mixture Regression is a technique developed for multivariate nonlinear regression modelling, it
constructs a sequence of M Gaussian mixtures for a joint density of the data, and then derive conditional density
and regression functions from each mixture [31]. Although in other texts ’mixture’ and ’component’ is used
interchangbly, to avoid confusion, we refer to Gaussian mixture components д as ’mixtures’, and the Gaussian
mixture model itself as a ’component’ of the ensemble model. We use GMR with M = 3 in our investigation.
The ensemble of GMRs is constructed in the same way as for AdaBoostR, where each GMR is trained independently per source using the Expectation Maximization (EM) algorithm. To initialize the EM algorithm, we use the
k-Means++ algorithm to set initial means and variances of each GMR mixture. One important distinction from
the ensemble of AdaBoostRs is that, predictions from component GMRs are combined using weighting function
(Eq. 1) but instead of using the mean feature importance per source, we use the confidence statistics generated by
the GMR models to weight the different component GMR per sample. In effect this means the weightings are
dynamic and are computed on a case by case basis.

5.2 Model Adaptation
We explored ways of model adaptation of the above-mentioned universal prediction models (trained on data
from all users), so that they may be trained on user-specific data give better generalization performance.
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

Tracking Fatigue and Health State in Multiple Sclerosis Patients Using Ubiquitous Sensing

•

1:13

MAP-Adapted GMR. We consider a model adaptation method developed in [27] for speaker verification
using Adapted Gaussian Mixture Models (GMM). Although originally intended for classification of speakers, this
method satisfies our need for adapting to data specific to an individual in order to achieve better generalization.
As we are considering regression, we adopt the formulation to Gaussian Mixture Regression (GMR) models [31]
instead.
The main idea of MAP-Adapted GMR is to adopt the parameters of the GMR using Maximum A Posterior
(MAP), by modifying the Maximization step in the EM-algorithm according to new observations, which in our
case refer to the user-specific data. Each universal GMR would be modified that the posterior probabilities of the
unimodal gaussian component given the new observations are maximized. As this is a non-iterative process so
once the new sufficient statistics are calculated, the adaptation only needs to be performed once for each new set
of observations.
The adaptation procedure is as follows: We first use data from the training set to produce an ensemble of
universal GMR models, each with weight, mean and covaraince matrix parameters λν (w, µ, Σ). Then we consider
user u from the testing set, and prepare his/her first T observations to be used for adaptation, Xu = {x 1 , ..., x T }.
For gaussian component д of each GMR λν , the component’s posterior probability given the observation x t is
(we omit the ν indexes for clarity in the following equations):
wд pд (x t )
p(д | x t ) = ÍM
k =1 w k pk (x t )

(2)

Using the posterior probability of the component д, we then can calculate sufficient statistics for updating the
weight, mean and variance:
nд =

T
Õ
t =1

1 Õ
p(д | x t )x t ,
nд t =1
T

p(д | x t ) ,

Eд (x) =

Eд (xx ′) =

1 Õ
p(д | x t )x t x t′
nд t =1
T

(3)

The updated parameters of the MAP adapted GMM are calculated using α as follows:

(4)

αд = nд /(nд + τ )
wˆд = [αд nд /T + (1 − αд )wд ]γ

,

µˆд = αд Eд (x) + (1 − αд )µд ,

(5)

σˆд 2 = αд Eд (xx ′) + (1 − αд )(σд2 + µд2 ) − µˆд 2
(6)
ÍM
where γ is a normalization coefficient such that д ŵд = 1 and τ is a relevance factor of the original model, a
higher τ means a greater weighting will be given to the universal model.

Translation Using Residual Error. The second approach consists of a very simple transformation and was
motivated by insights when analyzing prediction results given by the universal models by adjusting residual errors.
This is motivated by the observation that for most predictions given by the universal models, the predictions
were consistently off by some similar value for datapoints belonging to the same user. The simple transformation
to adjust this is, to use the bias for the user’s first completed weekly questionnaire, and to apply this bias onto all
subsequent predictions given to that user. In effect, we apply a scalar translation of the prediction according to
the residual error of the first week. Subsequent weeks’ predictions are given by:
(7)

ŷi′ = ŷi + b
where b is the residual error for the first week reported by the user which yi is associated with.

, Vol. 1, No. 1, Article 1. Publication date: November 2018.

1:14

•

5.3

Model Selection and Evaluation

Here we describe how we select features, fine-tune for hyperparameters, and evaluate the model performance.
Feature Selection. We have a total of 248 features and 1508 examples. We split users in the dataset randomly
for training and testing, so that roughly 80% of the datapoints are in the training set and 20% in the testing set.
We further divide the training dataset into source-specific subsets. Feature selection is done using the importance
vector of AdaboostR per source. Each subset of data is fed into an AdaboostR, which generates an importance
vector through averaging the importance vectors provided by its base regressors. We select features with a feature
importance above the mean importance iteratively until the number of selected features are under a certain
threshold D, per source. D is determined through grid search for each model in each prediction task.
Hyperparameter tuning. The hyperparameters (feature threshold, window length, window end-day, number
of windows, imputation thresholds) are selected through a grid search process where integer values within a
reasonable range for each hyperparameter were tested. We use leave-one-user-out cross validation such that
such that the average mean absolute error is minimized.
Evaluation. As baseline, we also report results on a hypothesized model which always predicts the global mean
score for each prediction task. We report performance achieved by the considered models using the following
metrics:
• Mean Absolute Error (MAE). To assess the absolute difference between predicted values and ground truth
across the entire population. For FSS this is with reference to a score that ranges from 1 to 7, and for
EQ-5D-5L a score that ranges from 0 to 1.
• Pearson correlation r . To assess the correlations r between predicted values and ground truth across the
entire population, where p-value means the significance.

6 PREDICTNG FATIGUE AND HEALTH STATE USING UNIVERSAL MODELS
In this section, we present prediction results of the universal ensemble models of AdaboostR and GMR for the
prediction tasks of FSS-M and EQ-M, and FSS-W and EQ-W.

6.1

Predicting FSS-M and EQ-M

Table 2 and 3 shows the performance of the prediction models in predicting mean fatigue and health state
respectivel, both ensemble models of AdaboostR and GMR outperform baseline and achieve signifcant and strong
correlation with ground truth.
Figure 6 shows a comparison of the MAE distribution across tested users for both models. In both tasks, the
generalization performance of the ensemble models closely match each other, with the 75th-percentile for the
FSS-M task averaging at 1.41 points in a 1-to-7 scale, and that of the EQ-M task averaging at 0.089 on a 0-to-1
scale.
Through grid search, we find that the threshold for number of features D should be in the 18 to 20 range for
both tasks. The consequence of this large threshold per source is mainly explained by its effect on limiting the
number of static features sourced from the screener questionnaire. For sources such as the daily sleep quality
question, the effect of having a large D has no effect since it only has 6 features. However, this becomes a
significant criteria for the static source, which has 82 features. The observation that the models would perform
better when considering more static variables makes sense as predicting the mean scores relates to capturing
more stable relations that may be better captured by the static variables.
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

Tracking Fatigue and Health State in Multiple Sclerosis Patients Using Ubiquitous Sensing
mae
r

Baseline AdaboostR
1.05
0.95
0.57*

GMR
1.00
0.34*

mae
r

Table 2. FSS-M, * p<0.05

1.0

GMR
AdaboostR

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.0

GMR
0.084
0.72*

(b) EQ-M

Cumulative Probability

Cumulative Probability

0.9

AdaboostR
0.086
0.63*

1:15

Table 3. EQ-M, * p<0.05

(a) FSS-M
1.0

Baseline
0.11
-

•

GMR
AdaboostR

0.8
0.6
0.4
0.2

0.5

1.0

1.5

2.0
mae

2.5

3.0

3.5

0.05

0.10

0.15

0.20
mae

0.25

0.30

0.35

Fig. 6. CDFs of MAEs obtained in predicting FSS-M and EQ-M.

6.2 Predicting FSS-W and EQ-W
Table 4 and 5 shows the performance of the prediction models in predicting weekly fatigue and health state
respectively. AdaboostR consistently achieves better MAE than the baseline and GMR in both tasks, outperforming
GMR by 17.4% on average.
Figure 6 shows a comparison of the per-person MAE distribution across tested users for both models. AdaboostR
is seen to achieve better generalization performance, this is especially true for the FSS-W task, where GMR is
seen to result in a large error of 3.5 points in the worst case, while AdaboosR results in MAE of 2 points in the
worst case.
For these tasks, we observe setting the number of features D as lying between 9 to 11 work best. The above
results are computed with the number of time series windows consider set as 2, time series length as 10. For
FSS-W prediction, the best model for AdaboostR only consists of the subset of source regressors from watch,
daily fatigue question, and static.

MAE
r

Baseline AdaboostR
1.26
0.99
0.65*
Table 4. FSS-W, * p<0.05

GMR
1.20
0.25*

MAE
r

Baseline
0.11
-

AdaboostR
0.091
0.61*

GMR
0.11
0.56*

Table 5. EQ-W, * p <0.05

7 MODEL ADAPTATIONS
For model adaptations, we compare two approaches: MAP-Adapted GMR with T user-supplied labels (AdaptedGMR (T )), and residual-error shifted AdaboostR (Adapted-AdaboostR). The model performances are compared in
Table 6 and 7.
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

1:16

•
(b) EQ-W

(a) FSS-W
1.0

GMR
AdaboostR

0.8

Cumulative Probability

Cumulative Probability

1.0

0.6
0.4
0.2

GMR
AdaboostR

0.8
0.6
0.4
0.2

0.0
0.0

0.5

1.0

1.5

2.0
mae

2.5

3.0

3.5

0.05

0.10

mae

0.15

0.20

0.25

Fig. 7. CDFs of MAEs obtained in predicting FSS-W and EQ-W.

Baseline
MAE
r

1.26
-

UniversalAdaboostR
0.99
0.65*

Universal- AdaptedGMR
AdaboostR
1.20
0.51
0.25*
0.91*

Adapted GMR(1)
0.97
0.65*

Table 6. FSS-W predictions using universal and adapted models using 1 user-supplied datapoint,* p<0.05

Baseline
MAE
r

0.11
-

UniversalAdaboostR
0.091
0.61*

Universal- AdaptedGMR
AdaboostR
0.11
0.052
0.56*
0.87*

Adapted GMR(1)
0.085
0.80*

Table 7. EQ-W predictions using universal and adapted models using 1 user-supplied datapoint, * p<0.05

7.1

Adapted Gaussian Mixture Regression

Despite the small number of datapoints being available per person, we observe that the MAP-Adapated GMRs
works well in giving better performance than the universal GMRs. The degree to which performance is improved
is observed to be closely related to the number of adapted datapoints per individual T . We varied the number
of datapoints from 1 to 10 and found that the MAE decreases monotomically as the number of datapoints T
increases. As shown in Figure 8, on the whole the MAE distributions shifts more to the left as more datapoints are
being adapted, for both FSS-W and EQ-W. In both cases, only using 1 datapoint per person is enough to improve
the MAE distribution significantly, for FSS-W, this means a drop of 19% of MAE from 1.20 to 0.97, and for EQ-W,
a drop of 23% from 0.11 to 0.085.
In addition, we also consider the changes in MAE per person using the universal versus MAP-adapted GMR.
At T = 2, 4 out of 28 users experienced a small increase in MAE when using the MAP-adapted GMR, averaged at
3.5%. In the worst case, one user’s MAE increased by 5%. Upon closer inspection we find that this user’s first 2
weeks of data only consisted of static and Aura data, so only MAP-Adapted GMRs are available for these sources.
This user started using all other modalities in the subsequent weeks, but predictions were made for those sources
using GMR components which are not adapted to his/her data.
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

Tracking Fatigue and Health State in Multiple Sclerosis Patients Using Ubiquitous Sensing

1.0

0.8

0.8

0.6
GMR
Adapted-GMR(1)
Adapted-GMR(2)
Adapted-GMR(3)
Adapted-GMR(4)
Adapted-GMR(5)
Adapted-GMR(10)

0.0

0.0

0.5

1.0

1.5

mae

2.0

2.5

3.0

Cumulative Probability

Cumulative Probability

1.0

0.2

1:17

(b) EQ-W

(a) FSS-W

0.4

•

0.6

0.2
0.0
0.00

3.5

GMR
Adapted-GMR(1)
Adapted-GMR(2)
Adapted-GMR(3)
Adapted-GMR(4)
Adapted-GMR(5)
Adapted-GMR(10)

0.4

0.05

0.10

0.15
mae

0.20

0.25

Fig. 8. CDFs of MAEs when varying adaptation threshold in GMR models for predicting FSS-W and EQ-W.
(b) EQ-W

1.0

1.0

0.8

0.8

0.6
0.4

GMR
Adapted-GMR(1)
Adapted-GMR(10)
AdaboostR
Adapted-AdaboostR

0.2
0.0

0.0

0.5

1.0

1.5

mae

2.0

2.5

3.0

3.5

Cumulative Probability

Cumulative Probability

(a) FSS-W

0.6
0.4

GMR
Adapted-GMR(1)
Adapted-GMR(10)
AdaboostR
Adapted-AdaboostR

0.2
0.05

0.10

0.15
mae

0.20

0.25

Fig. 9. CDFs of MAEs when varying adaptation threshold in GMR models for predicting FSS-W and EQ-W.

7.2 Translation of Residual Error
Here we apply a simple scalar translation of the prediction according to the residual error obtained in the the
first week, applied onto predictions made by the AdaboostR ensemble model. We note that this simple operation
yields a powerful reduction of MAE in both FSS-W and EQ-W case. For FSS-W, MAE is reduced by 49%, and for
EQ-W, MAE is reduced by of 53%.
In Figure 9 we compare the universal models as well as the two adaptation methods, simple translation and
adapted GMR. We also included two models of adapted GMR with 1 and 10 datapoints adapted per person
to represent a scarce and abundant data situation. For FSS-W, it is clear that the simlpe translation is enough
to outperform all other considered model. For EQ-W, only the Adapted-GMR which takes 10 datapoints per
individual (with MAE 0.049) could match the performance given by the simple translation approach (MAE 0.052).
Although this presents possibilities that the error could be reduced even further if we keep on increasing the
number of adapted datapoints, this situation is unlikely in the future, given that in the current study the mean
number of weekly questionnaires completed is under 10. However, this result also highlights that using the simple
transformation is a pragmatic approach which works effectively in personalizing the model to individual users.
To ensure this translation is effective, we also consider the changes in MAE per person before and after applying
the translation. Out of 28 subjects tested, 3 subjects experienced a minute increase in MAE that is up to 0.55%,
and 2 subjects experienced small increase in MAE up to 2.3%. Upon closer inspection, we believe that reasons for
the worsening performance for these individuals are due to their longer time series length. The 2 subjects have a
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

1:18

•
Table 8. Model selection.

Item

Alternatives explored

Data with Imputed Gaps

Filling gaps of 1, 4, 7 days

Multimodal Fusion

Single regressor , ensemble

Component Models

AdaboostR, GBRT, LASSO
SVR (Linear), SVR (RBF)

Data Source

All sources, Device only,
Device + Static,
Daily Questions + Static,

Data Grouping

Device-level,
Modality-level

Window Selection

Window Length
5 to 14 days
Number of Windows 1 or 2 windows
Window end point
-5 to 5 days before weekly survey fill-in

mae
r

Baseline Ensemble
1.05
0.95
0.57*

Single
1.08
0.29*

Table 9. Predicting FSS-M with single or ensemble
regressors, * p<0.05

mae
r

Baseline
0.11
-

Ensemble
0.084
0.72*

Single
0.089
0.58

Table 10. Predicting EQ-M with single or ensemble
regressors, * p<0.05

mean time series length of 16.1weeks, 85% longer than the rest of the test set. It is possible that the adaptation
could benefit from a recaliberation.

8 SENSITIVITY ANALYSIS
In arriving at the results presented in previous sections, we performed a number of investigations varying a
number of model formulations and different hyperparameters, as documented in Table 8
We perform grid search to obtain optimal values using cross validation. In cases where the performance of of
the alternatives are not significantly different, we opt for choices which are the simplest and easiest to interpret.
For instance in the case of choosing the window end point, we choose this as 0, i.e. considered window ending
on the date of filling in the weekly questionnaire. In the following we present some comments relating to the
prediction tasks of FSS-M and EQ-M:
Multimodal fusion. As an alternative to an ensemble of regressors, we also considered employing a single
regressor with concatenated features from the different modalities, this essentially represents an early multimodal
fusion. One downside to this approach is that there cannot be any null values for any feature within a single
datapoint, as was the case in ensemble, to overcome this it is required to select features which would be both
important and abundant together. Table 9 and 10 show comparisons between the formulations. For predicting
FSS-M, a single regressor predicts worse than the best ensemble and the baseline. For predicting EQ-M, although
the inccrease in MAE is small, the correlation found is not as strong or significant (with p = 0.06).
Subset of data. We also consider subsets of source-specific regressors that is included in the ensemble model.
We compared results of considering devices-only, devices + static, and all (devices + daily quesitons + static), and
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

Tracking Fatigue and Health State in Multiple Sclerosis Patients Using Ubiquitous Sensing

•

1:19

we observed no great difference in the resulting models’ MAEs, variations are within 5%. However, using devices
data alone does significant harm the correlation coefficient, with an average decrease of 57% in r .

9 DISCUSSION
We present the discussion of the results, their implications and limitations of our study.

9.1

Discussion

The Data. Use of Derived Data. Like many related studies, our analysis builds on derived data from lower-level
activity inference models that are fairly mature in the industry; as seen in [36, 37], the authors have relied on
inferences such as walking, running, sleep stages build on prior classifiers. The derived data is inferred using
commercial-quality models by Withings, and we have verified through discussions that they have validated their
models in similar fashions to those paper in the literature. (i.e., controlled user trials) at a similar scale. In addition,
these devices are used by millions of people on a daily basis - an added check since other methods have not been
tested against. Further, we highlight that our dataset, being a mixture of raw information (e.g. weight, height) as
well as derived data, represents an increasingly popular form of data useful for wellbeing research. However, we
do acknowledge that the accuracy of the derived data might not be perfect, since these devices are currently
intended to be used as ’general wellness’ as opposed to regulated medical device [5]. We are also limited by the
fact that the derived data are only available at daily levels and cannot investigate more fine-grained behavioral
patterns, e.g. steps during different times of the day. Nonetheless we would like to investigate the possibility
of using such derived measurements as proxies for personal disease monitoring at home by the patient. In a
preprocessing stage we also set sensible criteria on the derived data to remove unreasonable measurements, e.g.
measured bed-in time should be between 6pm and 6am, which inevitably creates a possibility for the rejection of
genuine measurements.
Missingness. The resulting dataset contains many gaps due to the absence of data. Although the patients
were conscious participants of the study, data was collected effectively in the wild in the sense that there
was no requirement about device usage or daily/weekly questionnaire participation. For device measurements,
participants’ usage is a key factor leading to missingness - participants may not use the devices every day, they
may not use all 3 devices on the same day, or their use of a single device may not enable all measurements
to be derived for the day (e.g. a patient may wear smart watch during the day but not during sleep). A small
number of these gaps is due to the removal of unreasonable derived values in a bid to ensure data quality. Low
participation is seen particularly in the Daily questions, which was not attempted at all by half the participants.
The missingness gives rise to issues such as a limited number of training examples and missing modality problem,
but we have also found it to be useful to take into account of missingness as an indicator for patient’s usage
patterns. This has shown to be a valuable feature that is retained by the feature selection algorithm we employed
with AdaboostR, and we also found that if we consider data with imputed gaps without the usage features, the
model performance is not as good as when we take into account usage features. This means that some cases, the
actual measurement does not matter as much as whether a measurement was actually made.
The daily questions. We note that these daily questions are not validated clinical instruments and are thus not
necessarily reliable and robust measures for tracking fatigue and sleep quality. Contrary to expectations, data
collected through these modalities do not always improve prediction performance, in fact for FSS-W the best
model considers a subset of regressors that ignores these daily questions. One reason for this is that the data
collected here is noisy and incomplete. It is not uncommon that we observe patients reporting No or Low fatigue
in the daily questions just a few days prior to reporting in the FSS that they experience high fatigue with a score
above 6. Since the patients fill in these daily questions as much as they please, we are left with incomplete data
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

1:20

•

which makes us uncertain about the usefulness of these daily questions, however this also means that sometimes
the action of whether answering the daily question or not (captured by the usage feature) is more informative
than the actual answer.
Ensemble Model. Under the ensemble model formulation, a datapoint only needs to have at least data from
one time-varying source in order to be considered valid. This greatly increases the flexibility in the model, as
the tracking of fatigue and health status can be thus extended to users who own and use different subsets of
the wellness devices, a realistic situation if our modelling framework is applied in the commercial market in the
future.
Adaptations. The simple adapted ensemble model of Adaboost Regressors is able to significantly reduce errors
by 51% on average and improves generalization performance. We believe that the simple adaptation is a pragmatic
approach given the sparsity of data. By empirical observation it is clear that adjusting the first residual error does
not describe all of the individual prediction errors, but it is an effective approach and under no circumstances do
we see a great (beyond 2%) increase in error in any individual. Predictions from this adapted model show good
correlations with the ground truth on a population level and on an individual level for both FSS-W and EQ-W.
Alternative formulations. In terms of performance, ensemble models are also seen to perform better than single
classifiers which take in imputed data, showing that our framework is a valid choice for handling multimodal
data. Although we presented the best results from the best ensemble model resulting from hyperparameter
tuning in previous sections, our sensitivity analysis also shows that the performance resulting from different
hyperparameter settings are not far off. This supports that our prediction results are not the products of extreme
hand-engineered solutions but could be possibly matched by similar models which might be varied if deployed in
the future.

9.2

Implications of Results

Altogether, our results confirm the feasibility that weekly reported scores of Fatigue and Health State can be
accurately and regularly tracked in MS patients. One implication is that, now patients may be able to employ
such a model to track themselves for long periods of time at weekly intervals, simply by using a general model
that calibrates once. Given that the disease does progress we might expect that the patients could re-calibrate
every 4 months or so, in order to improve personal adaptations. Although patients do have to be equipped with
smart devices, but once this is set up and calibrated, the burden of measuring week-to-week fatigue scores can
be transferred to the devices and the patients would be able to use this information in conjunction with other
summaries provided by the devices to develop a holistic view of their conditions. Being able to obtain at ease
such descriptions of fatigue in terms of a clinically-validated equipment instead of arbitrary personal metrics also
meant that the patients can share with their doctors more useful and more objective measures of their fatigue.

9.3

Limitations

While the current study provides evidence that ubiquitous sensing with connected wellness devices may help
track and predict fatigue levels and health states of MS patients, there are a number of limitations.
The Data. Although the number of patients investigated are comparable to most MS studies, the size of our dataset
is small and the demographics of patients investigated are limited (mostly female RRMS patients). Our collected
data does not provide measurements more fine-grained than daily levels, it is possible that morning/afternoon
fluctuations of activities could be important. Gait is the only proxy for activity or exercise taken by the patients
here, which may also be too narrow. In addition, we also have not collected any data that is immediately related
to the emotional wellbeing of the MS patients, despite that this could be a major factor in a patient’s perceived
levels of fatigue. Although the screener surveys were done to collect background variables from the patients, it is
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

Tracking Fatigue and Health State in Multiple Sclerosis Patients Using Ubiquitous Sensing

•

1:21

probable that these variables (e.g. drug choice) could change over the course of the study, but this was not being
tracked. For most background variables, only binary indications are given, this does not give the full picture and
in future studies we believe a smaller number of background variables may be collected but at greater detail (e.g.
years since diagnosed with other diseases instead of whether other diseases are present).
Ensemble Modelling. Although our final results demonstrate low levels of MAEs for both FSS and EQ-5D-5L
scores, in our ensemble model we have only considered homogeneous settings for each component regressor
(except for feeding in source-speicific data). It is possible that more complicated forms of the ensemble, where
each component is fine-tuned independently, including the use of different types of regression models per source,
could lead to better results which capture inter-modality variations.
To pave way for future work in this direction, future studies should seek to address the limitations in data
collection. It would also be interesting to have some incorporation of measurements of patients’ emotional state,
for instance, through use of smartphone data or Ecological Momentary Assessment (EMA) methods. It would
also be useful to collect information relating to environmental effects (e.g. local weather, humidity information),
which had been shown in MS literature to be related to symptom triggers. In order to better adapt to personal
changes, low-user-burden ways of calibrating the models could be investigated, e.g. asking for a binary indication
of whether this week feels more fatigued than last week.

10 RELATED WORK
In recent years, increasing interest has been placed on using ubiquitous sensing technology to aid Multiple
Sclerosis disease management. Digital and remote control technologies, enabled by the availability of cheap
and ubiquitous sensors, can help over come previous limitations in data collection at low cost. A lot number
of pilot studies have been carried out to explore the feasibility of deploying ubquitous sensing in MS patient’s
natural environments so that longitudinal assessment of their symptoms could be performed. The focus of many
such studies tend to be in exploring the feasibility of data collection using ubiqutious sensing and analyzing the
correlations. [22] explored using real-time depth sensors to identify gait problems and falls in 21 MS patients,
and found that depth sensors in home could gather real-time gait parameters but not for detection of falls. [30]
used activity sensors to gather information about the level of physical activity carried out by 11 MS patients, and
correlated the tracked daily physical activity fluctuations to disability changes in MS patients. [21] performed a
study of a larger scale, with 248 MS patients being handed FitBit activity trackers to collect actvitiy data, the
authors analysed correlations found in the tracked data and reported data. Certain technologies have already
been developed for MS monitoring and management which are alternative or complementary to traditional
in-clinic approaches. MS Mosaic is a smartphoen app that allows MS patients to track their symptoms over time
by manually reporting their symptoms (e.g. Faituge)and also integrating health and fitness data available on
smartphones to monitor symptom triggers. Floodlight is also another smartphone apps which tracks changes in
MS over time through ’active tests’, where patients are asked to perform daily simepl tasks on their smartphone,
as well as passive monitoring through smartphone health data. [3] have reported the results from the same dataset
studied in our work, but with basic analytic results about correlations between expected fatigue changes and
behavioral measurements. In general, most of these related studies have mostly relied on ground truth symptom
measurement which had not been previously clinically validated, as far as we know, no technology so far have
been developed for tracking fatigue and health state as measured in terms of the FSS and EQ-5D-5L.
Closely related to our work are also studies which have utilised ubiqutious sensing in monitoring symptoms for
other diseases, many of which have been carried out to reproduce predictions for clinically-validated self-report
instruments in the concerned disease. For example, [36] develops a prediction system that tracks schizophrenia
symptoms based on a standard instrument using passive sensing from mobile phones, they were able to accurately
predict reported schizophrenia scores using Gradient Boosted Regression Trees (GBRT). [37] proposed a new
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

1:22

•

approach in predicting depression using passive sensing data from college students’ smartphone and wearables
through the use of a proposed set of symptom features, they used generalized linear mixed model (GLMM)
to predict self-reported depression scores and found correlations between their proposed symptom features
and depression scores. Other than disease monitoring, a number of studies have also been carried looking into
monitoring of more general wellness indicator, since this could be applied to the general non-clinical population,
the sample dataset sizes studied could be much bigger, therefore also allowing more advanced techniques to be
applied (e.g. deep neural networks). [35] analyzes multimodal time-series data and predicts the ability to achieve
weight objective for users of smart connected devices using deep long-short-term memory architectures.

11

CONCLUSION

As a lifelong debilitation disease that affects millions of people worldwide, MS needs to be better understood by
researchers and better monitored by patients. Having large-scale longitudinal data of MS patient’s condition
furthers this goal, and in this study we carried out the first investigation into methods to obtain such data
through ubiquitous sensing at ease. In particular we focused our tasks on data relating to MS patient’s fatigue
and quality of life, through use of two widely used instruments by the MS community, Fatigue Severity Scale
(FSS) and EQ-5D index. We conducted a study to collect behavioral, physiological device data and self-reported
data from 198 MS patients, using connected wellness devices over 6 months. In our investigations, we proposed
an ensemble regression models which can cope with the data’s missingness, as well as adaptation techniques to
further improve generalization performance. Our models are able to achieve good prediction performance for the
tasks considered, namely predicting a per-participant mean reported score and a per-week per-participant score
for each metric. We find that with the universal mode performance are in line with acceptable instrument errors,
for FSS (SEM 0.7) we report MAE 0.99 and for EQ-5D (SEM 0.093) we report MAE 0.091. Adapted models improve
these results further (FSS: MAE 0.51, EQ-5D: 0.052). These promising results in our dataset show the feasibility
in continuous and unobtrusive tracking of fatigue and health state, and potential for future replications into
larger-scale replication studies, which has positive implications for supporting MS patient disease management
and clinical research.

REFERENCES
[1] 2018. Withings. https://www.withings.com. Accessed: 2018-11-08.
[2] B. E. Aouizerat, C. A. Miaskowski, C. Gay, C. J. Portillo, T. Coggins, H. Davis, C. R. Pullinger, and K. A. Lee. 2010. Risk factors and
symptoms associated with pain in HIV-infected adults. J Assoc Nurses AIDS Care 21, 2 (2010), 125–133.
[3] Sourav Bhattacharya, Alberto Gil C. P. Ramos, Fahim Kawsar, Nicholas D. Lane, Lynn M. Gionta, Joanne Manidis, Greg Silvesti, and
Mathieu Vegreville. 2018. Monitoring Daily Activities of Multiple Sclerosis Patients with Connected Health Devices. In Proceedings of
the 2018 ACM International Joint Conference and 2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable
Computers (UbiComp ’18). ACM, New York, NY, USA, 666–669. https://doi.org/10.1145/3267305.3267682
[4] A. Bisecco, G. Caiazzo, A. d’Ambrosio, R. Sacco, S. Bonavita, R. Docimo, M. Cirillo, E. Pagani, M. Filippi, F. Esposito, G. Tedeschi, and A.
Gallo. 2016. Fatigue in multiple sclerosis: The contribution of occult white matter damage. Mult. Scler. 22, 13 (11 2016), 1676–1684.
[5] Tim Bradshaw. 2018. Tech and healthcare often struggle to sync. Financial Times (29 Jan 2018). https://www.ft.com/content/
9de679a4-04dd-11e8-9650-9c0ad2d7c5b5
[6] R. F. Brown, E. M. Valpiani, C. C. Tennant, S. M. Dunn, M. Sharrock, S. Hodgkinson, and J. D. Pollard. 2009. Longitudinal assessment of
anxiety, depression, and fatigue in people with multiple sclerosis. Psychol Psychother 82, Pt 1 (Mar 2009), 41–56.
[7] ROBERT FERRARI and ANTHONY SCIENCE RUSSELL. 2010. Effect of a Symptom Diary on Symptom Frequency and Intensity in Healthy Subjects. The Journal of Rheumatology 37, 11 (2010), 2387–2389. https://doi.org/10.3899/jrheum.100513
arXiv:http://www.jrheum.org/content/37/11/2387.full.pdf
[8] E. Fogarty, C. Walsh, R. Adams, C. McGuigan, M. Barry, and N. Tubridy. 2013. Relating health-related Quality of Life to disability
progression in multiple sclerosis, using the 5-level EQ-5D. Mult. Scler. 19, 9 (Aug 2013), 1190–1196.
[9] Yoav Freund and Robert E Schapire. 1997. A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting. J.
Comput. System Sci. 55, 1 (1997), 119 – 139. https://doi.org/10.1006/jcss.1997.1504
[10] M. M. Goldenberg. 2012. Multiple sclerosis review. P T 37, 3 (Mar 2012), 175–184.
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

Tracking Fatigue and Health State in Multiple Sclerosis Patients Using Ubiquitous Sensing

•

1:23

[11] M. Heine, I. van de Port, M.B. Rietberg, E.E.H. van Wegen, and G. Kwakkel. 2015. Exercise therapy for fatigue in multiple sclerosis.
Cochrane Database of Systematic Reviews 9 (2015). https://doi.org/10.1002/14651858.CD009956.pub2
[12] Sverker Johansson, Anders Kottorp, Kathryn A. Lee, Caryl L. Gay, and Anners Lerdal. 2014. Can the Fatigue Severity Scale 7-item
version be used across different patient populations as a generic fatigue measure - a comparative study using a Rasch model approach.
Health and Quality of Life Outcomes 12, 1 (22 Feb 2014), 24. https://doi.org/10.1186/1477-7525-12-24
[13] Sverker Johansson, Charlotte Ytterberg, Jan Hillert, Lotta Widén Holmqvist, and Lena von Koch. 2008. A longitudinal study of variations
in and predictors of fatigue in multiple sclerosis. Journal of neurology, neurosurgery, and psychiatry 79 4 (2008), 454–7.
[14] S. Johansson, C. Ytterberg, J. Hillert, L. Widen Holmqvist, and L. von Koch. 2008. A longitudinal study of variations in and predictors of
fatigue in multiple sclerosis. J. Neurol. Neurosurg. Psychiatry 79, 4 (Apr 2008), 454–457.
[15] E. Kim, J. Lovera, L. Schaben, J. Melara, D. Bourdette, and R. Whitham. 2010. Novel method for measurement of fatigue in multiple
sclerosis: Real-Time Digital Fatigue Score. J Rehabil Res Dev 47, 5 (2010), 477–484.
[16] G. Kobelt, J. Berg, P. Lindgren, S. Fredrikson, and B. Jonsson. 2006. Costs and quality of life of patients with multiple sclerosis in Europe.
J. Neurol. Neurosurg. Psychiatry 77, 8 (Aug 2006), 918–926.
[17] L. B. Krupp, P. K. Coyle, C. Doscher, A. Miller, A. H. Cross, L. Jandorf, J. Halper, B. Johnson, L. Morgante, and R. Grimson. 1995. Fatigue
therapy in multiple sclerosis: results of a double-blind, randomized, parallel trial of amantadine, pemoline, and placebo. Neurology 45, 11
(Nov 1995), 1956–1961.
[18] L. B. Krupp, N. G. LaRocca, J. Muir-Nash, and A. D. Steinberg. 1989. The fatigue severity scale. Application to patients with multiple
sclerosis and systemic lupus erythematosus. Arch. Neurol. 46, 10 (Oct 1989), 1121–1123.
[19] Amy E. Latimer-Cheung, Lara A. Pilutti, Audrey L. Hicks, Kathleen A. Martin Ginis, Alyssa M. Fenuta, K. Ann MacKibbon, and Robert W.
Motl. 2013. Effects of Exercise Training on Fitness, Mobility, Fatigue, and Health-Related Quality of Life Among Adults With Multiple
Sclerosis: A Systematic Review to Inform Guideline Development. Archives of Physical Medicine and Rehabilitation 94, 9 (2013), 1800 –
1828.e3. https://doi.org/10.1016/j.apmr.2013.04.020
[20] Y. C. Learmonth, D. Dlugonski, L. A. Pilutti, B. M. Sandroff, R. Klaren, and R. W. Motl. 2013. Psychometric properties of the Fatigue
Severity Scale and the Modified Fatigue Impact Scale. J. Neurol. Sci. 331, 1-2 (Aug 2013), 102–107.
[21] James McIninch, Shoibal Datta, Pronabesh DasMahapatra, Emil Chiauzzi, Rishi Bhalerao, Alicia Spector, Sherrie Goldstein, Liz Morgan,
and Jane Relton. 2015. Remote Tracking of Walking Activity in MS Patients in a Real-World Setting (P3.209). Neurology 84, 14 Supplement
(2015). arXiv:http://n.neurology.org/content http://n.neurology.org/content/84/14_Supplement/P3.209
[22] P. Newland, J. M. Wagner, A. Salter, F. P. Thomas, M. Skubic, and M. Rantz. 2016. Exploring the feasibility and acceptability of sensor
monitoring of gait and falls in the homes of persons with multiple sclerosis. Gait Posture 49 (09 2016), 277–282.
[23] Nokia. [n. d.]. Nokia Health Mate app, Your Activity Tracker and LIfe Coach User Guide. Nokia.
[24] Mari Palta, Han-Yang Chen, Robert M. Kaplan, David Feeny, Dasha Cherepanov, and Dennis G. Fryback. 2011. Standard Error of
Measurement of 5 Health Utility Indexes across the Range of Health for Use in Estimating Reliability and Responsiveness. Medical
Decision Making 31, 2 (2011), 260–269. https://doi.org/10.1177/0272989X10380925 arXiv:https://doi.org/10.1177/0272989X10380925
PMID: 20935280.
[25] T. Pereira, C. Correia, and J. Cardoso. 2015. Novel Methods for Pulse Wave Velocity Measurement. J Med Biol Eng 35, 5 (2015), 555–565.
[26] R. Rabin and F. de Charro. 2001. EQ-5D: a measure of health status from the EuroQol Group. Ann. Med. 33, 5 (Jul 2001), 337–343.
[27] Douglas A. Reynolds, Thomas F. Quatieri, and Robert B. Dunn. 2000. Speaker Verification Using Adapted Gaussian Mixture Models.
Digital Signal Processing 10, 1 (2000), 19 – 41. https://doi.org/10.1006/dspr.1999.0361
[28] L. A. Rolak. 2003. Multiple sclerosis: it’s not the disease you thought it was. Clin Med Res 1, 1 (Jan 2003), 57–60.
[29] K. M. Schreurs, D. T. de Ridder, and J. M. Bensing. 2002. Fatigue in multiple sclerosis: reciprocal relationships with physical disabilities
and depression. J Psychosom Res 53, 3 (Sep 2002), 775–781.
[30] L. Shammas, T. Zentek, B. von Haaren, S. Schlesinger, S. Hey, and A. Rashid. 2014. Home-based system for physical activity monitoring
in patients with multiple sclerosis (Pilot study). Biomed Eng Online 13 (Feb 2014), 10.
[31] Hsi G. Sung. 2004. Gaussian mixture regression and classification. Ph.D. Dissertation. Rice University.
[32] N Téllez, Jordi Rio, Mar Tintorè, C Nos, Ingrid Galán, and X Montalban. 2006. Fatigue in Multiple Sclerosis Persists Over Time: a
longitudinal study. Journal of neurology 253 (11 2006), 1466–70. https://doi.org/10.1007/s00415-006-0247-3
[33] B. van Hout, M. F. Janssen, Y. S. Feng, T. Kohlmann, J. Busschbach, D. Golicki, A. Lloyd, L. Scalone, P. Kind, and A. S. Pickard. 2012.
Interim scoring for the EQ-5D-5L: mapping the EQ-5D-5L to EQ-5D-3L value sets. Value Health 15, 5 (2012), 708–715.
[34] Mandy van Reenen and Bas Janssen. 2015. EQ-5D-5L User Guide. EQ-5D.
[35] Petar Veličković, Laurynas Karazija, Nicholas D. Lane, Sourav Bhattacharya, Edgar Liberis, Pietro Liò, Angela Chieh, Otmane Bellahsen,
and Matthieu Vegreville. 2018. Cross-modal Recurrent Models for Weight Objective Prediction from Multimodal Time-series Data. In
Proceedings of the 12th EAI International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth ’18). ACM, New
York, NY, USA, 178–186. https://doi.org/10.1145/3240925.3240937
[36] Rui Wang, Weichen Wang, Min S. H. Aung, Dror Ben-Zeev, Rachel Brian, Andrew T. Campbell, Tanzeem Choudhury, Marta Hauser,
John Kane, Emily A. Scherer, and Megan Walsh. 2017. Predicting Symptom Trajectories of Schizophrenia Using Mobile Sensing. Proc.
, Vol. 1, No. 1, Article 1. Publication date: November 2018.

1:24

•

ACM Interact. Mob. Wearable Ubiquitous Technol. 1, 3, Article 110 (Sept. 2017), 24 pages. https://doi.org/10.1145/3130976
[37] Rui Wang, Weichen Wang, Alex daSilva, Jeremy F. Huckins, William M. Kelley, Todd F. Heatherton, and Andrew T. Campbell. 2018.
Tracking Depression Dynamics in College Students Using Mobile Phone and Wearable Sensing. Proc. ACM Interact. Mob. Wearable
Ubiquitous Technol. 2, 1, Article 43 (March 2018), 26 pages. https://doi.org/10.1145/3191775
[38] Weichen Wang, Gabriella M. Harari, Rui Wang, Sandrine R. Müller, Shayan Mirjafari, Kizito Masaba, and Andrew T. Campbell. 2018.
Sensing Behavioral Change over Time: Using Within-Person Variability Features from Mobile Sensing to Predict Personality Traits.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 2, 3, Article 141 (Sept. 2018), 21 pages. https://doi.org/10.1145/3264951
[39] K. Wynia, B. Middel, J. P. van Dijk, J. H. De Keyser, and S. A. Reijneveld. 2008. The impact of disabilities on quality of life in people with
multiple sclerosis. Mult. Scler. 14, 7 (Aug 2008), 972–980.

, Vol. 1, No. 1, Article 1. Publication date: November 2018.

Appendix B

Conference Paper: Ubicomp 2018
This work was completed in collaboration with researchers from The Univesity of Edinburgh,
University of Cambridge and Nokia Bell Labs, Cambridge. This was accepted for the December
2017 issue of IMWUT and was presented in the ACM Conference on Pervasive and Ubiquitous
Computing (UbiComp) 2018. I also gave a conference presentation on this work at MobiUK
2018 held in Cambridge.

46

Multimodal Deep Learning for Activity and Context Recognition
VALENTIN RADU, The University of Edinburgh
CATHERINE TONG, University of Oxford
SOURAV BHATTACHARYA, Nokia Bell Labs
NICHOLAS D. LANE, University of Oxford and Nokia Bell Labs
CECILIA MASCOLO, University of Cambridge
MAHESH K. MARINA, The University of Edinburgh
FAHIM KAWSAR, Nokia Bell Labs and TU Delft
Wearables and mobile devices see the world through the lens of half a dozen low-power sensors, such as, barometers,
accelerometers, microphones and proximity detectors. But differences between sensors ranging from sampling rates, discrete
and continuous data or even the data type itself make principled approaches to integrating these streams challenging. How,
for example, is barometric pressure best combined with an audio sample to infer if a user is in a car, plane or bike? Critically
for applications, how successfully sensor devices are able to maximize the information contained across these multi-modal
sensor streams often dictates the fidelity at which they can track user behaviors and context changes. This paper studies the
benefits of adopting deep learning algorithms for interpreting user activity and context as captured by multi-sensor systems.
Specifically, we focus on four variations of deep neural networks that are based either on fully-connected Deep Neural Networks
(DNNs) or Convolutional Neural Networks (CNNs). Two of these architectures follow conventional deep models by performing
feature representation learning from a concatenation of sensor types. This classic approach is contrasted with a promising
deep model variant characterized by modality-specific partitions of the architecture to maximize intra-modality learning. Our
exploration represents the first time these architectures have been evaluated for multimodal deep learning under wearable data –
and for convolutional layers within this architecture, it represents a novel architecture entirely. Experiments show these generic
multimodal neural network models compete well with a rich variety of conventional hand-designed shallow methods (including
feature extraction and classifier construction) and task-specific modeling pipelines, across a wide-range of sensor types and
inference tasks (four different datasets). Although the training and inference overhead of these multimodal deep approaches is
in some cases appreciable, we also demonstrate the feasibility of on-device mobile and wearable execution is not a barrier to
adoption. This study is carefully constructed to focus on multimodal aspects of wearable data modeling for deep learning by
proving a wide range of empirical observations, which we expect to have considerable value in the community. We summarize
our observations into a series of practitioner rules-of-thumb and lessons learned that can guide the usage of multimodal deep
learning for activity and context detection.
Additional Key Words and Phrases: Mobile sensing, sensor fusion, multi-modal, deep neural networks, deep learning, context
detection, activity recognition
Authors’ addresses: Valentin Radu, The University of Edinburgh; Catherine Tong, University of Oxford; Sourav Bhattacharya, Nokia Bell Labs;
Nicholas D. Lane, University of Oxford and Nokia Bell Labs; Cecilia Mascolo, University of Cambridge; Mahesh K. Marina, The University of
Edinburgh; Fahim Kawsar, Nokia Bell Labs and TU Delft.

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that
copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy
otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from
permissions@acm.org.
© 2017 Copyright held by the owner/author(s). Publication rights licensed to Association for Computing Machinery.
2474-9567/2017/11-ART157 $15.00
https://doi.org/10.1145/3161174
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

157

157:2

•

V. Radu, et al.

ACM Reference Format:
Valentin Radu, Catherine Tong, Sourav Bhattacharya, Nicholas D. Lane, Cecilia Mascolo, Mahesh K. Marina, and Fahim
Kawsar. 2017. Multimodal Deep Learning for Activity and Context Recognition. Proc. ACM Interact. Mob. Wearable Ubiquitous
Technol. 1, 4, Article 157 (November 2017), 27 pages. https://doi.org/10.1145/3161174

1

INTRODUCTION

The popularity of wearables, and mobile sensing devices in general, has given rise to a growing interest in complex
sensing applications (e.g. user activity and context recognition), with such tasks already available on commercial
wearables to track jogging [42], sleep [48] and even posture [45]. Common to these recognition tasks is their
reliance on numerous low-energy small form-factor sensors (e.g., light detector, magnetometer, accelerometer,
barometer, heart-rate). With each sensing modality carrying a unique perspective, combinations of multiple such
sensing streams can boost detection quality and exceed their potential in isolation. Taking this approach, the
Microsoft Band [48] determines when a user is asleep by combining heart rate levels with accelerometer data of
wrist motion, while the MSP [13] distinguishes between walking and climbing stairs, which are relatively similar
in acceleration patterns, with extra information from a barometer.
Majority of current multimodal sensing solutions rely on shallow classifiers, (such as Decision Tree, Random
Forest, SVM) operating on independent features extracted from each sensing modality. These features are used
to perform sensor fusion following two strategies: Feature Concatenation (such as in [9, 28]) that treat features
uniformly irrespective of their sensing modality to produce a single feature vector for classification; and Ensemble
Classifiers (applied in [22, 72]) in which outputs of classifiers operating only on features of one modality are
blended together. However, an important challenge for activity and context classification is to integrate seemingly
incompatible sensor types (consider fusing accelerometer data and camera frames). Because sensing modalities
vastly differ by sampling rate, statistical properties and data types, standard approaches for model training struggle
to merge the information available from these diverse sources. The key here is to not only extract discriminative
features from individual sensors, but also to discover features that jointly use separate sensors streams to capture
information neither has in isolation.
Deep learning [2, 14] presents a promising, much unexplored opportunity to combat this sensors fusion challenge.
In an area of rapid innovation, deep learning algorithms have shown to be remarkably successful in unimodal
applications, such as recognition of words [27], objects [35] and faces [66]. One of its defining characteristics is
the ability to learn dense hierarchical networks that transform relatively raw forms of data into inferences (e.g., an
activity class). These networks merge the roles of features extraction and classification stages present in shallow
modeling methods (e.g. SVMs [5]) and replace the need for hand-engineered, task-specific features with layers
of data representations that act as features, automatically learned directly from data. There is already building
evidence suggesting deep methods could overcome current bottlenecks in learning cross-sensor features for routine
detections. New training methods that leverage variation in information [63], multi-view representations [69],
or modified autoencoders [52, 70] are able to fuse highly heterogeneous pairs of data types, such as text mixed
with images [64] and audio linked with video [52, 60]. The resulting bi-modality deep models offer considerable
accuracy gains in tasks like image captioning [63] and emotion recognition [15, 33, 43] (merging facial expressions
with sound).
This paper presents a case study of adopting deep learning algorithms for multimodal human activity and context
recognition, using sensor data collected with mobile devices. We investigate the sensor fusion approaches taken in
both deep and shallow learning, and ask the following questions: (i) how do the studied techniques fare with existing
practices? (ii) under what circumstances (e.g. modeling task, data types) is it beneficial to apply deep learning? (iii)
how the technique may be deployed? These questions are examined under two approaches to multimodal learning.
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

Multimodal Deep Learning for Activity and Context Recognition

•

157:3

The first, Feature Concatenation (FC), is attractive in terms of simplicity as a strategy though it is at risk of missing
crucial intra-modality correlations. The second, a novel alternative that we term Modality-Specific Architecture
(MA) is a deep learning specific technique that places emphasis on learning both intra-modality and cross-modality
relations. Our empirical study spans four datasets representative of a wide range of activity and context recognition
tasks in ubiquitous computing. For each dataset, we evaluate: (i) four deep learning techniques based on FC and
MA, with Deep Neural Networks (DNN) and Convolutional Neural Networks (CNNs) as base classifiers; (ii) two
shallow classifier techniques: Decision Tree, Random Forest; (iii) any available task-specific classifier. Our MA
architectures, trained here on mobile sensing data, are adaptations of the architecture first proposed in [52] for
speech detection integrating video and sound modalities.
Our results show that these deep network architectures exceed current machine learning solutions over a range
of mobile sensing tasks (human activity recognition, gait recognition, sleep stage detection and indoor-outdoor
detection). This consistently better performance demonstrates a general-purpose characteristic of deep neural
network architectures across diverse multimodal detection tasks, even matching that of highly-engineered purposebuilt methods designed for a specific detection task. In addition to comparing accuracies, we also investigate the
computational overhead of these techniques, as well as document the various lessons learnt in evaluating our
training framework. Our findings suggest wearable resource limits (such as energy) are not a barrier to the adoption
of explored deep learning methods.
Key contributions of this research are:
• A systematic study of multimodal deep learning techniques applied to a broad range of activity and context
recognition tasks. Our empirical results demonstrate the ability of feature representational learning to produce
accurate results even across highly heterogeneous sensors under different settings.
• We study the Modality-Specific Architecture, a specific type of split-architecture deep learning never previously
applied to wearable modeling tasks. Within this variety of deep learning, we are also the first to test this
architecture in-conjunction with convolutional layers (relative to feed-forward fully-connected DNN layers).
• Summary of experiences into general rules of thumbs and lessons learnt for future adoption of multimodal deep
learning techniques in mobile sensing research.
• A system resource feasibility study of the overhead imposed by multimodal deep architectures. Experiments
with two mobile processors show that memory, battery and computational footprint of these detection algorithms
are not a barrier to their adoption.
• Development of a framework [18] to support training and evaluation of these models on different multimodal
sensing tasks.

2 SHALLOW LEARNING APPROACHES
Shallow methods are commonly used for multimodal activity and context recognition. The term shallow is used to
contrast with alternate deep learning architecutres [2, 14]. We first summarize the challenges of multimodal fusion,
followed by surveying the two commonly adopted multimodal modeling strategies:
(i) Feature Concatenation
(ii) Ensemble Classifiers

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

157:4

2.1

•

V. Radu, et al.

Challenges for Multimodal Sensor Fusion

Different sensing modalities carry information with various perspectives, which often complement each other,
allowing for useful information gain. As such, leveraging a diverse set of sensors on mobile devices when available
can only be beneficial to detection accuracy.
However, building appropriate models for multimodal fusion, i.e. models which fully leverage information contained
within and across each sensor, is not trivial. The difficulty is mainly attributed to intrinsic differences between
sensor data. Coming from different input channels with varying data types and sampling rates, each modality is
characterized by distinctive statistical properties, representation and correlation structures. Typical models treat
multimodal data as heterogeneous, resulting in ambiguous features and requiring special detection pipelines to deal
with this multimodal data.
As a result of these differences, it is difficult to systematically recognize useful cross-modality relationships in
addition to uni-modality ones. For instance, human speech can be perceived through three modalities: a stream
of 2D-structured pixels (video), a time-series real-valued acoustic waveform (audio) and a sparse distribution
of words (text). Cross-modality relationships which exist between low-level features across different modalities
are highly non-linear and thus difficult to find. If we only consider video and audio, correlations are still highly
non-linear and difficult to find from a mix of pixels and waveforms even if attempting by hand [52]. More generally,
multi-modality data present even greater challenges since this difficult and time-consuming process needs to be
performed for each sensor pair.
To illustrate this aspect in the context of multimodal sensing with mobile devices, we consider the following
examples. A generic human activity recognition task utilizing the GPS, accelerometer and audio signals (e.g.
indoor-outdoor detection) presents a range of challenges for modality fusion. Obviously, sampling rates differ
substantially between sensor pairs: GPS signals change on time-scales of a minute, while accelerometer signal
streams at sub-second rates (30Hz). This means that a GPS sample must be correlated to thousands of accelerometer
readings; learning from such an imbalance distribution can easily degenerate typical models. Similarly, considering
the GPS and audio signals, these are again very different. Even high sampling rate pairs like accelerometer and
audio still need heavy filtering and preprocessing to align. Another example where these observations hold the same
is the case of context understanding for indoor localization with smartphones. Typical sensing modalities for this
task include inertial sensors (accelerometer and gyroscope) and WiFi scans, which come at different frequencies
and in completely different formats (uniform data streams vs. uneven blobs of wireless environment observations).
Integrating these sensing modalities is often done through heavy-engineered solutions, such as particle filters for
indoor localization [58], but in most cases these are task-specific and constrained to a predetermined environment.
Several challenges exist in preprocessing sensor signals to comply with the input structure expected by a classifier.
Generally, shallow classifiers operate on small size inputs which take advantage of the already distilled information
presented to them in the form of features, specially hand-engineered for specific tasks – which can be an art on its
own. Selecting the appropriate features may not be always intuitive to system designers even for a single modality;
this difficulty is even more stringent with multimodal data as features have to complement each other across sensing
modalities.
Nevertheless, shallow methods consider features as independent knobs, incapable of learning the key interdependent
relations between sensing modalities, e.g. correlation in lip pose and motions between audio and visual data for
speech recognition [52].

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

Multimodal Deep Learning for Activity and Context Recognition

Modality 1
Modality 1
Single
Feature
Vector

Classification
Model
Inference

Modality n
Modality n

(a)

Feature Concatenation

(b)

Feature
Vector

157:5

Inference
Ensemble
Classifier

…

….

Hand
selected
features

Feature
Vector

•

Inference

Inference

Ensemble Classifier

Fig. 1. Schematic of common approaches to shallow multimodal learning with (a) Feature Concatenation and (b)
Ensemble Classifier models. For Feature Concatenation hand-selected features are extracted from each sensing
modalities and concatenated into a single features vector as input to a classifier, while the Ensemble Classifier
approach performs detections on each sensing modality independently to combine their estimations as final
inference.

2.2

Strategies in Shallow Multimodal Learning

Existing sensor fusion strategies in multimodal activity recognition models can be categorized into two families,
depending on whether sensor fusion occurs at a feature or at a classifier level. We call these (i) Feature Concatenation
(FC), and (ii) Ensemble Classifiers (EC) respectively, schematically represented in Figure 1.
Feature Concatenation with Shallow Classifiers. With this strategy, hand-selected features from each modality
are combined into a single feature vector presented to a classifier for detection across all features.
Various multimodal sensing systems have adopted this approach using different classifiers for diverse recognition
tasks (SVM [9], AdaBoost [28], GMMs [44]). While some classifier types, such as ensemble learners like Random
Forest [5], may do better than others at teasing out relationships between features the degree to which multimodal
information is maximized is dependent on the quality of these hand-crafted uni- and cross-modal features. Often
feature selection in concert with the extraction of a large number of candidate features for each sensing modality is
attempted to automate this process (a technique adopted in systems like MSP [13]), though still bounded by the
quality of selected features. In practice, Feature Concatenation can easily overlook inter-sensor relationships with
the number of explored feature combinations limited by the curse of dimensionality [5].
Ensemble of Shallow Classifiers. On the other hand, the integration of modalities is done after separate classifiers
operating on each sensor (modality) provide their estimation. These estimations provided by each sensing modality
classifier are fused to yield an overall class estimation. A range of classifier fusion methods exists, including
probability-based Bayesian fusion models and majority voting schemes (more details in [30]).
Like FC, variations of EC are also commonly adopted in multimodal activity models [30, 56, 72]. One key attraction
is that available classifiers for each sensor type (tested and verified with other applications) can be readily adopted
to undertake a new task on same sensing modality. In essence, this facilitates the creation of robust sensor-specific
classifier generic to multiple tasks, while merging their results enables the evidence of each modality type to be
considered before a final inference. However, a fundamental weakness of EC is that because fusion takes place so
late a lot of potential information and cross-sensor relationships are already lost.
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

157:6

•

V. Radu, et al.

3 DEEP LEARNING TECHNIQUES
In this section, we discuss deep learning models used in multimodal activity and context recognition. We begin
with an overview of existing methods, followed by a technical description of two kinds of multimodal deep learning
models: Feature Concatenation (FC) and Modality-Specific Architecture (MA).

3.1

Overview

Deep learning models have been applied successfully to a growing number of detections with a single modality.
Through their ability to learn feature representations directly from raw data (images, voice, text) rather than relying
on domain-specific features and their hierarchical structure, deep models present a viable solution to overcome the
challenges of multimodal sensing exposed above.
The structure of a generic deep learning architecture is presented in Figure 2. This consists of interconnected units
that are grouped together in layers. Information propagates through layers, each performing transformations on
their input as a function of internal feature representations, globally contributing to the final classification result.
The first layer (input layer) accepts data in raw or lightly processed format, while the final layer (output layer)
provides the class (e.g. categories of activity and context) according to the value of associated unit. Layers in
between input and output layers are called hidden layers, because their values are not monitored, although essential
to propagating information based on their layer parameters. Unit parameterization is automatically determined
during training and depends on the layer type (e.g. whether it is convolutional or feed-forward layers) as well as
training methods, pre-training and fine-tuning [14].

Input
layer

Sensor Data

Hidden layers

Output
layer

Inference

Fig. 2. Typical Deep Neural Network structure with feed-forward fully-connected layers.

Input Layer Representation. Deep architectures embody feature representational learning, with input layer
taking values from raw sensor data, or lightly processed data.
Raw Data. Raw measurements, e.g. sensor readings, can be used as input directly.
Feature Selection. It is common for deep architectures to have a light preprocessing stage to change the dimensionality of the raw input signal (for example very sparse word vectors) in a process resembling features extraction
in traditional classifiers, although this is a light and generic (valid across many tasks) data transformation process.

3.2 Multimodal Deep Learning
Deep learning architectures hold important properties which are advantageous to multimodal recognition tasks.
As mentioned before, due to their feature representation learning, there is no need for a preprocessing phase to
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

Multimodal Deep Learning for Activity and Context Recognition

•

157:7

extract domain-specific features from input data, this having two important consequences for multimodal data.
First, custom layer representations can be trained to combine both uni-modal and cross-modal data from sensors.
Second, the hierarchy in learned representations means that cross-modal relationships can be learned at both lowand high-levels of abstraction, corresponding to raw data and refined aggregated concepts respectively.
The same strategies for combining information from multimodal inputs as discussed for shallow classifiers can be
applied to deep neural networks, based on the level where fusion is achieved: Feature Concatenation (FC) with
concatenated inputs from multiple sensing modalities, and Modality-Specific Architecture (MA), with sensorspecific branches for each modality before fusion is achieved later in the network. We describe these two in more
details below.
Essential to all machine learning classifiers is the training process. Various approaches to achieve training and
tuning of multimodal architectures exist here, commonly built on the back-propagation algorithm. Back-propagation
offers the flexibility of distributing gradients both on the joint section of the network, but also on the split section
on each modalities branches. Flexibility of the network is not limited just to back-propagation, but also manifested
in flexibility over data availability (or quality). As such, training algorithms specific to deep architectures facilitate
robustness to missing modality inputs, which allows it to generate (or reconstruct) missing input modality from
the available input by using the joint representation of relations between modalities. For example, auto-encoder
algorithms, originally designed for uni-modal deep models to improve noise tolerance, are adapted to provide a type
of tolerance to missing modalities [43, 52, 70]; this in turn, is understood to assist in discovering representations that
are less prominent, but still discriminative, in power. One illustrative example of such an architecture is the image
caption generation network, which can have its image representation layers improved (i.e., increased detection
quality) through a training method that requires the model to generate both reasonable text and images when only
an image is provided (with text related input layers set to a default state).
Many implementations of deep learning architectures with multiple modalities have been proposed in literature
including Restricted Boltzmann Machine (RBM), CNN, DNN [51, 52]. We employ DNNs and CNNs under
both sensor fusion strategies FC and MA, constructing 4 different architectures (FC-DNN, FC-CNN, MA-DNN,
MA-CNN), which are described in the following sections.

3.3

Feature Concatenation Deep Learning

We refer to a commonly used approach in multimodal data integration using a deep classifier with concatenated
modalities input as Feature Concatenation (FC).
In this approach, sensor fusion is performed right at the input layer by concatenating raw sensor streams (or lightly
processed data) of multiple modalities, to achieve a single large input space. Data propagation pipeline inside the
network proceeds as earlier described, performing a set of transformations on the concatenated input (Figure 2).
This simple design allows easier training, since the model is less sensitive to hyper-parameter settings.
An important remark here is that feature representations inside the network have access to the whole space of
sensing modalities (cross-modality information). However, previous work [52, 63] have shown that intra-sensor
correlations (within the same modality) are stronger than inter-sensor ones (across multiple modalities). Since
hidden layers in FC architectures are exposed to cross-modality information, it is harder to specialize them during
training to extract the essential intra-sensor relations, so these get easily neglected. In addition, training an FC deep
model is also problematic for an unbalanced mixture of inputs, as the units inside the network are easily dominated
by those few proven modalities.
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

157:8

•

V. Radu, et al.

Feed-forward Deep Neural Network (FC-DNN). Feed-forward Deep Neural Networks are comprised of
multiple stacked fully-connected layers, with the information passing from the input layer, starting as concatenated
multimodal data and being transformed sequentially by each layer according to their internal feature representations
and activations. Information flows in one direction through the network, which makes it easy to stack several hidden
layers together. Class estimation is provided by the output layer as described before. In essence, modalities fusion
is achieved at the input level by combining sensor streams into a joint input to propagate through the DNN.
Different activation function and regularization methods also bring their contribution to transformations propagated
between hidden layers.
Convolutional Neural Network (FC-CNN). Similar to FC-DNN, sensing modalities are concatenated into a
single input, which is interpreted with a Convolutional Neural Network in this case.
Convolutional Neural Networks have brought major leaps across many research areas [41]. Two layers are specific
to this construction, Convolution layers and Pooling layers. Convolution layers are characterized by shared weights
and biases as stacks of filters, much smaller in size than the input signal being convolved over. A stack of filters is
trained to recognize different patterns (or features) no matter where these are encountered in the input space by
sliding across the whole input. Although these filters are determined automatically in training, a good initialization
strategy can determine non-overlapping behaviors of filters, each specializing in recognizing different patterns.
Convolution layers are typically followed by a Pooling layer, which reduces the size of the new representation
constructed by filter activations. Pooling and Convolution layers can be stacked to produce more complex features,
progressing in composition throughout the network. A common example comes from computer vision where first
Convolution layers detect simple features like lines, points, colors, followed by other Convolution layers that
activate for shapes, corners, edges and so on until by the end they recognize full body-parts or faces.
Last few layers in a CNN are typically fully-connected layers, as the ones found in DNNs (described in previous
section), taking advantage of strong features generated by the previous layers to determine a class estimation.

3.4

Modality-Specific Architecture in Deep Learning

We refer to this construction comprising of two types of hidden layers – hidden layers related to a specific sensor
type and hidden layers that capture unified concepts across sensor types – as Modality-Specific Architecture (MA).
In this construction, separate architectures are built for each modality to first learn sensor-specific information
before their generated concepts are unified through representations that bridge across all the sensors (i.e., shared
modality representations) later in the network (as illustrated in Figure 3). MA is based on the architecture proposed
in [52], although our formulation and experiments represent the first time this solution has been tested on mobile
sensor data.
Deep Neural Networks (MA-DNNs). Formalizing the earlier high-level description of a multimodal deep
learning architecture: the state (AiL+1 ) of each individual DNN layer: (x iL+1 ) of layer (L + 1) is dependent on the
unit weights connecting the j th node in layer L to the i th node in layer L + 1. The output is determined by the
activation function, for example for a logistic activation function this can be formulated as:
AiL+1 =

1 + exp(−

1
P

L+1 L
j wi j x j )

(1)

As shown in Figure 3, separate architectural branches (Mk ) exist for each sensor type without any intra-branch
connections between layers until later unifying cross sensor layers (Ul ) in the larger multimodal architecture.
While Mk layers learn representations tied to a single modality (such as the accelerometer), Ul layers seek to
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

Multimodal Deep Learning for Activity and Context Recognition
Modality 1

1

157:9

Modality n

Modality 2

v

•

v

h (1)
1

h (1)
2

h (2)
1

h (2)
2
u

v

2

…

n

h (1)
n
h (2)
n

Multi-Modal DNN

Fig. 3. Modality-specific Deep Neural Networks. The network adopts a split architecture: separate branches exist for
each of n modalities, which are then joint in the unifying cross-sensor layers.

learn representations that fuse information between sensors. Collectively, all layers contribute to the learning
of a joint representation of all sensor modalities; in other words, P (vacc . , vдyr o . , vдps , . . . | Θ) where Θ spans all
model parameters. With respect to the architecture, a key hyper-parameter is the depth (i.e., the number of layers)
of every Mk branch and Ul . This changes the complexity and richness of feature representation learned at each
architectural branch. Some sensors are simple (such as a light indicator) requiring little representational power,
others are complex (such as audio data) and benefit from the rich degree of processing to capture the information
they contain. As a result, it is common for Mk to be of variable depth across different branches. The respective
depth of each also impacts, at least conceptually, the type of semantic information that is being attempted to be
fused between each sensor. Depth is also a factor for Ul in terms of controlling the opportunity for representations
that fuse sensors to be discovered, therefore this is impacted by the richness, and sheer number, of the sensors that
fan in. As is standard practice, such hyper-parameters are decided with cross-validation at training time.
Multimodal DNN Learning Algorithm. Conventional deep model training processes, like back-propagation with
supervised training [14], is well suited for this task, due to the flexibility to split gradients onto each modality branch.
In our earlier work [57], we have explored the unsupervised approach as an initial training step with auto-encoders,
followed by traditional back-propagation to fine-tune the network feature representations in a construction called
Restricted Boltzmann Machines. However, the impact of this extra step on accuracy is not significant enough
overall to be deemed important, but the associated increase in training time is a penalty. For that reason we use the
traditional back-propagation for the experiments presented in the evaluation section.
Performing Inferences. Post training, inferences with a multimodal deep model occur similarly as with regular
DNNs. Sensor data of each type is provided as input to the corresponding architectural branch of the MA classifier.
Each branch of the network performs its internal computations independently, same as described for FC before,
producing feature signatures influenced by their internal feature representations. These are then combined in the
joint part of the network, following a typical forward pass from here.
Convolutional Neural Network (MA-CNN). The multimodal construction using CNNs is analogous to that
of MA-DNN. Each sensing modality has its own dedicated CNN to extract preliminary features over several
layers (operating as described for FC-CNN). These produce intra-sensor features which are combined through
fully-connected layers to identify the target class.
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

157:10

• V. Radu, et al.

4 EVALUATION
In this section, we empirically compare different techniques for multimodal learning on wearable devices. We
evaluate the performance of feature representational learning methods, with two feature concatenation (FC) deep
classifiers: FC-DNN and FC-CNN, and two Modality-Specific Architecture (MA) deep classifiers: MA-DNN
and MA-CNN, as detailed in Section 3. These are compared against two commonly adopted shallow methods,
Random Forest (RF) or Decision Tree (DT), or any task-specific purpose-built technique where available. To offer
an overview, our key findings are summaries below:
• Feature representational learning works consistently well across a wide range of activity recognition tasks
(recognition of activity, gait, sleep stage and indoor-outdoor), outperforming shallow classifiers throughout
while avoiding reliance on hand-tuned dedicated features.
• MA-CNN gives the best accuracy in 3 out of 4 datasets studied despite the nature of classification tasks being
very different. Energy consumption measurements indicate this is also sustainable on common wearable devices.
This makes MA-CNN a strong candidate as a default classifier for activity recognition and context detection
with wearables and mobile devices.
• MA deep classifiers outperform FC on all four datasets, achieving accuracies that are on average 5% better. The
difference in accuracies between the MA and FC approaches is most obvious in complex classification tasks,
such as activity recognition, where MA outperform by up to 16%. Nevertheless, both MA and FC based deep
classifiers achieve better accuracies than shallow classifiers.

4.1

Methods

This subsection details the datasets and baselines used for evaluation.
Datasets. We consider four publicly available datasets in order to represent custom setups in a wide range of
activity recognition tasks performed on wearable and mobile devices. Table 1 summarises key features of the data.
STISEN Heterogeneity Activity Recognition Dataset, collected and studied by Stisen et al. [65]. This dataset
contains readings of two motion sensors, Accelerometer and Gyroscope, from 9 users performing 6 activities
(‘Biking’, ‘Sitting’, ‘Standing’, ‘Walking’, ‘Stair Up’, ‘Stair Down’). Great device diversity is captured in the
dataset, each participant collecting data with 8 different smartphones and 4 smartwatches.
GAIT A dataset comprising of data from 460 participants, which forms a diverse sample of the population with
distribution across ages (8 to 78 years old) and genders. Previously studied by Ngo et al. [53] with highly engineered
signal-based solutions. Gait recognition is done on 5 classes: walking on flat surface, walking up slope, walking
down slope, descending stairs and ascending stairs. The data was captured with two inertial sensors (accelerometer
and gyroscope), each sampling in triaxial dimension. Remarkable to this dataset is the large population sample and
diversity as mentioned earlier.
Sleep-Stage (SS) The Sleep-EDF Database [19], part of PhysioNet, contains physiological data (two EEG readers,
one EOG and one EMG) collected from 20 people, annotated with 6 sleep stages (‘Awake’, ‘Stage 1’, ‘Stage 2’,
‘Stage 3’, ‘Stage 4’, ‘REM’). All participants in this dataset suffer from sleep disorders, making it substantially
difficult to find simple patterns across all subjects.
Indoor-Outdoor (IO) This dataset [56] contains smartphone sensor readings (light, proximity, magnetic, microphone, cell, battery thermometer), from two different phones and annotated with ‘indoor’ or ‘outdoor’. This was
collected in 3 different environments (university campus, city center, residential areas), which brings high variations
in the signal patterns as previously highlighted in [56].
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

Multimodal Deep Learning for Activity and Context Recognition
Dataset

No. of users

No. of classes

No. of modalities

STISEN
GAIT
Sleep-Stage
Indoor-Outdoor

9
460
20
2

6
5
5
2

2
2
4
7

•

157:11

Table 1. Summary of datasets used in our evaluation. Each dataset is selected based on its intrinsic complexity, such
as the number of users (GAIT), diversity of sensing devices (STISEN), diversity of participants (SS) and number of
sensing modalities (IO).

Baselines and tools. This section introduces the classifiers used for comparison on the four datasets summarized
before (Table 1). We consider the following popular shallow classification techniques as our benchmark:
• Random Forest (RF): shallow-classifier-based feature concatenation, ensemble of decision tree classifiers;
• Decision Tree (DT): shallow-classifier-based feature concatenation; C4.5 is often used in wearable devices due
to the low resource footprint and effectiveness in types of activities with few degrees of freedom (small feature
space), e.g. walking or running.
For each recognition task, we compare the performance of deep classification techniques (FC-DNN, FC-CNN,
MA-DNN, MA-CNN) with shallow techniques (RF and DT). In the case of the GAIT dataset, we also extend the
comparison to five other purpose-built inference models, previously considered in the literature and established as
best-performing for gait recognition [53].
We compare the performance of these classifiers based on the F1-score, defined as the harmonic mean of precision
and recall, 2×precision×recall
precision+recall . This metric is sensitive to misclassifications, and also robust to unbalanced distributions
of samples across classes.
Methodology. Evaluation of shallow classifiers was performed in line with their original works, such as employing
the same features as described in [65], for activity recognition or by extracting ECDF features (which shows good
performance in our evaluation despite its compression effect). In cases where an earlier analysis is not available
(e.g. for SS), training and testing of traditional classifiers are performed with Weka [23].
Datasets are split into training set and test set following the leave-one-outmethod, permuting which instance is left
aside as test data and averaging across all iterations to get the final performance. It is never trivial to train deep
neural networks optimally, so to speed up the training process, we performed a random search to identify the most
appropriate hyperparameters (including depth and number of nodes) for each task, guided by the best F1-score on
the test set.
Deep neural networks are particularly good at extracting their own internal features representation, performing well
directly on raw data. The only intervention on these datasets was to normalize the sampling rate with a low-high
pass filter, this being common practice when using Android devices due to the irregular sampling rate. Sampling
frequency is chosen in alignment with previous analysis on such datasets. Appropriate time window size is another
task-specific parameter as well as the overlapping between signal segments (experimenting with values between
50% and 70%), which control the amount of useful information provided to the classifier as independent inputs and
increase the number of training samples respectively. We consider these the minimal preprocessing requirements
for training with deep neural networks. To highlight the advantages of just minimal preprocessing of data for
training deep neural networks, we perform other common preprocessing transformations like frequency domain (by
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

157:12

• V. Radu, et al.

transforming the time window signal using the Fast Fourier Transform) and the Empirical Cumulative Distribution
Function (ECDF) features at specific interest points, to compare with.

4.2

Comparison of Multimodal Context Recognition Techniques

Here we present the results achieved by the previously described multimodal techniques on the four context
recognition tasks: activity recognition (Stisen dataset), gait recognition (Gait dataset), sleep stage detection (SS
dataset) and indoor vs. outdoor detection (IO dataset).
Figure 4 shows the average F1-scores of selected classifiers. We interpret these results taking the following views:
Deep vs. Shallow Classifier. Deep learning classifiers outperform shallow classifiers across all four datasets,
generalizing across diverse tasks without the pain of features identification as required when working with traditional
shallow classifiers. When comparing deep solutions against common shallow classifiers (DT, RF), the average
accuracy difference is substantial, 27%. CNN-based architectures dominate in all but one dataset (GAIT), where a
task-specific approach [53] performs slightly better.
Deep: Feature Concatenation vs. Modality-Specific Architecture. Table 2 presents the F1 scores for best
performing MA deep classifiers, FC deep classifiers and shallow classifiers across the four datasets. From this we
see that MA consistently outperforms FC deep architectures in terms of accuracy. This is an indicator that early
representations on each sensing modality help to discriminate between classes right from the first few layers of
the network, in contrast to concatenated modalities inputs which mix data representations too early, thus missing
valuable insights within each sensing modality.
Feature Concatenation: Deep vs. Shallow. Considering both shallow and deep classifiers adopting FC, FC-deep
classifiers on average outperform FC-shallow classifiers, by 24% in many cases.

STISEN
GAIT
Sleep-Stage
Indoor-Outdoor

MA- deep

FC- deep

Best-performing shallow

81.6
89.5
66.4
82.3

70.36
88.6
65.1
80.1

74.5 (RF)
93.22 (NGO2014)
55.04 (RF)
58.92 (RF)

Table 2. Comparison of MA-deep classifier, FC-deep classifier and the best performing shallow classifier for each
dataset. We highlight the best-performing architecture under each task.

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

Multimodal Deep Learning for Activity and Context Recognition

•

157:13

MA-DNN

MA-DNN

MA-CNN
FC-DNN

MA-CNN

FC-CNN

FC-DNN

DT

FC-CNN

RF
NGO2014
NGO2012

DT

SIIRTOLA2012
APIWAT2011

RF

BOF2012

0

25

50

75

100

0

F1 Score

MA-DNN

MA-CNN

MA-CNN

FC-DNN

FC-DNN

FC-CNN

FC-CNN

DT

DT

RF

RF
50
F1 Score

(c) Sleep-Stage dataset

75

100

(b) GAIT dataset

MA-DNN

25

50
F1 Score

(a) STISEN dataset

0

25

75

100

0

25

50

75

100

F1 Score

(d) Indoor-Outdoor dataset

Fig. 4. F1 score achieved by different classifiers, (MA- and FC- neural networks based methods, and shallow or
purpose-built methods) on the four datasets. This evaluation is performed with input samples in time domain for
deep learning classifiers and features extracted specifically for each dataset to use in shallow classifiers. Despite the
effort with shallow classifiers to extract the most relevant features for each domain task (based on previous studies
for each dataset), deep learning classifiers still perform better without such requirements.

4.3 Activity recognition with large device diversity: STISEN dataset
The first experiment is conducted on the Stisen dataset, which features data from only 9 users but with large device
diversity. To obtain reliable user-independent results, we perform training with the leave-one-out policy, so that
data from each subject is used in turn once as test data, while data from all other eight subjects is contained in a
training set. In the preprocessing phase, sample rate of sensor data collected with Android devices is normalized to
50Hz, and segmented in time windows of 2 seconds with overlapping of 50%. This is required to guarantee that
inputs to neural networks are always the same size and capture a constant time window.
Results for this experiment averaging over 9 subjects are presented in Figure 4(a), which shows that MA deep
classifiers achieve the best accuracies, with F1-score of 82%, while FC deep classifier and shallow classifiers both
achieving just about 70%-75%.
A more in-depth perspective is provided in Figure 5, where the accuracy of each deep classifier is presented per
subject. This shows that MA deep classifiers are able to maintain an accuracy above their FC counterparts. It is clear
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

157:14

• V. Radu, et al.
100

F1 Score

75
50
25
0

User A

User B

User C

User D

MA-DNN

User E

User F

MA-CNN

User G

FC-DNN

User H

User I

FC-CNN

Fig. 5. Per-user comparison of the four deep learning methods MA-DNN, MA-CNN, FC-DNN, and FC-CNN on the
activity recognition task using the Stisen dataset.

that FC deep classifiers perform suboptimally for some users, indicating a bad generalization due to not identifying
relevant intra-modality feature representations, while the MA is uniformly better across all users.
Though deep learning methods achieve better performance than shallow classifiers, the complexity of this dataset has
an impact on the accuracy magnitude, with values below 90%. To improve this, we found that incremental training
with the MA-DNN architecture, where less than 5 minutes of labeled data from the same device (customizing the
model to one individual-device pair) is enough to boost performance by about 18%, well into the desirable region.
Feature representation learning. Deep classifiers taking raw data (time domain) as input are found to produce
better results than shallow classifiers, which must rely on adequate features selection. We consider the following
alternative forms of preprocessing transformations on our input data:
• Fast Fourier Transformation (FFT), input data in frequency domain;

• Empirical Cumulative Distribution Function (ECDF) with chosen sample points.
These transformations are akin to features extraction as their role is to filter the raw data stream into a different,
more compact representation.
In Figure 6 we observe that, when compared to raw data inputs, applying these transformations in the data
preprocessing stage lowers the accuracy of MA deep classifiers (also trained with transformed samples), by almost
5%. This decrease in accuracy of MA classifiers after applying feature extraction (data transformations) suggests
that MA deep classifiers are more capable to perform inferences directly from raw data. Access to raw data allows
these classifiers to extract their own unfiltered representation of strong features in sensor signals.
100

Raw data

FFT

EDCF

F1 Score

75

50

25

0

MA-DNN

FC-DNN

Fig. 6. Comparison of accuracies achieved by classifiers without features extraction (no data transformation) and
with features extraction (data transformation with FFT and ECDF) on the STISEN dataset.

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

Multimodal Deep Learning for Activity and Context Recognition

•

157:15

4.4 Activity recognition with large number of participants: GAIT dataset
This recognition experiment is performed on the GAIT dataset, which joins data from a very large number of
participants (460), with a broad demographic distribution. We split this dataset into two sections, used for training
and test, following the same distribution as presented in [53].
In this experiment, we compare deep classifiers with purpose-built solutions and shallow classifiers. As before, we
evaluate four deep classifiers: FC-DNN, FC-CNN, MA-DNN and MA-CNN. For benchmarking these, we use the
same shallow classifiers (DT and RF) and additionally some earlier purpose-built solutions engineered for this task
and dataset alone as presented in [53]: NGO2014, NGO2012, SIIRTOLA2012, APIWAT2011, and BOF2012.
Figure 4(b) presents the performance of above mentioned models, showing that both representational learning
methods (FC and MA) and the purpose-built shallow classifier, NGO2014, produce very good results. The highest
accuracy was achieved by NGO2014 at 93.2%, followed by MA-DNN and FC-CNN at 89.7%. It is worth noting
here that this gap in accuracy between the highly-engineered purpose-built detector, NGO2014, and the general
purpose deep classifiers is surprisingly narrow. This indicates that general representational learning methods can
closely match the performance of purpose-built methods, potentially limited only by data surplus and training
effort.
Figure 7 presents a per action class comparison of performance across the best-considered models. It is easy to
observe the consistently good performance of deep classifiers across classes. Further, Figure 8 shows a per user
cumulative distribution of the F1 scores achieved by FC and MA deep classifiers. This distribution shows that even
on a per-user level, MA deep classifiers outperform FC deep classifiers, with above 90% accuracy in more than
50% of the cases.
100

F1 Score

75
50
25
0

Level Walk
MA-DNN

Up-Stairs
MA-CNN

FC-DNN

Down-Stairs
FC-CNN

NGO2014

Up-Slope
NGO2012

SIIRTOLA2012

Down-Slope
APIWAT2011

BOF2012

Cumulative Probability

Fig. 7. Per-action class comparison between the performance of all deep learning classifiers and purpose-built
solutions on the GAIT dataset.

FC-DNN
FC-CNN
MA-DNN
MA-CNN

Average F1 Score

Fig. 8. Cumulative distribution of per-user F1 score of deep classifiers on the GAIT dataset.
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

157:16

• V. Radu, et al.

Feature representation learning. Here we compare different preprocessing transformations for this dataset,
similar to those presented for the Stisen dataset. As shown in Figure 9, data transformations significantly lower the
accuracy of all deep classifiers (by 11% on average) compared to inference on raw data. This decrease in accuracy
after applying feature extraction confirms earlier observations made on the Stisen dataset, suggesting that deep
classifiers are capable of performing inference directly on raw data much better than when these are interpreted by
various transformations.

100

Raw data

FFT

EDCF

FC-DNN

FC-CNN

F1 Score

75

50

25

0

MA-DNN MA-CNN

Fig. 9. Comparison of accuracies achieved by deep classifiers without feature extraction and with features extraction
(data transformation with FFT and EDCF) on the GAIT dataset.

4.5

Sleep Stage Detection

This experiment considers other sensing modalities, different from the accelerometer and gyroscope available in
the previous two datasets, detecting sleep stage from physiological data signals.
The SS dataset has 4 modalities with a sampling frequency of 100Hz. In the preprocessing stage, the sampling
frequency is down-sampled to 10Hz to reduce the size of input to our neural networks (and thus the computational
costs), while also capturing a large enough time window of 10 seconds for each classification instance. We find that
sleep stages 1 and 3 are highly similar, so we group them as a single class. Features for shallow classifiers were
extracted using the ECDF method presented before.
From the results presented in Figure 4(c), we can see that feature representational learning methods achieve
much better accuracies than shallow methods. On average, we find that deep classifiers enable a 29% accuracy
improvement over shallow methods. When looking at a break down of F1-scores per class (Table 3), we find
that this improvement is mainly attributed to an almost doubling of performance on classes ‘Sleep Stage 4’ and
‘REM’, which shallow classifiers find particularly difficult to detect. MA deep classifiers are slightly more accurate
than FC by about 2%, while shallow classifiers are clearly suboptimal for this task. One possible explanation is
the simplicity of chosen features to train shallow classifiers, though it also highlights the difficulty of identifying
relevant features in new and unexplored detection tasks.
Feature representation learning. Figure 10 presents a comparison between time domain signals input (raw data)
and the same two signal transformations as before, FFT and ECDF provided as input to the four deep classifiers.
While the performance of deep classifiers on the raw data is nearly 70%, operating on signal transformations
reduces the accuracy to about 12% on average.
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

Multimodal Deep Learning for Activity and Context Recognition
MA-DNN

MA-CNN

FC-DNN

FC-CNN

RF

J48 (DT)

66.13
27.59
77.08
68.40
72.48
64.50

70.94
30.03
80.18
79.59
75.91
68.22

65.06
25.07
76.19
68.40
70.86
63.19

69.28
29.50
79.65
74.20
73.94
67.01

51.28
33.15
70.62
44.53
47.33
55.04

39.74
33.63
60.43
31.28
37.09
46.59

Wake
Stage 1 & 3
Stage 2
Stage 4
REM
Weighted average

•

157:17

Table 3. F1 scores for all classifiers in each sleep stage detection on the Sleep-Stage dataset.

100

Raw data

FFT

EDCF

FC-DNN

FC-CNN

F1 Score

75

50

25

0

MA-DNN MA-CNN

Fig. 10. Comparison of accuracies achieved by classifiers without features extraction and with features extraction
(data transformation FFT and ECDF) on the Sleep-Stage dataset.

4.6

Indoor-Outdoor Detection

The IO dataset has its own unique characteristics which make this an interesting exploration – 7 independent and
different sensing modalities. It is a binary classification task, though highly diverse across the three environments
where data was collected from.
‘Indoor’ and ‘outdoor’ areas are sampled from three environments: Campus, City Centre, Residential area, which
we labeled as ‘env1’, ‘env2’ and ‘env3’ respectively. We perform the training with the leave-one-out (environment)
method, so that each environment takes turn in being the test dataset while the other two assist in training the
classifier. Table 4 presents results of each classifier over the three iterations.
Figure 4(d) again confirms that feature representational learning methods are successful, as they achieve much
better accuracy than shallow methods (by 43% on average). This observation still holds on a per-environment level,
as shown in Table 4. It can be observed that deep classifiers perform consistently better across all environments.
Another observation is that all classifiers perform significantly poorer when tested with ‘env2’, suggesting that
it is the hardest environment to detect; this is also true taking a geographical perspective of the areas where data
was collected from, with the university Campus and the Residential environments being in closer geographical
proximity and farther away from the City Centre. We also see that within shallow classifiers, Random Forest
perform better than Decision Tree by 7%.
Feature representational learning. In Figure 11 and as previously observed, classification on raw data with deep
classifiers achieves the best performance, here about 81%. After preprocessing the input data with previously
mentioned transformations (FFT and ECDF), the accuracy of classifiers drops by about 13% on average.
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

157:18

• V. Radu, et al.
Training set

Test set

MA-DNN

MA-CNN

FC-DNN

FC-CNN

DT

RF

env2 + env3
env1 + env3
env1 + env2

env1
env2
env3

87.75
65.44
92.64

87.87
67.38
92.97

84.5
57.62
90.19

87.87
67.38
92.97

77.05
26.6
60.95

68.45
38.7
69.63

Table 4. F1 scores for cross-environment evaluation on the Indoor-Outdoor dataset.

100

Raw data

FFT

EDCF

FC-DNN

FC-CNN

F1 Score

75

50

25

0

MA-DNN MA-CNN

Fig. 11. Comparison of accuracies achieved by deep classifiers without feature extraction and with features extraction
(data transformation with FFT and ECDF) on the Indoor-Outdoor dataset.

5 MOBILE HARDWARE FEASIBILITY
Deep architectures exert significant resource challenges on embedded platforms, mainly due to their high demands
of memory, computations and energy. In the following, we present runtime experiments on two embedded platforms,
namely Snapdragon 400 and Snapdragon 800 SoCs, see Figure 12. Feasibility experiments presented in this section
are focused mainly on system resource-usage of the deep architectures. Deployment experiments are performed
with an efficient hand-tuned implementation of all deep models presented earlier in this work.

5.1 Target Mobile Hardware
Qualcomm Snapdragon 400. While targeting wearable devices, this Qualcomm processor offers similar performance to many smartphones. It is found within a range of smartwatches, such as the LG G Watch R [42] and
includes a quad-core 1.4 GHz CPU and 1 GB of RAM. Additional GPU and DSP processors are also available, but
due to a lack of driver support we are forced to use the CPU only for experiments.
Qualcomm Snapdragon 800. As the second embedded platform we use the Snapdragon 800 SoC and run all the
deployment experiments on this platform and measure energy consumption and overall runtimes. As in the case
with Snapdragon 400, we only use the CPU on Snapdragon 800 to execute the deep models.

5.2 Model Runtime Implementation
To assess the resources demanded by the various multimodal DNNs validated in the prior section, a shared runtime
is implemented that executes the inference stage (only) of each model. This prototype is realized through a mix of
modules from the Torch [67] ported individually to each processor, that is supported by a set of custom C/C++
components implemented by the authors. Although Torch introduces a degree of overhead, as it acts as an interpreter
for the high-level Lua language (in which we encode all models and their parameters), it also offers a number of
low-level, highly optimized mathematical operation APIs, which are useful for deep model executions. That said,
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

Multimodal Deep Learning for Activity and Context Recognition

(a) Snapdragon 400

•

157:19

(b) Snapdragon 800

Fig. 12. The development board for profiled wearable-class hardware; processors and measured energy profiles of
the boards are identical to that of processors found in commercial wearables. For example, the Snapdragon 400
(a) is found within smartwatches, such as the LG G Watch R Smartwatch and (b) Snapdragon 800 is found within
Samsung Galaxy 9005 and Nokia Lumia 1520.

certain native Torch operations are replaced with C/C++ extensions to exploit processor-specific opportunities for
execution speedup, and better memory management. Furthermore, additional components (e.g., FFT library) are
used for any conventional feature extraction as needed by the model specification.
Overall, this implementation can be characterized as adopting best practices understood by those who regularly handoptimize deep learning models – either for scalability, or in this case operation in resource-limited environments.
More obvious examples of incorporated optimizations include keeping of minimal model architectures needed
by the inference stage, and the profiling of the data flow of runtime execution to understand memory and cache
bottlenecks; or even changing the power profile of processor components to improve the trade-off between execution
times and energy use.

5.3 System Resource Usage Experiments
For each of the four activity datasets evaluated in the prior section, we examine runtime resource demands, e.g.,
memory, computation and energy, of all deep models studied in this paper. Performance comparisons are drawn
across all models on two embedded platforms.
The memory requirements of different types of deep model architectures trained on individual data sets are
summarized in Table 5. While storing individual model parameters we use 32-bit precision. The largest model
(33.1 MB) was found to be the FC-DNN, trained on the STISEN dataset and the smallest model (0.2 MB) was the
MA-DNN model trained on the Indoor-Outdoor dataset.
Table 6 and 7 respectively illustrates the average running time (in milli-seconds) and energy consumption (in mJ)
of the deep models observed on the Snapdragon 400 platform. We repeated each inference 1000 times and took
the average time and energy to mitigate the effect of inherent variations in OS executions. Similarly in Table 8
and 9 we present the runtime results as observed on the Snapdragon 800 platform, which is heavily impacted by
the Android scheduling system, resulting in poorer performance than Linux based Snapdragon 400. Despite this,
results indicate that the deep models can be executed efficiently on embedded platforms.
Lastly, in Figure 13, we present a variation of CPU load and memory requirement observed on the Snapdragon
400 platform, while executing a MA-CNN model trained on the Gait dataset. The MA-CNN model begins by
executing two convolutional layers in parallel and keeping the CPU load almost 100%. The convolution layers
require small number of parameters and this keep the overall memory demand low. Once the convolution operations
are completed, the CPU load drops to a lower value as the OS becomes occupied in loading the parameters from
memory, making memory demand rise. Once all the parameters are loaded in the memory the CPU load becomes
rises again to obtain the final inference result.
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

157:20

• V. Radu, et al.

100

2.00

Memory requirement (MB)

1.75

80

CPU load (%)

1.50
60

1.25
1.00

40

0.75
0.50

20
0

0.25
0.0

0.5

1.0

1.5

2.0

Time (ms)

2.5

3.0

0.00

Fig. 13. CPU load and memory requirement against time.

MA-DNN
MA-CNN
FC-DNN
FC-CNN

STISEN (MB)

GAIT (MB)

Sleep-Stage (MB)

Indoor-Outdoor (MB)

22.1
8.4
33.1
8.4

12.5
18.6
2.1
6.0

1.9
3.7
0.3
0.3

0.2
0.4
0.6
0.6

Table 5. Trained Model sizes (in MBytes) across all data sets under 32-bit precision.

MA-DNN
MA-CNN
FC-DNN
FC-CNN

STISEN (ms)

GAIT (ms)

Sleep-Stage (ms)

Indoor-Outdoor (ms)

2.8
9.7
3.5
6.5

1.9
3.3
2.2
7.7

1.5
2.5
0.8
1.5

1.7
0.9
0.5
0.7

Table 6. Average model execution time (milli-seconds) observed on Snapdragon 400.

MA-DNN
MA-CNN
FC-DNN
FC-CNN

STISEN (mJ)

GAIT (mJ)

Sleep-Stage (mJ)

Indoor-Outdoor (mJ)

5.4
18.7
6.7
12.5

3.7
6.4
4.2
14.8

2.9
4.8
1.5
2.9

3.3
1.7
1.0
1.3

Table 7. Average energy consumption (milli-Joule) due to individual deep models observed on Snapdragon 400.

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

Multimodal Deep Learning for Activity and Context Recognition

MA-DNN
MA-CNN
FC-DNN
FC-CNN

STISEN (ms)

GAIT (ms)

Sleep-Stage (ms)

Indoor-Outdoor (ms)

38.8
134.4
48.5
90.1

26.3
45.7
30.5
106.7

20.8
34.7
11.0
20.8

23.6
12.5
6.9
9.7

•

157:21

Table 8. Average model execution time (milli-seconds) observed on Snapdragon 800.

MA-DNN
MA-CNN
FC-DNN
FC-CNN

STISEN (mJ)

GAIT (mJ)

Sleep-Stage (mJ)

Indoor-Outdoor (mJ)

63.6
220.5
79.6
90.1

43.2
75.0
50.0
106.7

34.1
56.8
18.2
34.1

38.6
20.5
11.4
15.9

Table 9. Average energy consumption (milli-Joule) due to individual deep models observed on Snapdragon 800.

6 DISCUSSION AND LIMITATIONS
This section discusses the practicality of using deep learning for general ubiquitous computing tasks, observed
from our experience, describing the difficulties encountered and choices made in training deep neural networks;
continuing the discussion with current limitations and the opportunity for future work.
Sensor Signal Preprocessing. From the experiments reported in Section 4, it is clear that operating directly on
raw data (i.e., time domain), instead of preprocessing data with FFT or ECDF is not only more computationally
efficient (avoiding data transformations) but also effective in training a more accurate model. Choosing an optimal
time window size is also important and very specific to the detection task. When activity classes are very similar, a
larger time window can help to capture more information – the obvious downside is that a larger input increases
computation cost for the neural network. We find that it is a good practice to start with small time windows (such
as 30 ms) and gradually expand to capture more information.
The Training Process. A good strategy in training is to start with a small network (such as two layers with a small
number of neurons per layer) and gradually expand the size and complexity of the network driven by observations
on a separate set of instances (validation set).
When calibrating the network, we consider the key factors: bias, variance, training data distribution. High bias
occurs when the model is performing poorly on both training and validation datasets; this is usually addressed by
increasing the size of the model or that of the training set. High variance occurs when the classifier overfits training
data with good performance on training set but poor on validation set, in which case reducing the network size
or introducing regularization (discussed below) can help. In situations where datasets are too small, alternative
solutions have proven successful in eliminating this limitation by adopting Active Learning in Bayesian DNNs [16].
In the following we detail some assumptions and decisions made in this exploration:
Learning Rate. In the traditional stochastic gradient descent, this indicates the weights update strength in backpropagation. Careful selection of its value is important: a large value may never converge, while a value too small
may take infinitely long to converge. A typical value is 1e-3, though no two training sets are the same, so variations
need to be considered to achieve a good convergence. In our exploration, values between 1e-1 and 1e-5 were the
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

157:22

• V. Radu, et al.

most effective. Learning rate also works in pair with momentum which encourages updates when gradients are
consistently in the same direction. Adam algorithm for learning rate policy was determined to be very efficient in
many cases.
Number of epochs. The training process executes forward and backward propagations over the entire dataset in one
epoch. It is typical for networks to converge very slowly on a complex dataset, affected by noise in data or high
similarity in classes. In this situation, a higher number of epochs is required to converge, lengthening the training
time. With too many epochs the network may just produce insignificant updates, which should be detected by an
early stop policy when the network has converged. In our implementation, we restricted the number of epochs to a
maximum of 400 with an adaptive learning rate policy.
Network initialization. The simplest approach to initialize the weights between neurons and biases is with random
small values chosen from a mean zero and one variance distribution. Auto-encoders are another solution in
initializing the network before supervised learning. From unlabelled data instances an auto-encoders can extract
features by reproducing the input to the output on sections of the network. However, in our case datasets are already
labeled and networks have only a small number of layers so the impact of auto-encoders is minimal.
Dropout ratio. The dropout layer is a common method for regularization due to its simplicity and efficiency. This
implies randomly dropping connections between neurons during training to avoid reliance on single paths through
the network (dominant neurons). Its disadvantage comes from extending training time due to more combinations
of network connections needing to be reinforced for the network to learn effectively. Training time is affected by
dropout factor and width of the connecting layers.
Batch Normalization. This is another very efficient solution for regularization. With the presence of a Batch
Normalization layer, weights are normalized again after each update, which allows for a larger value for learning
rate to be used – faster training time.
We make our implementation code available as a training framework dedicated to multimodal sensing data for other
researchers to use in their work [18].
Additional Deep Learning Methods. Advances in deep learning continue to proliferate and produce a growing
range of potential avenues with the potential to improving modeling of wearable and mobile sensor data. It
is important to note that in this investigation we concentrated only on performing inferences on static frames,
discarding their temporal connection with other frames. This can be seen as one shot classification, not requiring to
track sensor signals for a long period of time, ideal for applications requiring occasional sensing. However, other
solutions like Recurrent Neural Networks (RNNs) [20] and Long Short-Term Memory (LSTM) can take advantage
of this time correlation to improve performance even further. We leave this as open opportunity for further research.

7 RELATED WORK
Applications of Multimodal Learning. Multimodal learning has a vast application domain. Applications have
been seen in audio-visual speech recognition [52], image captioning [63], machine translation [34], sentiment
analysis [55] and affect recognition [30]. In the space of ubiquitous computing, example applications include
human activity recognition [1], sleep detection [12] and emotion recognition [36]. Many recognition tasks were
previously only primarily performed with unimodal learning, with the availability of low-energy sensors, many
such tasks are recently explored using multimodal learning. For example, authentication models involve both gaze
and touch recognition [32], or eating recognition might involve motion of head, wrist and audio [47].
Multimodal Sensor Fusion. Conceptually, classification models based on multimodal sensor data have a clear
relationship to techniques of sensor fusion. Within sensor networks, and more broadly in fields such as robotics,
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

Multimodal Deep Learning for Activity and Context Recognition

•

157:23

fusion methods routinely leverage different sensor types for purposes like localization [6, 10, 54, 61]. However,
the fusion techniques developed are difficult to directly apply to the design of learning algorithms and the feature
representations they operate on. More direct insights and methods are found in the design of classifiers of related
domains, such as: computer vision, scene understanding [21] and affective computing [30] – as well as numerous
examples of existing models of context and activity recognition. In short: the use of, and benefiting from, the input
of multiple sensor types is nothing new. But understanding how to combine significantly different sensor inputs is
still an open problem. Although multimodal models are routinely seen, the tools we have to construct them (ranging
from ensembles of separate classifiers to co-training or simply collapsing data types into single feature vectors)
each have their shortcomings; and even simple questions (such as, at what stage should data types be merged?)
must still be addressed on a case by case basis (e.g., [62]).
Multimodal Deep Learning. A prime example in the general space of multimodal deep learning is audio-visual
speech recognition [50], where much work has been done using neural networks [52]. A number of neural networks
have been proposed to perform multimodal deep learning, including CNN [51], RBM [52] and RNN [46]. The
choice of neural network often depends on the type of recognition involved, as there is currently no consensus
on which network would work best. For instance, in tasks where sequential data is involved (e.g. image sentence
description [46]), multimodal versions of recurrent neural networks have been frequently proposed to handle these
tasks. While there is work comparing a small number of multimodal learning methods, such as [8] which compares
decision tree classifiers with back propagation neural networks, we note that there has not been a comprehensive
case study comparing a greater number of deep and shallow multimodal learning architectures. Finally, we wish to
highlight an early version of this study was presented in poster form [57] – though the work presented here is of
course a significant extension.
Deep Learning in Ubiquitous Computing. Only recently has the exploration into deep learning methods for
mobile sensing scenarios begun (e.g., [24, 39]). But with the diversity of exploration rapidly expanding [3, 7, 16,
17, 25, 31, 40, 49, 71]. To the best of our knowledge, the work presented here is the first time that the detection
of indoor/outdoor context and transportation mode has been attempted with any form of deep learning, even for
single sensor modalities. There is still much to be understood in how such models should be architected, and which
variety of algorithms will be most effective – our work adds to this knowledge, that is still in a nascent stage.
Closely related models to those we propose in this work are found in [52]. However, we use simpler Restricted
Boltzmann Machines rather than the deep version described in [52] (although, both are still forms of deep learning).
Similarly, [33, 64] concern themselves with multimodal models but focus tightly on learning features. None
of these papers consider mobile sensor data types nor the classification objectives we study here. Furthermore,
few consider a mobile platform as the operating environment of their models. In fact, little multimodal study of
this aspect of our work exists, although broad understanding of resource-limited deep learning is accelerating
[4, 11, 26, 29, 37, 38, 59, 68] and we expect many existing results to extend to multimodal formulations, though
this still remains to be verified.

8 CONCLUSION
In this paper, we perform a systematic study of multimodal deep learning architectures to assess how and when
these new techniques satisfy the exigencies of activity and context inferences with mobile devices. We present
experiments with four distinct variants of deep neural networks across very diverse and difficult context detection
datasets, while comparing their performance with common shallow classifiers and hand-crafted task-specific
detectors. Two of these variants are state-of-the-art in deep learning architectures for performing modalities fusion
used in other scenarios (video, voice, text) – here, referring to as MA-DNN and MA-CNN – and are for the first time
used with wearables and mobile sensing devices for activity recognition and context detection. Experiments that
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

157:24

• V. Radu, et al.

span a wide range of sensor types, competing multimodal learning algorithms, and activity and context detection
tasks, collectively show our proposed general-purpose deep approach to multimodal sensor fusion modeling is both
broadly applicable and is able to exceed the performance of previous general solutions and even match task-specific
sensor-tuned solutions. This innovation in sensor data modeling is complemented with a practical proof-of-concept
implementation designed to measure the overhead of these techniques on two state-of-the-art mobile/wearable
processors. Results show that devices that adopt the deep modeling approach, emphasized here, are able to maintain
sustainable norms of size, weight and lifetime despite the increased complexity of deep learning methods.

ACKNOWLEDGMENTS
This project received funding from the European Commission’s Horizon 2020 research and innovation programme
under grant agreement No 687698, through a HiPEAC Collaboration Grant. We thank all the anonymous reviewers
for their constructive comments, which helped us to improve the quality of this work.

REFERENCES
[1] Michael Barz, Mohammad Mehdi Moniri, Markus Weber, and Daniel Sonntag. 2016. Multimodal Multisensor Activity Annotation Tool.
In Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct (UbiComp ’16). ACM,
New York, NY, USA, 17–20. https://doi.org/10.1145/2968219.2971459
[2] Yoshua Bengio, Ian J. Goodfellow, and Aaron Courville. 2015. Deep Learning. (2015). http://www.iro.umontreal.ca/~bengioy/dlbook
Book in preparation for MIT Press.
[3] S. Bhattacharya and Nicholas D. Lane. 2016. From smart to deep: Robust activity recognition on smartwatches using deep learning.
In 2016 IEEE International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops). 1–6. https:
//doi.org/10.1109/PERCOMW.2016.7457169
[4] Sourav Bhattacharya and Nicholas D. Lane. 2016. Sparsification and separation of deep learning layers for constrained resource inference
on wearables. In Proceedings of the 14th ACM Conference on Embedded Network Sensor Systems CD-ROM. ACM, 176–189.
[5] Christopher M. Bishop. 2006. Pattern Recognition and Machine Learning (Information Science and Statistics). Springer-Verlag New
York, Inc., Secaucus, NJ, USA.
[6] Tatiana Bokareva, Wen Hu, Salil Kanhere, Branko Ristic, Neil Gordon, Travis Bessell, Mark Rutten, and Sanjay Jha. 2006. Wireless
sensor networks for battlefield surveillance. In Proceedings of the land warfare conference. 1–8.
[7] Heike Brock, Yuji Ohgi, and James Lee. 2017. Learning to judge like a human: convolutional networks for classification of ski jumping
errors. In Proceedings of the 2017 ACM International Symposium on Wearable Computers. ACM, 106–113.
[8] Donald E. Brown, Vincent Corruble, and Clarence Louis Pittard. 1993. A comparison of decision tree classifiers with backpropagation neural networks for multimodal classification problems. Pattern Recognition 26, 6 (1993), 953 – 961. https://doi.org/10.1016/0031-3203(93)
90060-A
[9] Andreas Bulling, Jamie A. Ward, and Hans Gellersen. 2012. Multimodal recognition of reading activity in transit using body-worn sensors.
TAP 9, 1 (2012), 2. https://doi.org/10.1145/2134203.2134205
[10] Jose A Castellanos and Juan D Tardos. 2000. Mobile robot localization and map building: A multisensor fusion approach. Kluwer
academic publishers.
[11] Guoguo Chen, Carolina Parada, and Georg Heigold. 2014. Small-footprint Keyword Spotting Using Deep Neural Networks. In IEEE
International Conference on Acoustics, Speech, and Signal Processing (ICASSP’14).
[12] W. Chen, A. Sano, D. L. Martinez, S. Taylor, A. W. McHill, A. J. K. Phillips, L. Barger, E. B. Klerman, and R. W. Picard. 2017.
Multimodal ambulatory sleep detection. In 2017 IEEE EMBS International Conference on Biomedical Health Informatics (BHI). 465–468.
https://doi.org/10.1109/BHI.2017.7897306
[13] Tanzeem Choudhury, Gaetano Borriello, Sunny Consolvo, Dirk Haehnel, Beverly Harrison, Bruce Hemingway, Jeffrey Hightower,
Predrag "Pedja" Klasnja, Karl Koscher, Anthony LaMarca, James A. Landay, Louis LeGrand, Jonathan Lester, Ali Rahimi, Adam Rea,
and Danny Wyatt. 2008. The Mobile Sensing Platform: An Embedded Activity Recognition System. IEEE Pervasive Computing 7, 2
(April 2008), 32–41. https://doi.org/10.1109/MPRV.2008.39
[14] Li Deng and Dong Yu. 2014. DEEP LEARNING: Methods and Applications. Technical Report MSR-TR-2014-21. http://research.
microsoft.com/apps/pubs/default.aspx?id=209355
[15] Samira Ebrahimi Kahou, Xavier Bouthillier, Pascal Lamblin, Çağlar Gülçehre, Vincent Michalski, Kishore Reddy Konda, Sébastien Jean,
Pierre Froumenty, Yann Dauphin, Nicolas Boulanger-Lewandowski, Raul Chandias Ferrari, Mehdi Mirza, David Warde-Farley, Aaron
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

Multimodal Deep Learning for Activity and Context Recognition

•

157:25

Courville, Pascal Vincent, Roland Memisevic, Christopher Pal, and Yoshua Bengio. 2015. EmoNets: Multimodal deep learning approaches
for emotion recognition in video. Journal on Multimodal User Interfaces (2015), 1–13. https://doi.org/10.1007/s12193-015-0195-2
[16] Yarin Gal, Riashat Islam, and Zoubin Ghahramani. 2017. Deep Bayesian Active Learning with Image Data. CoRR abs/1703.02910 (2017).
http://arxiv.org/abs/1703.02910
[17] Petko Georgiev, Sourav Bhattacharya, Nicholas D. Lane, and Cecilia Mascolo. 2017. Low-resource Multi-task Audio Sensing for Mobile
and Embedded Devices via Shared Deep Neural Network Representations. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 1, 3,
Article 50 (Sept. 2017), 19 pages. https://doi.org/10.1145/3131895
[18] Github repository 2017. Multimodal Deep Learning Framework. https://github.com/vradu10/deepfusion.git. (2017).
[19] A. L. Goldberger, L. A. N. Amaral, L. Glass, J. M. Hausdorff, P. Ch. Ivanov, R. G. Mark, J. E. Mietus, G. B. Moody, C.-K. Peng, and
H. E. Stanley. 2000. PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic
Signals. Circulation 101, 23 (2000), e215–e220. Circulation Electronic Pages: http://circ.ahajournals.org/cgi/content/full/101/23/e215
PMID:1085218; doi: 10.1161/01.CIR.101.23.e215.
[20] Alex Graves, A-R Mohamed, and Geoffrey Hinton. 2013. Speech recognition with deep recurrent neural networks. In Acoustics, Speech
and Signal Processing (ICASSP), 2013 IEEE International Conference on. IEEE, 6645–6649.
[21] Matthieu Guillaumin, Jakob Verbeek, and Cordelia Schmid. 2010. Multimodal semi-supervised learning for image classification. In
Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on. IEEE, 902–909.
[22] Haodong Guo, Ling Chen, Liangying Peng, and Gencai Chen. 2016. Wearable sensor based multimodal human activity recognition
exploiting the diversity of classifier ensemble. In Proceedings of UbiComp. ACM.
[23] Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The WEKA Data Mining
Software: An Update. SIGKDD Explor. Newsl. 11, 1 (Nov. 2009), 10–18. https://doi.org/10.1145/1656274.1656278
[24] Nils Hammerla, James Fisher, Peter Andras, Lynn Rochester, Richard Walker, and Thomas Plötz. 2015. PD Disease State Assessment in
Naturalistic Environments using Deep Learning. In AAAI 2015.
[25] Nils Hammerla, Shane Halloran, and Thomas Ploetz. 2016. Deep, Convolutional, and Recurrent Models for Human Activity Recognition
using Wearables. In Proceedings of IJCAI. ACM.
[26] Song Han, Huizi Mao, and William J Dally. 2015. Deep compression: Compressing deep neural networks with pruning, trained quantization
and huffman coding. arXiv preprint arXiv:1510.00149 (2015).
[27] Awni Y. Hannun, Carl Case, Jared Casper, Bryan C. Catanzaro, Greg Diamos, Erich Elsen, Ryan Prenger, Sanjeev Satheesh, Shubho
Sengupta, Adam Coates, and Andrew Y. Ng. 2014. Deep Speech: Scaling up end-to-end speech recognition. CoRR abs/1412.5567 (2014).
http://arxiv.org/abs/1412.5567
[28] Samuli Hemminki, Petteri Nurmi, and Sasu Tarkoma. 2013. Accelerometer-based Transportation Mode Detection on Smartphones. In
Proceedings of the 11th ACM Conference on Embedded Networked Sensor Systems (SenSys ’13). ACM, New York, NY, USA, Article 13,
14 pages. https://doi.org/10.1145/2517351.2517367
[29] Loc N Huynh, Youngki Lee, and Rajesh Krishna Balan. 2017. DeepMon: Mobile GPU-based Deep Learning Framework for Continuous
Vision Applications. In Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services. ACM,
82–95.
[30] Ashish Kapoor and Rosalind W Picard. 2005. Multimodal affect recognition in learning environments. In Proceedings of the 13th annual
ACM international conference on Multimedia. ACM, 677–682.
[31] Thomas Kautz, Benjamin H Groh, Julius Hannink, Ulf Jensen, Holger Strubberg, and Bjoern M Eskofier. 2017. Activity recognition in
beach volleyball using a Deep Convolutional Neural Network. Data Mining and Knowledge Discovery (2017), 1–28.
[32] Mohamed Khamis, Florian Alt, Mariam Hassib, Emanuel von Zezschwitz, Regina Hasholzner, and Andreas Bulling. 2016. GazeTouchPass:
Multimodal Authentication Using Gaze and Touch on Mobile Devices. In Proceedings of the 2016 CHI Conference Extended Abstracts on
Human Factors in Computing Systems (CHI EA ’16). ACM, New York, NY, USA, 2156–2164. https://doi.org/10.1145/2851581.2892314
[33] Yelin Kim, Honglak Lee, and E.M. Provost. 2013. Deep learning for robust feature generation in audiovisual emotion recognition. In
Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on. 3687–3691. https://doi.org/10.1109/ICASSP.
2013.6638346
[34] Ryan Kiros, Ruslan Salakhutdinov, and Richard S. Zemel. 2014. Unifying Visual-Semantic Embeddings with Multimodal Neural Language
Models. CoRR abs/1411.2539 (2014). http://arxiv.org/abs/1411.2539
[35] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. 2012. ImageNet Classification with Deep Convolutional Neural Networks.
In Advances in Neural Information Processing Systems 25, F. Pereira, C.J.C. Burges, L. Bottou, and K.Q. Weinberger (Eds.). Curran
Associates, Inc., 1097–1105. http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf
[36] Saewon Kye, Junhyung Moon, Juneil Lee, Inho Choi, Dongmi Cheon, and Kyoungwoo Lee. 2017. Multimodal Data Collection Framework
for Mental Stress Monitoring. In Proceedings of the 2017 ACM International Joint Conference on Pervasive and Ubiquitous Computing
and Proceedings of the 2017 ACM International Symposium on Wearable Computers (UbiComp ’17). ACM, New York, NY, USA,
822–829. https://doi.org/10.1145/3123024.3125616

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

157:26

• V. Radu, et al.

[37] Nicholas D. Lane, S. Bhattacharya, P. Georgiev, C. Forlivesi, L. Jiao, L. Qendro, and F. Kawsar. 2016. DeepX: A Software Accelerator for
Low-Power Deep Learning Inference on Mobile Devices. In 2016 15th ACM/IEEE International Conference on Information Processing in
Sensor Networks (IPSN). 1–12. https://doi.org/10.1109/IPSN.2016.7460664
[38] Nicholas D. Lane, Sourav Bhattacharya, Petko Georgiev, Claudio Forlivesi, and Fahim Kawsar. 2015. An early resource characterization
of deep learning on wearables, smartphones and internet-of-things devices. In Proceedings of the 2015 International Workshop on Internet
of Things towards Applications. ACM, 7–12.
[39] Nicholas D. Lane and Petko Georgiev. 2015. Can Deep Learning Revolutionize Mobile Sensing?. In HotMobile 2015.
[40] Nicholas D. Lane, Petko Georgiev, and Lorena Qendro. 2015. DeepEar: Robust Smartphone Audio Sensing in Unconstrained Acoustic
Environments Using Deep Learning. In Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous
Computing (UbiComp ’15). ACM, New York, NY, USA, 283–294. https://doi.org/10.1145/2750858.2804262
[41] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep Learning. Nature (2015).
[42] LG G Watch R 2017. LG G Watch R. https://www.qualcomm.com/products/snapdragon/wearables/lg-g-watch-r. (2017).
[43] Wei Liu, Wei-Long Zheng, and Bao-Liang Lu. 2016. Multimodal Emotion Recognition Using Multimodal Deep Learning. CoRR
abs/1602.08225 (2016). http://arxiv.org/abs/1602.08225
[44] Hong Lu, Jun Yang, Zhigang Liu, Nicholas D. Lane, Tanzeem Choudhury, and Andrew T. Campbell. 2010. The Jigsaw Continuous
Sensing Engine for Mobile Phone Applications. In Proceedings of the 8th ACM Conference on Embedded Networked Sensor Systems
(SenSys ’10). ACM, New York, NY, USA, 71–84. https://doi.org/10.1145/1869983.1869992
[45] Lumo Lift 2017. Lumo Lift. http://www.lumobodytech.com. (2017).
[46] J. Mao, W. Xu, Y. Yang, J. Wang, and A. L. Yuille. 2014. Explain Images with Multimodal Recurrent Neural Networks. ArXiv e-prints
(Oct. 2014). arXiv:cs.CV/1410.1090
[47] Christopher Merck, Christina Maher, Mark Mirtchouk, Min Zheng, Yuxiao Huang, and Samantha Kleinberg. 2016. Multimodality Sensing
for Eating Recognition. In Proceedings of the 10th EAI International Conference on Pervasive Computing Technologies for Healthcare
(PervasiveHealth ’16). ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering), ICST, Brussels,
Belgium, Belgium, 130–137. http://dl.acm.org/citation.cfm?id=3021319.3021339
[48] Microsoft Band 2017. Microsoft Band. http://www.microsoft.com/Microsoft-Band/. (2017).
[49] Francisco Javier Ordóñez Morales and Daniel Roggen. 2016. Deep convolutional feature transfer across mobile activity recognition
domains, sensor modalities and locations. In Proceedings of the 2016 ACM International Symposium on Wearable Computers. ACM,
92–99.
[50] Y. Mroueh, E. Marcheret, and V. Goel. 2015. Deep multimodal learning for Audio-Visual Speech Recognition. In 2015 IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP). 2130–2134. https://doi.org/10.1109/ICASSP.2015.7178347
[51] Sebastian Münzner, Philip Schmidt, Attila Reiss, Michael Hanselmann, Rainer Stiefelhagen, and Robert Dürichen. 2017. CNN-based
Sensor Fusion Techniques for Multimodal Human Activity Recognition. In Proceedings of the 2017 ACM International Symposium on
Wearable Computers (ISWC ’17). ACM, New York, NY, USA, 158–165. https://doi.org/10.1145/3123021.3123046
[52] Jiquan Ngiam, Aditya Khosla, Mingyu Kim, Juhan Nam, Honglak Lee, and Andrew Y. Ng. 2011. Multimodal Deep Learning. In
Proceedings of the 28th International Conference on Machine Learning, ICML 2011, Bellevue, Washington, USA, June 28 - July 2, 2011,
Lise Getoor and Tobias Scheffer (Eds.). Omnipress, 689–696.
[53] Trung Thanh Ngo, Yasushi Makihara, Hajime Nagahara, Yasuhiro Mukaigawa, and Yasushi Yagi. 2015. Similar gait action recognition
using an inertial sensor. Pattern Recognition 48, 4 (2015), 1289 – 1301. https://doi.org/10.1016/j.patcog.2014.10.012
[54] Reza Olfati-Saber and Jeff S Shamma. 2005. Consensus filters for sensor networks and distributed sensor fusion. In Decision and Control,
2005 and 2005 European Control Conference. CDC-ECC’05. 44th IEEE Conference on. IEEE, 6698–6703.
[55] Soujanya Poria, Erik Cambria, Newton Howard, Guang-Bin Huang, and Amir Hussain. 2016. Fusing audio, visual and textual clues for
sentiment analysis from multimodal content. Neurocomputing 174, Part A (2016), 50 – 59. https://doi.org/10.1016/j.neucom.2015.01.095
[56] Valentin Radu, Panagiota Katsikouli, Rik Sarkar, and Mahesh K. Marina. 2014. A Semi-supervised Learning Approach for Robust
Indoor-outdoor Detection with Smartphones. In Proceedings of the 12th ACM Conference on Embedded Network Sensor Systems (SenSys
’14). ACM, New York, NY, USA, 280–294. https://doi.org/10.1145/2668332.2668347
[57] Valentin Radu, Nicholas D. Lane, Sourav Bhattacharya, Cecilia Mascolo, Mahesh K Marina, and Fahim Kawsar. 2016. Towards multimodal
deep learning for activity recognition on mobile devices. In Proceedings of the 2016 ACM International Joint Conference on Pervasive
and Ubiquitous Computing: Adjunct. ACM, 185–188.
[58] Valentin Radu and Mahesh K. Marina. 2013. HiMLoc: Indoor Smartphone Localization via Activity Aware Pedestrian Dead Reckoning
with Selective Crowdsourced WiFi Fingerprinting. In In Proc. Indoor Positioning and Indoor Navigation (IPIN). IEEE. http://dx.doi.org/
10.1109/IPIN.2013.6817916
[59] Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, and Ali Farhadi. 2016. Xnor-net: Imagenet classification using binary
convolutional neural networks. In European Conference on Computer Vision. Springer, 525–542.
[60] Devendra Singh Sachan, Umesh Tekwani, and Amit Sethi. 2013. Sports Video Classification from Multimodal Information Using Deep
Neural Networks. In 2013 AAAI Fall Symposium Series.
Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

Multimodal Deep Learning for Activity and Context Recognition

•

157:27

[61] Gyula Simon, Miklós Maróti, Ákos Lédeczi, György Balogh, Branislav Kusy, András Nádas, Gábor Pap, János Sallai, and Ken Frampton.
2004. Sensor network-based countersniper system. In Proceedings of the 2nd international conference on Embedded networked sensor
systems. ACM, 1–12.
[62] Cees GM Snoek, Marcel Worring, and Arnold WM Smeulders. 2005. Early versus late fusion in semantic video analysis. In Proceedings
of the 13th annual ACM international conference on Multimedia. ACM, 399–402.
[63] Kihyuk Sohn, Wenling Shang, and Honglak Lee. 2014. Improved Multimodal Deep Learning with Variation of Information. In Advances
in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems 2014, December 8-13 2014,
Montreal, Quebec, Canada, Zoubin Ghahramani, Max Welling, Corinna Cortes, Neil D. Lawrence, and Kilian Q. Weinberger (Eds.).
2141–2149. http://papers.nips.cc/paper/5279-improved-multimodal-deep-learning-with-variation-of-information
[64] Nitish Srivastava and Ruslan R Salakhutdinov. 2012. Multimodal Learning with Deep Boltzmann Machines. In Advances in Neural
Information Processing Systems 25, F. Pereira, C.J.C. Burges, L. Bottou, and K.Q. Weinberger (Eds.). Curran Associates, Inc., 2222–2230.
http://papers.nips.cc/paper/4683-multimodal-learning-with-deep-boltzmann-machines.pdf
[65] Allan Stisen, Henrik Blunck, Sourav Bhattacharya, Thor Siiger Prentow, Mikkel Baun Kjærgaard, Anind Dey, Tobias Sonne, and
Mads Møller Jensen. 2015. Smart Devices are Different: Assessing and Mitigating Mobile Sensing Heterogeneities for Activity
Recognition. In The 13th ACM Conference on Embedded Networked Sensor Systems.
[66] Yaniv Taigman, Ming Yang, Marc’Aurelio Ranzato, and Lior Wolf. 2014. DeepFace: Closing the Gap to Human-Level Performance in
Face Verification. In Conference on Computer Vision and Pattern Recognition (CVPR).
[67] Torch 2017. Torch. http://torch.ch/. (2017).
[68] Ehsan Variani, Xin Lei, Erik McDermott, Ignacio Lopez Moreno, and Javier Gonzalez-Dominguez. 2014. Deep neural networks for small
footprint text-dependent speaker verification. In IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP
2014, Florence, Italy, May 4-9, 2014. IEEE, 4052–4056. https://doi.org/10.1109/ICASSP.2014.6854363
[69] Weiran Wang, Raman Arora, Karen Livescu, and Jeff Bilmes. 2015. On deep multi-view representation learning. In Proceedings of the
32nd International Conference on Machine Learning (ICML-15). 1083–1092.
[70] Pengcheng Wu, Steven C.H. Hoi, Hao Xia, Peilin Zhao, Dayong Wang, and Chunyan Miao. 2013. Online Multimodal Deep Similarity
Learning with Application to Image Retrieval. In Proceedings of the 21st ACM International Conference on Multimedia (MM ’13). ACM,
New York, NY, USA, 153–162. https://doi.org/10.1145/2502081.2502112
[71] Shuochao Yao, Shaohan Hu, Yiran Zhao, Aston Zhang, and Tarek Abdelzaher. 2017. Deepsense: A unified deep learning framework for
time-series mobile sensing data processing. In Proceedings of the 26th International Conference on World Wide Web. International World
Wide Web Conferences Steering Committee, 351–360.
[72] Piero Zappi, Thomas Stiefmeier, Elisabetta Farella, Daniel Roggen, Luca Benini, and Gerhard Tröster. 2007. Activity Recognition from
On-Body Sensors by Classifier Fusion: Sensor Scalability and Robustness. In 3rd Int. Conf. on Intelligent Sensors, Sensor Networks, and
Information Processing (ISSNIP). 281–286. http://www2.ife.ee.ethz.ch/~droggen/publications/wear/EDAS_ISSNIP.pdf

Received February 2017; revised August 2017; accepted October 2017

Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, Vol. 1, No. 4, Article 157. Publication date:
November 2017.

Multimodal Deep Learning for Activity and Context
Recognition
Valentin Radu† , Catherine Tong§ , Sourav Bhattacharya‡ , Nicholas D. Lane‡§ ,
Cecilia Mascolo∗ , Mahesh K. Marina† , and Fahim Kawsar‡4
†

University of Edinburgh, § University of Oxford, ‡ Nokia Bell Labs,
∗
University of Cambridge, 4 TU Delft

The popularity of smart mobile and wearable devices has given rise to a growing interest in complex sensing tasks such as activity and context recognition. These tasks typically rely on data from
a multitude of modalities, captured by low-energy small form-factor sensors such as light detectors, magnetometer, accelerometer and barometer. A successful combination of information across
multi-modal sensor streams dictates the fidelity at which they can track user behavior and context.
In this study, we consider the benefits of adopting deep learning algorithms for activity and
context recognition as captured by multi-sensor systems. Specifically, we use fully-connected Deep
Neural Networks (DNNs) and Convolutional Neural Networks (CNNs) and compare two multimodal architectures for each type of neural network. One architecture, Feature Concatenation
(FC), is a commonly employed approach for multimodal data fusion, which simply concatenate
raw sensor streams at the input layer. We compare this to a novel architecture, Modality-Specific
Architecture (MA); In this architecture (Fig. 1), separate neural networks are built per modality,
before their generated concepts are unified through representations which bridge across all sensors.
MA is based on the architecture proposed in [Ngiam et al., 2011], although our formation and experiments is the first time that this architecture has been tested on mobile data [Radu et al., 2018].
We use 4 publicly available datasets for evaluation, covering recognition of human activity,
gait, sleep stages, as well as indoor-outdoor detection. Our experiments show that these generic
multimodal neural network models compete well with shallow methods and task-specific modelling
pipelines, across a wide range of sensor types and inference tasks. Although the training and
inference overhead of these multimodal deep approaches is in some cases appreciable, we also
demonstrate the feasibility of on-device mobile and wearable execution is not a barrier to adoption.
This study is carefully constructed to focus on multimodal aspects of wearable data modeling
for deep learning by proving a wide range of empirical observations, which we expect to have
considerable value in the community. We summarize our observations into a series of practitioner
rules-of-thumb and lessons learned that can guide the usage of multimodal deep learning for activity
and context detection.
Figure 1: Modality-Specific Architecutre (MA) with Deep Neural Networks. Separate branches
exist for each of n modalities, which are joined in unifying cross-sensor layers.
Modality 1

Modality n

Modality 2

v1

v2

h1(1)

h2(1)

h1(2)

h2(2)
u

vn

…

hn(1)
hn(2)

Multi-Modal DNN

References
[Ngiam et al., 2011] Ngiam, J., Khosla, A., Kim, M., Nam, J., Lee, H., and Ng, A. Y. (2011). Multimodal deep
learning. In Getoor, L. and Scheffer, T., editors, Proceedings of the 28th International Conference on Machine
Learning, ICML 2011, Bellevue, Washington, USA, June 28 - July 2, 2011, pages 689–696. Omnipress.
[Radu et al., 2018] Radu, V., Tong, C., Bhattacharya, S., Lane, N. D., Mascolo, C., Marina, M. K., and Kawsar,
F. (2018). Multimodal deep learning for activity and context recognition. Proc. ACM Interact. Mob. Wearable
Ubiquitous Technol., 1(4):157:1–157:27.

Appendix C

Conference Paper: Pervasive Health
2019
This work was co-supervised by Nic Lane and Gabriella Harari, a psychologist from Stanford University. We are currently revising the manuscript for submission to the International Conference
on Pervasive Computing Technologies for Healthcare (PervasiveHealth 2019).

75

1

Predicting Big-Five Personality Using Large-scale Networked Mobile
and Appliance Data
We present the first large-scale (9110-user) study of data from both mobile and networked appliances for Big-Five personality
inference. Building on methods (viz. features and classifiers) previously successful for personality detection from mobile-only
data, this investigation shows Big-Five personality can be detected with accuracies of 77% (similar levels as other studies) under
this setting – despite the size and complexity (mix of mobile and appliance) of the dataset. This result acts as a replication study
of techniques that are commonly utilized in the literature, but under a type of dataset previously never studied. Moreover, we
offer ancillary results, in particular, as to behavior and physical health features that correlate with mobile and appliance data
and how inference accuracy alters as cohort scale and diversity change. Collectively these results provide initial insights as to
how to model data from mobile and appliances for use-cases likely beyond personality inference, for instance, wellbeing and
mental health. We anticipate our findings are timely given the rapid uptake by consumers for smart devices in the home,
which will cause datasets of this type to be more readily available in the near future.
CCS Concepts: • Human-centered computing → Ubiquitous and mobile devices; • Applied computing → Psychology;
ACM Reference format:
. 2018. Predicting Big-Five Personality Using Large-scale Networked Mobile and Appliance Data. 1, 1, Article 1 (May 2018),
11 pages.
https://doi.org/0000001.0000001

1 INTRODUCTION
Personality traits describe a person’s characteristic patterns of thinking, feeling, and behaving. From an applied
perspective, knowing a user’s personality could be useful for device customization (e.g. personalization based
on psychological characteristics) and for understanding contributing factors to their wellbeing. Traditionally,
personality traits are measured using self-report surveys, which is time-consuming and can be difficult to scale
up in commercial settings. However, mobile sensing technologies permit unobtrusive collection of real-world
behavioral patterns [11]. Such technologies may be used to classify personality traits passively, without requiring
methods such as experience sampling [12], or other related survey instruments.
A number of prior studies have been conducted looking into the automated inference of personality [3–
5, 8, 9, 15, 17, 21], and other psychological states (e.g. mood [16, 18], stress [2]) from everyday digital technologies.
The results from past studies suggest that people’s personality traits manifest in ways that can be captured by
measurements from digital media devices (e.g., smartphone sensors and phone logs) and platforms (e.g., social
media). Moreover, features from these measurements can predict a person’s self-rating on the Big Five personality
traits (Extraversion, Agreeableness, Conscientiousness, Emotional-stability and Openness). However, past studies
tend to (i) be small-scaled and focused on homogeneous samples (under 200 people), (ii) collect data only from
one digital media source (e.g. smartphone), (iii) typically in experimental settings, and (iv) focuses primarily on
measurements of sociability and mobility behavior (e.g. call logs, location information).
Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that
copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s).
© 2018 Copyright held by the owner/author(s).
XXXX-XXXX/2018/5-ART1
https://doi.org/0000001.0000001
, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:2

•

Given these limitations, our primary question is: whether existing approaches for personality inference be
applied to data which (i) involves a large, diversified user population, (ii) collects data from a wide mixture of
digital media sources (including mobile devices and home networked appliances) which could contain sparse
measurements, (iii) uses real-world data that are naturally collected from these devices in-the-wild as people use
them, and (iv) focuses on other types of measurements about health and physiological behaviors. Increasingly
data with such properties is becoming readily available as consumers integrate a mixture of smart-devices (e.g.,
bathroom scales, in-bed sleep trackers, along with the more common phones and wearables) into their lives. This
in turn raises the importance of understanding the opportunities for performing societal-scale personality and
wellbeing experiments this data will afford, that typically are done with mobile-only data [16, 18].
To answer this question, in this study, we examine the accuracy of inference when predicting the Big Five
personality traits of users based on a dataset with the aforementioned characteristics. Our dataset consists of
measurements from 9110 users of Withings devices [1] (also known as Nokia Digital Health), collected from the
range of devices owned by the user (ranging from smart watches to blood pressure monitors). To the best of
our knowledge, this is the first large-scale study reporting on a dataset with a mixture of networked mobile and
appliance data sources for personality inferences.
We deliberately design this study to build on past research methods and make our results comparable to
existing work. As such, we follow the general inference approach adopted in [3, 4, 23, 24], that proved successful
at a smaller scale on mobile-centric data. Our work begins with a replication study of such methods with our
Withings dataset. Results show that comparable accuracy levels for personality inference, as prior work, are
indeed possible using the data. We then examine the individual merits of using data sourced from different digital
media devices: only appliances (i.e., weighing scale, sleep tracker, blood pressure monitor), only mobile devices
(i.e., smartwatch), and a mixture of appliances and mobile devices (i.e., smartwatch, weighing scale, sleep tracker
and blood pressure monitor). Next, we evaluate the scalability of personality inference models by assessing
their performance across a spectrum scale of users, from 83 users (same as that in [3]) to 9110 users. Finally, we
summarise and discuss our findings, providing insights and lesson learned for future studies.

2 BACKGROUND
In this section, we provide background relating to personality studies in psychology research and survey existing
automated approaches for personality inference.
The Study of Personality Personality traits describe a person’s characteristic patterns of thinking, feeling,
and behaving. The most widely used model for measuring personality focuses on the Big-Five personality traits Extraversion, Agreeableness, Conscientiousness, Emotional-stability and Openness to experiences. Personality
inventories, consisting of adjectives to describe the respondent, are common instruments for assessing the
personality dimensions. The 44-item Big Five Inventory [13] and the Ten-Item Personality Inventory (TIPI)
[10] have both been employed in automated personality inference research, for instance in [5, 15] and [3, 4]
respectively.
There have been several attempts to predict personality traits by modelling data from everyday digital media
technologies. Broadly, the past work can be described as taking two approaches: (1) a platform-based approach
that focuses on data from various social media platforms, and (2) a device-based approach that focuses on data
from various mobile devices.
Platform-based approach Existing work in personality inference using data from social media primarily
focus on two kinds of information: linguistic features and social network information. Linguistics features
have been shown to be related to personality traits, [8, 9] applied linguistic analysis onto tweets and Facebook
profile information to predict traits. [8, 9, 15] have also used social network information such as friendships, in
personality inference; while[14] have shown that personality traits could be predicted from Facebook likes. Such
, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Predicting Big-Five Personality Using Large-scale Networked Mobile and Appliance Data

(b) Distribution of personality trait scores.

Gender

31-40

41-50

male

0

2000

4000

51-60 >60
female

6000

8000

10000

No. of users

<21

1:3

Fig. 1. Descriptive information of dataset.

(a) Demographics.
Age

•

ex.
ag.
co.
em.
op.

2000
1000
0

1

2
3
4
Personality score

5

(c) Mean number of days per modality.

activity heart rate
activity
heart rate
steps
blood pressure
pwv
sleep
weight
0

50

100
150
Mean No. of Days

200

studies have demonstrated the viability of personality prediction from social media platforms. Thus, we focus
our efforts on device-based approaches in the present research.
Device-based approach More related to our study are device-based approach to personality inference [3–5, 17].
[17] uses low-level sensor data from sociometric badges to study individual and group behaviour, using high-level
behavioural descriptions such as physical and speech activity. Although the goal of [17] is not personality
inference, their results show that it is possible to correlate high-level behavioural information with personality
traits. [3–5, 21] all utilise data from smartphones for personalty inference, using information such as call logs,
use of Bluetooth. [21] focuses on inference through building a picture of the social network of smartphone users,
while [5] proposes behavioural indicators for inference, e.g. regularity and diversity found in calls/ texts, spatial
behavior from GPS signals. In [3, 4] the authors use aggregated features from mobile logs and sensor data (e.g.
call/SMS logs, BT logs) for personality inference, we find their studies to be the most applicable on our dataset for
direct comparison, therefore we use their approach and results as guidance and reference throughout this paper.
More generally, studies that examine personality inferences from physiological data is lacking so far. Part of the
reason for this lack of research may be the need for additional device hardware which might be a prohibiting factor
in collecting such measurements. However, there have been prototypes developed for recognising emotions from
physiological signals such as skin temperature and ECG signals [7]. It has been suggested that the advantages of
using such data include the fact that physiological signals may offer a more direct view into our psychological
states and may be ‘difficult to fake’ [16]. Thus, in the present research we explore physiological measurements
and their relationship to personality by focusing on physiological measurements from the following types of
devices: weighing scale, sleep tracker, and blood pressure monitor.

3 METHODOLOGY
In this section, we discuss the dataset and study design.

3.1 Dataset
Our dataset comprises of personality scores and behavioral and physiological data of 9270 users of Withings
devices. The user population spans a diverse demographic spectrum, as seen in Figure 1(a).
The TIPI Scale. Individuals included in the study are voluntary respondents of an online questionnaire sent
out in March 2017. Respondents complete the TIPI, a 10-item survey instrument used for assessing Big-Five
personality dimensions, as part of a larger questionnaire. Following the survey design [10], final scores for each
personality dimension are computed, resulting in scores ranging from 1 to 5 in intervals of 0.5, where a higher
score means a stronger association with the personality trait. Figure 1(b) shows the distribution of personality
scores for the entire dataset. In our analysis, we split each trait into high-scoring and low-scoring groups through
the median for binary classification. After removing users who had invalid responses and unrealiable sensor
measurements, our dataset consists of 9110 individuals.
, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:4

•
Table 1. Dataset Sensor Measurements.

Modality

Measurements

Source

Steps

step count, gait speed

smart watch (mobile)

Sleep

sleep duration, bed-in/out times,
time to sleep, time to wake,
no. of times of being awake, awake duration,
duration of awake/ light/ REM† / deep sleep,

smart watch (mobile),
sleep tracker (appliance)

Weight

weight, BMI.

scale (appliance)

Heart rate

average/ minimum/ maxmimum heart rate

smart watch (mobile),
sleep tracker, scale (appliance)

Pulse wave
velocity (pwv)

pwv
pwvH (a score indicating the healthiness of pwv)

scale (appliance)

Blood pressure (sbp)

sbp

blood pressure monitor (appliance)

Activity

activity duration, calories burned, activity heart rate

smart watch (mobile)

† Only available through appliance.

Behavioral and Physiological Data. Table 1 lists all measurements taken from the following Withings devices.
• Phone app. A repository for measurements taken from all Withings devices for user’s monitoring and
goal-setting purposes. Manual entry for missing data is also available (e.g. user may enter weight/ height.)
• Smart watch. Wearable device which comes in different models, provides inference data on activity, sleep
(and heart rate in certain models).
• Sleep tracker. WIFI-enabled pad placed under mattress, provides inference data on sleep and heart rate.
• Weighing scale. WIFI-enabled scale which comes in different models, provides raw weight measurements
(as well as inference data on pulse wave velocity and heart rate in certain models).
• Blood pressure monitor. WIFI-enabled device, provides raw data on blood pressure and heart rate.

Each user’s data from all devices that he/she owns are collected in daily resolution over a time window of up to 1
year. The amount of data present per user is dependent on usage, and Figure 1(c) shows the mean number of
days per modality per person in the dataset.

Raw and Inference Data. Like many studies in the area, our models build on lower-level activity inference
models that are fairly mature in the industry; in [23, 24], the authors have relied on inferences such as walking,
running, sleep stages build on prior classifiers. Our inference data is based on commercial-quality models by
Withings, and we have verified through discussions that they have validated their models in similar fashions to
those paper in the literature. (i.e., controlled user trials) at a similar scale. In addition, these devices are used by
millions of people on a daily basis - an added check since other methods have not been tested against. Further, we
highlight that our dataset, being a mixture of raw information (e.g. weight, blood pressure) as well as inference
data, represents an increasingly popular form of data useful for wellbeing research.
Unique Dataset Characteristics. Our dataset is different from other commonly studied datasets for personality
inference in the following manners:
• Large-scale, diversed population. There is no pre-selection of the subjects for this study, any Withings
device user who has voluntarily completed the survey is included.
• Data collection in-the-wild. Individuals collect data as they use these devices in their everyday lives.
• Sparsity. Amount of data collected is dependent on user’s usage and ownership of different devices.
, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Predicting Big-Five Personality Using Large-scale Networked Mobile and Appliance Data

•

1:5

• Mix of data sources. Data are collected from both mobile devices and home networked appliances.
• Mix of raw and inference data. Data consists of raw measurements as well as behavioral data inferred with
commercial-quality models.
• Focus on behavioral and physiological features. Primary functions of Withings devices relate to health and
wellbeing, so the dataset focuses on other types of measurements about health and physiological behaviors

3.2

Method

This study aims to verify that existing methods can be applied onto our dataset for personality inference, which
is an application domain without strong baselines for direct comparisons. Therefore, we reference and adopt
the general approach taken in many related works looking at sensor-based datasets for inference of wellbeing
information [3–5, 23]. Such general approach is a 2-step process of first looking for features, then applying a
machine learning model for inference. In detail, the approach first considers a measurement time series of a
suitable window length, then obtaining features by aggregating the time series, followed by feature selection
with correlation-based analysis or established feature selection algorithms, and finally using a machine learning
model is used to infer the interested trait or well-being state.
Benchmark. In terms of the inference problem, the most closely related to our work amongst these related
works are [3, 4], as they also considered a binary classification problem for Big-Five personality traits. The
dataset considered in [3] (which we refer to as Phone83users) consists of smartphone data from 83 users over 8
months, with logs of calls, SMS, Bluetooth scans, application usage; while the dataset in [4] (which we refer to as
Phone117users) consists of smartphone data from 117 users over 17 months, with logs of calls, SMS, Bluetooth
scans, calling profiles and application usage. We use the accuracies achieved in their work as benchmarks.

4 RESULTS
In this section, we present results from a replication study of existing methods with our Withings dataset, which
shows comparable accuracies with prior work at 77%. We then present experiments examining the merits of
using different data sources, as well as evaluating the scalability of inference models.

4.1

Replication Study

In this subsection, we apply the general approach taken in existing work onto our dataset.
Motivation. This serves as a first step in establishing that personality inference is feasible with this new type
of data and features. Through correlation analysis we also hope to gain more insights into the relationships
present between modalities and traits.
Setup. To extract features, we split time series of measurements across months, aggregating events by taking
mean, minimum, maximum, standard deviation, kurtosis, variability and count. We follow a basic feature selection
procedure based on pairwise Pearson correlation test between each feature and each trait. This is followed by
feature selection, where we rank the features by their correlation strengths and impose a cut-off of |r | > 0.05,
and eliminate features which contain too few examples as well as those which may be redundant until we have
the number of features below 20. Having selected the features, we impose some dataset inclusion requirements: (i)
user-months must have least 7 measurements for each modality, (ii) users must have at least 30 measurements in
total for each modality. Having collected a dataset of valid users, we consider a binary classification of each trait,
using the median to group scores into two classes. We report accuracies achieved using leave-one-cross-validation
with SVM and Decision Tree, and a 5-fold cross validation with DNN.
Results. Features. We find a number of strong and significant correlations between features and traits (|r|>0.1
and p<0.001). Many of the correlations found to align with expectations and results from other studies; for
, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:6

•
Table 2. List of 17 selected features and their strongest trait correlations found.

Modality

Feature

Strongest correlations

r

No. of items

No. of users

Pulse wave
mean pwvH
velocity (pwv) mean pwv

Ag.
Em.

-0.18
+0.12

2373

702

Sleep

mean bed-in
mean bed-out
variability in sleep duration
standard dev. in bed-in
minimum deep sleep duration
standard dev. in light sleep duration
standard dev. in bed-out
variability in time to sleep

Co.
Co.
Co.
Co.
Co.
Op.
Co.
Co.

-0.17
-0.14
-0.10
-0.09
+0.09
+0.09
-0.09
-0.05

45799

6888

Blood
pressure (sbp)

mean sbp
no. of sbp measurements

Ag.
Ex.

+0.14
-0.10

1718

408

Weight

maxmimum weight
mean BMI
no. of weight measurements

Ag.
Co.
Op.

-0.12
-0.08
-0.06

13707

2650

Heart rate

variability in average heart rate

Co.

-0.06

13630

2270

Steps

variability in gait speed

Ex.

+0.06

31454

5405

Table 3. Left: Accuracy (%) of classifiers as well as baseline (always-majority-class) using 17 behavioural features in the our
study. Right: Accuracy(%) reported in Phone83users and Phone117users.

Decision Tree SVM DNN
Ex.
Ag.
Co.
Em.
Op.

72.1
79.6
75.6
68.1
73.6

69.7
78.9
71.2
63.1
63.3

77.5
84.2
77.1
74.4
73.4

Baseline
66.2
78.6
71.6
54.4
61.6

Ex.
Ag.
Co.
Em.
Op.

Phone83users

Phone117users

75.9
69.6
74.4
71.5
69.3

77
75
75
71
74

example, we find a number of sleep features correlating strongly with Conscientiousness; this is not surprising
given that [19] has shown that morningness correlates with conscientiousness. We also find that mean BMI
correlates negatively with Conscientiousness, which aligns with the relations found in [22]. Through ranking
the features by their correlation coefficients, eliminating features which do not have at least 500 user-months,
and removing redundant features which may carry overlapping information manually (e.g. mean BMI and mean
weight), we arrive at 17 input features with |r|>0.05 and p<0.001, as listed in Table 2. After enforcing the inclusion
criteria, the resulting dataset consists of 168 users with number of examples (N) = 451.
Classificiation. Table 3 presents accuracies achieved by Decision Tree, SVM, DNN, a baseline classifier which
always chooses the majority class, as well as benchmarks from [3, 4].
Implications. Application onto our dataset produces results that are consistent with other existing work, even
with such different characteristics. Further investigations can be made to enhance feature selection and modelling
schemes, but it appears that it is feasible to do personality inference using new types of dataset such as this.
, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Predicting Big-Five Personality Using Large-scale Networked Mobile and Appliance Data

4.2

•

1:7

Modelling smart appliances

The next set of results considers: how does inference performance vary when modelling data from different
sources?
Motivation. Modelling data from multiple modalities and sources often present many challenges. However,
the effect of using data from different sources on inference performance is not clear as previous studies only
considered single channels. To the best of our knowledge, our dataset is the first which enables this comparison
to be done for personality inference and we seek to shed light on the matter.
Setup. We introduce three scenarios covering features from different sources: (i) mixture of mobile and
appliances, (ii) mobile only, (iii) networked appliance only. In each scenario, the model takes in 12 to 14 features
that had been found to be the most strongly correlated to personality traits from each source. Table 4 lists the
considered modalities for each scenario.
As before, we consider the users with the complete set of modalities considered. As there are only 586 users of
sleep trackers, the inclusion criteria means that the dataset for appliance-only is small compared to the others. To
control for scales of the data, we consider this same number of examples (221) in each scenario and compare the
inference performance. This binary classification was performed with Decision Tree and DNN.
Table 4. Datasets and considered modalities

Data source

Modalities

Mixed source
Appliance only
Mobile only

pwv, sleep (from both mobile and appliance), sbp, weight
pwv, sleep (appliance only), sbp, weight
sleep (mobile only), activity, heart rate, steps

No. of users

No. of examples

168
61
715

451
221
1377

Results. In Table 5 we compare the accuracies achieved by Decision Tree and DNN across the 3 scenarios. The
results of this experiment can be summarized as follows.
With both classifiers, classification using mobile-only data achieves poor performance, particularly for DNN
with an average of 36.6% only. This poor performance might be explained by the weak correlations found between
mobile-sourced features (other than sleep) with personality traits. Given that there had previously been many
studies suggesting activity as correlates of personality traits [20], it is surprising that including it as a feature
should incur such low accuracies. We believe this might be a consequence of the sparsity in user’s activity data
(as seen in Figure 1(c)) which made this modality not suitable for personality inference in our dataset.
In all but one case, appliance-only data provides better performance than alternatives, outperforming mixedsource by an average of 19.0% and 8.5% respectively for Decision Tree and DNN. While this is a first sign that
appliance-only data can be a promising alternative to other datasets, we note that the worse performance of
mixed-source data might be simply due to noise presented from mobile-sourced data, which seems to be poor
personality predictors using data at this scale and type.
Finally, we observe that mixed-source data could be handled better with DNN than Decision Tree. DNN
provides the only example (Agreeableness) where a mixed-source classification is better than appliance-only;
also, the performance of DNN with mixed-source is within 10% of that of appliance-only, despite the appaling
performance of DNN with mobile-only data. This suggests that DNN might be more suitable in handling and
dissecting mixed-sourced data to extract useful information.
Implications. Using appliance-only data at a small scale, using behavioral and physiological data achieves
good performance, this demonstrates the possibility of using this type of data for wellbeing analysis. However,
we also caution that the mobile-only dataset here uses very different features from what had been studied in
related studies. It is also only possible to perform the experiment on a small scale, as the number of users who
regularly use networked appliances is still a limiting factor.
, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:8

•

Table 5. Accuracy (%) of decision tree classifier using features from different sources. Datasets from mixed-source and mobile
only were scaled down to have (N=221) for fair comparison with the dataset with appliance only.

Decision Tree

Ex.
Ag.
Co.
Em.
Op.

DNN

Mixed source

Appliance only

Mobile only

Mixed source

Appliance only

Mobile only

68.4
72.9
67.9
68.3
68.8

87.3
81.0
79.2
81.4
83.3

49.8
67.4
58.8
53.8
54.3

77.1
83.7
77.7
70.5
73.9

84.2
82.6
80.8
88.1
79.9

39.5
19.8
30.9
44.7
48.1

Table 6. Scale of the considered dataset as modality density criteria are gradually removed.

1
2
3
4
5

4.3

Modality density requirement

No. of users

No. of examples

pwv, sleep, sbp, weight, heart rate, steps
pwv, sleep, sbp, weight, heart rate
pwv, sleep
pwv
-

164
242
1147
1466
9110

458
647
3417
4154
71629

Scalability analysis

In this subsection, we look into the interplay between the choice of modalities, dataset size, and model performance.
Motivation. In our analysis so far, we see that the dataset scale is greatly diminished when we require users to
be active users of all modalities involved in the input features. Since our dataset is of a much greater scale and
potentially more complex to model than prior work, this experiment allows us to study the tradeoff between
performance and scale, and to gain insights about whether current methods are sufficient for larger scale analysis.
To study this, we look at accuracy for this type of new data (appliance and mobile mixture) while holding
constant at comparable levels of population size. In addition, we also want to study the impact of demographics
on performance as this information is withheld from the studied models.
Setup. We study the inference problem at 6 different scales, from only 83 users to the entire dataset of 9110
users. We consider the 17-item feature list (with 6 modalities, ref. Table 2). To increase the number of users
considered, we gradually relax the inclusion criteria such that users must only possess enough data for (6 − n)
modalities. Table 6 illustrates this increasing dataset scale and the modality density requirement at each step. At
each step, we incrementally train an SVM with data of the newly included users, but letting the model ignore
missing modalities. In order to provide a useful reference to compare with Phone83users, we also added an
additional step where we use the full inclusion criteria but restrict user number to 83 users only.
Results. Scalability. It should be expected that, at larger dataset scales and with sparser inputs, the performance
of the model will be lower (as a consequence of poorer generalization amongst the diverse population and fewer
useful information). The results demonstrate a downward general trend on average for the personality traits,
matching with this expectation. However, although the performance for Conscientiousness and Extraversion
have both gone down at scale, they remain at a reasonable level of accuracy of 68% and 65% respectively even
when considering the entire dataset of 9110 users. Conscientiousness has been found to demonstrate strong
correlations with most selected features, which might explain its good performance at scale.
Demographic difference. Figure 3 presents accuracy results achieved by the initial Decision Tree model (described
in Section 4.1) but separated by user’s age and gender groups. It appears that personality classification for
under-30s achieves better accuracies on average by 15%, and that for the male population as well by 6.8%. These
, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Predicting Big-Five Personality Using Large-scale Networked Mobile and Appliance Data

•

1:9

Accuracy(%)

Fig. 2. Evaluation results for accuracy as modality requirements are gradually relaxed to increase dataset size.
80
ex.
Phone83users ex.
Phone117users ex.
ag.
Phone83users ag.
Phone117users ag.
75
co.
Phone83users co.
Phone117users co.
em.
Phone83users em.
Phone117users em.
70
op.
Phone83users op.
Phone117users op.

65
60
83 164
(211) (458)

1466
(4154)
No. of users
(No. of examples)

9110
(71629)

differences in accuracies might be related to nuanced differences in the way personality manifests in behaviour
across age and gender groups; for instance, literature in the psychology domains suggests that significant gender
differences exists for emotional stability [25]. The fact that gender and age were held as hidden factors to the
classification models might have contributed to these observed differences.

Accuracy (%)

100

all ages
under 30
31 to 60
above 60

80
60
40
20
0 ex.

ag.

co.

em.

op.

Accuracy F1 score (%)

Fig. 3. Evaluation results for different demographic subsets: varying across age groups (left) and genders (right).

100

both
male
female

80
60
40
20
0 ex.

ag.

co.

em.

op.

Implications. Inference performance using mixed-data sources seems to be scalable to 9110 users for Conscientiousness and Extraversion. However, for the rest (and especially for Agreeableness), accuracy drops rapidly
once the dataset size surpasses a thousand users. Better generalization might be achieved if demographic factors
are provided to the model.

5 DISCUSSION
Our findings show that using a large-scale dataset with sparsely collected passive behavioural and physiological
data is a feasible approach for personality inference. Using existing approach on this dataset, we were able
to achieve accuracies in the same range as results in prior work. Due to the mixed-source data available, we
are able to present the first evaluation of sourcing data from mobile device or networked appliance. While in
this experiment we observe that a poor performance of using mobile-only data, we do not claim that this is
the general case for all mobile data since our features for mobile-data are particularly sparse. It remains as our
future work to better compare data sources when a suitable dataset becomes available. In our scalability analysis,
the observation that the general trend for inference performance goes down as scale increases aligns with our
expectations. However, scalability seems to be different for each personality trait. In particular, accuracies for
, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:10

•

conscientiousness and extraversion remain at 68% and 65% respectively even when considering the entire dataset
of 9110 valid users.
As our work serves to be the first investigation into personality inference using such dataset, we discuss a
number of limitations in our work and insights that we believe would be useful for future work:
Personality-dependent inference. From our results, we see that for the same task, variation in accuracies
amongst personality traits can be as much as 59%. Rather than using the same features and classifier models for
all Big-Five personalities, better performance might be achieved if each prediction problem is tailored to each
personality dimension, but not all five at a time.
Regression as inference. Our current work uses the median value to separate users into 2 classes: high-scoring
and low-scoring group for each personality trait. We note that while this might be logical in a machine learning
context, personality traits are viewed as continuous variables in psychology instead of discrete opposites such as
extraversion versus introversion. It is proposed that personalities are to be conceived of as density distributions
[6]. Further, we also find that model performance can be sensitive to which group the median value is placed.
Given these, it will be worthwhile investigating personality inference as a regression problem in future work.
Demographic influence. Our results regarding demographic variations suggests that the current model
(which does not take demographic meta-data as input features) may not be able to generalise the inference
performance across population. Results from [25] have suggested that there could be significant differences
between personality scores obtained between gender groups. Future work could look into including demographic
variables as input features.
Data Sparsity. Although there are 9110 valid users in our dataset, many users are not included in the majority
of the analysis in this paper under the current approach as each considered user must have enough data for every
input modality. Our future work seeks to examine ways of feature selection and discovery such that the analysed
user population size could be maximised.
Lastly, we wish to note that our results seek to demonstrate the possibilities of using appliance-only data for
personality inference, which is promising because this might open up a future research space where current
models developed for mobile technologies (such as [16]) could be deployed on appliance data.

6 CONCLUSION
In conclusion, we presented the first large-scale (9110-user) study of data from both mobile and networked
appliances for Big-Five personality inference. We demonstrated, to varying degrees, that it is feasible to perform
personality inference using existing methods with such data, despite its complexity. We also offer ancillary results
from investigations of how inference performance is changed using different device sources and at varying data
scales. Our findings and insights drawn can help towards performing analysis on this increasingly popular form
of dataset in the near-future when people have a ready access to a rich stream of sensor data from mixed sources.

REFERENCES
[1] [n. d.]. Withings. https://health.nokia.com/uk/en/.
[2] Andrey Bogomolov, Bruno Lepri, Michela Ferron, Fabio Pianesi, and Alex (Sandy) Pentland. 2014. Daily Stress Recognition from Mobile
Phone Data, Weather Conditions and Individual Traits. In Proceedings of the 22Nd ACM International Conference on Multimedia (MM ’14).
ACM, New York, NY, USA, 477–486. https://doi.org/10.1145/2647868.2654933
[3] G. Chittaranjan, J. Blom, and D. Gatica-Perez. 2011. Who’s Who with Big-Five: Analyzing and Classifying Personality Traits with
Smartphones. In 2011 15th Annual International Symposium on Wearable Computers. 29–36. https://doi.org/10.1109/ISWC.2011.29
[4] Gokul Chittaranjan, Jan Blom, and Daniel Gatica-Perez. 2013. Mining large-scale smartphone data for personality studies. Personal and
Ubiquitous Computing 17, 3 (01 Mar 2013), 433–450. https://doi.org/10.1007/s00779-011-0490-1
[5] Yves-Alexandre de Montjoye, Jordi Quoidbach, Florent Robic, and Alex (Sandy) Pentland. 2013. Predicting Personality Using Novel
Mobile Phone-Based Metrics. In Social Computing, Behavioral-Cultural Modeling and Prediction, Ariel M. Greenberg, William G. Kennedy,
, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Predicting Big-Five Personality Using Large-scale Networked Mobile and Appliance Data

•

1:11

and Nathan D. Bos (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 48–55.
[6] William Fleeson. 2001. Toward a Structure- and Process-Integrated View of Personality: Traits as Density Distributions of States. 80 (07
2001), 1011–27.
[7] A. Gluhak, M. Presser, L. Zhu, S. Esfandiyari, and S. Kupschick. 2007. Towards Mood Based Mobile Services and Applications. In
Proceedings of the 2Nd European Conference on Smart Sensing and Context (EuroSSC’07). Springer-Verlag, Berlin, Heidelberg, 159–174.
http://dl.acm.org/citation.cfm?id=1775377.1775390
[8] J. Golbeck, C. Robles, M. Edmondson, and K. Turner. 2011. Predicting Personality from Twitter. In 2011 IEEE Third International
Conference on Privacy, Security, Risk and Trust and 2011 IEEE Third International Conference on Social Computing. 149–156. https:
//doi.org/10.1109/PASSAT/SocialCom.2011.33
[9] Jennifer Golbeck, Cristina Robles, and Karen Turner. 2011. Predicting Personality with Social Media. In CHI ’11 Extended Abstracts on
Human Factors in Computing Systems (CHI EA ’11). ACM, New York, NY, USA, 253–262. https://doi.org/10.1145/1979742.1979614
[10] Samuel Gosling et al. 2003. A Very Brief Measure of the Big-Five Personality Domains. 37 (12 2003), 504–528.
[11] Gabriella M. Harari, Nicholas D. Lane, Rui Wang, Benjamin S. Crosier, Andrew T. Campbell, and Samuel D. Gosling. 2016. Using
Smartphones to Collect Behavioral Data in Psychological Science: Opportunities, Practical Considerations, and Challenges. Perspectives
on Psychological Science 11, 6 (2016), 838–854. https://doi.org/10.1177/1745691616650285 PMID: 27899727.
[12] Joel M Hektner, Jennifer A Schmidt, and Mihaly Csikszentmihalyi. 2007. Experience sampling method: Measuring the quality of everyday
life. Sage.
[13] O. P. John, Donahue, E. M., and R. L. Kentle. 1991. The Big Five Inventory–Versions 4a and 54. In Berkeley, CA: University of California,Berkeley, Institute of Personality and Social Research.
[14] Michal Kosinski, David Stillwell, and Thore Graepel. 2013. Private traits and attributes are predictable from digital records of human behavior. Proceedings of the National Academy of Sciences 110, 15 (2013), 5802–5805. https://doi.org/10.1073/pnas.1218772110
arXiv:http://www.pnas.org/content/110/15/5802.full.pdf
[15] Lin Li, Ang Li, Bibo Hao, Zengda Guan, and Tingshao Zhu. 2014. Predicting Active Users’ Personality Based on Micro-Blogging
Behaviors. PLOS ONE 9, 1 (01 2014), 1–11. https://doi.org/10.1371/journal.pone.0084997
[16] Robert LiKamWa, Yunxin Liu, Nicholas D. Lane, and Lin Zhong. 2013. MoodScope: Building a Mood Sensor from Smartphone Usage
Patterns. In Proceeding of the 11th Annual International Conference on Mobile Systems, Applications, and Services (MobiSys ’13). ACM, New
York, NY, USA, 389–402. https://doi.org/10.1145/2462456.2464449
[17] Daniel Olguín Olguín, Peter A. Gloor, and Alex Pentland. 2009. Capturing Individual and Group Behavior with Wearable Sensors. In
AAAI Spring Symposium: Human Behavior Modeling.
[18] Kiran K. Rachuri, Mirco Musolesi, Cecilia Mascolo, Peter J. Rentfrow, Chris Longworth, and Andrius Aucinas. 2010. EmotionSense: A
Mobile Phones Based Adaptive Platform for Experimental Social Psychology Research. In Proceedings of the 12th ACM International
Conference on Ubiquitous Computing (UbiComp ’10). ACM, New York, NY, USA, 281–290. https://doi.org/10.1145/1864349.1864393
[19] Christoph Randler. 2008. MorningnessâĂŞeveningness, sleepâĂŞwake variables and big five personality factors. Personality and
Individual Differences 45, 2 (2008), 191 – 196. https://doi.org/10.1016/j.paid.2008.03.007
[20] Ryan Rhodes and Nicole E.I. Smith. 2007. Personality Correlates of Physical Activity: A Review and Meta-Analysis. 39 (05 2007), S341.
[21] Jacopo Staiano, Bruno Lepri, Nadav Aharony, Fabio Pianesi, Nicu Sebe, and Alex Pentland. 2012. Friends Don’T Lie: Inferring Personality
Traits from Social Network Structure. In Proceedings of the 2012 ACM Conference on Ubiquitous Computing (UbiComp ’12). ACM, New
York, NY, USA, 321–330. https://doi.org/10.1145/2370216.2370266
[22] Angelina R Sutin, Luigi Ferrucci, Alan B. Zonderman, and A. Terracciano. 2011. Personality and obesity across the adult life span.
Journal of personality and social psychology 101 3 (2011), 579–92.
[23] Rui Wang, Weichen Wang, Min S. H. Aung, Dror Ben-Zeev, Rachel Brian, Andrew T. Campbell, Tanzeem Choudhury, Marta Hauser,
John Kane, Emily A. Scherer, and Megan Walsh. 2017. Predicting Symptom Trajectories of Schizophrenia Using Mobile Sensing. Proc.
ACM Interact. Mob. Wearable Ubiquitous Technol. 1, 3, Article 110 (Sept. 2017), 24 pages. https://doi.org/10.1145/3130976
[24] Rui Wang, Weichen Wang, Alex daSilva, Jeremy F. Huckins, William M. Kelley, Todd F. Heatherton, and Andrew T. Campbell. 2018.
Tracking Depression Dynamics in College Students Using Mobile Phone and Wearable Sensing. Proc. ACM Interact. Mob. Wearable
Ubiquitous Technol. 2, 1, Article 43 (March 2018), 26 pages. https://doi.org/10.1145/3191775
[25] Yanna Weisberg, Colin DeYoung, and Jacob Hirsh. 2011. Gender Differences in Personality across the Ten Aspects of the Big Five.
Frontiers in Psychology 2 (2011), 178. https://doi.org/10.3389/fpsyg.2011.00178

, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Appendix D

Conference Poster: MobiSys 2018
The following are the accepted abstract and poster presented at the ACM International Conference on Mobile Systems (MobiSys) 2018. This work includes some of the early studies that lead
to the PervasiveHealth submission in Appendix C.

87

Poster: Inference of Big-Five Personality Using Large-scale
Networked Mobile and Appliance Data
Catherine Tong† , Gabriella M. Harari§ , Angela Chieh‡ ,
Otmane Bellahsen‡ , Matthieu Vegreville‡ , Eva Roitmann‡ , Nicholas D. Lane†∗

† University of Oxford, § Stanford University, ‡ Nokia Digital Health - Withings, ∗ Nokia Bell Labs

CCS CONCEPTS
• Human-centered computing → Ubiquitous and mobile devices;
Ubiquitous and mobile devices; • Applied computing → Psychology; Psychology;

1

INTRODUCTION

Personality traits describe a person’s characteristic patterns of
thinking, feeling, and behaving. The most widely used model for
measuring personality focuses on the Big-Five personality traits extraversion, agreeableness, conscientiousness, emotionalstability
and openness. From an applied perspective, knowing a user’s personality could be useful for device customization (e.g. personalization based on psychological characteristics) and for understanding
contributing factors to their wellbeing. Traditionally, personality
traits are measured using self-report surveys, which can be difficult
to scale up in commercial settings. However, mobile sensing technologies permit unobtrusive collection of real-world behavioral
patterns [3]. Such technologies may be used to classify personality
traits passively, without requiring surveys. Prior research examing
this topic [1] indicates the capabilities of using mobile data for their
classification. However, these studies used small datasets (under 100
users) and focused on social data (e.g. SMS logs) from only mobile
devices. In this study, we aim to understand if methods used in prior
studies [1] can be applied to an increasingly popular form of data
- large-scale datasets with sparsely collected passive behavioural
data.
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
MobiSys ’18, June 10–15, 2018, Munich, Germany
© 2018 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-5720-3/18/06.
https://doi.org/10.1145/3210240.3210823

Mean no. of days
per user

We present the first large-scale (9270-user) study of data from both
mobile and networked appliances for Big-Five personality inference.
We correlate aggregated behavioral and physical health features
with personalities, and perform binary classification using SVM
and Decision Tree. We find that it is possible to infer each Big-Five
personality at accuracies of 75% from this dataset despite its size and
complexity (mix of mobile and appliance) as prior methods offer
similar accuracy levels. We would like to achieve better accuracies
and this study is a first step towards seeing how to model such data.

200
150
100
50
0

Sleep

Pulse wave
velocity (pwv)

Activity

Weight

Heart rate
Blood
pressure (sbp)

Steps

Figure 1: Data per modality. Left to right: modalities the most strongly
correlated with Big-Five traits to the least.
Accuracy (%)

ABSTRACT

80
75
70
65
60
55

SVM

Ex.

Ag.

Co.

DT

Em.

Baseline

Op.

Figure 2: Classification accuracies.

2

METHODOLOGY

Data. 9270 Withings-device users completed a TIPI survey [2] to
measure their Big-Five personality traits. We collect sensor data
from all Withings devices each user owns (e.g. weight scale, sleep
tracker) in daily resolutions over a window of up to 1 year. The
data is passive with some inferred behavioral statistics (e.g. sleepstage durations). Each modality is in varying amounts depending
on individual usage (Fig. 1).
Data Analysis. We split sensor data across months, aggregating events to extract features, which we use to perform Pearson’s
correlation with personality traits.
Classification. We consider a binary classification task for each
Big-Five personality, using the median to group each into 2 classes.
We use features most strongly correlated with personality and at
least 500 user-months as input features to SVM and Decision Tree.

3

RESULTS

Correlations. We find a number of strong and significant correlations between features and traits (|r|>0.1 and p<0.01), e.g. mean and
variance in bed-in time with co. and em.; mean weight with ag.
Classification. We use 17 input features from sleep, pwv, weight
and sbp. The current study achieves similar accuracies to those
observed in [1] (Fig. 2).
Summary. Our study replicates the personality classification analysis done in [1]. We show the application of SVM and Decision Tree
onto a new type of large-scale complex dataset to binarily classify
Big-Five personality traits is able to achieve accuracies of 74.6%.

REFERENCES

[1] Chittaranjan, G., et al. Who’s who with big-five: Analyzing and classifying
personality traits with smartphones. ISWC ’11, 29–36.
[2] Gosling, S., et al. A very brief measure of the big-five personality domains.
504–528.
[3] Harari, G., et al. Using smartphones to collect behavioral data in psychological
science: Opportunities, practical considerations, and challenges. 838–854.

Inference of Big-Five Personality
Using Large-scale Networked
Mobile and Appliance Data
Catherine Tong†, Gabriella M. Harari§, Angela Chieh‡, Otmane Bellahsen‡,
Matthieu Vegreville‡, Eva Roitmann‡, Nicholas D. Lane†*
†

University of Oxford, §Stanford University, ‡Nokia Digital Health - Withings, *Nokia Bell Labs

Introduction

Framework
Mixed-source data

Motivation: Personality inference is useful for device
customisation and wellbeing studies.
Big Five Personality: Extraversion, Agreeableness,
Conscientiousness, Emotionalstability. Measuring through
self-report surveys is cumbersome.
Phone
App

Existing Work: Device-based approach for automated
personality inference tend to:
•Use small-scaled and homogeneous sample
•Collect only from one mobile source
•Focus on social and mobile behavior.

Important Results

• We show the application of SVM and Decision Tree onto a new
type of large-scale complex dataset to binarily classify Big-Five

Feature Selection
Found 17 features most strongly correlated with
personalities and with at least 500 user-months.

Data

Personality Inference
Binary Classification (grouping each trait by median)
using SVM and Decision Tree.
We use Leave-One-Out-Cross-Validation.

Personality Data:
•TIPI Survey sent out to Withings device users, outputting
scores for each personality trait for each respondent
•9110 valid respondents

41-50

male

0

2000

4000

Results

51-60 >60

Correlation:
We find a number of strong and significant correlations
between features and traits (|r|>0.1 and p<0.01), e.g. mean
and variance in bed-in time with co. and em.; mean weight
with ag.

female

6000

8000

10000

Behavioral and Physiological Data:
Unique Characteristics:
• Large-scale, diverse
activity heart rate
population
activity
heart rate
• Mix of data sources
steps
blood pressure
• Mix of raw and
pwv
sleep
inference data
weight
• Sparsity
0
• Focus on behavioral
and physiological
features

Accuracy (%)

Gender

31-40

Sleep
Tracker

Data Analysis
Pearson’s Correlation test between features
and personality traits.

• We replicate the personality classification analysis done in
existing work.

<21

SmartScale

Feature Extraction
Aggregating sensor data across months, taking mean
and variance for each modality.

Goal: Apply methods used in prior studies to a new style of
dataset for personality inference.

Age

Smart- Blood
Watch pressure
monitor

80
75
70
65
60
55

SVM

Ex.

Ag.

Co.

DT

Em.

Baseline

Op.

Inference:
50

100
150
Mean No. of Days

200

Using input features from sleep, pwv, weight and sbp, we
achieve similar accuracies to baselines observed in
Chittaranjan et al. 2011.

Future Work
We would like to achieve better accuracies and this study is a first step towards seeing how to model such data.

Ditto: Fair and Robust Federated Learning Through Personalization

Tian Li 1 Shengyuan Hu 1 Ahmad Beirami 2 Virginia Smith 1

Abstract
Fairness and robustness are two important concerns for federated learning systems. In this work,
we identify that robustness to data and model poisoning attacks and fairness, measured as the uniformity of performance across devices, are competing constraints in statistically heterogeneous
networks. To address these constraints, we propose employing a simple, general framework for
personalized federated learning, Ditto, that can
inherently provide fairness and robustness benefits, and develop a scalable solver for it. Theoretically, we analyze the ability of Ditto to achieve
fairness and robustness simultaneously on a class
of linear problems. Empirically, across a suite
of federated datasets, we show that Ditto not
only achieves competitive performance relative to
recent personalization methods, but also enables
more accurate, robust, and fair models relative to
state-of-the-art fair or robust baselines.

1. Introduction
Federated learning (FL) aims to collaboratively learn from
data that has been generated by, and resides on, a number of
remote devices or servers (McMahan et al., 2017). FL stands
to produce highly accurate statistical models by aggregating
knowledge from disparate data sources. However, to deploy
FL in practice, it is necessary for the resulting systems to be
not only accurate, but to also satisfy a number of pragmatic
constraints regarding issues such as fairness, robustness, and
privacy. Simultaneously satisfying these varied constraints
can be exceptionally difficult (Kairouz et al., 2019).
We focus in this work specifically on issues of accuracy,
fairness (i.e., limiting performance disparities across the network (Mohri et al., 2019)), and robustness (against trainingtime data and model poisoning attacks). Many prior efforts
have separately considered fairness or robustness in federated learning. For instance, fairness strategies include using
1

Carnegie Mellon University 2 Facebook AI. Correspondence
to: Tian Li <tianli@cmu.edu>.
Proceedings of the 38 th International Conference on Machine
Learning, PMLR 139, 2021. Copyright 2021 by the author(s).

minimax optimization to focus on the worst-performing devices (Mohri et al., 2019; Hu et al., 2020) or reweighting the
devices to allow for a flexible fairness/accuracy tradeoff (Li
et al., 2020e; 2021). Robust methods commonly use techniques such as gradient clipping (Sun et al., 2019) or robust
aggregation (Blanchard et al., 2017; Yin et al., 2018).
While these approaches may be effective at either promoting
fairness or defending against training-time attacks in isolation, we show that the constraints of fairness and robustness
can directly compete with one another when training a single
global model, and that simultaneously optimizing for accuracy, fairness, and robustness requires careful consideration.
For example, as we empirically demonstrate (Section 4),
current fairness approaches can render FL systems highly
susceptible to training time attacks from malicious devices.
On the other hand, robust methods may filter out rare but
informative updates, causing unfairness (Wang et al., 2020).
In this work, we investigate a simple, scalable technique to
simultaneously improve accuracy, fairness, and robustness
in federated learning. While addressing the competing constraints of FL may seem like an insurmountable problem, we
identify that statistical heterogeneity (i.e., non-identically
distributed data) is a root cause for tension between these
constraints, and is key in paving a path forward. In particular, we suggest that methods for personalized FL—which
model and adapt to the heterogeneity in federated settings
by learning distinct models for each device—may provide
inherent benefits in terms of fairness and robustness.
To explore this idea, we propose Ditto, a scalable federated multi-task learning framework. Ditto can be seen as
a lightweight personalization add-on for standard global FL.
It is applicable to both convex and non-convex objectives,
and inherits similar privacy and efficiency properties as traditional FL. We evaluate Ditto on a suite of federated
benchmarks and show that, surprisingly, this simple form of
personalization can in fact deliver better accuracy, robustness, and fairness benefits than state-of-the-art, problemspecific objectives that consider these constraints separately.
We summarize our contributions below:
• We propose Ditto, a multi-task learning objective for
federated learning that provides personalization while
retaining similar efficiency and privacy benefits as traditional FL. We provide convergence guarantees for our

Ditto: Fair and Robust Federated Learning Through Personalization

proposed Ditto solver, which incorporate common practices in cross-device federated learning such as limited
device participation and local updating. Despite its simplicity, we show that Ditto can deliver similar or superior accuracy relative to other common methods for
personalized federated learning.
• Next, we demonstrate that the benefits of Ditto go beyond accuracy—showing that the personalized objective
can inherently offer robustness superior to that of common robust FL methods across a diverse set of data and
model poisoning attacks. On average across all datasets
and attacks, Ditto improves test accuracy by ∼6% (absolute) over the strongest robust baseline.
• Similarly, we show that Ditto can naturally increase
fairness—reducing variance of the test accuracy across
devices by ∼10% while maintaining similar or superior
accuracy relative to state-of-the-art methods for fair FL.
• Finally, we highlight that Ditto is particularly useful
for practical applications where we simultaneously care
about multiple constraints (accuracy, fairness, and robustness). We motivate this through analysis on a toy
example in Section 3, as well as experiments across a
suite of federated datasets in Section 4.

2. Background & Related Work
Robustness and fairness are two broad areas of research
that extend well beyond the application of federated learning. In this section we provide precise definitions of the
notions of robustness/fairness considered in this work, and
give an overview of prior work in robustness, fairness, and
personalization in the context of federated learning.
Robustness in Federated Learning. Training-time attacks (including data poisoning and model poisoning) have
been extensively studied in prior work (Biggio et al., 2012;
Gu et al., 2017; Chen et al., 2017; Shafahi et al., 2018; Liu
et al., 2018; Huang et al., 2020; Xie et al., 2020; Wang
et al., 2020; Dumford & Scheirer, 2018; Huang et al., 2020).
In federated settings, a number of strong attack methods
have been explored, including scaling malicious model
updates (Bagdasaryan et al., 2020), collaborative attacking (Sun et al., 2020), defense-aware attacks (Bhagoji et al.,
2019; Fang et al., 2020), and adding edge-case adversarial training samples (Wang et al., 2020). Our work aims
to investigate common attacks related to Byzantine robustness (Lamport et al., 2019), as formally described below.
Definition 1 (Robustness). We are conceptually interested
in Byzantine robustness (Lamport et al., 2019), where the
malicious devices can send arbitrary updates to the server to
compromise training. To measure robustness, we assess the
mean test performance on benign devices, i.e., we consider
model w1 to be more robust than w2 to a specific attack

if the mean test performance across the benign devices is
higher for model w1 than w2 after training with the attack.
We examine three widely-used attacks in our threat model:
• (A1) Label poisoning: Corrupted devices do not have
access to the training APIs and training samples are poisoned with flipped (if binary) or uniformly random noisy
labels (Bhagoji et al., 2019; Biggio et al., 2011).
• (A2) Random updates: Malicious devices send random
zero-mean Gaussian parameters (Xu & Lyu, 2020).
• (A3) Model replacement: Malicious devices scale their
adversarial updates to make them dominate the aggregate
updates (Bagdasaryan et al., 2020).
While non-exhaustive, these attacks have been commonly
studied in distributed and federated settings, and explore
corruption at various points (the underlying data, labels,
or model). In terms of defenses, robust aggregation is a
common strategy to mitigate the effect of malicious updates (Blanchard et al., 2017; Pillutla et al., 2019; Sun
et al., 2019; Li et al., 2019; He et al., 2020). Other defenses include gradient clipping (Sun et al., 2019) or normalization (Hu et al., 2020). While these strategies can
improve robustness, they may also produce unfair models
by filtering out informative updates, especially in heterogeneous settings (Wang et al., 2020). In our experiments
(Section 4), we compare Ditto with several strong defenses (median, gradient clipping (Sun et al., 2019), Krum,
Multi-Krum (Blanchard et al., 2017), gradient-norm based
anomaly detector (Bagdasaryan et al., 2020), and a new defense proposed herein) and show that Ditto can improve
both robustness and fairness compared with these methods.
Fairness in Federated Learning. Due to the heterogeneity of the data in federated networks, it is possible that the
performance of a model will vary significantly across the
devices. This concern, also known as representation disparity (Hashimoto et al., 2018), is a major challenge in FL,
as it can potentially result in uneven outcomes for the devices. Following Li et al. (2020e), we provide a more formal
definition of this fairness in the context of FL below:
Definition 2 (Fairness). We say that a model w1 is more
fair than w2 if the test performance distribution of w1
across the network is more uniform than that of w2 , i.e.,
std {Fk (w1 )}k∈[K] < std {Fk (w2 )}k∈[K] where Fk (·) denotes the test loss on device k∈[K], and std{·} denotes
the standard deviation. In the presence of adversaries, we
measure fairness only on benign devices.
We note that there exists a tension between variance and
utility in the definition above; in general, a common goal is
to lower the variance while maintaining a reasonable average performance (e.g., average test accuracy). To address

Ditto: Fair and Robust Federated Learning Through Personalization

representation disparity, it is common to use minimax optimization (Mohri et al., 2019; Deng et al., 2020) or flexible
sample reweighting approaches (Li et al., 2020e; 2021) to
encourage a more uniform quality of service. In all cases,
by up-weighting the importance of rare devices or data, fair
methods may not be robust in that they can easily overfit to
corrupted devices (see Section 4.3). The tension between
fairness and robustness has been studied in previous works,
though for different notions of fairness (equalized odds)
or robustness (backdoor attacks) (Wang et al., 2020), or in
centralized settings (Chang et al., 2020). Recently, Hu et al.
(2020) proposed FedMGDA+, a method targeting fair and
robust FL; however, this work combines classical fairness
(minimax optimization) and robustness (gradient normalization) techniques, in contrast to the multi-task framework
proposed herein, which we show can inherently provide
benefits with respect to both constraints simultaneously.
Personalized Federated Learning. Given the variability
of data in federated networks, personalization is a natural approach used to improve accuracy. Numerous works
have proposed techniques for personalized federated learning. Smith et al. (2017) first explore personalized FL via
a primal-dual MTL framework, which applies to convex
settings. Personalized FL has also been explored through
clustering (e.g., Ghosh et al., 2020; Sattler et al., 2020;
Muhammad et al., 2020), finetuning/transfer learning (Zhao
et al., 2018; Yu et al., 2020), meta-learning (Jiang et al.,
2019; Chen et al., 2018; Khodak et al., 2019; Fallah et al.,
2020; Li et al., 2020a; Singhal et al., 2021), and other forms
of MTL, such as hard model parameter sharing (Agarwal
et al., 2020; Liang et al., 2020) or the weighted combination
method in Zhang et al. (2021). Our work differs from these
approaches by simultaneously learning local and global
models via a global-regularized MTL framework, which
applies to non-convex ML objectives.
Similar in spirit to our approach are works that interpolate
between global and local models (Mansour et al., 2020;
Deng et al., 2021). However, as discussed in Deng et al.
(2021), these approaches can effectively reduce to local minimizers without additional constraints. The most closely
related works are those that regularize personalized models
towards their average (Hanzely & Richtárik, 2020; Hanzely
et al., 2020; Dinh et al., 2020), which can be seen as a
form of classical mean-regularized MTL (Evgeniou & Pontil, 2004). Our objective is similarly inspired by meanregularized MTL, although we regularize towards a global
model rather than the average personalized model. As we
discuss in Section 3, one advantage of this is that it allows for
methods designed for the global federated learning problem
(e.g., optimization methods, privacy/security mechanisms)
to be easily re-used in our framework, with the benefit of
additional personalization. We compare against a range of
personalized methods empirically in Section 4.4, showing

that Ditto achieves similar or superior performance across
a number of common FL benchmarks.
Finally, a key contribution of our work is jointly exploring the robustness and fairness benefits of personalized FL.
The benefits of personalization for fairness alone have been
demonstrated empirically in prior work (Wang et al., 2019;
Hao et al., 2020). Connections between personalization
and robustness have also been explored in Yu et al. (2020),
although the authors propose using personalization methods
on top of robust mechanisms. Our work differs from these
works by arguing that MTL itself offers inherent robustness
and fairness benefits, and exploring the challenges that exist
when attempting to satisfy both constraints simultaneously.

3. Ditto: Global-Regularized Federated
Multi-Task Learning
In order to explore the possible fairness/robustness benefits
of personalized FL, we first propose a simple and scalable
framework for federated multi-task learning. As we will see,
this lightweight personalization framework is amenable to
analyses while also having strong empirical performance.
We explain our proposed objective, Ditto, in Section 3.1
and then present a scalable algorithm to solve it in federated
settings (Section 3.2). We provide convergence guarantees
for our solver, and explain several practical benefits of our
modular approach in terms of privacy and efficiency. Finally,
in Section 3.3, we characterize the benefits of Ditto in
terms of fairness and robustness on a class of linear problems. We empirically explore the fairness and robustness
properties against state-of-the-art baselines in Section 4.
3.1. Ditto Objective
Traditionally, federated learning objectives consider fitting a
single global model, w, across all local data in the network.
The aim is to solve:
min G(F1 (w), . . . FK (w)) ,
w

(Global Obj)

where Fk (w) is the local objective for device k, and G(·) is a
function that aggregates the local objectives {Fk (w)}k∈[K]
from each device. For example, in FedAvg (McMahan et al.,
2017), G(·) is typically set to be a weighted average of
PK
local losses, i.e., k=1 pk Fk (w),
P where pk is a pre-defined
non-negative weight such that k pk = 1.
However, in general, each device may generate data xk via a
distinct distribution Dk , i.e., Fk (w) := Exk ∼Dk [fk (w; xk )].
To better account for this heterogeneity, it is common to
consider techniques that learn personalized, device-specific
models, {vk }k∈[K] across the network. In this work we
explore personalization through a simple framework for
federated multi-task learning. We consider two ‘tasks’:
the global objective (Global Obj), and the local objective

Ditto: Fair and Robust Federated Learning Through Personalization

Fk (vk ), which aims to learn a model using only the data
of device k. To relate these tasks, we incorporate a regularization term that encourages the personalized models to
be close to the optimal global model. The resulting bi-level
optimization problem for each device k ∈ [K] is given by:
λ
2
min hk (vk ; w ) := Fk (vk ) + kvk − w∗ k
vk
2
(Ditto)
s.t. w∗ ∈ arg min G(F1 (w), . . . FK (w))) .
∗

w

Here the hyperparameter λ controls the interpolation between local and global models. When λ is set to 0, Ditto
is reduced to training local models; as λ grows large, it
recovers global model objective (Global Obj) (λ → +∞).
Intuition for Fairness/Robustness Benefits. In addition
to improving accuracy via personalization, we argue that
Ditto can offer fairness and robustness benefits. To reason
about this, consider a simple case where data are homogeneous across devices. Without adversaries, learning a single
global model is optimal for generalization. However, in the
presence of adversaries, learning globally might introduce
corruption, while learning local models may not generalize
well due to limited sample size. Ditto with an appropriate
value of λ offers a tradeoff between these two extremes: the
smaller λ, the more the personalized models vk can deviate
from the (corrupted) global model w, potentially providing
robustness at the expense of generalization. In the heterogeneous case (which can lead to issues of unfairness as
described in Section 2), a finite λ exists to offer robustness
and fairness jointly. We explore these ideas more rigorously
in Section 3.3 by analyzing the tradeoffs between accuracy,
fairness, and robustness in terms of λ for a class of linear
regression problems, and demonstrate fairness/robustness
benefits of Ditto empirically in Section 4.
Other Personalization Schemes. As discussed in Section 2, personalization is a widely-studied topic in FL. Our
intuition in Ditto is that personalization, by reducing reliance on the global model, can reduce representation disparity (i.e., unfairness) and potentially improve robustness.
It is possible that other personalization techniques beyond
Ditto offer similar benefits: We provide some initial, encouraging results on this in Section 4.4. However, we specifically explore Ditto due to its simple nature, scalability,
and strong empirical performance. Ditto is closely related
to works that regularize personalized models towards their
average (Hanzely & Richtárik, 2020; Hanzely et al., 2020;
Dinh et al., 2020), similar to classical mean-regularized
MTL (Evgeniou & Pontil, 2004); Ditto differs by regularizing towards a global model rather than the average personalized model. We find that this provides benefits in terms of
analysis (Section 3.3), as we can easily reason about Ditto

relative to the global (λ → ∞) vs. local (λ → 0) baselines;
empirically, in terms of accuracy, fairness, and robustness
(Section 4); and practically, in terms of the modularity it
affords our corresponding solver (Section 3.2).
Other Regularizers. To encourage the personalized models vk to be close to the optimal global model w∗ , there are
choices beyond the L2 norm that could be considered, e.g.,
using a Bregman divergence-based regularizer or reshaping
the L2 ball using the Fisher information matrix. Under the
logistic loss (used in our experiments), the Bregman divergence will reduce to KL divergence, and its second-order
Taylor expansion will result in an L2 ball reshaped with the
Fisher information matrix. Such regularizers are studied in
other related contexts like continual learning (Kirkpatrick
et al., 2017; Schwarz et al., 2018), multi-task learning (Yu
et al., 2020), or finetuning for language models (Jiang
et al., 2020). However, in our experiments (Section 4.4),
we find that incorporating approximate empirical Fisher
information (Yu et al., 2020; Kirkpatrick et al., 2017) or
symmetrized KL divergence (Jiang et al., 2020) does not
improve the performance over the simple L2 regularized
objective, while adding non-trivial computational overhead.
Remark (Relation to FedProx). We note that the L2
term in Ditto bears resemblance to FedProx, a method
which was developed to address heterogeneity in federated
optimization (Li et al., 2020d). However, Ditto fundamentally differs from FedProx in that the goal is to learn
personalized models vk , while FedProx produces a single
global model w. For instance, when the regularization hyperparameter is zero, Ditto reduces to learning separate local
models, whereas FedProx would reduce to FedAvg. In fact,
Ditto is significantly more general than FedProx in that
FedProx could be used as the global model solver in Ditto
to optimize G(·). As discussed above, other regularizers
beyond the L2 norm may also be used in practice.
3.2. Ditto Solver
To solve Ditto, we propose jointly solving for the global
model w∗ and personalized models {vk }k∈[K] in an alternating fashion, as summarized in Algorithm 1. Optimization
proceeds in two phases: (i) updates to the global model, w∗ ,
are computed across the network, and then (ii) the personalized models vk are fit on each local device. The process of
optimizing w∗ is exactly the same as optimizing for any objective G(·) in federated settings: If we use iterative solvers,
then at each communication round, each selected device can
solve the local subproblem of G(·) approximately (Line 5).
For personalization, device k solves the global-regularized
local objective minvk hk (vk ; wt ) inexactly at each round
(Line 6). Due to this alternating scheme, our solver can
scale well to large networks, as it does not introduce addi-

Ditto: Fair and Robust Federated Learning Through Personalization

tional communication or privacy overheads compared with
existing solvers for G(·). In our experiments (all except Table 3), we use FedAvg as the objective and solver for G(·),
under which we simply let device k run local SGD on Fk
(Line 5). We provide a simplified algorithm definition using
FedAvg for the w∗ update in Algorithm 2 in the appendix.
Algorithm 1: Ditto for Personalized FL
Input: K, T , s, λ, η, w0 , {vk0 }k∈[K]
2 for t = 0, · · · , T − 1 do
3
Server randomly selects a subset of devices St ,
and sends wt to them
4
for device k ∈ St in parallel do
5
Solve the local sub-problem of G(·)
inexactly starting from wt to obtain wkt :
1

wkt ← UPDATE GLOBAL(wt , ∇Fk (wt ))
6

/* Solve hk (vk ; wt ) */
Update vk for s local iterations:
vk = vk − η(∇Fk (vk ) + λ(vk − wt ))

7

Send ∆tk := wkt − wt back
Server aggregates {∆tk }:
wt+1 ← AGGREGATE wt , {∆tk }k∈{St }

8



return {vk }k∈[K] (personalized), wT (global)

We note that another natural choice to solve the Ditto
objective is to first obtain w∗ , and then for each device k,
perform finetuning on the local objective minvk hk (vk ; w∗ ).
These two approaches will arrive at the same solutions in
strongly convex cases. In non-convex settings, we observe
that there may be additional benefits of joint optimization:
Empirically, we find that the updating scheme tends to guide
the optimization trajectory towards a better solution compared with finetuning starting from w∗ , particularly when
w∗ is corrupted by adversarial attacks (Section 4.4). Intuitively, under training-time attacks, the global model may
start from a random one, get optimized, and gradually become corrupted as training proceeds (Li et al., 2020b). In
these cases, feeding in early global information (i.e., before
the global model converges to w∗ ) may be helpful under
strong attacks.
We note that Ditto with joint optimization requires the
devices to maintain local states (i.e., personalized models)
and carry these local states to the next communication round
where they are selected. Solving Ditto with finetuning
does not need devices to be stateful, while losing the benefits
of alternate updating discussed above.
Modularity of Ditto. From the Ditto objective and
Alg 1, we see that a key advantage of Ditto is its modularity, i.e., that we can readily use prior art developed for

the Global Obj along with the personalization add-on of
hk (vk ; w∗ ), as highlighted in red. This has several benefits:
• Optimization: It is possible to plug in other methods
beyond FedAvg (e.g., Li et al., 2020c; Karimireddy et al.,
2020; Reddi et al., 2021) in Algorithm 1 to update the
global model, and inherit the convergence benefits, if any
(we make this more precise in Theorem 1).
• Privacy: Ditto communicates the same information
over the network as typical FL solvers for the global objective, thus preserving whatever privacy or communication
benefits exist for the global objective and its respective
solver. This is different from most other personalization
methods where global model updates depend on local
parameters, which may raise privacy concerns (London,
2020).
• Robustness: Beyond the inherent robustness benefits of
personalization, robust global methods can be used with
Ditto to further improve performance (see Section 4.4).
In particular, while not the main focus of our work, we note
that Ditto may offer a better privacy-utility tradeoff than
training a global model. For instance, when training Ditto,
if we fix the number of communication rounds and add
the same amount of noise per round to satisfy differential
privacy, Ditto consumes exactly the same privacy budget
as normal global training, while yielding higher accuracy
via personalization (Section 4). Similar benefits have been
studied, e.g., via finetuning strategies (Yu et al., 2020).
Convergence of Algorithm 1. Note that optimizing the
global model wt does not depend on any personalized models {vk }k∈[K] . Therefore, w enjoys the same global convergence rates with the solver we use for G. Under this observation, we present the local convergence of Algorithm 1.
Theorem 1 (Local Convergence of Alg. 1; formal statement
and proof in Theorem 10). Assume for k ∈ [K], Fk is
strongly convex and smooth, under common assumptions,
if wt converges to w∗ with rate g(t), then there exists a
constant C<∞ such that for λ ∈ R, and for k ∈ [K], vkt
converges to vk∗ := arg minvk hk (vk ; w∗ ) with rate Cg(t).
Using Theorem 1, we can directly plug in previous convergence analyses for any G(·). For instance, when the global
objective and its solver are those of FedAvg, we can obtain
an O(1/t) convergence rate for Ditto under suitable conditions (Corollary 1). We provide a full theorem statement
and proof of convergence in Appendix B.
3.3. Analyzing the Fairness/Robustness Benefits of
Ditto in Simplified Settings
In this section, we more rigorously explore the fairness/robustness benefits of Ditto on a class of linear prob-

Ditto: Fair and Robust Federated Learning Through Personalization

lems. Throughout our analysis, we assume G(·) is the standard objective in FedAvg (McMahan et al., 2017).
Point Estimation. To provide intuition, we first examine
a toy one-dimensional point estimation problem. Denote
the underlying models for the devices as {vk }k∈[K] , vk ∈
R, and let the points on device k, {xk,1 , . . . , xk,n }1 , be
observations of vk with random perturbation, i.e., xk,i =
vk +zk,i , where zk,i ∼ N (0, σ 2 ) and are IID. Assume vk ∼
N (θ, τ 2 ), where θ is drawn from the uniform uninformative
prior on R, and τ is a known constant. Here, τ controls the
degree of relatedness of the data on different devices: τ =0
captures the case where the data on all devices are identically
distributed while τ → ∞ results in the scenario where the
data on different devices are completely unrelated.
The
Pnk
xk,i )2 .
local objective is minvk Fk (vk ) = 21 (vk − n1k i=1
In the presence of adversaries, we look at a specific type
of label poisoning attack. Let Ka denote the number of
malicious devices, and the ‘capability’ of an adversary is
modeled by τa , i.e., the underlying model of an adversary
follows N (θ, τa2 ) where τa2 > τ 2 .
We first derive the Bayes estimator (which will be the most
accurate and robust) for the real model distribution by observing a finite number of training points. Then, we show
that by solving Ditto, we are able to recover the Bayes
estimator with a proper λ∗ (with the knowledge of τ ). In addition, the same λ∗ results in the most fair solution among
the set of solutions of Ditto parameterized by λ. This
shows that Ditto with a proper choice of λ is Bayes optimal for this particular problem instance. In general, in
Theorem 8 (appendix), we prove that
λ∗ =

K
σ2
.
Ka
n Kτ 2 + K−1
(τa2 − τ 2 )

We see that λ∗ decreases when (i) there are more local
samples n, (ii) the devices are less related (larger τ ), or
(iii) the attacks are stronger (larger number of attackers,
Ka , and more powerful adversaries, τa ). Related theorems
(Theorem 6-9) are presented in Appendix A.3.
In Figure 1, we plot average test error, fairness (standard
deviation shown as error bars), and robustness (test error
in the adversarial case) across a set of λ’s for both clean
and adversarial cases. We see that in the solution space
of Ditto, there exists a specific λ which minimizes the
average test error and standard deviation across all devices
at the same time, which is equal to the optimal λ∗ given by
our theory. Figure 2 shows (i) Ditto with λ∗ is superior
than learning local or global models, and (ii) λ∗ should
increase as the relatedness between devices (1/τ ) increases.
1

For ease of notation, we assume each device has the same
number of training samples. It is straightforward to extend the
current analysis to allow for varying number of samples per device.

Figure 1. Empirically, the λ∗ given by Theorem 6-9 results in the
most accurate, fair, and robust solution within Ditto’s solution
space. λ∗ is also optimal in terms of accuracy and robustness
among any possible federated estimation algorithms.

Figure 2. Impact of data relatedness across all devices. When 1/τ
is small (less related), local outperforms global; when 1/τ is large
(more related), global is better than local. Ditto (λ∗ ) achieves the
lowest test error and variance (measured across benign devices).

Linear Regression. All results discussed above can be
generalized to establish the optimality of Ditto on a class
of linear regression problems (with additional assumptions
on feature covariance). We defer readers to Appendix A.2
for full statements and proofs. While our analyses here are
limited to a simplified set of attacks and problem settings,
we build on this intuition in Section 4—empirically demonstrating the accuracy, robustness, and fairness benefits of
Ditto using both convex and non-convex models, across a
range of federated learning benchmarks, and under a diverse
set of attacks.

4. Experiments
In this section, we first demonstrate that Ditto can inherently offer similar or superior robustness relative to strong
robust baselines (Section 4.1). We then show it results more
fair performance than recent fair methods (Section 4.2).
Ditto is particularly well-suited for mitigating the tension between these constraints and achieving both fairness
and robustness simultaneously (Section 4.3). We explore
additional beneficial properties of Ditto in Section 4.4.
Setup. For all experiments, we measure robustness via test
accuracy, and fairness via test accuracy variance (or standard deviation), both across benign devices (see Def. 1, 2).
We use datasets from common FL benchmarks (Caldas

Ditto: Fair and Robust Federated Learning Through Personalization

et al., 2018; Smith et al., 2017; TFF), which cover both
vision and language tasks, and convex and non-convex
models. Detailed datasets and models are provided in Table 4 in Appendix C. We split local data on each device
into train/test/validation sets randomly, and measure performance on the test data. For each device, we select λ locally
based on its local validation data. We further assume the
devices can make a binary decision on whether the attack is
strong or not. For devices with very few validation samples
(less than 4), we use a fixed small λ (λ=0.1) for strong attacks, and use a fixed relatively large λ (λ=1) for all other
attacks. For devices with more than 5 validation data points,
we let each select λ from {0.05, 0.1, 0.2} for strong attacks,
and select λ from {0.1, 1, 2} for all other attacks. See Appendix D.2 for details. More advanced tuning methods are
left for future work. Our code, data, and experiments are
publicly available at github.com/litian96/ditto.
4.1. Robustness of Ditto
Following our threat model described in Definition 1, we
apply three attacks to corrupt a random subset of devices.
We pick corruption levels until a point where there is a significant performance drop when training a global model. We
compare robustness (Def. 1) of Ditto with various defense
baselines, presenting the results of three strongest defenses

in Figure 3. Execution details and full results are reported in
Appendix D.4. As shown in Figure 3, Ditto achieves the
highest accuracy under most attacks, particularly those with
a large fraction of malicious devices. On average across
all datasets and attacks, Ditto results in ∼6% absolute
accuracy improvement compared with the strongest robust
baseline (Appendix D.4). In scenarios where a robust baseline outperforms Ditto, we have also found that replacing
the global objective and its solver (FedAvg) with a robust
version (e.g., using robust aggregators) can further improve
Ditto, yielding superior performance (Section 4.4).
4.2. Fairness of Ditto
To explore the fairness of Ditto, we compare against
TERM (Li et al., 2021) as a baseline. It is an improved
version of the q-FFL (Li et al., 2020e) objective, which has
been recently proposed for fair federated learning. TERM
also recovers AFL (Mohri et al., 2019), another fair FL
objective, as a special case. TERM uses a parameter t to
offer flexible tradeoffs between fairness and accuracy. In
Table 1, we compare the proposed objective with global,
local, and fair methods (TERM) in terms of test accuracies
and standard deviation. When the corruption level is high,
‘global’ or ‘fair’ will even fail to converge. Ditto results
in more accurate and fair solutions both with and without
attacks. On average across all datasets, Ditto reduces
variance across devices by ∼10% while improving absolute
test accuracy by 5% compared with TERM (on clean data).
4.3. Addressing Competing Constraints
In this section, we examine the competing constraints between robustness and fairness. When training a single global
model, fair methods aim to encourage a more uniform performance distribution, but may be highly susceptible to
training-time attacks in statistically heterogeneous environments. We investigate the test accuracy on benign devices
when learning global, local, and fair models. In the TERM
objective, we set t = 1, 2, 5 to achieve different levels of
fairness (the higher, the fairer). We perform the data poisoning attack (A1 in Def. 1). The results are plotted in Figure 4.
As the corruption level increases, we see that fitting a global
model becomes less robust. Using fair methods will be more
susceptible to attacks. When t gets larger, the test accuracy
gets lower, an indication that the fair method is overfitting
to the corrupted devices relative to the global baseline.

Figure 3. Robustness, i.e., average test accuracy on benign devices
(Definition 1), on Fashion MNIST and FEMNIST. We compare
Ditto with learning a global model and three strong defense
mechanisms (see Appendix D for results on all defense baselines),
and find that Ditto is the most robust under almost all attacks.

Next, we apply various strong robust methods under the
same attack, and explore the robustness/accuracy and fairness performance. The robust approaches include: Krum,
multi-Krum (Blanchard et al., 2017), taking the coordinatewise median of gradients (‘median’), gradient clipping
(‘clipping’), filtering out the gradients with largest norms
(‘k-norm’), and taking the gradient of the k-th largest loss

Ditto: Fair and Robust Federated Learning Through Personalization
Table 1. Average (standard deviation) test accuracy to benchmark performance and fairness (Definition 2) on Fashion MNIST and
FEMNIST. Ditto is either (i) more fair compared with the baselines of training a global model, or (ii) more accurate than the fair
baseline under a set of attacks. We bold the method with highest average minus standard deviation across all methods.

Fashion
Methods

clean

A1 (ratio of adversaries)

A2 (ratio of adversaries)

A3 (ratio of adversaries)

20%

20%

10%

50%

80%

50%

80%

20%

50%

global
.911 (.08) .897 (.08) .855 (.10) .753 (.13) .900 (.08) .882 (.09) .857 (.10) .753 (.10) .551 (.13) .275 (.12)
local
.876 (.10) .874 (.10) .876 (.11) .879 (.10) .874 (.10) .876 (.11) .879 (.10) .877 (.10) .874 (.10) .876 (.11)
fair (TERM, t=1) .909 (.07) .751 (.12) .637 (.13) .547 (.11) .731 (.13) .637 (.14) .635 (.14) .653 (.13) .601 (.12) .131 (.16)
Ditto
.943 (.06) .944 (.07) .937 (.07) .907 (.10) .938 (.07) .930 (.08) .913 (.09) .921 (.09) .902 (.09) .873 (.11)
FEMNIST
A1 (ratio of adversaries)
A2 (ratio of adversaries)
A3 (ratio of adversaries)
Methods

clean

20%

50%

80%

20%

50%

80%

10%

15%

20%

global
.804 (.11) .773 (.11) .727 (.12) .574 (.15) .774 (.11) .703 (.14) .636 (.15) .517 (.14) .487 (.14) .314 (.13)
local
.628 (.15) .620 (.14) .627 (.14) .607 (.14) .620 (.14) .627 (.14) .607 (.14) .622 (.14) .621 (.14) .620 (.14)
fair (TERM, t=1) .809 (.11) .636 (.15) .562 (.13) .478 (.12) .440 (.15) .336 (.12) .363 (.12) .353 (.12) .316 (.12) .299 (.11)
Ditto
.834 (.09) .802 (.10) .762 (.11) .672 (.13) .801 (.09) .700 (.15) .675 (.14) .685 (.15) .650 (.14) .613 (.13)

4.4. Additional Properties of Ditto

Figure 4. Fair methods can overfit to corrupted devices (possibly
with large training losses) by imposing more weights on them, thus
being particularly susceptible to attacks.

Figure 5. Compared with learning a global model, robust baselines
(i.e., the methods listed in the figure excluding ‘global’ and ‘Ditto’)
are either robust but not fair (with higher accuracy, larger variance),
or not even robust (with lower accuracy). Ditto lies at the lower
right corner, which is our preferred region.

where k is the number of malicious devices (‘k-loss’). For
Krum, multi-Krum, k-norm, and k-loss, we assume that
the server knows the expected number of malicious devices
that are selected each round, and can set k accordingly for
k-norm and k-loss. From Figure 5, we see that robust baselines are either (i) more robust than global but less fair, or
(ii) fail to provide robustness due to heterogeneity. Ditto
is more robust, accurate, and fair.

Personalization. We additionally explore the performance of other personalized FL methods in terms of accuracy and fairness, on both clean and adversarial cases. In
particular, we consider objectives that (i) regularize with the
average (L2SGD (Hanzely & Richtárik, 2020)) or the learnt
device relationship matrix (MOCHA (Smith et al., 2017)),
(ii) encourage closeness to the global model in terms of some
specific function behavior (EWC (Kirkpatrick et al., 2017;
Yu et al., 2020) and Symmetrized KL (SKL)), (iii) interpolate between local and global models (APFL (Deng et al.,
2021) and mapper (Mansour et al., 2020)), and (iv) have
been motivated by meta-learning (Per-FedAvg (HF) (Fallah et al., 2020)). We provide a detailed description in
Appendix C.
We compare Ditto with the above alternatives, using the
same learning rate tuned on FedAvg on clean data for all
methods except Per-FedAvg, which requires additional tuning to prevent divergence. For finetuning methods (EWC
and SKL), we finetune on each local device for 50 epochs
starting from the converged global model. We report results of baseline methods using their best hyperparameters. Despite Ditto’s simplicity, in Table 2 below, we
see that Ditto achieves similar or superier test accuracy
with slightly lower standard deviation compared with these
recent personalization methods.
We also evaluate the performance of MOCHA with a convex
SVM model in Table 7 in the appendix. MOCHA is more
robust and fair than most baselines, which is in line with our
reasoning that personalization can provide benefits for these
constraints. Further understanding the robustness/fairness
benefits of other personalized approaches would be an interesting direction of future work.

Ditto: Fair and Robust Federated Learning Through Personalization
Table 2. Ditto is competitive with or outperforms other recent
personalization methods. We report the average (standard deviation) of test accuracies across all devices to capture performance
and fairness (Definition 2), respectively.
Clean

50% Adversaries (A1)

Methods
FEMNIST CelebA FEMNIST CelebA
global
.804 (.11) .911 (.19) .727 (.12) .538 (.28)
local
.628 (.15) .692 (.27) .627 (.14) .682 (.27)
plain finetuning
.815 (.09) .912 (.18) .734 (.12) .721 (.28)
L2SGD
.817 (.10) .899 (.18) .732 (.15) .725 (.25)
EWC
.810 (.11) .910 (.18) .756 (.12) .642 (.26)
SKL
.820 (.10) .915 (.16) .752 (.12) .708 (.27)
Per-FedAvg (HF) .827 (.09) .907 (.17) .604 (.14) .756 (.26)
mapper
.792 (.12) .773 (.25) .726 (.13) .704 (.27)
APFL
.811 (.11) .911 (.17) .750 (.11) .710 (.27)
Ditto
.836 (.10) .914 (.18) .767 (.10) .721 (.27)

Augmenting with Robust Baselines. Ditto allows the
flexibility of learning robust w∗ leveraging any previous
robust aggregation techniques, which could further improve
the performance of personalized models. For instance, in the
aggregation step at the server side (Line 7 in Algorithm 1),
instead of simply averaging the global model updates as in
FedAvg, we can aggregate them via multi-Krum, or after
gradient clipping. As is shown in Table 3, Ditto combined
with clipping yields improvements compared with vanilla
Ditto. We present full results on different datasets trying
varying robust methods in Table 6 in the appendix.
Table 3. Augmenting Ditto with robust baselines can further
improve performance.

FEMNIST

A1

A2

A3

Methods

20% 80% 20% 80% 10% 20%

global
clipping
Ditto
Ditto + clipping

.773
.791
.803
.810

.574
.408
.669
.645

.774
.791
.792
.808

.636
.656
.681
.684

.517
.795
.695
.813

.364
.061
.650
.672

Comparing Two Solvers. As mentioned in Section 3.2,
another way to solve Ditto is to finetune on
minvk hk (vk ; w∗ ) for each k ∈ [K] after obtaining w∗ . We
examine the performance of two solvers under the model
replacement attack (A3) with 20% adversaries. In realistic
federated networks, it may be challenging to determine how
many iterations to finetune for, particularly over a heterogeneous network of devices. To obtain the best performance
of finetuning, we solve minvk hk (vk ; w∗ ) on each device
by running different iterations of mini-batch SGD and pick
the best one. As shown in Figure 6, the finetuning solver
improves the performance compared with learning a global
model, while Ditto combined with joint optimization performs the best. One can also perform finetuning after early
stopping; however, it is essentially solving a different objective and it is difficult to determine the stopping criteria. We
discuss this in more detail in Appendix D.1.

5. Conclusion and Future Work
We propose Ditto, a simple MTL framework, to address
the competing constraints of accuracy, fairness, and robustness in federated learning. Ditto can be thought of as a
lightweight personalization add-on for any global federated
objective, which maintains the privacy and communication
efficiency of the global solver. We theoretically analyze
the ability of Ditto to mitigate the tension between fairness and robustness on a class of linear problems. Our
empirical results demonstrate that Ditto can result in both
more robust and fairer models compared with strong baselines across a diverse set of attacks. Our work suggests
several interesting directions of future study, such as exploring the applicability of Ditto to other attacks such as
backdoor attacks (e.g., Sun et al., 2019); understanding the
fairness/robustness properties of other personalized methods; and considering additional constraints, such as privacy.

Acknowledgements
The work of TL, SH, and VS was supported in part by the
National Science Foundation Grant IIS1838017, a Google
Faculty Award, a Facebook Faculty Award, and the CONIX
Research Center. Any opinions, findings, and conclusions
or recommendations expressed in this material are those
of the author(s) and do not necessarily reflect the National
Science Foundation or any other funding agency.

References
Figure 6. Ditto with joint optimization (Algorithm 1) outperforms the alternative local finetuning solver under the strong model
replacement attack.

Tensorflow federated: Machine learning on decentralized data. URL https://www.tensorflow.org/
federated.
Agarwal, A., Langford, J., and Wei, C.-Y. Federated residual

Ditto: Fair and Robust Federated Learning Through Personalization

learning. arXiv preprint arXiv:2003.12880, 2020.
Bagdasaryan, E., Veit, A., Hua, Y., Estrin, D., and
Shmatikov, V. How to backdoor federated learning. In
International Conference on Artificial Intelligence and
Statistics, 2020.
Bhagoji, A. N., Chakraborty, S., Mittal, P., and Calo, S.
Analyzing federated learning through an adversarial lens.
In International Conference on Machine Learning, 2019.
Biggio, B., Nelson, B., and Laskov, P. Support vector machines under adversarial label noise. In Asian Conference
on Machine Learning, 2011.
Biggio, B., Nelson, B., and Laskov, P. Poisoning attacks
against support vector machines. In International Conference on Machine Learning, 2012.
Blanchard, P., Mhamdi, E. M. E., Guerraoui, R., and Stainer,
J. Machine learning with adversaries: Byzantine tolerant
gradient descent. In Advances in Neural Information
Processing Systems, 2017.

Dumford, J. and Scheirer, W. Backdooring convolutional
neural networks via targeted weight perturbations. arXiv
preprint arXiv:1812.03128, 2018.
Evgeniou, T. and Pontil, M. Regularized multi–task learning.
In International Conference on Knowledge Discovery and
Data Mining, 2004.
Fallah, A., Mokhtari, A., and Ozdaglar, A. Personalized federated learning: A meta-learning approach. In Advances
in Neural Information Processing Systems, 2020.
Fang, M., Cao, X., Jia, J., and Gong, N. Local model
poisoning attacks to byzantine-robust federated learning.
In U SEN IX Security Symposium, 2020.
Finn, C., Abbeel, P., and Levine, S. Model-agnostic metalearning for fast adaptation of deep networks. In International Conference on Machine Learning, 2017.
Ghosh, A., Chung, J., Yin, D., and Ramchandran, K. An efficient framework for clustered federated learning. In Advances in Neural Information Processing Systems, 2020.

Caldas, S., Wu, P., Li, T., Konečnỳ, J., McMahan, H. B.,
Smith, V., and Talwalkar, A. Leaf: A benchmark for federated settings. arXiv preprint arXiv:1812.01097, 2018.

Gu, T., Dolan-Gavitt, B., and Garg, S. Badnets: Identifying vulnerabilities in the machine learning model supply
chain. arXiv preprint arXiv:1708.06733, 2017.

Chang, H., Nguyen, T. D., Murakonda, S. K., Kazemi, E.,
and Shokri, R. On adversarial bias and the robustness of
fair machine learning. arXiv preprint arXiv:2006.08669,
2020.

Hanzely, F. and Richtárik, P. Federated learning of a
mixture of global and local models. arXiv preprint
arXiv:2002.05516, 2020.

Chen, F., Luo, M., Dong, Z., Li, Z., and He, X. Federated meta-learning with fast convergence and efficient
communication. arXiv preprint arXiv:1802.07876, 2018.
Chen, X., Liu, C., Li, B., Lu, K., and Song, D. Targeted
backdoor attacks on deep learning systems using data
poisoning. arXiv preprint arXiv:1712.05526, 2017.
Cohen, G., Afshar, S., Tapson, J., and van Schaik, A. Emnist: an extension of mnist to handwritten letters. arXiv
preprint arXiv:1702.05373, 2017.
Deng, Y., Kamani, M. M., and Mahdavi, M. Distributionally
robust federated averaging. Advances in Neural Information Processing Systems, 2020.
Deng, Y., Kamani, M. M., and Mahdavi, M. Adaptive
personalized federated learning, 2021. URL https:
//openreview.net/forum?id=g0a-XYjpQ7r.
Dinh, C. T., Tran, N. H., and Nguyen, T. D. Personalized
federated learning with moreau envelopes. In Advances
in Neural Information Processing Systems, 2020.
Duarte, M. F. and Hu, Y. H. Vehicle classification in distributed sensor networks. Journal of Parallel and Distributed Computing, 2004.

Hanzely, F., Hanzely, S., Horváth, S., and Richtárik, P.
Lower bounds and optimal algorithms for personalized
federated learning. Advances in Neural Information Processing Systems, 2020.
Hao, W., Mehta, N., Liang, K. J., Cheng, P., El-Khamy, M.,
and Carin, L. Waffle: Weight anonymized factorization
for federated learning. arXiv preprint arXiv:2008.05687,
2020.
Hashimoto, T., Srivastava, M., Namkoong, H., and Liang, P.
Fairness without demographics in repeated loss minimization. In International Conference on Machine Learning,
2018.
He, L., Karimireddy, S. P., and Jaggi, M. Byzantine-robust
learning on heterogeneous datasets via resampling. In
NeurIPS Workshop on Scalability, Privacy, and Security
in Federated Learning, 2020.
Hu, Z., Shaloudegi, K., Zhang, G., and Yu, Y. FedMGDA+:
Federated learning meets multi-objective optimization.
arXiv preprint arXiv:2006.11489, 2020.
Huang, W. R., Geiping, J., Fowl, L., Taylor, G., and Goldstein, T. Metapoison: Practical general-purpose cleanlabel data poisoning. In Advances in Neural Information
Processing Systems, 2020.

Ditto: Fair and Robust Federated Learning Through Personalization

Jiang, H., He, P., Chen, W., Liu, X., Gao, J., and Zhao, T.
SMART: Robust and efficient fine-tuning for pre-trained
natural language models through principled regularized
optimization. In Proceedings of the 58th Annual Meeting
of the Association for Computational Linguistics, 2020.
Jiang, Y., Konečnỳ, J., Rush, K., and Kannan, S. Improving
federated learning personalization via model agnostic
meta learning. arXiv preprint arXiv:1909.12488, 2019.
Kairouz, P., McMahan, H. B., Avent, B., Bellet, A., Bennis,
M., Bhagoji, A. N., Bonawitz, K., Charles, Z., Cormode,
G., Cummings, R., et al. Advances and open problems
in federated learning. arXiv preprint arXiv:1912.04977,
2019.
Karimireddy, S. P., Kale, S., Mohri, M., Reddi, S., Stich, S.,
and Suresh, A. T. Scaffold: Stochastic controlled averaging for federated learning. In International Conference
on Machine Learning, 2020.
Khodak, M., Balcan, M.-F. F., and Talwalkar, A. S. Adaptive
gradient-based meta-learning methods. In Advances in
Neural Information Processing Systems, 2019.
Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J.,
Desjardins, G., Rusu, A. A., Milan, K., Quan, J., Ramalho, T., Grabska-Barwinska, A., et al. Overcoming
catastrophic forgetting in neural networks. Proceedings
of the National Academy of Sciences, 2017.
Lamport, L., Shostak, R., and Pease, M. The byzantine
generals problem. In Concurrency: the Works of Leslie
Lamport. 2019.
Li, J., Khodak, M., Caldas, S., and Talwalkar, A. Differentially private meta-learning. In International Conference
on Learning Representations, 2020a.
Li, L., Xu, W., Chen, T., Giannakis, G. B., and Ling, Q.
Rsa: Byzantine-robust stochastic aggregation methods
for distributed learning from heterogeneous datasets. In
AAAI Conference on Artificial Intelligence, 2019.

Li, T., Sanjabi, M., Beirami, A., and Smith, V. Fair resource allocation in federated learning. In International
Conference on Learning Representations, 2020e.
Li, T., Beirami, A., Sanjabi, M., and Smith, V. Tilted empirical risk minimization. In International Conference on
Learning Representations, 2021.
Li, X., Huang, K., Yang, W., Wang, S., and Zhang, Z. On the
convergence of fedavg on non-iid data. In International
Conference on Learning Representations, 2020f.
Liang, P. P., Liu, T., Ziyin, L., Salakhutdinov, R., and
Morency, L.-P. Think locally, act globally: Federated
learning with local and global representations. arXiv
preprint arXiv:2001.01523, 2020.
Liu, Y., Ma, S., Aafer, Y., Lee, W., Zhai, J., Wang, W.,
and Zhang, X. Trojaning attack on neural networks. In
Network and Distributed System Security Symposium,
2018.
Liu, Z., Luo, P., Wang, X., and Tang, X. Deep learning
face attributes in the wild. In International Conference
on Computer Vision, 2015.
London, B. PAC identifiability in federated personalization.
In NeurIPS 2020 Workshop on Scalability, Privacy, and
Security in Federated Learning, 2020.
Mahdavifar, H., Beirami, A., Touri, B., and Shamma, J. S.
Global games with noisy information sharing. IEEE
Transactions on Signal and Information Processing over
Networks, 2018.
Mansour, Y., Mohri, M., Ro, J., and Suresh, A. T. Three
approaches for personalization with applications to federated learning. arXiv preprint arXiv:2002.10619, 2020.
McMahan, B., Moore, E., Ramage, D., Hampson, S., and
y Arcas, B. A. Communication-efficient learning of deep
networks from decentralized data. In International Conference on Artificial Intelligence and Statistics, 2017.

Li, M., Soltanolkotabi, M., and Oymak, S. Gradient descent
with early stopping is provably robust to label noise for
overparameterized neural networks. In International Conference on Artificial Intelligence and Statistics, 2020b.

Mohri, M., Sivek, G., and Suresh, A. T. Agnostic federated learning. In International Conference on Machine
Learning, 2019.

Li, T., Sahu, A. K., Zaheer, M., Sanjabi, M., Talwalkar,
A., and Smith, V. Federated optimization in heterogeneous networks. In Conference on Machine Learning and
Systems, 2020c.

Muhammad, K., Wang, Q., O’Reilly-Morgan, D., Tragos, E.,
Smyth, B., Hurley, N., Geraci, J., and Lawlor, A. Fedfast:
Going beyond average for faster training of federated
recommender systems. In International Conference on
Knowledge Discovery & Data Mining, 2020.

Li, T., Sahu, A. K., Zaheer, M., Sanjabi, M., Talwalkar, A.,
and Smith, V. Federated optimization in heterogeneous
networks. Proceedings of Machine Learning and Systems,
2020d.

Pillutla, K., Kakade, S. M., and Harchaoui, Z. Robust aggregation for federated learning. arXiv preprint
arXiv:1912.13445, 2019.

Ditto: Fair and Robust Federated Learning Through Personalization

Reddi, S., Charles, Z., Zaheer, M., Garrett, Z., Rush, K.,
Konečnỳ, J., Kumar, S., and McMahan, H. B. Adaptive
federated optimization. In International Conference on
Learning Representations, 2021.
Sattler, F., Müller, K.-R., and Samek, W. Clustered federated
learning: Model-agnostic distributed multitask optimization under privacy constraints. IEEE Transactions on
Neural Networks and Learning Systems, 2020.
Schwarz, J., Czarnecki, W., Luketina, J., GrabskaBarwinska, A., Teh, Y. W., Pascanu, R., and Hadsell,
R. Progress & compress: A scalable framework for continual learning. In International Conference on Machine
Learning, 2018.
Shafahi, A., Huang, W. R., Najibi, M., Suciu, O., Studer,
C., Dumitras, T., and Goldstein, T. Poison frogs! targeted clean-label poisoning attacks on neural networks.
In Advances in Neural Information Processing Systems,
2018.
Singhal, K., Sidahmed, H., Garrett, Z., Wu, S., Rush, K.,
and Prakash, S. Federated reconstruction: Partially local
federated learning. arXiv preprint arXiv:2102.03448,
2021.
Smith, V., Chiang, C.-K., Sanjabi, M., and Talwalkar, A. S.
Federated multi-task learning. In Advances in Neural
Information Processing Systems, 2017.
Sun, G., Cong, Y., Dong, J., Wang, Q., and Liu, J. Data
poisoning attacks on federated machine learning. arXiv
preprint arXiv:2004.10020, 2020.
Sun, Z., Kairouz, P., Suresh, A. T., and McMahan, H. Can
you really backdoor federated learning? arXiv preprint
arXiv:1911.07963, 2019.
Wang, H., Sreenivasan, K., Rajput, S., Vishwakarma, H.,
Agarwal, S., Sohn, J.-y., Lee, K., and Papailiopoulos, D.
Attack of the tails: Yes, you really can backdoor federated
learning. In Advances in Neural Information Processing
Systems, 2020.
Wang, K., Mathews, R., Kiddon, C., Eichner, H., Beaufays,
F., and Ramage, D. Federated evaluation of on-device
personalization. arXiv preprint arXiv:1910.10252, 2019.
Xiao, H., Rasul, K., and Vollgraf, R. Fashion-mnist: a
novel image dataset for benchmarking machine learning
algorithms. arXiv preprint arXiv:1708.07747, 2017.
Xie, C., Huang, K., Chen, P.-Y., and Li, B. DBA: Distributed backdoor attacks against federated learning. In
International Conference on Learning Representations,
2020.

Xu, X. and Lyu, L. Towards building a robust and fair federated learning system. arXiv preprint arXiv:2011.10464,
2020.
Yin, D., Chen, Y., Kannan, R., and Bartlett, P. Byzantinerobust distributed learning: Towards optimal statistical
rates. In International Conference on Machine Learning,
2018.
Yu, T., Bagdasaryan, E., and Shmatikov, V. Salvaging
federated learning by local adaptation. arXiv preprint
arXiv:2002.04758, 2020.
Zhang, M., Sapra, K., Fidler, S., Yeung, S., and Alvarez,
J. M. Personalized federated learning with first order
model optimization. In International Conference on
Learning Representations, 2021.
Zhao, Y., Li, M., Lai, L., Suda, N., Civin, D., and Chandra,
V. Federated learning with non-iid data. arXiv preprint
arXiv:1806.00582, 2018.

Efficient deep learning in
resource-constrained environments
PhD Proposal

Edgar Liberis

St Catharine’s College

First year report submitted in partial fulfilment of the requirements for the degree of
Doctor of Philosophy

Contents

1

PhD Proposal

5

1.1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5

1.2

Tackling resource usage of neural networks . . . . . . . . . . . . . . . . .

6

1.3

Resource-efficient deep learning . . . . . . . . . . . . . . . . . . . . . . .

7

1.3.1

Model compression: making large networks compact . . . . . . .

7

1.3.2

Neural architecture search: compact models from scratch . . . . .

8

1.3.3

Optimising neural network inference software and hardware . .

9

1.3.4

Holistic optimisation opportunities . . . . . . . . . . . . . . . . .

9

Projects carried out so far . . . . . . . . . . . . . . . . . . . . . . . . . . .

10

1.4.1

Exploring network pruning . . . . . . . . . . . . . . . . . . . . . .

10

1.4.2

Inference software and custom neural networks on MCUs . . . .

10

1.4.3

Achieving low memory usage through operator reordering . . .

11

1.4.4

Machine learning in space (application investigation) . . . . . . .

12

1.4.5

Neural architecture search with MCU resource constraints . . . .

12

Research directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

13

1.5.1

Neural architecture search with compiler-like optimisations . . .

13

1.5.2

Tackle challenges in a particular end-to-end application . . . . . .

14

1.5.3

Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

15

Timeline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

15

1.4

1.5

1.6

2

Literature survey

17

2.1

What are neural networks?

. . . . . . . . . . . . . . . . . . . . . . . . . .

17

2.2

Convolutional neural networks . . . . . . . . . . . . . . . . . . . . . . . .

18

2.3

Computation of neural networks . . . . . . . . . . . . . . . . . . . . . . .

18

2.4

Compact models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

20

2.4.1

Quantisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

20

2.4.2

Pruning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

22

2.4.3

Cheaper building blocks . . . . . . . . . . . . . . . . . . . . . . . .

23

2.4.4

Distillation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

24

Neural architecture search . . . . . . . . . . . . . . . . . . . . . . . . . . .

24

2.5.1

Search space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

25

2.5.2

Evaluating candidate models . . . . . . . . . . . . . . . . . . . . .

26

2.5.3

Search algorithms and action space . . . . . . . . . . . . . . . . .

26

2.5.4

NAS for compact models . . . . . . . . . . . . . . . . . . . . . . .

27

Deep learning inference software . . . . . . . . . . . . . . . . . . . . . . .

28

2.5

2.6

Bibliography

31

A Attached papers

41

Chapter 1
PhD Proposal
1.1

Introduction

Neural networks are a class of machine learning models that have emerged as versatile
competitors to complex hand-crafted systems for tasks with an abundance of labelled
data. In particular, convolutional and recurrent neural networks (CNNs and RNNs,
respectively) have been able to make great strides in computer vision, audio and natural
language processing, powering surveillance, translation, knowledge database and
medical diagnosis systems, among many others.
The most recent rise in popularity of neural networks was facilitated by the emergence of
more powerful computer hardware, namely programmable (general-purpose) graphics
processing units (GPUs). The highly parallel design of GPUs makes them a good fit
for linear algebra operations, which are at the heart of neural network computation. In
2012, this allowed the breakthrough CNN AlexNet [51] to drastically improve on image
classification error rate in the ImageNet competition. The network was powered by two
nVidia GTX 580 GPUs and the CUDA programming platform.
Since then, improving prediction accuracy has been the primary objective of neural
network development, while continuing to rely on modern graphics cards or newlydeveloped high-performance accelerators, such as TPUs, for training (creation of the
model) and inference (prediction using the model). The dependency on powerful hardware makes it challenging to use neural networks when such computational power is
not available or would be impractical, such as on mobile phones, space satellites or
everyday devices powered by microcontroller units (MCUs).

5

1.2

Tackling resource usage of neural networks

In a real-world deployment, in addition to having an acceptable prediction accuracy,
neural networks have to fit within a certain inference latency, power consumption and
memory usage (both storage and runtime) constraints. For example, a facial recognition
program running on an MCU (e.g. a doorbell camera), would be constrained by the
amount of on-chip memory and power supply; many event detection systems (e.g.
pedestrian recognition in self-driving vehicles) would not be constrained by memory or
power as much, but would have to respond as quickly as possible.
In neural network research, making large models fit within tight computational resource
constraints is achieved by applying model compression techniques [17]. They usually
create a smaller model from the larger model by, for example, reducing the number of
parameters in the network via pruning. While compression has beneficial effects on the
model’s storage requirements, memory use and inference speed, it often comes at the
cost of reduced accuracy. Hence, model compression methods can be seen as exploring
the trade-off between accuracy and runtime properties of a neural network.
In my thesis, I am to investigate ways to reduce resource consumption of neural networks during inference. Specifically, I restrict the focus of the work to two relatively
underexplored constraints: inference latency and runtime memory usage. Resource constraints are interlinked, so, for example, gains in memory usage or latency are likely to
also improve storage requirement and power use.
• Runtime memory usage. This has received relatively little attention due to most
target platforms having a sufficient supply of RAM. However, optimising for
(peak) memory usage, can make previously-undeployable models run on hardware with a limited amount of memory, such as microcontrollers. Even on platforms that have abundant RAM, this would allow the model to fit within faster
on-chip memories or custom accelerator chips/co-processors, producing further
gains in latency and power usage.
• Latency. Enabling deep learning models to run faster would create more intelligent rapid-response systems (e.g. safety or trading systems). Additionally, finishing execution sooner would allow hardware to go to low power states quicker,
thus also conserving energy.
I intend to push the accuracy vs resources trade-off boundary (Pareto front) in model
compression by employing a more holistic approach that optimises neural network

6

architecture and its execution (in software) together, jointly, to make the best use of underlying hardware. At the cost of being less hardware-agnostic, this vertical integration
approach would allow optimising with respect to particular execution properties, memory layout and other hardware capabilities of the target platform, producing a tightly
coupled system that retains good prediction accuracy while fitting within runtime
constraints.
I propose to achieve this by designing automated model design and/or compression
methodology, together with a tailored neural network execution runtime (when required), that is capable of producing fast and memory-efficient models which leverage
the strengths of the underlying hardware. Using automated algorithms would allow
recreating these holistically-optimised systems for many devices (within a particular
class of devices that share similar properties), keeping the methodology relevant as
hardware continues to develop.
To further explain and justify this holistic optimisation direction, Section 1.3 briefly
reviews and identifies opportunities current model compression and efficient inference
methodology (full detailed literature survey is available in Chapter 2). Section 1.4
enumerates projects carried out thus far; Section 1.5 proposes concrete future research
directions; Section 1.6 proposes a research timeline.

1.3

Resource-efficient deep learning

1.3.1

Model compression: making large networks compact

There are several mostly-independent and orthogonal research directions within model
compression that can help to produce compact models.
• Pruning. Pruning discards individual parameters or groups of them (fine-grained
and structured pruning, respectively) from a neural network. Fine-grained pruning produces sparse parameter matrices, which require costly sparse computation
primitives at runtime. Thus many works opt for structured pruning, which drops
individual channels or units in convolutional and fully-connected layers. In effect,
structured pruning adjusts hyperparameters of an architecture in a more informed
way after or during model training. Pruning improves runtime memory usage
by shrinking intermediate tensors (activation maps) and latency by reducing the
amount of computation required.
• Weight decomposition. Weight decomposition approaches break up large param7

eter (weight) matrices into a product of 2 or more smaller matrices. In addition
to reducing the size of a model’s parameter matrices, computation on smaller
matrices uses less memory at runtime.
• Distillation. Distillation approaches train a smaller (student) model by requiring
it to emulate a larger (teacher) model.
• Dynamic routing. A neural network does not have to perform the same computation for all inputs—instead it may choose to route to or skip certain layers based
on the perceived difficulty of the input. Early-exit networks [87], in particular,
allow reducing inference latency on simpler inputs.
• Quantisation and binarisation. Neural networks were shown to perform well
when the precision of parameters and activation maps is reduced to 8 or fewer
bits per element. In addition to drastically reducing per-parameter storage requirements, certain bit-widths allows using SIMD to speed up the computation
on supported hardware. Quantisation can be pushed to the extreme by considering binary weights and/or activations (binarisation), which would allow using
efficient bit-wise arithmetic [30].
The aforementioned approaches produce a compact model which is also already trained
for the task at hand. However, they do not usually allow precisely targeting a particular
runtime constraint, such as imposing an upper bound on running time in seconds or the
number of bytes of memory used at inference. In fact, many works only quantify the
reduction in model size and the number of floating-point operations (FLOPs) needed
for inference, without assuming any properties of the underlying hardware.

1.3.2

Neural architecture search: compact models from scratch

Designing neural networks under hard constraints is an optimisation problem that is
well-suited for an automated search algorithm: this is widely explored in the Neural
Architecture Search (NAS) research direction. Traditionally, the search aims to produce
an architecture that achieves greater accuracy for the task at hand than human-made
designs. However, the search goal can be augmented with accurate runtime constraints
to automatically discover neural networks with low resource usage and high accuracy.
Common NAS methods create new neural network architectures by assembling them
from a vocabulary of primitives (a matrix multiplication, a convolution, a depthwise
convolution, etc.). Compared to model compression, constrained NAS provides more
flexibility during design time, as it creates candidate architectures from scratch rather
8

than by working from a single large existing architecture. In addition to classification
accuracy, constrained NAS systems typically target latency and power constraints
for ”mobile” hardware [86, 10], others (but very few) consider extremely constrained
microcontroller platforms with 0.5–256 KB storage and memory limits [15, 29, 61].

1.3.3

Optimising neural network inference software and hardware

In numerical computation and systems research, satisfying runtime constraints can be
approached by optimising inference software or hardware:
• Software optimisation. Latency and runtime memory usage can be improved by
using algorithmically and computationally efficient implementations of primitive
operations, such as fast matrix multiplication and convolution; optimally laying
out data in memory and leveraging caching; fusing adjacent operators, changing
their order or executing them partially.
• Hardware optimisation. A popular way to accelerate a neural network workload
is to design custom circuitry, usually based on systolic array architecture. This can
be a custom chip/ASIC, an accelerator core in a multicore system or a design for
an FPGA board. The designs tend to optimise both execution speed/throughput
and power usage.
Works above typically excel at optimising linear algebra workloads for the target software and/or hardware platform but tend to assume very little about the overall neural
network architecture that is being executed. They also try to preserve the correctness
and precision of the computation, regardless of whether the network could be made to
recover from this.

1.3.4

Holistic optimisation opportunities

Previously discussed model compression and NAS methods often assume very little
about the underlying inference software and hardware. Similarly, inference software
and hardware are often designed to be agnostic about the models they are meant to be
executing. While this allows compression methods and hardware/software designs to
stay general and applicable in more cases, it also misses out on performance gains that
can be achieved if both are optimised jointly.
Of course, one has to be cautious of not over-optimising for a particular platform or
chip, resulting in a vertical integration that cannot be generalised to other environments.
9

However, I believe there’s a balance to be struck by developing methodology that can
automatically produce specialised solutions for devices within a particular class of
hardware platforms, such as microcontrollers or small linear algebra accelerators.
There have been some works that attempt to bridge the gap between neural network
architecture and the way it is executed to achieve better efficiency, suggesting it is a
developing research direction. For example, neural architecture search for microcontroller platforms [29, 61] or mobile devices [85, 94]; partial evaluation of a residual
connection branch in MobileNets [80], or inducing sparsity at training time to leverage
an accelerator for sparse linear algebra [14]. However, due to residing between the
domains of deep learning and systems, this area has been relatively underexplored.

1.4

Projects carried out so far

So far, I have carried out several projects relating to model compression, neural architecture search and runtime properties of neural network inference.

1.4.1

Exploring network pruning

I have familiarised myself with and implemented pruning of weights in a neural
network, i.e. sparsifying weight matrices (fine-grained pruning) or removing individual
weight groups (structured pruning). This has led me to explore many different ways of
applying pruning—how much to prune at a time, whether sparsity should be included
as a regularisation term, whether it is possible to apply pruning before training or
whether fine-tuning after pruning is necessary, and so on—which showed that applying
a model compression method can be non-trivial. The experiments verified that over
95% of parameters could be removed without significantly affecting the classification
accuracy, as was reported previously [70], which confirms that neural networks are
compressible and adaptable.

1.4.2

Inference software and custom neural networks on MCUs

Microcontroller platforms have a peculiar memory hierarchy: there is typically a limited
amount of on-chip memory available (<1 MB of read-only flash and read-write SRAM)
and larger but slower memories, such as RAM, are not present (unless external storage
is available). I have explored data movement costs of neural network execution, im-

10

plemented a low-overhead inference engine (a runtime), as well as model training and
quantisation pipeline. Using external storage was found to be prohibitively slow, which
forces neural network inference to fit within on-chip memory if latency is a concern.
This has taught me the specifics of microcontroller programming and different approaches one could take for network quantisation. Additionally, it has identified the
peak memory usage as a big obstacle to deploying models to hardware with limited
memory (model size, also an obstacle, has already been more extensively explored
in compression research). I co-designed a model with a small memory footprint and
leveraged previously-built quantisation pipeline to train it for the Visual Wake Words
competition [20] (person detection under 256 KB of RAM and storage usage).
I have also created an interactive practical for deploying keyword recognition models
onto an MCU1 , used in the “Principles of Machine Learning Systems (L46)“ Part III /
MPhil module.

1.4.3

Achieving low memory usage through operator reordering

To execute a neural network on a microcontroller, one may use some of the recent
popular runtimes, such as TensorFlow Lite Micro and CMSIS-NN libraries, which
implement quantised computation of many network layer types. There, networks are
executed in a simple read-execute-write fashion: each operator (layer) is fully executed
one at a time in a particular order; no partial evaluation or parallelism is supported.
Measuring peak memory usage algorithmically is not straightforward if the network
architecture contains branches (diverging execution paths). Here’s why: upon reaching
a branching point, the runtime has a choice which operator to execute next. Different
execution orders change which tensors will be held in memory at each step, which in
turn affects the peak memory usage. To solve this problem, I devised a graph algorithm
to find the lowest achievable peak memory usage for any architecture and the order of
operator execution that achieves it [59]. By changing the execution order, the memory
usage of our chosen model was reduced sufficiently to make it run on our target MCU
(see an attached paper in Appendix A for a full description of the methodology).
Later on, I found that integrating this precise peak memory usage computation with
NAS was instrumental in discovering models that use almost all available RAM. This
algorithmic estimation has eliminated the need to benchmark candidate models on
the device during search (device-in-the-loop NAS can be slow) or relying on underapproximations, as it was done in prior works [29].
1 https://colab.research.google.com/drive/17I7GL8WTieGzXYKRtQM2FrFi3eLQIrOM

11

1.4.4

Machine learning in space (application investigation)

I have explored machine learning in a concrete constrained environment—on-device
deep learning for space devices. Space hardware is typically quite underpowered due to
it also having to be radiation-hardened and has strict power requirements, to make sure
the device can complete its mission. This makes it akin to microcontroller hardware
used on Earth and face similar problems with model deployment [8].

1.4.5

Neural architecture search with MCU resource constraints

The usual target for resource-efficient on-device AI is mobile devices; however, in
comparison, MCUs have even less computational power. Therefore it is challenging to
apply existing NAS methods to find microcontroller-friendly models: they were never
designed to handle such extreme resource scarcity. I will briefly touch upon essential
components of a constrained NAS system and modifications needed for finding MCUsized models.
Search space. The search space is a set of all possible candidate architectures, together
with a vocabulary of building blocks and a set of allowed changes NAS can make to
the architectures during the search. In contrast to mobile or GPU platforms, MCUs
are more sensitive to network hyperparameters: for example, choosing between a
conv. layer with 172 and 192 channels is unlikely to make a meaningful difference for
a GPU-sized model (though the former may have lower accuracy), but on an MCU
choosing the larger layer may tip the model over the strict memory budget. This level
of hyperparameter granularity (and, by a similar argument, finely-controlled layer
connectivity) is not typically required for GPU- or mobile-level NAS due to the relative
abundance of RAM.
Constraints. Intuitively, because performant neural networks are large, we would
expect the best architectures to make use of all available resources and thus be located at
a boundary between models that fit within the resource constraints and ones that do not.
This requires NAS to be able to quickly and precisely compute resource requirements to
know which networks lie just below the resource constraints.
Search algorithm. Using a highly granular search space and precise resource constraints
increase the complexity of the search problem requires a suitable search algorithm. For
example, I found that Bayesian optimisation using Gaussian Processes, while known to
work in NAS [49, 47], performed worse than evolutionary algorithms, due to a smooth
approximation to a network’s accuracy (provided by GPs) being inadequate to capture

12

the subtle differences between networks in the search space.
Model compression. Model compression methodology, such as pruning, can be used
in NAS to further shrink the memory footprint of models found during the search.
This makes the search and the pruning share the task of determining the model’s
hyperparameters: the search produces a base network, which is then adjusted by
pruning in a more informed way by discarding channels/units that were deemed
unimportant during training.
I have incorporated the insights described above in my largest project to date. I built
a neural architecture search (NAS) system, called µNAS, to automate the design of
resource-efficient and highly-accurate MCU-sized networks. µNAS explicitly targets
the three primary aspects of resource scarcity of MCUs: the size of RAM, persistent
storage and processor speed, and represents an advance in resource-efficient models,
especially for “mid-tier” MCUs with memory requirements ranging from 0.5 KB to
64 KB. On a variety of image classification datasets µNAS is able to (a) improve top-1
classification accuracy by up to 4.8%, or (b) reduce memory footprint by 4–13×, or
(c) reduce the number of multiply-accumulate operations by ≈1700×, compared to
existing MCU specialist literature and resource-efficient models. The paper is available
in Appendix A.

1.5

Research directions

Informed by my current experience, I see the following promising approaches to reduce
memory usage and latency at inference by employing holistic hardware-aware model
design. The list is tentative, the exact scope and ambition of each project will be refined.

1.5.1

Neural architecture search with compiler-like optimisations

In a system where network architecture and execution software are tightly coupled
with the hardware, evaluating the network one operator at a time may not be the most
efficient approach. Depending on computation capabilities of the hardware, degree
of parallelism, data throughput, amount of on-chip cache memory and which memory access patterns are favourable, execution engine can choose to evaluate multiple
operators together, evaluate them partially, change data layout as necessary, etc.
To discover which architectures would benefit from optimisation by the execution
engine the most, NAS has to be aware of hardware properties at search time, much like

13

a compiler. Doing so would eliminate the need for hand-crafted evaluation tricks, as
those would be discovered automatically.
Searching for an optimal way to execute a sequence of linear algebra operations is an
active research direction: Jia et al. [46] develop computation graph transformations
that improve efficiency and works such as TVM [13] and Tensor Comprehensions [91]
offer automated loop tiling and memory management, in particular for novel operators.
However, these “model compiler” approaches aim to exactly preserve the computation,
which prevents from discovering big optimisations that could have been achieved by a
change in network architecture.
Incorporating compiler-like knowledge into NAS would require:
1. including a detailed model of the hardware and its capabilities, like those found
in compilers;
2. incorporating knowledge about graph transformations that simplify the architecture without changing the result (akin to an optimisation pass in a compiler);
3. restricting the search space to cope with the combinatorial explosion.
As it is a large project, I intend to split it into two works that gradually build towards
the goal:
1. Building upon µNAS, which incorporated model resource usage constraints (incl.
simple scheduling to determine peak memory usage), I intend to incorporate
other operator runtime properties (based on their implementation) and more
sophisticated scheduling during search to compute more sophisticated latency
constraints.
2. NAS may not be the only driver that suggests architecture changes: computation
graph transformations coming from a “model compiler” or model compression
(e.g. pruning) need to be incorporated in a way that provides feedback for the
search and guides it towards more resource-efficient models.

1.5.2

Tackle challenges in a particular end-to-end application

It would be beneficial to apply insights from my prior work and the above research
directions to a concrete application. This would introduce more problem-specific
challenges and may yield more insights on the construction of resource-efficient models

14

and inference software. For example, consider automatic speech recognition (ASR) on
microcontrollers. While a lot of developed microcontroller-specific methodology is
applicable, adjustments may have to be made for:
• Different kinds of models. 2D-convolutional networks are typically used for images,
but recurrent, transformer and 1D-convolutional networks are more common in
audio and natural language processing.
• Memory-efficient vocabulary representation. In contrast to keyword recognition,
which targets a limited vocabulary, ASR (in theory) targets the entire English
language. This requires a (likely implicit) memory-efficient process of decoding
detected utterances into words.
• Near real-time inference speed. If no audio caching is allowed, resulting models and
software have to transcribe speech in near real-time (a tighter latency constraint).

1.5.3

Evaluation

Research outcomes can be evaluated by applying the methodology to real-world deployments of neural networks and quantifying the reduction in resource usage, and
whether that resulted in additional gains, such as allowing the use of cheaper hardware.

1.6

Timeline

I believe the projects proposed above, in addition to work already carried out, come
together to form a PhD thesis that tells a story of achieving hardware-aware neural
network optimisation through model compression, tailored runtime design and neural
architecture search, and doing so in an automated fashion to allow the methodology to
be applied to a variety of tasks and target hardware.
Term

Work planned

MT 2020, LT 2021 Explore architectural and runtime changes that yield improvement in inference latency and memory use of neural networks.
This will be done for a chosen problem set-up and target platform
(e.g. audio processing on an MCU).
In addition to work carried out by me previously, this will showcase the practical difficulties of building resource-efficient neural
network-based applications and may yield further insights.
15

ET 2022

Take steps towards hardware-aware NAS, first by incorporating
runtime properties of each operator and creating constraints based
on those properties. This fulfils the first part of the proposed
compiler-like NAS project. Submit the second year report.

Long vacation
Break for an internship.
2021
MT 2021, LT 2022 Continue work on NAS, incorporate computation graph transformations, scheduling information and model pruning. This fulfils
the second part of the proposed compiler-like NAS project.
ET 2022
Thesis write-up, finish up outstanding experiments.
LV 2022
Finish write-up, thesis submission, viva, corrections.

16

Chapter 2
Literature survey
2.1

What are neural networks?

(Artificial) neural networks are machine learning models, given by collections of interconnected artificial neurons, designed to perform a specific computation. The first
model of an artificial neuron was introduced by McCulloch and Pitts [68] in 1943,
loosely inspired by the neurons in mammalian brains, which fire once they have been
stimulated by sufficient input signal. Mathematically, an output neuron of a neuron is a
weighted sum of its inputs, gated by an activation function. Rosenblatt [78] in 1958 has
successfully applied this idea to develop a linear binary classifier, called the perceptron,
whose linear sum coefficients (aka parameters or weights) were learned from a set of
training data using an iterative algorithm.
While the potential applications of the perceptron seemed promising at the time [72], it
was soon realised that it doesn’t have sufficient representation power to learn complex
functions. To address this, networks of perceptrons (where neurons are inputs to other
neurons) arranged in layers—multilayer perceptrons (MLPs)—have been developed
and the backpropagation algorithm [79] was devised to allow gradient-based function
optimisation algorithms (i.e. gradient descent) to be used for training. Cybenko [24]
showed that 2-layer MLPs can represent a wide variety of functions (universal approximation theorem), given a sufficient (finite) number of neurons.
Unfortunately, for large inputs, MLPs can get prohibitively big and difficult to train
until convergence. To cope with this, neural networks are designed to better match the
structure or properties of the data they’re processing by imposing weight sharing (some
neurons share parameters) and limited connectivity (some neurons only receive a part
of the input).

17

2.2

Convolutional neural networks

While many compression methods can be applied to most neural networks, here I
will mostly focus on convolutional neural networks (CNNs). CNNs [31] are the most
popular research direction in deep learning; they have practically overtaken the field of
computer vision and achieved state-of-the-art results in object detection, recognition,
tracking, recommender systems, information extraction from images and others.
Much like MLPs, CNNs have a layered structure, consisting of convolutional layers. At
the heart of a convolutional layer is a mathematical convolution operation of the input
with a learned kernel. Tunable parameters of a convolution (hyperparameters) are the
kernel size, stride, dilation factor, and the number of output channels.
The availability of high quality labelled image datasets has greatly contributed to the
rapid development of new CNN architectures. The commonly used datasets are:
• MNIST [56]. The MNIST database consists of preprocessed handwritten digits
from 0 to 9, of size 28x28 pixels, with 60000 images for training and 10000 images
for testing.
• CIFAR-10 and CIFAR-100 [50]. The CIFAR-10 and CIFAR-100 datasets contain
images from 10 and 100 categories, respectively, such as ”bird”, ”dog”, and ”aeroplane”. Both datasets have 60000 32x32 colour images with 6000 images and 600
images per category, respectively.
• ImageNet [25]. The ImageNet dataset consists of 1.28 M and 50000 256x256 (after
standard preprocessing) colour images for training and test sets, respectively. The
images are labelled into 1000 categories, such as ”panda”, ”cat” and ”platypus”.
In what follows, I describe neural networks from a computational point of view and
expose the high resource usage problem. Then I will discuss network compression
methodology and neural architecture search in greater detail, that can be used to create
more resource-efficient neural networks. Finally, we will touch upon what optimisations
can be made in software to make models more resource-efficient.

2.3

Computation of neural networks

Neural network computations directly translate to linear algebra operations: computing
the output of a set of independent neurons (a fully-connected layer) can be implemented

18

with a single matrix multiplication operation, followed by an element-wise application
of the activation function; similarly, a convolutional layer can be computed using the
mathematical convolution primitive, or matrix multiplication, if the input is laid out in
memory in a special way (im2col algorithm [11]).
The kinds of computations required, incl. types of operations or the numbers of neurons
of each layer, are defined by the architecture of the neural network. Traditionally, neural
networks have followed a straightforward iterative (linear) computation path: outputs
of one layer are used as inputs only to the succeeding layer to produce a new output.
However, modern architectures contain skip-connections [38] and branches [84]. Thus,
in software, the neural network can be represented as a computation graph: a directed
acyclic graph (DAG), whose nodes correspond to a primitive linear algebra operation
(e.g. a matrix multiply or an element-wise operation) and edges representing a data
dependency between them.
Many software packages have been developed to facilitate the development and training
of neural networks (and save practitioners from having to write GPU code!), such as
Caffe [45], TensorFlow [1], Keras [18], Chainer [89] and PyTorch [73]. Frameworks offer
the following set of features:
• Static or dynamic computations graphs. Dynamic computation graphs allow
choosing which operations to run based on input data [89, 73], whereas static
computation graphs are fixed at compile time [45, 1]. The former allows more
flexibility, while the latter gives more scope for ahead-of-time optimisation.
• Automatic differentiation. Users don’t have to implement backpropagation manually; the computation will be automatically augmented with nodes for computing
gradients and parameter updates.
The current renaissance of neural networks is facilitated by the increased computational
capabilities of the present hardware. During training, millions of parameters need to be
updated [51] based on gradients computed on millions of data points, with the process
repeated over multiple training epochs (dataset iterations), which requires speciallydesigned hardware to do reasonably quickly. The AlexNet [51] network popularised
the use of graphics processing units (GPUs) and CUDA programming platform, which
are designed to support simple parallel computations, making them a natural fit for
this task. Original AlexNet implementation took 6 days to train the network until
convergence on two nVidia GTX 580 GPUs. Nowadays, more custom hardware is
available to accelerate training, such as tensor processing units (TPUs) from Google [48]
and Graphcore Intelligence Processing Units (IPUs) [32].

19

No. of param-s

Size

FLOPs

Accuracy on
ImageNet [25]

60 M
144 M
57 M
3.4 M
2.4 M

240 MB
576 MB
228 MB
13.6 MB
9.4 MB

1.4 G
39 G
22.6 G
0.3 G
0.3 G

61.0%
74.5%
79.3%
72.0%
67.6%

AlexNet [51]
VGG-19 [82]
ResNet-152 [38]
MobileNetV2 [80]
ShuffleNet [94]

Table 2.1: Various CNNs and their resource usage.
Table 2.1 summarises the computational properties of popular convolutional neural
networks to show the cost of inference (evaluating the network once to obtain predictions for a particular input). Due to having to fetch a large number of parameters and
perform many floating-point operations, running such networks on consumer hardware, especially on mobile devices and microcontroller platforms, can be prohibitively
expensive. Addressing resource consumption of neural networks is addressed by model
compression.

2.4

Compact models

The following approaches have been explored in model compression literature to create
compact models, suitable for inference in resource-constrained environments. Most
approaches typically result in some amount of accuracy loss, exhibiting a trade-off
between model’s accuracy and its resource usage.

2.4.1

Quantisation

Weights of a neural network, as well as any intermediate tensors (activation maps), are
typically represented by matrices of 32-bit floating-point numbers, occupying 4 bytes
per element. However, it’s possible to carry out computations at lower precision, saving
the amount of storage and computation required by the model.
In practice, a quantisation implementation has 3 tunable properties:
• Bit-width of parameters. Courbariaux et al. [22] show that as little as 10 bits of
precision is enough to both train and run the network for inference. Since then,
the precision required at inference has been lowered to 8 [42], 4 [6] or 1 bit (binary
networks are discussed below). Choosing bit-widths that are divisors of a native

20

word size of the target platform (e.g. 4, 8 or 16 bits for 32-bit platforms) may allow
leveraging SIMD instructions to compute multiple outputs at the same time, as
done in the CMSIS-NN library [52], and eliminate any decoding overhead.
• Granularity. Quantisation granularity dictates how finely the model is quantized.
Options include selecting the bit-width per-parameter (fine-grained quantization), per-layer or for the entire model (coarse-grained quantization). Intuitively,
finer quantization is more flexible and should approximate the full-precision
model better. However, it also requires additional logic and bookkeeping due
to the (potential) mismatch of bit-width between layer’s operands, weights and
activations. As a result, a common compromise is to perform layer-wise quantization [42, 65, 96, 60].
• Representation formula. At runtime, quantised values are typically represented
by integers. This allows using more efficient integer arithmetic units, instead of
floating-point units, as long as the bit-width is carefully chosen to capture the
required range and computation is designed to perform saturating arithmetic. In
particular, the following ways of representing values have been developed:
Q-format (fixed-point) quantisation [60]. This a method splits an n bit number into
integral and fractional parts, allocating a and b bits to each, respectively. Such
number is denoted by Qa.b (with n = a + b). For example, for 8-bit numbers,
Q0.7 (1 bit left for sign) representable values lie in the range [−1, 1) with a
step of 2−7 . Using Q-format quantisation allows leveraging integer ALUs but
has the overhead of requiring to keep track of the decimal position for each
operand. The representable range of values is symmetric and centred around
0, which may be a problem for long-tailed or asymmetric value distributions.
Affine quantisation [42]. This implementation represents the (i, j)th element of a
weight matrix Wi,j ∈ R as the affine mapping of an (8-bit) integer Qi,j using
parameters S (floating-point scale) and Z (32-bit integral offset), defined as
Wi,j = S( Qi,j − Z ). This allows more precise control over the width and
centre of the represented range by controlling shared parameters S and Z.
Unless Z = 0, the offset term introduces extra terms that need to computed
during matrix multiplication.
Powers-of-two quantisation [33]. In a more extreme case, weights can be represented
by powers of two: Wi,j ∈ {0, ±2−n−1 , . . . , ±2n }. This allows replacing a
multiplication operation with a bit-wise shift, which is faster to compute.
Perhaps the most efficient implementation of neural network inference can be obtained
where weights and activations are binary [23, 74, 30]. In this case, on hardware with
21

native 32-bit word support, 32 multiply-accumulate operations can be performed at
once by using XNOR instruction for element-wise multiplication and POPCOUNT to
accumulate across the product.
The success of a network quantisation will largely depend on the quantisation approach
adopted during training. Methods for quantising the network can be largely grouped
into post-training quantisation [6], where all matrices are quantised after the network
has been trained and no access to training data is needed, and quantisation during
training. The latter in particular has received a lot of research attention: many methods
keep weights at full precision during training as proxies and rounding them during
forward (inference) pass to obtain a quantised version [42]. The rounding function (a
step) is not differentiable, so a straight-through estimator (STE) [7] is employed to let
gradients flow through [95]. Alternatively, quantisation can be approached by learning
a categorical distribution for the weights [66, 65] or more carefully designing gradient
calculation [44]. The interaction of quantisation with optimiser parameters and batch
normalisation layers is studied by Alizadeh et al. [2].

2.4.2

Pruning

Pruning weight matrices has been successfully used to both regularise and reduce the
size footprint of the neural network. In practice, pruning methods can be categorised
based on the following properties:
• Criteria/salience metric. Salience metric tells which weights are deemed unimportant and can be removed from the network. Some works use a weight’s magnitude [36]—arguing that, intuitively, a weight is unimportant if it’s small—and
some use a theoretically-justified Hessian-based measure [37], or a learned importance metric [70]. However, it should be noted that computing an inverse of a
Hessian matrix is prohibitively expensive for large networks and some simplifying
assumptions should be applied.
• Regularisation. Extra specially-designed regularisation terms can be added to the
optimisation objective to produce more prunable parameters under the salience
criteria. For example, some magnitude-based compression methods add an L1 or
an L2 loss [3].
• Granularity. Pruning can be applied to remove individual weights, resulting in
sparse weight matrices (fine-grained pruning) or to remove weights in groups, for
example removing channels (filters) in CNNs [88, 58].

22

• Mode. Pruning mode defines the process by which the network’s parameters
are pruned. If a practitioner is targeting a particular sparsity level, all of the
parameters that need to be discarded can be either pruned at once (one-shot
pruning) [57, 58] or in multiple instalments (iterative pruning) [36, 62]. The
network is usually retrained, or trained for longer, to regain as much lost prediction
accuracy as possible.

2.4.3

Cheaper building blocks

Replacing expensive operations, such as large convolutions and matrix multiplications
with cheaper alternatives is one of the most popular approaches to model compression.
Low-rank decomposition replaces a weight matrix with a product of two or more
lower rank matrices, which allows lowering both the required storage and the computational complexity of a layer. Weight matrices of fully-connected layers can be split
using SVD decomposition [9, 53], and convolutional layers have been accelerated by
decomposing convolutional kernels using rank-1 tensors [26], and depthwise-separable
convolutions [43, 19].
Kernels and weight matrices can also be decomposed as a linear combination of some
basis functions, i.e. a kernel is represented by a set of coefficients in the new basis. If
basis functions are extensively shared among many kernels, this allows compressing
the representation of a model. New basis can be either fixed [90] or learned at training
time [35, 21].
Finally, a structural constraint can be imposed on the weight matrix, which acts as a
form of weight sharing and allows a compressed version of a matrix to be stored in
memory. For example, Cheng et al. [16] use a circular projection, which allows the Fast
Fourier Transform (FFT) to be used for computation.
Typically, once a cheaper primitive has been built using one of the above methods, it
is applied throughout the network and an entire architecture is assembled. Popular
such architectures include MobileNet [80], assembled using ”inverted residual blocks”;
SqueezeNet [40], assembled using blocks that induce an information bottleneck; ShuffleNet [94], that primarily uses pointwise group convolutions and inter-group channel
shuffling and LeanResNet [27] impose extra structure on convolutional kernels. Efficient architectures can also be designed automatically [85, 86], which we discuss in
Section 2.5.

23

2.4.4

Distillation

Knowledge transfer, or distillation, compression methods involve teaching compact
student models by mimicking larger teacher models. Seminal work by Ba and Caruana
[4] discusses differences between shallow and deep networks. As shallow networks
are difficult to train from scratch, the authors introduce a stronger training signal by
making a shallow network match its logits (outputs of the final layer, softened label
probabilities) to those of a deeper network.
In general, student networks are kept deep to ease the training. Further works explore
other ways of incorporating hints and output match points from the teacher network:
• Luo et al. [67] attempt to preserve outputs of other hidden layers, which intuitively
correspond to high-level features, rather than final label probabilities.
• Chen et al. [12] use function-preserving transformations to quickly transfer knowledge between networks.
• Romero et al. [77] train thinner networks by synchronising more intermediate
representations between teacher and student, coping with different representation
widths by introducing a linear transformation.
• Zagoruyko and Komodakis [92] train students to mimic attention maps of the
teacher network, effectively allowing them to focus on the same areas in the
feature maps.

2.5

Neural architecture search

Until recently, advancing state-of-the-art using deep learning has required manually
designing and tweaking neural network architectures. Neural architecture search aims
to automate this task and has since achieved state-of-the-art in several computer vision
problems [76, 85].
NAS designs novel architectures by sampling the search space and evaluating the
picked candidate architecture based on a certain performance metric, usually accuracy
on the validation set. Different approaches to NAS typically differ in how they: (a)
design the search space (space of representable architectures); (b) evaluate candidate
models; (c) choose the action space and the search algorithm.

24

2.5.1

Search space

The search space defines which architectures can be represented (and thus discovered)
by NAS. The design of the search space also determines the difficulty of the search.
• Linear architectures. Much like early manually-designed neural network architectures, early work in NAS employs linear architectures, where the input is
transformed iteratively by each successive layer. Thus the degrees of freedom
permitted in the search space are the layer types (convolution, full-connected,
depthwise-separable convolution, etc.), their parameters (number of hidden units,
stride and kernel size of convolution, etc.) and the maximum number of layers.
• Branching architectures. Most current state-of-the-art architectures contain branches
[19, 38]. In NAS, if the restriction of linearity above is relaxed, architectures can
become arbitrary directed acyclic graphs (DAGs), with the search bounded by the
number of nodes in the DAG. In addition to having to choose layer type and their
parameters, the search will have to explore many inter-layer connectivity options,
which may result in a combinatorial explosion, making the search prohibitively
expensive.
• Block architectures. To restrict the search space, recent works adopt a combination of the above approaches by considering linear architectures consisting of
repeated motifs, called blocks or cells (which may contain branches). Many existing
hand-crafted architectures follow this design pattern [80, 40, 85], which splits the
problem into 2 parts: designing the architecture of a block and designing the
connectivity between the blocks (the macro-architecture). The former can be created
using NAS and the macro-architecture can either be chosen manually or borrowed
from known networks.
In CNNs, successive layers typically gradually reduce the spatial dimension of the
input, while increasing the feature (filter, channel) dimension. This requires cell
designs to be parametrised to accept inputs of several different sizes and reduce
their dimensionality for the following cell. Tan and Le [85] restrict the search space
by parametrising the output dimensionality of each successive cell, as well as the
depth and input resolution of the network via a single compound scale parameter,
which allows the authors to obtain models of different sizes by changing the scale.

25

2.5.2

Evaluating candidate models

During the search, the optimisation algorithm will have to evaluate many candidate
architectures. As the aim of the search is typically accuracy, evaluating an architecture
involves training it from scratch, which can take days on thousands of GPUs [97, 86].
This calls for ways to speed up the evaluation, typically achieved by taking shortcuts
during training or employing cheaper proxy metrics:
• Extrapolating performance. The training time of a model can be reduced by
simply terminating it earlier, training on a smaller subset of data, lower-resolution
images or using a smaller macro-architecture. This would underestimate the
performance of a network, but do so consistently for all candidate models.
Alternatively, learning curves (loss or accuracy plot) of a network can be extrapolated to see which candidate models can be terminated early, based on the initial
portion of the curves and architectural hyperparameters. Liu et al. [63] guide
the search by training a surrogate model to predict the accuracy of a candidate
network based on its architecture. However, using another machine learning
model to predict performance can cause the performance to suffer from the lack
of training data (we want to make as few ”full” evaluations as possible during
search) and poor performance on the out-of-distribution inputs (model won’t
perform well on the kinds of inputs it has not seen before).
• Transfer learning. Novel models can be built by gradually expanding candidates:
each candidate model’s weights can be initialised to those of a previous candidate.
This, followed by a few epochs of training to make use of the increased capacity,
allows to drastically cut the computation required for evaluation, at the cost of
restricting the search procedure.
Sharing weights between candidate models has been shown to work well where
candidate models are sub-graphs of a larger model [10]. Then, NAS can prune
certain operations, while the weights of the remaining layers are initialised to
those of the parent model. Similarly, while being fast, this restricts the search
space.

2.5.3

Search algorithms and action space

Search algorithms and action spaces define how the NAS explores the search space. The
following approaches have been explored in NAS literature:

26

• Genetic algorithms. Using genetic (evolutionary) algorithms to design neural
networks was pioneered by Miller et al. [69] in 1989. Genetic algorithms evolve
a population of architectures, by randomly choosing parent architectures that
generate a new architecture (with a small mutation probability) in a crossover step,
and retaining a certain number of the fittest (best-performing) architectures for
the next iteration.
Network architectures are complex objects, so meaningful and robust definitions
for the crossover and mutation steps, as well as the individual retention policy, are
required. Existing methods employ tournament selection for choosing parents and
discard either the oldest or the worst performing architecture at each step [75, 76].
• Distribution sampling and optimisation. In a tree-structured search space, Monte
Carlo Tree Search can be applied [71]. Alternatively, Bayesian optimisation is a
popular technique for hyperparameter search and has recently been applied to
jointly optimise for a network’s architecture and hyperparameters by efficiently
exploring high-dimension spaces [93]. The authors cast NAS an optimisation
problem in a categorical distribution and use the BOHB method [28] to explore
the distribution.
Categorical distributions can also be optimised by employing continuous relaxation (approximating a categorical distribution with a continuous one, that gets
closer and closer to the categorical distribution over time). This allows using
gradient-based methods to perform the optimisation itself and even combining it
with neural network training.
• Reinforcement learning. A reinforcement learning agent can be used to design
the networks. In a stateful setting, an agent modifies existing candidate architectures using a set of allowed actions. In a stateless setting, the agent’s action space
is the same as the search space, and the agent just performs a single choice. To
represent the agent’s policy, Q-learning [5] or an RNN controller trained using
REINFORCE or proximal policy optimisation [97, 98] were used.
• Random search. Random search is a simple, but a surprisingly effective way
to search high-dimensional search spaces. Some works found previously listed
techniques only marginally better than random search [76] or not at all better [81].

2.5.4

NAS for compact models

Neural architecture search can also be used to produce compact models, that is searching
for the best-performing architecture under certain resource constraints, such as model
27

size or memory usage. Constraint satisfaction is an NP-complete problem, but the
search can be turned into an unconstrained optimisation problem by, for example,
designing the search space to only include architectures that satisfy the constraints.
Among other works that search for efficient models [83, 64], we note the following ones:
• Fedorov et al. [29] obtain microcontroller-level CNNs (<2 KB) for visual recognition by using multi-objective Bayesian optimisation to jointly optimise for model
accuracy, working memory and model size, while also incorporating pruning techniques to more efficiently optimise the sizes of fully-connected and convolutional
layers.
• He et al. [39] use reinforcement learning to sample the hyperparameter search
space of known models layer by layer, where each layer also has an associated
sparsity ratio (obtained by pruning). The actor learns two policies: a resourceconstrained one that ensures that the agent is always above a certain sparsity ratio
and an accuracy-guaranteed one which optimises both accuracy and resource
usage.
• MNasNet [86] directly optimises for accuracy and latency on mobile devices by
evaluating models on a grid of Pixel 1 phones (expensive!) instead of opting for
proxy metrics, such as the number of FLOPs, and uses a factorised (block) search
space to improve search time.

2.6

Deep learning inference software

In software, neural network computation is represented as a computation graph, with
nodes corresponding to primitive linear algebra operations. We will discuss both intranode optimisations, i.e. improving memory usage or speed of particular operations, as
well as inter-node optimisations, i.e. optimising by changing the computation graph. In
addition to methods listed below, Lane et al. [53] show that some model compression
techniques can be applied at runtime. Intra-node optimisations include:
• Manually optimised implementations. Many software packages ship optimised
implementations of matrix multiplication and convolution operations. Due to
different hardware properties and programming paradigms, efficient implementations would be different for each target platform. For example, cuDNN, which
powers most deep learning frameworks on nVidia GPU platforms, contains

28

manually-tuned tiled matrix multiplication algorithms and several implementations of a convolution (e.g. via the im2col algorithm [11] or a Winograd transform [55]), which make best use of the parallel programming and limited amount
of shared memory on nVidia hardware. For CPU and mobile phone platforms,
Eigen [34] is commonly used, which makes use of caching and vectorisation. For
ARM MCU platforms, CMSIS-NN [52] offers quantised operator implementations
with SIMD support.
• Automatically discovered optimised implementations. Neural network researchers
may use an operation that doesn’t map to any existing linear algebra primitives,
and thus a highly-optimised optimisation would not be available. TVM [13] and
Tensor Comprehensions [91] address this gap by allowing to define new operators
in a custom DSL. An efficient implementation is then found using an ML-based
cost and evolutionary algorithms, respectively. MLIR [54] also introduces an
intermediate optimisation to enable the LLVM compiler to perform required optimisations. Optimising an implementation involves performing vectorisation, loop
tiling (e.g. using polyhedral compilation techniques) and data layout optimisation
to make the best use of caching and memory locality. TVM also performs latency
hiding and layer fusion optimisations, discussed below.
Inter-node optimisations include:
• Operator fusion using their mathematical properties. Properties of some deep
learning layers allow combining (fusing) them together to reduce the number
nodes in a computation graph. For example, batch normalisation [41] layers perform subtraction of a learned mean and division by standard deviation. Since both
are constant at inference, this linear operation can be ”folded” into a preceding
linear operation (a convolution or a matrix multiplication), by dividing its weights
by the standard deviation and appropriately changing the bias.
• Equivalent graph transformations. Each time a new node in the computation
graph is executed, the runtime faces certain context switch overheads. This can be
improved by making nodes do more work, if possible: for example, two matrix
multiply operators, that share the same weight matrix, can be combined into one
with its inputs appropriate concatenated before and split after the multiplication
(see Figure 2.1). Note that concatenation and split nodes don’t have to exist at
runtime—producer or consumer nodes can simply be instructed to write to or read
from certain memory addresses. Jia et al. [46] generalise this idea by discovering
equivalent graph transformations that preserve both the mathematical identities

29

A'

B'

Split
A'

B'

[A';B']

Optimise

MatMul
MatMul

MatMul

[A;B]
Concat

A

W

B
A

W

B

Figure 2.1: An example graph transformation to increase computational efficiency.
(encoded in first-order logic) and computation precision (verified using a set of
generated input matrices and outputs compared before and after transformation).
• Optimisation in generated code. Computation of a node is typically performed
by a tailored piece of code, called a kernel, launching which, as discussed previously, has a certain overhead. A deep learning compiler can discover subgraphs
that can be merged into a single custom ”super-node”, powered by a single kernel.
Generating code for multiple operators at once allows memory access optimisations: for example, combining element-wise non-linearities (e.g. ReLU) with a
previous layer, by computing a non-linearity as the last step before the value is
written to memory. TensorFlow’s [1] XLA compiler performs such optimisations
for GPU kernels.
• Evaluation strategies. In order to evaluate a node, its inputs and the output
buffer should be present in memory. This can become a memory bottleneck when
evaluating networks with large layers on platforms with a limited amount of
RAM, such as MCUs. This can be circumvented by evaluating a set of nodes
partially or as needed by the downstream consumer node. Sandler et al. [80]
describe such optimisation for the ”bottleneck residual block” in the MobileNetV2
network, which consists of a linear operation, followed by a channel-wise operation, followed by another linear operation. The authors note that the input to the
channel-wise operation doesn’t need to be materialised in full—only 1 channel
at a time is required—which allows them to reduce the memory usage bottleneck. Other approaches explore different ways of scheduling nodes (different
topological orderings of the graph) to improve on runtime memory usage [59].

30

Bibliography
[1] Martı́n Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey
Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al.
Tensorflow: A system for large-scale machine learning. In 12th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 16), pages 265–283,
2016.
[2] Milad Alizadeh, Javier Fernández-Marqués, Nicholas D Lane, and Yarin Gal. An
empirical study of binary neural networks’ optimisation. 2018.
[3] Jose M Alvarez and Mathieu Salzmann. Learning the number of neurons in deep
networks. In Advances in Neural Information Processing Systems, pages 2270–2278,
2016.
[4] Jimmy Ba and Rich Caruana. Do deep nets really need to be deep? In Advances in
neural information processing systems, pages 2654–2662, 2014.
[5] Bowen Baker, Otkrist Gupta, Nikhil Naik, and Ramesh Raskar. Designing neural
network architectures using reinforcement learning. arXiv preprint arXiv:1611.02167,
2016.
[6] Ron Banner, Yury Nahshan, and Daniel Soudry. Post training 4-bit quantization of
convolutional networks for rapid-deployment. In Advances in Neural Information
Processing Systems, pages 7948–7956, 2019.
[7] Yoshua Bengio, Nicholas Léonard, and Aaron Courville. Estimating or propagating
gradients through stochastic neurons for conditional computation. arXiv preprint
arXiv:1308.3432, 2013.
[8] P Blacker, CP Bridges, and S Hadfield. Rapid prototyping of deep learning models
on radiation hardened cpus. In 2019 NASA/ESA Conference on Adaptive Hardware
and Systems (AHS), pages 25–32. IEEE, 2019.

31

[9] Chenghao Cai, Dengfeng Ke, Yanyan Xu, and Kaile Su. Fast learning of deep
neural networks via singular value decomposition. In Pacific Rim International
Conference on Artificial Intelligence, pages 820–826. Springer, 2014.
[10] Han Cai, Ligeng Zhu, and Song Han. ProxylessNAS: Direct neural architecture
search on target task and hardware. arXiv preprint arXiv:1812.00332, 2018.
[11] Kumar Chellapilla, Sidd Puri, and Patrice Simard. High performance convolutional
neural networks for document processing. 2006.
[12] Tianqi Chen, Ian Goodfellow, and Jonathon Shlens. Net2net: Accelerating learning
via knowledge transfer. arXiv preprint arXiv:1511.05641, 2015.
[13] Tianqi Chen, Thierry Moreau, Ziheng Jiang, Haichen Shen, Eddie Yan, Leyuan
Wang, Yuwei Hu, Luis Ceze, Carlos Guestrin, and Arvind Krishnamurthy. Tvm:
end-to-end optimization stack for deep learning. arXiv preprint arXiv:1802.04799,
2018.
[14] Yu-Hsin Chen, Tien-Ju Yang, Joel Emer, and Vivienne Sze. Eyeriss v2: A flexible
accelerator for emerging deep neural networks on mobile devices. arXiv preprint
arXiv:1807.07928, 2018.
[15] Hsin-Pai Cheng, Jinwon Lee, Parham Noorzad, and Jamie Lin. QTravelers
Visual Wake Words contest submission. https://github.com/newwhitecheng/
vwwc19-submission (Accessed Sep 2019), 2019.
[16] Yu Cheng, Felix X Yu, Rogerio S Feris, Sanjiv Kumar, Alok Choudhary, and Shi-Fu
Chang. An exploration of parameter redundancy in deep networks with circulant
projections. In Proceedings of the IEEE International Conference on Computer Vision,
pages 2857–2865, 2015.
[17] Yu Cheng, Duo Wang, Pan Zhou, and Tao Zhang. A survey of model compression
and acceleration for deep neural networks. arXiv preprint arXiv:1710.09282, 2017.
[18] François Chollet et al. Keras. https://keras.io, 2015.
[19] François Chollet. Xception: Deep learning with depthwise separable convolutions.
In Proceedings of the IEEE conference on computer vision and pattern recognition, pages
1251–1258, 2017.
[20] Aakanksha Chowdhery, Pete Warden, Jonathon Shlens, Andrew Howard, and
Rocky Rhodes. Visual wake words dataset. arXiv preprint arXiv:1906.05721, 2019.

32

[21] Taco Cohen and Max Welling. Group equivariant convolutional networks. In
International conference on machine learning, pages 2990–2999, 2016.
[22] Matthieu Courbariaux, Yoshua Bengio, and Jean-Pierre David. Training deep
neural networks with low precision multiplications. arXiv preprint arXiv:1412.7024,
2014.
[23] Matthieu Courbariaux, Itay Hubara, Daniel Soudry, Ran El-Yaniv, and Yoshua
Bengio. Binarized neural networks: Training deep neural networks with weights
and activations constrained to+ 1 or-1. arXiv preprint arXiv:1602.02830, 2016.
[24] George Cybenko. Approximations by superpositions of a sigmoidal function.
Mathematics of Control, Signals and Systems, 2:183–192, 1989.
[25] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A
large-scale hierarchical image database. In 2009 IEEE conference on computer vision
and pattern recognition, pages 248–255. Ieee, 2009.
[26] Emily L Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, and Rob Fergus.
Exploiting linear structure within convolutional networks for efficient evaluation.
In Advances in neural information processing systems, pages 1269–1277, 2014.
[27] Jonathan Ephrath, Lars Ruthotto, Eldad Haber, and Eran Treister. Leanresnet: A low-cost yet effective convolutional residual networks. arXiv preprint
arXiv:1904.06952, 2019.
[28] Stefan Falkner, Aaron Klein, and Frank Hutter. Practical hyperparameter optimization for deep learning. 2018.
[29] Igor Fedorov, Ryan P. Adams, Matthew Mattina, and Paul N. Whatmough. SpArSe:
Sparse Architecture Search for CNNs on Resource-Constrained Microcontrollers.
pages 1–26, 2019. URL http://arxiv.org/abs/1905.12107.
[30] Joshua Fromm, Meghan Cowan, Matthai Philipose, Luis Ceze, and Shwetak Patel.
Riptide: Fast end-to-end binarized neural networks. Proceedings of Machine Learning
and Systems, 2, 2020.
[31] Kunihiko Fukushima. Neocognitron: A self-organizing neural network model
for a mechanism of pattern recognition unaffected by shift in position. Biological
cybernetics, 36(4):193–202, 1980.
[32] GraphCore. Introducing the GraphCore RackScale IPU-POD (tm). https:
//www.graphcore.ai/posts/introducing-the-graphcore-rackscale-ipu-pod
(Accessed Nov 2019), 2018.
33

[33] Denis A Gudovskiy and Luca Rigazio. ShiftCNN: Generalized low-precision
architecture for inference of convolutional neural networks. arXiv preprint
arXiv:1706.02393, 2017.
[34] Gaël Guennebaud, Benoı̂t Jacob, et al. Eigen v3. http://eigen.tuxfamily.org, 2010.
[35] David Ha, Andrew Dai, and Quoc V Le.
arXiv:1609.09106, 2016.

Hypernetworks.

arXiv preprint

[36] Song Han, Jeff Pool, John Tran, and William Dally. Learning both weights and
connections for efficient neural network. In Advances in neural information processing
systems, pages 1135–1143, 2015.
[37] Babak Hassibi and David G Stork. Second order derivatives for network pruning:
Optimal brain surgeon. In Advances in neural information processing systems, pages
164–171, 1993.
[38] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning
for image recognition. In Proceedings of the IEEE conference on computer vision and
pattern recognition, pages 770–778, 2016.
[39] Yihui He, Ji Lin, Zhijian Liu, Hanrui Wang, Li-Jia Li, and Song Han. AMC: AutoML
for model compression and acceleration on mobile devices. In Proceedings of the
European Conference on Computer Vision (ECCV), pages 784–800, 2018.
[40] Forrest N Iandola, Song Han, Matthew W Moskewicz, Khalid Ashraf, William J
Dally, and Kurt Keutzer. SqueezeNet: AlexNet-level accuracy with 50x fewer
parameters and ¡0.5 MB model size. arXiv preprint arXiv:1602.07360, 2016.
[41] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167,
2015.
[42] Benoit Jacob, Skirmantas Kligys, Bo Chen, Menglong Zhu, Matthew Tang, Andrew
Howard, Hartwig Adam, and Dmitry Kalenichenko. Quantization and training of
neural networks for efficient integer-arithmetic-only inference. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recognition, pages 2704–2713, 2018.
[43] Max Jaderberg, Andrea Vedaldi, and Andrew Zisserman. Speeding up convolutional neural networks with low rank expansions. arXiv preprint arXiv:1405.3866,
2014.

34

[44] Sambhav R. Jain, Albert Gural, Michael Wu, and Chris H. Dick. Trained quantization thresholds for accurate and efficient fixed-point inference of deep neural
networks. arXiv preprint arXiv:1903.08066, 2019.
[45] Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long,
Ross Girshick, Sergio Guadarrama, and Trevor Darrell. Caffe: Convolutional
architecture for fast feature embedding. In Proceedings of the 22nd ACM international
conference on Multimedia, pages 675–678. ACM, 2014.
[46] Zhihao Jia, Oded Padon, James Thomas, Todd Warszawski, Matei Zaharia, and
Alex Aiken. Taso: optimizing deep learning computation with automatic generation of graph substitutions. In Proceedings of the 27th ACM Symposium on Operating
Systems Principles, pages 47–62. ACM, 2019.
[47] Haifeng Jin, Qingquan Song, and Xia Hu. Auto-Keras: an efficient neural architecture search system. In Proceedings of the 25th ACM SIGKDD International Conference
on Knowledge Discovery & Data Mining, pages 1946–1956, 2019.
[48] Norman P Jouppi, Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal,
Raminder Bajwa, Sarah Bates, Suresh Bhatia, Nan Boden, Al Borchers, et al. Indatacenter performance analysis of a tensor processing unit. In 2017 ACM/IEEE
44th Annual International Symposium on Computer Architecture (ISCA), pages 1–12.
IEEE, 2017.
[49] Kirthevasan Kandasamy, Willie Neiswanger, Jeff Schneider, Barnabas Poczos, and
Eric P Xing. Neural architecture search with bayesian optimisation and optimal
transport. In Advances in neural information processing systems, pages 2016–2025,
2018.
[50] Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Cifar-10/100 (canadian institute for advanced research). 2010. URL http://www.cs.toronto.edu/~kriz/
cifar.html.
[51] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification
with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097–1105, 2012.
[52] Liangzhen Lai, Naveen Suda, and Vikas Chandra. CMSIS-NN: Efficient neural
network kernels for ARM Cortex-M CPUs. arXiv preprint arXiv:1801.06601, 2018.
[53] Nicholas D Lane, Sourav Bhattacharya, Petko Georgiev, Claudio Forlivesi, Lei Jiao,
Lorena Qendro, and Fahim Kawsar. Deepx: A software accelerator for low-power

35

deep learning inference on mobile devices. In Proceedings of the 15th International
Conference on Information Processing in Sensor Networks, page 23. IEEE Press, 2016.
[54] Chris Lattner and Jacques Pienaar. Mlir primer: A compiler infrastructure for the
end of moore’s law, 2019.
[55] Andrew Lavin and Scott Gray. Fast algorithms for convolutional neural networks.
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
pages 4013–4021, 2016.
[56] Yann LeCun and Corinna Cortes. MNIST handwritten digit database. 1999. URL
http://yann.lecun.com/exdb/mnist/.
[57] Namhoon Lee, Thalaiyasingam Ajanthan, and Philip HS Torr. Snip: Single-shot
network pruning based on connection sensitivity. arXiv preprint arXiv:1810.02340,
2018.
[58] Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. Pruning
filters for efficient convnets. arXiv preprint arXiv:1608.08710, 2016.
[59] Edgar Liberis and Nicholas D Lane. Neural networks on microcontrollers: saving
memory at inference via operator reordering. arXiv preprint arXiv:1910.05110, 2019.
[60] Darryl Dexu Lin, Sachin S. Talathi, and V. Sreekanth Annapureddy. Fixed point
quantization of deep convolutional networks. arXiv preprint arXiv:1511.06393, 2015.
[61] Ji Lin, Wei-Ming Chen, Yujun Lin, John Cohn, Chuang Gan, and Song Han.
MCUNet: Tiny deep learning on iot devices. arXiv preprint arXiv:2007.10319,
2020.
[62] Tao Lin, Sebastian U Stich, Luis Barba, Daniil Dmitriev, and Martin Jaggi. Dynamic
model pruning with feedback. arXiv preprint arXiv:2006.07253, 2020.
[63] Chenxi Liu, Barret Zoph, Maxim Neumann, Jonathon Shlens, Wei Hua, Li-Jia Li,
Li Fei-Fei, Alan Yuille, Jonathan Huang, and Kevin Murphy. Progressive neural
architecture search. In Proceedings of the European Conference on Computer Vision
(ECCV), pages 19–34, 2018.
[64] Yu Liu, Xuhui Jia, Mingxing Tan, Raviteja Vemulapalli, Yukun Zhu, Bradley Green,
and Xiaogang Wang. Search to Distill: Pearls are Everywhere but not the Eyes.
arXiv preprint arXiv:1911.09074, 2019.
[65] Christos Louizos, Karen Ullrich, and Max Welling. Bayesian compression for deep
learning. In Advances in Neural Information Processing Systems, pages 3288–3298,
2017.
36

[66] Christos Louizos, Matthias Reisser, Tijmen Blankevoort, Efstratios Gavves, and
Max Welling. Relaxed quantization for discretized neural networks. arXiv preprint
arXiv:1810.01875, 2018.
[67] Ping Luo, Zhenyao Zhu, Ziwei Liu, Xiaogang Wang, and Xiaoou Tang. Face model
compression by distilling knowledge from neurons. In Thirtieth AAAI Conference
on Artificial Intelligence, 2016.
[68] Warren S McCulloch and Walter Pitts. A logical calculus of the ideas immanent in
nervous activity. The bulletin of mathematical biophysics, 5(4):115–133, 1943.
[69] Geoffrey F Miller, Peter M Todd, and Shailesh U Hegde. Designing neural networks
using genetic algorithms. In ICGA, volume 89, pages 379–384, 1989.
[70] Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov. Variational dropout
sparsifies deep neural networks. In Proceedings of the 34th International Conference
on Machine Learning-Volume 70, pages 2498–2507. JMLR. org, 2017.
[71] Renato Negrinho and Geoff Gordon. Deeparchitect: Automatically designing and
training deep architectures. arXiv preprint arXiv:1704.08792, 2017.
[72] Mikel Olazaran. A sociological study of the official history of the perceptrons
controversy. Social Studies of Science, 26(3):611–659, 1996.
[73] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang,
Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
Automatic differentiation in PyTorch. In NeurIPS Autodiff Workshop, 2017.
[74] Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, and Ali Farhadi. XNORNet: Imagenet classification using binary convolutional neural networks. In
European Conference on Computer Vision, pages 525–542. Springer, 2016.
[75] Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu,
Jie Tan, Quoc V Le, and Alexey Kurakin. Large-scale evolution of image classifiers.
In Proceedings of the 34th International Conference on Machine Learning-Volume 70,
pages 2902–2911. JMLR. org, 2017.
[76] Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc V. Le. Aging evolution
for image classifier architecture search. In AAAI Conference on Artificial Intelligence,
2019.
[77] Adriana Romero, Nicolas Ballas, Samira Ebrahimi Kahou, Antoine Chassang,
Carlo Gatta, and Yoshua Bengio. Fitnets: Hints for thin deep nets. arXiv preprint
arXiv:1412.6550, 2014.
37

[78] Frank Rosenblatt. The perceptron: a probabilistic model for information storage
and organization in the brain. Psychological review, 65(6):386, 1958.
[79] David E Rumelhart, Geoffrey E Hinton, Ronald J Williams, et al. Learning representations by back-propagating errors. Cognitive modeling, 5(3):1, 1988.
[80] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and LiangChieh Chen. MobileNetV2: Inverted residuals and linear bottlenecks. In Proceedings
of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4510–4520,
2018.
[81] Christian Sciuto, Kaicheng Yu, Martin Jaggi, Claudiu Musat, and Mathieu Salzmann. Evaluating the search phase of neural architecture search. arXiv preprint
arXiv:1902.08142, 2019.
[82] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for
large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.
[83] Dimitrios Stamoulis, Ruizhou Ding, Di Wang, Dimitrios Lymberopoulos, Bodhi
Priyantha, Jie Liu, and Diana Marculescu. Single-path NAS: Designing hardwareefficient convnets in less than 4 hours. arXiv preprint arXiv:1904.02877, 2019.
[84] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir
Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going
deeper with convolutions. In Proceedings of the IEEE conference on computer vision
and pattern recognition, pages 1–9, 2015.
[85] Mingxing Tan and Quoc V Le. Efficientnet: Rethinking model scaling for convolutional neural networks. arXiv preprint arXiv:1905.11946, 2019.
[86] Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler, Andrew
Howard, and Quoc V Le. Mnasnet: Platform-aware neural architecture search
for mobile. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition, pages 2820–2828, 2019.
[87] Surat Teerapittayanon, Bradley McDanel, and Hsiang-Tsung Kung. Branchynet:
Fast inference via early exiting from deep neural networks. In 2016 23rd International Conference on Pattern Recognition (ICPR), pages 2464–2469. IEEE, 2016.
[88] Lucas Theis, Iryna Korshunova, Alykhan Tejani, and Ferenc Huszár. Faster gaze
prediction with dense networks and fisher pruning. arXiv preprint arXiv:1801.05787,
2018.

38

[89] Seiya Tokui, Kenta Oono, Shohei Hido, and Justin Clayton. Chainer: a nextgeneration open source framework for deep learning. In Proceedings of workshop on
machine learning systems (LearningSys) in the twenty-ninth annual conference on neural
information processing systems (NIPS), volume 5, pages 1–6, 2015.
[90] Vincent WS Tseng, Sourav Bhattachara, Javier Fernández-Marqués, Milad Alizadeh,
Catherine Tong, and Nicholas D Lane. Deterministic binary filters for convolutional neural networks. International Joint Conferences on Artificial Intelligence
Organization, 2018.
[91] Nicolas Vasilache, Oleksandr Zinenko, Theodoros Theodoridis, Priya Goyal,
Zachary DeVito, William S Moses, Sven Verdoolaege, Andrew Adams, and Albert
Cohen. Tensor comprehensions: Framework-agnostic high-performance machine
learning abstractions. arXiv preprint arXiv:1802.04730, 2018.
[92] Sergey Zagoruyko and Nikos Komodakis. Paying more attention to attention:
Improving the performance of convolutional neural networks via attention transfer.
arXiv preprint arXiv:1612.03928, 2016.
[93] Arber Zela, Aaron Klein, Stefan Falkner, and Frank Hutter. Towards automated
deep learning: Efficient joint neural architecture and hyperparameter search. arXiv
preprint arXiv:1807.06906, 2018.
[94] Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, and Jian Sun. ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices. In Proceedings
of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,
2018. ISBN 9781538664209. doi: 10.1109/CVPR.2018.00716.
[95] Shuchang Zhou, Yuxin Wu, Zekun Ni, Xinyu Zhou, He Wen, and Yuheng
Zou. Dorefa-net: Training low bitwidth convolutional neural networks with
low bitwidth gradients. arXiv preprint arXiv:1606.06160, 2016.
[96] Yiren Zhou, Seyed-Mohsen Moosavi-Dezfooli, Ngai-Man Cheung, and Pascal
Frossard. Adaptive quantization for deep neural network. In Thirty-Second AAAI
Conference on Artificial Intelligence, 2018.
[97] Barret Zoph and Quoc V Le. Neural architecture search with reinforcement learning.
arXiv preprint arXiv:1611.01578, 2016.
[98] Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V Le. Learning transferable architectures for scalable image recognition. In Proceedings of the IEEE
conference on computer vision and pattern recognition, pages 8697–8710, 2018.

39

40

Appendix A
Attached papers
I attach the following 2 papers produced during my PhD so far:
• “Neural networks on microcontrollers: saving memory at inference via operator reordering”. Published at the “On-device Intelligence Workshop at MLSys 2020: 3rd
Conference on Machine Learning and Systems”.
• “µNAS: constrained neural architecture search for microcontrollers”. Currently under
review at the “MLSys 2021: 4th Conference on Machine Learning and Systems”.

41

arXiv:1910.05110v2 [cs.LG] 3 Mar 2020

Neural networks on microcontrollers:
saving memory at inference via operator reordering
Edgar Liberis1
edgar.liberis@cs.ox.ac.uk

Nicholas D. Lane1,2
nicholas.lane@cs.ox.ac.uk

Department of Computer Science
University of Oxford, Oxford, UK

2

1

Samsung AI Center Cambridge
Cambridge, UK

Abstract
Designing deep learning models for highly-constrained hardware would allow
imbuing many edge devices with intelligence. Microcontrollers (MCUs) are an
attractive platform for building smart devices due to their low cost, wide availability,
and modest power usage. However, they lack the computational resources to
run neural networks as straightforwardly as mobile or server platforms, which
necessitates changes to the network architecture and the inference software. In
this work, we discuss the deployment and memory concerns of neural networks on
MCUs and present a way of saving memory by changing the execution order of
the network’s operators, which is orthogonal to other compression methods. We
publish a tool for reordering operators of TensorFlow Lite models1 and demonstrate
its utility by sufficiently reducing the memory footprint of a CNN to deploy it on
an MCU with 512KB SRAM.

1 Introduction
Deep learning can bring computational intelligence to personal and IoT devices. Using deep learning
models directly on the edge devices allows for greater cost-efficiency, scalability and privacy for endusers, compared to relying on a remote server to carry out the processing. However, the development
of lightweight neural networks, suitable for such underpowered hardware, is centred around mobile
phones as the target platform.
Here, we venture further and explore a more resource-constrained platform—microcontroller units
(MCUs). MCUs are cheap, widespread and are geared towards energy-efficient workloads. They
offer an alternative to designing a purpose-built custom chip, allowing to save on development cost
and time. However, a unit typically consists of a low-frequency processor and only several hundred
kilobytes of on-chip memory [1], and thus severely underpowered compared to mobile devices.
Specially designed network architectures and inference software are required to cope with hardware
constraints of MCUs. In this work, we: (a) discuss memory limitations of a microcontroller platform
and how it affects neural network deployment; (b) devise a way to minimise the peak memory usage
of a neural network by making inference software follow a particular execution order of its operations.
We implement our methodology as a tool for reordering operators within TensorFlow Lite models.1
We successfully apply it to a chosen convolutional neural network, reducing the memory footprint
enough to make it fit within the on-chip memory of our microcontroller platform, which would not
have been possible using the default provided operator execution order. Operator reordering is carried
1

Available for download at https://github.com/oxmlsys/tflite-tools

A version of this paper appears at the On-device Intelligence Workshop at MLSys 2020: 3rd Conference on
Machine Learning and Systems.

out only at inference and does not change the architecture or the output of a neural network, making
it fully orthogonal to many other network compression methods.

2 Background
2.1 Neural network execution
A neural network can be thought of as a computation graph which expresses dependencies between
individual operations (also called layers or operators). An operator, e.g. a 2D convolution or addition,
takes one or more input tensors and produces a single output. Modern deep learning frameworks
optimise the network’s computation graph for inference in advance by e.g. fusing adjacent operators
and folding batch normalisation layers into preceding linear operations. The execution proceeds by
evaluating one operator at a time in a topological order of nodes in the graph.
An operator requires buffers for its inputs and output to be present in memory before its execution
can commence. Once the operator has finished executing, memory occupied by its inputs can be
reclaimed (if not use elsewhere) and the output buffer will eventually be used as an input to other
operators. We define a working set as a set of tensors that need to be kept in memory at any given
point in execution. This comprises input and output tensors of a pending operator and other tensors
that were already produced and need to be held back in memory for subsequent operators.
Classic neural network architectures, such as the original multilayer perceptron, AlexNet [2], VGG [3],
consist of a linear sequence of layers, which are iteratively applied to transform the input. However,
more recent architectures, such as ResNet [4], Inception [5], NasNet [6], introduce divergent processing paths where the same tensor can be processed by several layers, i.e. their computation graph is no
longer linear and has branches. This means that the inference software may have multiple operators
available for execution at any given step.
2.2 Resource scarcity of microcontroller hardware
A microcontroller unit that would be powerful enough to execute neural networks reasonably quickly
(e.g. ARM Cortex M series) typically has a low-frequency RISC processing core (up to 400 MHz)
and 128–2048KB of on-chip memory [1]. The memory is partitioned into read-write static RAM
(SRAM) and read-only NOR-Flash memories, with the latter housing the executable code and static
data. In contrast to mobile or desktop hardware, there are no intermediate levels in this memory
hierarchy, although the set-up may have some backing storage. A backing storage, e.g. an SD-card,
typically has a high capacity but is slow [7] and power-costly to access (≈100x more energy required
to read a value outside of on-chip memory [8]).
The lack of intermediate memories forces applications to fit within the on-chip memory to remain
fast. For neural networks, this makes aiming for a small peak working set size and parameter count
(model size) an important goal in model design. Note that it’s not necessary to pursue the maximal
memory saving—aiming just below the on-chip memory capacity is sufficient.
Memory requirements of a neural network can be directly mapped to the two types of on-chip memory.
Parameters (trainable weights, constants) of a network are immutable and can be embedded into the
executable code as static data stored in NOR-Flash. Any intermediate tensors that are dependent
upon input (so-called activation matrices) are produced at runtime and would have to be stored in
SRAM. Thus the model size and peak memory usage are constrained by the capacities of NOR-Flash
and SRAM memories, respectively.
In Section 4, we show how choosing operator execution order affects which tensors reside in SRAM
(are in the working set). We exploit this to minimise the peak working set size (peak memory usage).

3 Related work
The design of compact models is an active topic of deep learning research, albeit usually under less
extreme constraints than those of microcontroller hardware. One can obtain a smaller neural network
by using layer decomposition [9, 10], pruning [11, 12], quantisation [13] and binarisation [14, 15],
distillation [16] or exploiting sparsity [17]. Popular mobile-friendly CNN architectures include
2

MobileNet [18] and ShuffleNet [19]. MNasNet [20] and EfficientNet [21] develop architecture search
algorithms to design a network within a certain floating-point operation count or memory budget. In
particular, Fedorov et al. [22] incorporate the maximal working memory size of an operator into their
optimisation goal.
A relatively underexplored set of methods include complex evaluation strategies for parts of the
network to save memory at runtime. For example, authors of MobileNet [18] note that a building
block of their model has a channel-wise operation, whose output is accumulated into another tensor,
which allows processing the input tensor in parts. Also, Alwani et al. [23] propose not to materialise
an output tensor of a large convolution operation in memory at all, and compute its individual output
elements as needed by succeeding operators.
The development of low-power machine learning models is fostered by the TinyML Summit [24] and
the Visual Wake Words competition [25], which looked for performant MCU-sized CNNs for person
detection. Compact deep learning models have been built for use on wearables devices [26] and for
keyword spotting [27, 28]. Concerns about the memory usage of neural networks and data movement
during execution are also discussed in neural network accelerator chip design literature [29–31].

4 Methods and implementation
Neural networks whose computation graphs contain branches allow some freedom over the order of evaluation of their operators.
When execution reaches a branching point, the inference software
has to choose which branch to start evaluating next. This choice
can affect which tensors need to be kept in memory (working set),
so we can construct an execution schedule that minimises the total
size of the working set at its peak (memory bottleneck).
To illustrate this, Figure 1 shows an example of a computation
graph, adapted from a real-world CNN. Evaluating operators as
numbered 1 through to 7 will result in peak memory usage of 5216,
coming from operator #3 (input and output buffers + the output
of operator #1 that is held back for operator #4). However, fully
evaluating the rightmost branch first (execution order 1, 4, 6, 2, 3,
5, 7), would result in peak memory usage of 4960, coming from
operator #2 (input and output buffers + output of operator #6 that
is held back for operator #7). Appendix A gives a more detailed
breakdown of the memory usage during computation, together
with plots produced by our tool, for both default and optimised
operator schedules.
We approach finding a memory-optimal execution schedule for
an arbitrary computation graph by algorithmically enumerating
all execution schedules and calculating their peak memory usage.
To simplify the problem, we assume that no operator will be
executed twice (this assumption is also made in TensorFlow). A
computation graph is a directed acyclic graph (DAG) and any
topological order of its nodes would produce a valid execution
schedule; in general, enumerating all topological orders of a DAG
is an explored problem in graph algorithms literature [32].

7×7×32

1
Conv2D
1x1
7×7×64

2
Conv2D
1x1
7×7×32

3
Conv2D
3x3 d/wise

4
Conv2D
3x3 d/wise

4×4×32

4×4×32

5
Conv2D
1x1
4×4×16

6
Conv2D
1x1
4×4×16

7
Concat
4×4×32

Figure 1: An example computation graph consisting of 1x1 and
3x3 depthwise convolution operators. Annotations on arrows
represent tensor sizes.

In Algorithm 1 (procedure M EM), we describe a dynamic programming algorithm that is concerned
with the minimal peak memory usage required to produce (and keep in memory) a set of tensors X.
It enumerates execution schedules recursively by trying to "undo" operators that produced each of the
tensors in X. The algorithm should be invoked on a set of network’s output tensors and the optimal
execution schedule can be traced by checking which recursive calls contributed to the answer. The
complexity of the algorithm is O(|V |2|V | ), where |V | is the number of operators of the network.
To simplify the implementation, the algorithm begins by filtering out tensors that don’t have an
operator that produced them (so-called constants), as those just contribute to memory usage and don’t
affect the execution schedule. A restriction that no operator is evaluated twice is implemented by
3

Algorithm 1 Computing the minimal peak memory usage of a neural network. PARTITION function
splits a set into two using a predicate; producer(x) denotes an operator that produced tensor x.
1: procedure M EM(X)
. Minimum amount of memory needed to compute tensors in X
2:
. Partition tensors into constants (no producer) and activation matrices
3:
cs, as ← PARTITION(X, x : producer(x) is None)
4:
if as is empty
P then
5:
return c∈cs |c|
. No operators left to order, report sizes of remaining constants
6:
end if
7:
m←∞
8:
for x in as do
. Try to unapply the operator that produced x
9:
rs ← as \ x
. Remaining tensors that need to be kept in memory
10:
is ← producer(x).inputs
. Tensors required to produce x
11:
if any(x is a predecessor of r for r in rs) then
12:
continue . x is a predecessor to r, so producer(x) would have to be evaluated twice
13:
end if
14:
. Peak memory usage will be determined by either the producer of x—i.e. memory used
its input tensors (is), output tensor (x) and other tensors (rs)—or by other operators in
the execution path (recursive
P case M EM(rs ∪ is))
15:
m0 ← max(M EM(rs ∪ is), t∈rs∪is∪{x} |t|)
16:
m ← min(m, m0 )
. Pick the execution path that gives minimal memory usage
17:
end forP
18:
return c∈cs |c| + m
19: end procedure

checking whether an operator is a predecessor to any of the remaining tensors, as this would require
it to be executed at some point again in the schedule. Note that M EM(X) may be invoked on the
same set of tensors multiple times (from different execution paths), so it should be memoized (i.e. the
output should be cached) to avoid recomputing the result.
We use a lightweight TensorFlow Light Micro inference engine [33] (henceforth micro-interpreter)
to run the neural network on the MCU itself. At the time of writing2 , the software did not support
reclaiming memory from tensors that were no longer needed, so we implement our own dynamic
memory allocator for tensor buffers. Internally, TensorFlow Lite assumes that tensors reside in
contiguous blocks of memory and cannot be fragmented. The memory allocator is only used by
the micro-interpreter, which allows us to ensure that C/C++ pointers to memory blocks are not
being remembered anywhere in the code. This enables us to move buffers in memory as needed for
defragmentation. We adopt a very simple defragmentation strategy of moving all tensor buffers to the
start of the memory region as much as possible after the execution of every operator.

5 Experiments
We deploy a neural network onto an MCU with both default and optimised operator schedules to
exhibit the difference in memory usage. We use one of the winning submissions of the Visual Wake
Words competition [25], called SwiftNet Cell [34, 35], as it has only 250KB of parameters and
contains many branches, which enables us to showcase the benefits of reordering. The model is
run using the modified micro-interpreter (as described above) on a NUCLEO-F767ZI prototyping
board [36]. The board features a Cortex M7 processor, running at 216Mhz, and has 512KB of SRAM.

2

At the time of publication of this pre-print, a dynamic memory allocator has been implemented by maintainers of TensorFlow Lite Micro, making this change no longer necessary. However, we keep the description of
our memory allocation strategy, as well as the power and latency measurements, as an illustrative example of
memory management overheads.

4

SwiftNet Cell
Default order Optimal order
Peak memory usage
(excl. overheads)
Execution time
Energy use

MobileNet v1
Static alloc.
Dynamic alloc.

351KB

301KB

241KB

55KB (↓ 186KB)

N/A
N/A

10243 ms
8775 mJ

1316 ms
728 mJ

1325 ms (↑ 0.68%)
735 mJ (↑ 0.97%)

Table 1: Peak memory usage, execution time and energy use of chosen models.
Table 1 shows that optimised ordering was able to save 50KB of memory, compared to the order
embedded in the model. Including the framework overhead (≈200KB for SwiftNet Cell, proportional
to the number of tensors), this made a sufficient difference to make the model’s memory footprint fit
within SRAM.3 We also check the overhead introduced by replacing a static memory allocator with
a dynamic one by running MobileNet-v1-based [37] person detection model (from the Tensorflow
Lite Micro repository [33]). Measurements show negligible (sub-1%) increase in execution time and
energy used by the MCU and the memory footprint was decreased by 186KB. In general, latency and
power consumption can be reduced with operator implementations that leverage processor capabilities
well (SIMD, DSP instructions).

6 Discussion
The results show that employing a different operator execution order for neural network inference
can make previously undeployable models fit within the memory constraints of MCU hardware.
Reordering operators can be implemented just within the inference software, making it orthogonal to
most other network compression approaches, which were likely to have been already used to create
an MCU-sized model.
Unlike mobile and server platforms, MCU hardware often doesn’t have enough memory to statically
pre-allocate all tensor buffers of the network, which requires the inference software to support
dynamic memory allocation. We showed that a simple defragmentation strategy is a viable option
with little overhead cost. However, when the execution schedule is known in advance, optimal tensor
buffer placement in memory may be precomputed.
Having a way of precisely computing peak memory usage for models with complex computation
graphs would benefit neural architecture search (NAS) procedures. The algorithm can be extended to
support various memory saving tricks: for example, if one of the inputs to the addition operator is not
used elsewhere, the result can be accumulated into it, eliminating the need for an output buffer.

7 Conclusion
Microcontrollers are a viable platform for running deep learning applications if the model designer
can overcome constraints imposed by limited memory and storage. In this work, we describe how to
minimise peak memory usage of a neural network during inference by changing the evaluation order
of its operators. By applying our methodology, we were able to achieve sufficient memory savings
to deploy the chosen CNN on a microcontroller with 512KB SRAM, which would not have been
possible otherwise. Our tool for embedding optimal operator ordering into TensorFlow Lite models
is available at https://github.com/oxmlsys/tflite-tools.
Acknowledgments
The work was supported by the Engineering and Physical Sciences Research Council UK (EPSRC
UK), grant ref. EP/S001530/1, and Samsung AI. The authors would also like to thank Javier
Fernández-Marqués for providing help with measuring energy usage.
3

The authors of the model note that peak memory usage can be lowered, likely by using fused operator
implementations. Further savings would come from optimising the memory usage of the micro-interpreter itself.

5

References
“STM32
High
Performance
MCUs.”
https://www.st.com/en/
[1] STMicroelectronics,
microcontrollers-microprocessors/stm32-high-performance-mcus.html (Accessed Sep
2019).
[2] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “ImageNet classification with deep convolutional neural
networks,” in Advances in Neural Information Processing Systems, 2012.
[3] K. Simonyan and A. Zisserman, “Very deep convolutional networks for large-scale image recognition,” in
International Conference on Learning Representations (ICLR), 2015.
[4] K. He, X. Zhang, S. Ren, and J. Sun, “Deep Residual Learning for Image Recognition,” in 2016 IEEE
Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770–778, IEEE, Jun 2016.
[5] C. Szegedy, S. Ioffe, V. Vanhoucke, and A. A. Alemi, “Inception-v4, inception-ResNet and the impact of
residual connections on learning,” in 31st AAAI Conference on Artificial Intelligence, AAAI 2017, 2017.
[6] B. Zoph, V. Vasudevan, J. Shlens, and Q. V. Le, “Learning Transferable Architectures for Scalable Image
Recognition,” Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern
Recognition, pp. 8697–8710, 2018.
[7] SD Association, “Bus Speed (Default Speed/High Speed/UHS/SD Express).” https://www.sdcard.
org/developers/overview/bus_speed/index.html (Accessed Sep 2019).
[8] M. Horowitz, “1.1 computing’s energy problem (and what we can do about it),” in 2014 IEEE International
Solid-State Circuits Conference Digest of Technical Papers (ISSCC), pp. 10–14, IEEE, 2014.
[9] N. D. Lane, S. Bhattacharya, P. Georgiev, C. Forlivesi, L. Jiao, L. Qendro, and F. Kawsar, “DeepX: A
software accelerator for low-power deep learning inference on mobile devices,” in Information Processing
in Sensor Networks (IPSN), 2016 15th ACM/IEEE International Conference on, pp. 1–12, IEEE, 2016.
[10] C. Cai, D. Ke, Y. Xu, and K. Su, “Fast learning of deep neural networks via singular value decomposition,”
in Pacific Rim International Conference on Artificial Intelligence, pp. 820–826, Springer, 2014.
[11] L. Theis, I. Korshunova, A. Tejani, and F. Huszár, “Faster gaze prediction with dense networks and Fisher
pruning,” 2018.
[12] S. Han et al., “Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization
and Huffman Coding,” CoRR, vol. abs/1510.00149, 2015.
[13] B. Jacob, S. Kligys, B. Chen, M. Zhu, M. Tang, A. Howard, H. Adam, and D. Kalenichenko, “Quantization
and training of neural networks for efficient integer-arithmetic-only inference,” in The IEEE Conference on
Computer Vision and Pattern Recognition (CVPR), June 2018.
[14] M. Alizadeh, J. Fernández-Marqués, N. D. Lane, and Y. Gal, “An empirical study of binary neural networks’
optimisation,” 2018.
[15] M. Courbariaux, I. Hubara, D. Soudry, R. El-Yaniv, and Y. Bengio, “Binarized neural networks: Training deep neural networks with weights and activations constrained to +1 or −1,” arXiv preprint
arXiv:1602.02830, 2016.
[16] G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural network,” arXiv preprint
arXiv:1503.02531, 2015.
[17] G. Georgiadis, “Accelerating Convolutional Neural Networks via Activation Map Compression,” 2018.
[18] M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L. C. Chen, “MobileNetV2: Inverted Residuals and
Linear Bottlenecks,” Proceedings of the IEEE Computer Society Conference on Computer Vision and
Pattern Recognition, pp. 4510–4520, 2018.
[19] X. Zhang, X. Zhou, M. Lin, and J. Sun, “ShuffleNet: An Extremely Efficient Convolutional Neural Network
for Mobile Devices,” in Proceedings of the IEEE Computer Society Conference on Computer Vision and
Pattern Recognition, 2018.
[20] M. Tan, B. Chen, R. Pang, V. Vasudevan, and Q. V. Le, “MnasNet: Platform-Aware Neural Architecture
Search for Mobile,” in Proceedings of the IEEE Computer Society Conference on Computer Vision and
Pattern Recognition, 2018.
[21] M. Tan and Q. V. Le, “EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,” 2019.

6

[22] I. Fedorov, R. P. Adams, M. Mattina, and P. N. Whatmough, “SpArSe: Sparse Architecture Search for
CNNs on Resource-Constrained Microcontrollers,” pp. 1–26, 2019.
[23] M. Alwani, H. Chen, M. Ferdman, and P. Milder, “Fused-layer cnn accelerators,” in The 49th Annual
IEEE/ACM International Symposium on Microarchitecture, p. 22, IEEE Press, 2016.
[24] “tinyML Summit.” https://www.tinymlsummit.org (Accessed Sep 2019).
[25] A. Chowdhery, P. Warden, J. Shlens, A. Howard, and R. Rhodes, “Visual Wake Words Dataset,” 2019.
[26] S. Bhattacharya and N. D. Lane, “Sparsification and separation of deep learning layers for constrained
resource inference on wearables,” in Proceedings of the 14th ACM Conference on Embedded Network
Sensor Systems CD-ROM, pp. 176–189, ACM, 2016.
[27] Y. Zhang, N. Suda, L. Lai, and V. Chandra, “Hello edge: Keyword spotting on microcontrollers,” arXiv
preprint arXiv:1711.07128, 2017.
[28] J. Fernández-Marqués, V. W.-S. Tseng, S. Bhattachara, and N. D. Lane, “On-the-fly deterministic binary
filters for memory efficient keyword spotting applications on embedded devices,” in Proceedings of the
2nd International Workshop on Embedded and Mobile Deep Learning, pp. 13–18, ACM, 2018.
[29] K. Siu, D. M. Stuart, M. Mahmoud, and A. Moshovos, “Memory requirements for convolutional neural
network hardware accelerators,” in 2018 IEEE International Symposium on Workload Characterization
(IISWC), pp. 111–121, Sep 2018.
[30] A. Parashar, M. Rhu, A. Mukkara, A. Puglielli, R. Venkatesan, B. Khailany, J. Emer, S. W. Keckler, and
W. J. Dally, “SCNN: An Accelerator for Compressed-sparse Convolutional Neural Networks,” 2017.
[31] Y. Chen, T. Krishna, J. S. Emer, and V. Sze, “Eyeriss: An energy-efficient reconfigurable accelerator for
deep convolutional neural networks,” IEEE Journal of Solid-State Circuits, vol. 52, pp. 127–138, Jan 2017.
[32] D. E. Knuth and J. L. Szwarcfiter, “A structured program to generate all topological sorting arrangements,”
Information Processing Letters, vol. 2, no. 6, pp. 153–157, 1974.
[33] TensorFlow Contributors, “TensorFlow Lite Micro.” https://github.com/tensorflow/tensorflow/
commits/master/tensorflow/lite/experimental/micro (Accessed Sep 2019), 2019.
[34] H.-P. Cheng, J. Lee, P. Noorzad, and J. Lin, “QTravelers Visual Wake Words contest submission.” https:
//github.com/newwhitecheng/vwwc19-submission (Accessed Sep 2019), 2019.
[35] H.-P. Cheng, T. Zhang, Y. Yang, F. Yan, S. Li, H. Teague, H. Li, and Y. Chen, “SwiftNet: Using Graph
Propagation as Meta-knowledge to Search Highly Representative Neural Architectures,” Jun 2019.
[36] STMicroelectronics,
“NUCLEO-F767ZI development board.” https://www.st.com/en/
evaluation-tools/nucleo-f767zi.html (Accessed Sep 2019), 2019.
[37] A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand, M. Andreetto, and H. Adam,
“MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications,” apr 2017.

7

Appendix A
 

 4 U J W F Y T W  N S U Z Y X
 4 U J W F Y T W  T Z Y U Z Y X
 4 Y M J W  Y J S X T W X

 2 J R T W ^  Z X F L J  
 0 ' 

 
 
 
 
 

Tensors in RAM
(output of op. #)

1 (Conv2D)
2 (Conv2D)
3 (Conv2D)
4 (Conv2D)
5 (Conv2D)
6 (Conv2D)
7 (Concat)

{0, 1}
{1, 2}
{1, 2, 3}
{1, 3, 4}
{3, 4, 5}
{4, 5, 6}
{5, 6, 7}

Usage (B)
4,704
4,704
5,216
4,160
1,280
1,024
1,024
5,216

Memory usage w/ default operator order

   
 ( T S H F Y 

   
 ( T S [  ) 

 4 U J W F Y T W X

   
 ( T S [  ) 

   
 ( T S [  ) 

   
 ( T S [  ) 

   
 ( T S [  ) 

Peak:

   
 ( T S [  ) 

 

Operator

Figure 2: Memory usage of the sample computation graph with default operator ordering.
 

 4 U J W F Y T W  N S U Z Y X
 4 U J W F Y T W  T Z Y U Z Y X
 4 Y M J W  Y J S X T W X

 
 
 
 

Operator

Tensors in RAM
(output of op. #)

1 (Conv2D)
4 (Conv2D)
6 (Conv2D)
2 (Conv2D)
3 (Conv2D)
5 (Conv2D)
7 (Concat)

{0, 1}
{1, 4}
{1, 4, 6}
{1, 2, 6}
{2, 3, 6}
{3, 5, 6}
{5, 6, 7}

Usage (B)
4,704
3,648
3,904
4,960
2,336
1,024
1,024
4,960

Memory usage w/ optimised operator order

   
 ( T S H F Y 

   
 ( T S [  ) 

 4 U J W F Y T W X

   
 ( T S [  ) 

   
 ( T S [  ) 

   
 ( T S [  ) 

Peak:

   
 ( T S [  ) 

 

   
 ( T S [  ) 

 2 J R T W ^  Z X F L J  
 0 ' 

 

Figure 3: Memory usage of the sample computation graph with optimised operator ordering.

8

MANUSCRIPT UNDER REVIEW

µNAS: C ONSTRAINED N EURAL A RCHITECTURE S EARCH
FOR M ICROCONTROLLERS
Edgar Liberis 1 Łukasz Dudziak 2 Nicholas D. Lane 1 2

A BSTRACT
IoT devices are powered by microcontroller units (MCUs) which are extremely resource-scarce: a typical MCU
may have an underpowered processor and around 64 KB of memory and persistent storage, which is orders of
magnitude fewer computational resources than is typically required for deep learning. Designing neural networks
for such a platform requires an intricate balance between keeping high predictive performance (accuracy) while
achieving low memory and storage usage and inference latency. This is extremely challenging to achieve manually,
so in this work, we build a neural architecture search (NAS) system, called µNAS, to automate the design of
such small-yet-powerful MCU-level networks. µNAS explicitly targets the three primary aspects of resource
scarcity of MCUs: the size of RAM, persistent storage and processor speed. µNAS represents a signiﬁcant
advance in resource-efﬁcient models, especially for “mid-tier” MCUs with memory requirements ranging from
0.5 KB to 64 KB. We show that on a variety of image classiﬁcation datasets µNAS is able to (a) improve top-1
classiﬁcation accuracy by up to 4.8%, or (b) reduce memory footprint by 4–13×, or (c) reduce the number of
multiply-accumulate operations by ≈1700×, compared to existing MCU specialist literature and resource-efﬁcient
models. µNAS is freely available for download at (In progress. URL to be provided after review.)
1

I NTRODUCTION

We would like to use deep learning to add computational
intelligence to small personal IoT devices. Running neural
networks on-device would allow a higher degree of privacy
and autonomy, due to the computation happening locally
and the user’s data never leaving the device. However, deep
learning typically requires much more computational power
than is available on these devices, forcing them to rely on a
remote compute server or a companion smartphone.
IoT devices are powered by microcontroller units (MCUs).
MCUs are ultra-small computers with a low-frequency processor, a persistent program memory (Flash) and volatile
static RAM—all contained within a single chip. They are
orders of magnitude cheaper and more power-efﬁcient compared to mobile phones and desktops, which contributes
to their widespread usage: more than 30B units were estimated to have shipped in 2019 (Grand View Research, 2020).
However, these beneﬁts come at the cost of drastically reduced computational power. Here, we consider “mid-tier”
IoT-sized MCUs with up to 64KB of SRAM and 64KB
1
Department of Computer Science and Technology, University
of Cambridge, United Kingdom 2 Samsung AI Centre Cambridge,
Cambridge, United Kingdom. Correspondence to: Edgar Liberis
<el398 at cam.ac.uk>.

Proceedings of the 4 th MLSys Conference, San Jose, CA, USA,
2021. Copyright 2020 by the author(s).

of persistent storage available1 for performing neural network inference. These severe resource constraints present a
challenge to running resource-intense computations.
Designing neural networks with small computational requirements is tackled by the ﬁeld of model compression.
Methods such as pruning, distillation, quantisation and
cheaper layers, have been developed to obtain compressed
models from large networks in a way that tries to minimise
the amount of lost accuracy (Cheng et al., 2017). This also
reveals a trade-off between the accuracy of a neural network
and its resource usage, or size, suggesting it is difﬁcult to
have small models that generalise well.
However, most model compression methods are not suitable
for producing MCU-sized neural networks. Many techniques target mobile devices (or similar platforms), which
have orders of magnitude of more computational resources
than MCUs, or focus on reducing the number of parameters
(model size) or ﬂoating-point operations (FLOPs) within
the network’s layers while keeping the overall architecture
(layer connectivity) intact, which does not fully capture all
types of resource scarcity of an MCU. Even manually de1

More powerful “top-tier” alternatives are also available at a
higher cost, such as ARM Cortex M4- or M7-based MCUs (up
to ≈400 MHz clock frequency, ≤ 512KB SRAM, ≤ 1MB Flash).
Considering “mid-tier” MCUs allows our methodology to be applied more broadly both now and also in the future, once the current
“mid-tier” becomes the new “low-” and the most widespread tier.

µNAS: Constrained Neural Architecture Search for Microcontrollers

signed resource-efﬁcient models, such as MobileNet and
SqueezeNet, would exceed the assumed resource budget by
over 10×. This necessitates further research into specialist
methods for deep learning on MCUs.
To illustrate the deployment challenges, let us brieﬂy go
through design considerations of executing a neural network
on an MCU and how the resource scarcity affects it:

by up to 4.8%, or (b) reduce memory usage by 4–13×, or
(c) reduce the number of multiply-accumulate operations by
≈1700×, depending on the task.
The main contributions of this work are:

• We propose and motivate a multiobjective constrained
NAS algorithm suitable for ﬁnding MCU-level architectures, called µNAS. It is assembled out of:
1. a granular search space;
2. a set of constraints that accurately capture resource scarcity of microcontroller platforms: peak
memory usage, model size and latency;
3. a search algorithm capable of optimising for multiple objectives in the said search space;
4. network pruning, to obtain small accurate models.
• We perform ablation studies to quantitatively justify
design decisions made in µNAS, namely:
1. whether using network pruning helps ﬁnd smaller
models than otherwise;
2. which search algorithm should be used;
3. how including or excluding individual objectives
inﬂuences the properties of the models found.
• We conduct extensive experiments over ﬁve
microcontroller-friendly image classiﬁcation tasks and
existing literature for resource-efﬁcient neural network
to demonstrate the superior performance of µNAS.

• Temporary data generated by the neural network (activation matrices) need to ﬁt within the SRAM of the
MCU (< 64 KB).
• Any static data, such as the neural network’s parameters and program code, need to ﬁt within the ROM /
Flash memory of the MCU (< 64 KB).
• A network needs to execute quickly to keep the inference process within reasonable power and time constraints while running on an underpowered processor.
To tackle neural network design under hard constraints, we
turn to neural architecture search (NAS). NAS automatically designs neural networks and is related to model selection and hyperparameter tuning but refers speciﬁcally to
selecting an architecture from a large predeﬁned space of
all neural networks, called the search space. During the
search, many common NAS algorithms consider numerous
candidate models, each assembled from a predeﬁned set
of building blocks, to ﬁnd the one with the highest accuracy (Elsken et al., 2019). When properly conditioned, NAS
can produce architectures within certain constraints or targeting several objectives at once, though this also increases
the difﬁculty of the search problem.
While NAS is a promising direction to consider when designing models for MCUs, most current NAS systems target
much larger platforms, such as GPUs or mobile devices.
We would expect them to fail to produce MCU-compatible
architectures because they were not designed to handle extreme resource scarcity of MCUs, owing at least to either an
inability to represent MCU-sized architectures in the search
space at all or doing so too coarsely, resulting in too few
candidates to choose from during search.
Our work, µNAS, is one of the ﬁrst few neural architecture search systems that target microcontrollers explicitly.
µNAS accurately captures the resource requirements and,
combined with model compression, successfully ﬁnds fast
high-accuracy microcontroller-sized neural networks with a
low memory footprint (< 64 KB).
In contrast to other NAS systems for MCUs (Fedorov et al.,
2019; Lin et al., 2020a), µNAS uses a standard neural network execution runtime, a ﬁne-grained search space and
accurate objective functions, which allows it to improve
upon other methods on ﬁve image classiﬁcation datasets using comparable MCU resource requirements. We found that
µNAS can either (a) improve top-1 classiﬁcation accuracy

2

R ELATED WORK

Until recently, due to high computational and memory requirements, neural networks have not been widely used in
machine learning for IoT-sized devices. Initially, elements
of gradient-based learning were combined with other machine learning algorithms to produce a resource-efﬁcient
solution. ProtoNN (Gupta et al., 2017) learn a sparse projection matrix, and use the distance between examples and
learned class prototypes for classiﬁcation. Bonsai (Kumar
et al., 2017) learn a sparse, shallow decision tree with feature extraction occurring at a decision path. Both methods
have a low memory footprint of under 2KB. More recently,
manually designed neural networks with quantisation and binarisation have been used for image classiﬁcation on MCUs,
too, though with a larger memory footprint (Zhang et al.,
2017; Mocerino & Calimera, 2019).
Neural architecture search (NAS) is a widely explored topic
in deep learning for desktop and server GPUs. There are
approaches based on reinforcement learning (Zoph & Le,
2016; Zhou et al., 2018; Tan et al., 2019), evolutionary
algorithms (Real et al., 2019), Bayesian optimisation (Kandasamy et al., 2018b; Jin et al., 2019) and gradient optimisation (Liu et al., 2018; Mei et al., 2019), that sometimes
employ weight sharing to amortise the cost of training across

µNAS: Constrained Neural Architecture Search for Microcontrollers

multiple candidate models (Pham et al., 2018; Guo et al.,
2019). Constrained multiobjective NAS has been traditionally used to ﬁnd “mobile”-level networks, such as by
optimising energy (Hsu et al., 2018) and latency (FernandezMarques et al., 2020; Cai et al., 2018) in addition to accuracy.
However, few works consider MCUs as the target platform.
The closest work to ours is “SpArSe” (Fedorov et al., 2019),
which ﬁnds both sparse and dense convolutional neural networks suitable for MCUs. In many ways, this work has
served us as a promising direction to take: we share similarities with multiobjective optimisation and the use of network
pruning. In comparison, we: (1) improve the key aspects
of search objectives, making them more faithful to how
neural networks are executed on an MCU; (2) improve on
the search space, allowing for more layer connectivity; and
(3) we adopt an alternative search procedure and a pruning
method–all of the which allows us to produce architectures
with higher accuracy and lesser resource usage.
Recently, Lin et al. (2020a) developed a neural network
execution runtime for MCUs together with a NAS tailored to
it (for comparison, we use an off-the-shelf runtime described
in Section 3.1). To the best of our understanding, the runtime
uses partial operator evaluation to store only one or more
columns2 of the output matrix of each operator. The NAS
targets larger MCUs, of > 256 KB SRAM and Flash, and
performs the search by selecting a subnetwork from a larger
model. This limits the connectivity of resulting models (i.e.
fewer architectures are considered during search) but allows
for faster convergence and targeting a more difﬁcult task of
ImageNet classiﬁcation. We compare discovered models
for the Speech Commands dataset: we ﬁnd that µNAS ﬁnds
models with a smaller memory footprint (in our range of
interest) without using a custom runtime.

3

D ESIGN OF µNAS

We believe the following two design requirements are essential for an MCU-level NAS and set it apart from mobile- or
GPU-level NAS systems:
1. A highly granular search space. To discover accurate networks that ﬁt within the strict resource requirements, NAS needs to control all aspects of a network:
its layers, their size (such as output size or convolutional kernel size) and connectivity. In contrast, NAS
for GPUs typically uses search spaces with a larger
resolution, e.g. manipulating groups of layers at a time
or replicating layers in predeﬁned patterns at predetermined input resolutions. (The granularity of the search
space is further discussed in Sections 3.3 and 3.5.)
2
Convolution can be implemented by an im2col transposition
followed by matrix multiplication. Thus here, a “column” is a
window of the input covered by a convolutional kernel.

2. Accurate resource use computation. To know which
models ﬁt within resource constraints, NAS needs to efﬁciently and accurately calculate or simulate how each
candidate network will use memory, storage and computational resources (based on an assumed execution
strategy). A precise computation is not often needed
for models running on GPUs or mobiles, as these platforms are not as resource-constrained as MCUs.
In the remainder of this section, we discuss the motivation
behind the requirements above and how they are implemented in µNAS. We start by describing how a neural network is executed on an MCU and, after brieﬂy formalising
the problem of multiobjective NAS, we will talk about major
components in µNAS, namely the search space, objective
functions, search algorithms and compression, that are all
crucial for ﬁnding performant MCU-sized architectures.
3.1 Neural network execution on MCUs
A model’s resource usage depends on the runtime, that is on
how the underlying software chooses to run the network for
inference and manage its memory usage. Knowledge of this
has to be incorporated into the NAS to correctly estimate a
candidate model’s resource usage during the search. Here,
we follow the execution strategy used by the TensorFlow
Lite Micro3 interpreter and CMSIS-NN libraries:
1. Operators (neural network layers) are executed in a
predeﬁned order, one at a time (no parallelism).
2. An operator is executed by (a) allocating/reserving
memory for its output buffer in SRAM, (b) fully executing the body of an operator and (c) deallocating its
input buffers (if not used elsewhere later on). Hence,
the activation matrices of a neural network are only
stored within SRAM.
3. Any static data, such as neural network weights, are
read from the executable binary, stored in Flash.
4. The network’s weights and all computation are quantised to an 8-bit ﬁxed precision data type (int8), e.g.
using the afﬁne quantisation (Jacob et al., 2018).
5. No operators are executed partially, or more than once,
and no data is written to external writeable storage (an
SD-card), as this would be prohibitively slow.
It is also possible to adopt a custom execution framework
that, for example, leverages partial execution, or operator
fusion, and adapt µNAS for that instead. However, by using TensorFlow Lite Micro, which is widely adopted and
supported by multiple chip vendors, µNAS can deliver stateof-the-art results that can be readily used, without having to
maintain a custom runtime.
3

https://github.com/tensorflow/
tensorflow/tree/master/tensorflow/lite/
micro

µNAS: Constrained Neural Architecture Search for Microcontrollers

3.2

What is Neural Architecture Search (NAS)?

At its core, NAS is a constrained zeroth-order optimisation
problem, where we seek to ﬁnd a neural network α∗ (belonging to the search space A) that maximises some objective
function (or goal), called L, such as the accuracy on the target dataset with respect to some resource usage constraints.
We assume that the validation set accuracy for a particular
architecture α is maximised by some weights θ∗ , obtained
via gradient descent. Evaluating L(α) is expensive since it
requires training a model, so we seek to ﬁnd the optimum
α∗ in a limited number of queries to L (evaluations of L).

Resource constraints can be treated as soft constraints,
i.e. reformulated as extra objectives with penalty terms.
This turns NAS into a multiobjective optimisation problem
(rewritten as a minimisation problem below). We include
four objectives, three of which are resource constraints (discussed in Section 3.4): (1) top-1 validation set accuracy, (2)
peak memory usage, (3) model size and (4) latency.
α∗

= argminα∈A
= argminα∈A

L(α)

{1.0 − VAL ACCURACY(α),
M ODEL S IZE(α),

(1)

P EAK M EM U SAGE(α),
L ATENCY(α)}
A solution to a multiobjective problem is no longer a singular value. It is common to consider a Pareto front as a set
of potential solutions: a set of points on which one objective function cannot be improved without making another
objective worse. In Section 3.5, we discuss a scalarisation
approach that turns the multiobjective goal into a single
objective that still encourages exploring the Pareto front.
3.3

Search space

Here, neural networks are directed acyclic graphs (DAGs),
with nodes and edges representing operators (layers) and
their connectivity. For convolutional neural networks
(CNNs), operator options include convolution (at different kernel sizes, numbers of channels or strides), pooling,
addition and matrix multiplication (fully-connected layers).
State-of-the-art GPU-level CNNs can contain a large number of operators, e.g. > 100 layers (He et al., 2016). If
architecture search were to be used to design a comparably
large model while having full freedom over layer connectivity, the problem would become intractable due to the size of
the search space. Instead, some NASes constrain the space
to 1 or 2 small “cells” (micro-architectures) to curb the number of connectivity options (Liu et al., 2018). These cells are
then replicated in a predeﬁned pattern to produce the ﬁnal
architecture (macro-architecture). Alternatively, the search
space can contain pruned versions of some predeﬁned large
super-architecture (Guo et al., 2019; Lin et al., 2020a).

However, NAS is known to ﬁnd good performing architectures that are wired in unexpected ways (Cheng et al., 2019).
So to give µNAS more freedom when searching under already tight resource requirements, we avoid imposing big
structural constraints. As one would not expect to run large
models on an MCU (they would violate the resource constraints), allowing more options in layer connectivity here
does not make the search problem intractable.
MCU-level architectures are very sensitive to layer hyperparameters, such as the numbers of channels or units in convolutional and fully-connected layers. For example, choosing
between a conv. layer with 172 and 192 channels is unlikely to make a meaningful difference for a GPU-sized
model (though the former may have lower accuracy), but on
an MCU choosing the larger layer may tip the model over
the strict memory budget. This requires considering hyperparameters at a high granularity, which is not commonly
needed for GPU-level NAS and has the negative effect of
enlarging the search space.
Thus we conclude that a sensible MCU search space would
consist of small models, with few restrictions on layer connectivity and highly granular hyperparameter options. The
search algorithms (described in Section 3.5) navigate the
search space by generating random architectures and applying changes to them (morphisms) to produce derivative
(child) networks. Morphisms here only affect the architecture: we do not attempt to preserve and transform learned
weights between the parent and the child networks.
Our search space, together with all degrees of freedom,
parameter limits and morphisms, is given in Table 1. This
highly granular search space comprises 1.15×10152 models.
3.4 Resource constraints
We focus on three constraints to be used in the search, each
representing a key aspect of resource scarcity on MCUs:
peak memory usage, model size and latency.
Peak memory usage. Under the execution strategy described earlier, an operator’s input and output buffers have
to be present in memory during its execution. Additionally,
depending on the architecture of the network, there can be
other buffers in memory that will be required by subsequent
operators and thus cannot be deallocated yet. Overall, let us
call the set of tensors that need to be present in memory at
each step the working set.
As execution proceeds, tensors are allocated and deallocated
at different times, changing the working set. To execute the
model on an MCU, the memory occupied by the working set
at its peak must be lower than the amount of SRAM.
Perhaps surprisingly, it is not straightforward to compute
the peak memory usage of a network when it has branches.

µNAS: Constrained Neural Architecture Search for Microcontrollers

Degree of freedom

Options

Morphisms

An architecture is N “convolutional” blocks, where each:
• connects either in series or in parallel to the previous one
• has M convolution layers, where each layer:
• optionally, has a preceding 2×2 max-pooling operation;
• is either a full or a depthwise convolution with stride S, C
channels K×K kernel size (S = 1 for 1×1 convolution and C is
not conﬁgured for depthwise convolution)

N in [1; 10]
{parallel, serial}
M in [1; 3]
{yes, no}
{full, d/wise}
K in {1, 3, 5, 7}
C in [1; 128]
S in {1, 2}
{yes, no}
{yes, no}
{avg, max}
P in {2, 4, 6}
F in [1; 3]
U in [10; 256]

append or remove random
change one to other
insert or remove random
change one to other
change types
change K by ± 2
change C by ± 1, 3, 5
change S by ± 1
change one to other
change one to other
change one to other
change P by ± 2
insert or remove random
change U by ± 1, 3, 5

•
•

is optionally followed by batch norm.;
is optionally followed by ReLU;

followed by a P ×P average or maximum pooling,

followed by F fully-connected layers, where each:
• has U units (output dimension), followed by a ReLU
followed by a ﬁnal fully-connected layer (U = number of classes).

Table 1. A template for candidate models, with free variables, their morphisms and bounds, which deﬁne the search space of µNAS.

1
2

4

3

6

4

2

5

3

6

5

7

7

PMU:
5216 B

PMU:
4960 B

1

1

ult

fa
De

1
Conv2D
1x1

d

ise
tim
Op
1

7×7×32

To achieve this, we build upon the algorithm by Liberis &
Lane (2019), which enumerates all topological orders of a
network’s computational graph to ﬁnd one that yields the
minimal peak memory usage. We extend it to model other
features, such as reusing input buffers of an ‘Add’ operator.

7×7×64

2
Conv2D
1x1
7×7×32

3
Conv2D
3x3 d/wise

4
Conv2D
3x3 d/wise

4×4×32

4×4×32

5
Conv2D
1x1
4×4×16

To the best of our knowledge, this is the ﬁrst work to compute memory usage accurately during the search, without
relying on on-device benchmarking (that is often slow) or
using under-approximations. Later (Section 3.5), we will
discuss that it is reasonable to assume that the most performant networks will have high resource usage. This makes a
precise memory usage computation essential in identifying
which candidate networks lie just below the resource limits.

6
Conv2D
1x1
4×4×16

7
Concat
4×4×32

2

3

2

that gives the smallest peak working set size.

6

Figure 1. An example computation graph where the default and optimised execution paths yield different peak memory usage (PMU)

Branches are commonly featured in popular CNNs as
residual connections (He et al., 2016), Inception modules (Szegedy et al., 2015), or NAS-designed cells (Cheng
et al., 2019). Here’s why: upon reaching a branching point,
the inference framework has a choice which operator to execute next. Different execution orders change which tensors
constitute the working set, which in turn affects the peak
memory usage (see example in Figure 1). Thus, to most accurately capture the minimum amount of memory required
to run a network, a NAS has to compute an execution order

Model size. All static data, such as code and parameters
(weights) of a neural network, are stored in the persistent
(Flash) memory of an MCU. Traditionally, each parameter
is represented by a 32-bit ﬂoating-point number (a float),
which occupies 4 bytes. However, we can reduce the perparameter storage requirement by using quantisation.
We assume an integer-only quantisation technique used in
TensorFlow Lite, which quantises each parameter from 32bit ﬂoats to 8-bit integers after training (by calibrating quantisation parameters on the validation set). This is an excellent choice for microcontrollers, as it is: (a) byte-aligned
(thus a value can be loaded directly with no decoding), (b)
does not require any ﬂoating-point arithmetic units to be
present on the chip, (c) is also widely adopted and (d) does
not make networks suffer from accuracy loss during quantisation (conﬁrmed by our and MCUNet (Lin et al., 2020a)
experiments). If needed, µNAS can be easily adapted for
other quantisation techniques.

µNAS: Constrained Neural Architecture Search for Microcontrollers

Thus to compute the storage requirement, NAS simply
counts the number of parameters of a neural network at
8 bits = 1 byte per parameter.

We settle on using a number of multiply-accumulate operations (MACs) as a proxy for model latency. To verify that
this estimator approximates actual model latency well, in
Figure 2, we plot the measured runtime of a 1000 random
models from our search space and versus the number of
MAC operations. For reference, we reproduce the ﬁgure
from BRP-NAS (Chau et al., 2020) to show how the number of FLOPs compares to latency on a desktop GPU. We
observe that MACs are not systematically under- or overapproximating latency on an MCU, and the result has an
R2 = 0.975 goodness-of-ﬁt.
3.5

Search algorithms

Intuitively, because performant neural networks are large,
we would expect the best architectures to make use of all
available resources and thus be located at a boundary between models that ﬁt within the resource constraints and
ones that do not. By design of the search space (both
ours and others), a change in a single axis (degree of freedom) can signiﬁcantly change layer properties and interconnectivity, thus potentially drastically altering the model’s
resource requirements and accuracy. This makes the boundary jagged, rendering multiobjective NAS a challenging task
for black-box optimisation methods.
Now, we establish a way to handle multiple objectives in
a single goal and discuss two optimisation algorithms implemented in µNAS: aging evolution (AE) and Bayesian op5

https://www.st.com/en/evaluation-tools/
nucleo-h743zi.html

�
�
�
�
�

�

���

���
���������

���

���

����������������������������

���
���

������������

Using a predictive model has become the dominant approach
for GPU-/mobile-level NAS (Tan et al., 2019; Chau et al.,
2020), as proxy metrics, such as FLOPs, fail to account for
scheduling, caching, parallelism and other properties of the
inference software or hardware. However, MCUs typically
lack these performance-enhancing features: the software
runs on a single-core processor at a ﬁxed frequency with no
data caching, which makes modelling the runtime simpler.

������������

Latency. In order to discover models that run sufﬁciently
quickly on an MCU, NAS has to have a notion of how
long it takes to perform a single inference: model latency.
Some NAS works have estimated latency by either using
a proxy metric, such as the number of ﬂoating-point operations (FLOPs) required to complete a forward pass (Mei
et al., 2019; Xie et al., 2018) or predicting the latency via a
surrogate model. The latter can be either a sum of latency
predictions of each layer or a prediction for a whole model
which takes into account inter-layer interactions (Chau et al.,
2020; Cai et al., 2018).

�����������������������������

��

���

��
� �

���

�

���
�

�

��

��
��
��������

��

Figure 2. (Top) A typical plot of FLOPs vs model latency on a
desktop GPU, reproduced with permission from Chau et al. (2020).
(Bottom) Our measured MACs vs model latency on a sample
of 1000 models from our search space. The models ran on a
NUCLEO-H743ZI25 MCU board using the TensorFlow Lite Micro
runtime. The values were averaged over ten runs. The data shows
that MACs are a good predictor of model latency on MCUs.

timisation (BO). Despite being inherently sequential, both
AE and BO allow for parallel point evaluation (Real et al.,
2019; Kandasamy et al., 2018a), allowing us to scale the
search over multiple GPUs. We compare the two in our
experiments to discover the best performing approach.
Handling multiple objectives. Akin to SpArSe, we use
random scalarisations (Paria et al., 2020, TS expression) to
combine multiple objectives into a single goal (the optimisation target function).
 t
λ1 (1.0 − VAL ACCURACY(α)),



λt P EAK M EM U SAGE(α),
2
Lt (α) = max
t

λ

3 M ODEL S IZE (α),

 t
λ4 MAC S(α)

(2)

Each objective has an associated scalar term λti , which speciﬁes its relative importance in the current search goal. To encourage the exploration of the Pareto front, the goal changes
at every search round (indexed by t) by resampling coefﬁcients λt . The trade-off preferences between multiple

µNAS: Constrained Neural Architecture Search for Microcontrollers

objectives can be encoded in the distribution for λ: we use
1/λi ∼ Uniform[0; b], where b is a user-speciﬁed soft upper
bound for the ith objective.
NAS via local search. Local search optimises the goal
function by repeatedly evolving a set of candidate points.
We use aging evolution (AE) as a local search algorithm
for NAS (Real et al., 2019). AE operates by keeping a
population of P architectures and, at each search round,
subsampling the population to get S architectures to choose
the one that gives the smallest value of Lt (α). A random
morphism is then applied to this winning architecture to
produce an offspring, which is then evaluated and added
to the population, replacing the oldest architecture. Aging
evolution has proved itself a competitive search algorithm
for NAS, beating many baselines and random search.
NAS via Bayesian optimisation. Bayesian optimisation
(BO) uses surrogate models to approximate the target function and guide the search towards promising unexplored
regions of its domain. BO is successfully used in hyperparameter optimisation (Falkner et al., 2018) and NAS (Jin
et al., 2019), often using Gaussian Processes (GPs) as a
surrogate model for the accuracy of a neural network.

We use structured pruning, which eliminates entire groups of
parameters: channels (in conv. layers) or units/neurons (in
fully-connected layers), resulting in smaller dense models,
as opposed to sparsifying the weight matrices. This makes
the search and the pruning share the task of determining
the model’s hyperparameters: the search produces a base
network, which is then adjusted by pruning in a more informed way by discarding channels/units that were deemed
unimportant during training.
µNAS employs DPF pruning (Lin et al., 2020b) which uses
the L2 norm of channels/units to discard weight groups until
the desired proportion of groups is removed. µNAS sets this
target “sparsity” proportion and the network is gradually
pruned during training until the target proportion is reached.
3.7 Summary of the µNAS search procedure
As an example, let us walk through the search procedure
when µNAS is used with aging evolution (AE) and pruning:
1. AE initialisation. A random initial population of networks is generated and trained, together with their
target “sparsity” values (random in the allowed range).
2. Preamble. A new search step t begins by generating a new goal function. This is done by resampling
coefﬁcients λ in Equation 2.
3. Search algorithm body. The search proceeds by the
rules of AE: the next architecture to be trained is determined by applying a random morphism (Table 1) to
the chosen parent. The target “sparsity” level for the
new model is inherited and randomly perturbed.
4. Write back. Once the training and pruning are complete, the values of all four objectives of the pruned
network (the ﬁnal accuracy, peak memory usage, storage usage and the number of MACs) are recorded, and
the network is added to the population. A new round
starts from step 2.

In µNAS, at each step of the search, BO decides which architecture to evaluate next by optimising the target function
(Lt ), with the only difference that VAL ACCURACY(θ) is
computed by sampling from the GP that approximates it
(other objectives are cheap to compute and thus do not require a surrogate model, unlike in SpArSe). GPs require a
kernel that captures the notion of similarity between any two
neural networks. For this, we build upon NASBOT (Kandasamy et al., 2018b), which uses optimal transport to deﬁne
a distance function between two computational graphs of
neural networks; we update the kernel to include free variables of our search space.
3.6

Model compression

Model compression methods, such as pruning, quantisation,
cheaper building blocks and distillation attempt to create
or train a smaller model using a bigger more performant
model, while retaining as much of the predictive performance as possible. Parameter-efﬁcient convolutional blocks,
such as inverted residual blocks of MobileNet V2 (Sandler
et al., 2018), and ﬁre modules of SqueezeNet (Iandola et al.,
2016), are already representable in the search space, allowing µNAS to recover them if necessary.
µNAS supports using model compression during the search:
in particular, we hypothesise that network pruning would
help in ﬁnding small architectures with high accuracy—we
will empirically determine this in our experiments.
Pruning. Pruning removes individual parameters from a
neural network that do not signiﬁcantly affect generalisation.

4

E VALUATION

The aim of the evaluation is twofold:
1. To show that all components of µNAS are required
for obtaining small, performant models. The design
of µNAS is empirically validated through ablation studies. Namely, we address: (a) whether aging evolution
or Bayesian optimisation perform better at discovering
the Pareto front; (b) whether including pruning yields
more performant small models; (c) we check the utility
of including both model size and peak memory usage
objectives by searching without either.
2. To show that µNAS produces superior models, as
compared to previous work on CNNs for MCUs.

µNAS: Constrained Neural Architecture Search for Microcontrollers
�����

���������������������������������������������������
���������������
����������������
������������

�����

�����

���������������
����������������
������������

����
����

�����

����

����
�
����

������������������������������������������������

����������

����������

�����

����

����

����

����

����
����
����������

����

����

�
����

����

����

����

����������

����

����

����

Figure 3. (Left) error rate vs size of models discovered by µNAS on the Chars74K dataset; (Right) ditto for the MNIST dataset. The
results show that µNAS conﬁgured with aging evolution and pruning ﬁnds the furthest advanced Pareto front.

4.1

Datasets

We evaluate µNAS on ﬁve image classiﬁcation problems:
MNIST (LeCun & Cortes, 2010), CIFAR-10 (Krizhevsky,
2009), Chars74K (De Campos et al., 2009) (English subset:
26 uppercase and 26 lowercase letters + 10 digits), Fashion
MNIST (Xiao et al., 2017) and Speech Commands (Warden,
2018). Datasets are split into training, validation and test
sets, with the validation set used for evaluating objectives
and tuning hyperparameters. Accuracy results are reported
on the unseen test set.
To compare with related work, “binary” versions of
Chars74K and CIFAR-10 are included, which have images
partitioned into two subclasses. All details on experiment
conﬁguration, dataset preprocessing and optimiser parameters are given in Appendix A. As far as we aware, the full
Chars74K or Fashion MNIST datasets do not have strong
low resource usage baselines to compare against. Except for
CIFAR-10, µNAS was run for 2000 steps, taking 2-10 GPU
days depending on the dataset. We set resource requirements
to either less than 64 KB of peak memory usage and storage,
corresponding to our target MCUs, or less than 2KB, when
required for comparison. We also perform experiments on
searching for sparse models (Appendix B).
4.2

Determining the best µNAS conﬁguration

µNAS can use both AE and BO as a search algorithm and
optionally use pruning during the search. We would like
to determine which implemented conﬁguration yields the
best results for ﬁnding models with low resource usage
and should therefore be used for further experiments. To
do so, we run µNAS in three conﬁgurations on Chars74K
and MNIST datasets: (1) plain aging evolution (AE); (2)
plain Bayesian optimisation (BO); (3) AE with pruning.
Figure 3 shows the model size vs error rate (1.0 − accuracy)
of discovered models for each conﬁguration. The lower-left
corner of the plot contains models with low error and low
resource usage; the further the Pareto front (highlighted in

the plots) extends into that corner area, the better size vs
accuracy trade-off µNAS is able to discover.
Search algorithm comparison shows that AE discovers a
further advanced Pareto front than BO. We hypothesise that
BO performs worse due to a smooth approximation to a
network’s accuracy (GPs) being inadequate to capture the
subtle differences between networks in the search space, especially when few points are available to build the surrogate
in the initial stages of the search.
We also observed that BO completes fewer search rounds
compared to AE in the same allotted time. This is due to
an added computational burden of (a) computing resource
usage of many models when optimising an acquisition function, (b) updating the posterior model and (c) computing the
kernel function after each new model has been trained.
The data shows that pruning is essential for ﬁnding models
with low resource usage and AE with pruning outperforms
other conﬁgurations implemented in µNAS. Therefore, AE
with pruning (the search procedure summarised earlier in
Section 3.7) is the strongest and default design choice and
will be used in further experiments.
4.3

The utility of resource objectives

Having developed precise resource usage computations, we
would like to check whether including them actually provides meaningful input to the search by guiding it towards
low resource usage models.
Here, we will observe how model size (MS) and peak memory usage (PMU) objectives inﬂuence the search. We run
µNAS on MNIST in three modes: all constraints present,
no model size (MS) constraint, and no peak memory usage
(PMU) constraint. We expect these three regimes to exhibit a
difference in the kinds of models found by µNAS: the PMU
objective should drive the search towards narrow models (a
lower memory bottleneck), MS—towards shallow models
(fewer layers); when both are present, a trade-off between

µNAS: Constrained Neural Architecture Search for Microcontrollers

��������������������������������������
��

�

��

�

��

�������������������������������

����
�����������������
����������

��

�

��

�

�

��

�

��

�

��

�

��

�

��

�

����

����
����������

����

����

����
�����������������
����������

����
����������

����

Figure 4. Error rate vs resource usage of MNIST models when (left) model size was unconstrained, (middle) peak memory usage was
unconstrained, (right) all constraints were present. Each architecture produces 3 data points: one for each metric (colour). The plots
show that both peak memory usage and model size objectives are inﬂuential and informative for the search.

low resource usage and accuracy should be discovered.
Found models are presented in Figure 4. We do not use
pruning and set a generous latency constraint to avoid introducing any additional bias to the results. The data supports the hypothesis above, showing that both objectives
are needed for the search: (a) when MS is unconstrained,
the search is dominated by the PMU constraint and driven
to models with low memory usage; this also implies high
accuracy, since it is possible to generate deep and narrow
networks with high model size but a low memory bottleneck; (b) when PMU is unconstrained, the search is driven
to models with low MS and average PMU; (c) when both
objectives are present, µNAS discovers a variety of trade-off
points between accuracy and resource usage, with models
that have low to moderate PMU and MS.
4.4

Discovered architectures

Table 2 shows networks discovered by µNAS. For each task,
we present a baseline model at multiple objective trade-off
points, together with a model discovered by µNAS that either improves upon or closely match on all (known) metrics.
The data shows that µNAS can discover truly tiny models,
advancing the state-of-the-art for MCU deep learning for 6
out of 7 tasks considered. The models are trainable from
scratch with pruning, and are within our assumed constraints
of “mid-tier” MCUs with a 64 KB memory and storage limit.
The results show: (a) an improved top-1 classiﬁcation accuracy by up to 4.8% for the same memory and/or model size
footprint (see MNIST; CIFAR-10 (bin.), Chars74K (bin.);
Speech Commands), or (b) a reduced memory footprint
by 4–13× while preserving accuracy (see MNIST, Speech
Commands, Fashion MNIST), or (c) a reduced number of
MACs by ≈1700× (see Speech Commands).
Targeting Speech Commands in particular shows the impor-

tance of considering MACs during the search: even when
model size and accuracy are comparable with the baselines,
there is scope for discovering models that are orders of magnitude faster (in MACs). For MNIST, the search found a
pruned (yet still dense) model with < 0.5 KB parameters
and > 99% accuracy. Earlier, Figure 3 showed that µNAS
discovered many models in this area of the accuracy-size
trade-off for MNIST, conﬁrming that this is not an outlier.
For CIFAR-10, µNAS is able to outperform the baseline for
the binary dataset; however, it falls short compared to the
models discovered by LEMONADE (Elsken et al., 2018) for
a full (10-class) dataset. Upon closer investigation, we ﬁnd
that the µNAS search does gradually push the Pareto front,
but requires many steps to do so (the search took 6000 steps,
≈30 GPU-days). We discuss this effect in the following
section and predict that if µNAS is given more search time,
it can discover better models for CIFAR-10. After all, it is
not uncommon to run aging evolution for tens of thousands
of steps (Real et al., 2019).

5

D ISCUSSION

We have both qualitatively and quantitatively justiﬁed the
design decisions made in µNAS, showing that it is able
to ﬁnd accurate yet small models, suitable for deployment
on microcontrollers. We now discuss overarching points
relating to µNAS and how it can be modiﬁed in future work.
5.1 Convergence of aging evolution
CIFAR-10 experiments showed that the search is slow at
advancing the Pareto front. We found that this is due to the
search space being too granular: while considering hyperparameters and morphisms at a high granularity is instrumental
for ﬁnding tiny models (see, for example, MNIST and other
results), it also makes the search less efﬁcient by requiring
multiple steps to change any candidate model in the popula-

µNAS: Constrained Neural Architecture Search for Microcontrollers
Dataset

Model

Accuracy (%)

Model size

RAM usage

MACs

Difference

MNIST

SpArSe (Fedorov et al., 2019)
SpArSe
BonsaiOpt (Kumar et al., 2017)
ProtoNN (Gupta et al., 2017)
µNAS (ours)

98.64
96.49
94.38
95.88
99.19

2770
1440
490
63’900
480

≥ 1960 B
≥ 1330 B
< 2000 B
< 64’000 B
488 B

unk.
unk.
unk.
unk.
28.6 K

Size ↑ 5.7×
Acc. ↓ 2.7%
Acc. ↓ 4.8%
Acc. ↓ 3.3%

CIFAR-10
(binary)

SpArSe
µNAS (ours)

73.84
77.49

780
685

≥ 1280 B
909 B

unk.
41.2 K

Acc. ↓ 3.7%

Chars74K
(binary)

SpArSe
µNAS (ours)

77.78
81.20

460
390

≥ 720 B
867 B

unk.
107 K

Acc. ↓ 3.4%

Speech
Commands

RENA (Zhou et al., 2018)
µNAS (ours)

94.04
94.11

47 K
41 K

unk.
21.6 KB

≈700 M
1.5 M

Size. ↑ 1.2×

DS-CNN (Zhang et al., 2017)
µNAS (ours)

93.39
92.31

23 K
21 K

unk.
52.8 KB

≈3’035 M
1.7 M

MACs ↑ 1785×

RENA
µNAS (ours)

94.82
95.26

67 K
56 K

unk.
11.5 KB

≈3’265 M
3.6 M

Size. ↑ 1.2×

≈91.20
≈95.91
95.60

<1M
<1M
95 K

80 KB
311 KB
23.8 KB

unk.
unk.
6.8 M

Acc. ↓ 4.4%
RAM ↑ 13×

92.50
93.22

≈100 K
63.6 K

unk.
12.6 KB

unk.
4.4 M

Size. ↑ 1.6×

≈91.77
86.79

10 K
17.4 K

unk.
15.8 KB

unk.
401 K

82.65
76.05

3.85 K
13.9 K

9.75 KB
1.81 KB

279 K
111 K

MCUNet (Lin et al., 2020a)
MCUNet
µNAS (ours)
Fashion
MNIST

reported6
µNAS (ours)

CIFAR-10

LEMONADE (Elsken et al., 2018)
µNAS (ours)

Chars74K

µNAS (ours)
µNAS (ours)

Acc. ↓ 5%

Table 2. Pareto-optimal architectures discovered by µNAS vs others. The difference column compares a baseline to a model discovered
by µNAS in the group (the last line of each group). “Unknown (unk.)” denotes data not reported by the authors. The results show that
µNAS outperforms most baselines by either improving accuracy for comparable resource usage or vice versa.

tion signiﬁcantly. Slow convergence is also likely to occur
for large ImageNet-based image classiﬁcation tasks, such as
Visual Wake Words (Chowdhery et al., 2019), exacerbated
by the fact that candidate models would also take longer
to train (up to an hour) than on CIFAR-10. Thus, while
using an evolutionary local search algorithm (like AE) on
this search space yields small and performant models, the
search can be time-consuming.
If search time is an issue, we envision the above being rectiﬁed by: (a) not using the same search space throughout the
entire search process, for example, by using a parametrised
space where granularity can vary throughout the search;
or (b) guiding the search, such as by using ranking models (Chau et al., 2020); or (c) employing weight sharing to
amortise the cost of training each candidate network.
5.2

Reusability of µNAS components

We demonstrated that satisfying two previously identiﬁed
design requirements (Section 3)—having a granular search
6
https://github.com/zalandoresearch/
fashion-mnist

space and an accurate resource usage computation—leads to
a NAS that can discover performant MCU-sized networks.
Overall, µNAS is modular: the search algorithm, objective
scalarisation, the search space, the computation of resource
usage and model compression (pruning) are all independent
of each other and can be reused elsewhere or swapped out,
for example, if a different network execution strategy is
assumed or should a different search algorithm be needed.
We make the source code of µNAS available publicly.7

6

C ONCLUSIONS

Neural architecture search is a powerful tool for automating
model design, especially when designing networks manually is challenging due to the need to balance high accuracy
and ﬁtting within extremely tight resource constraints. We
showed that through the suitable design of the search space,
search algorithm and explicit targeting of the three primary
resource bottlenecks, we are able to create a NAS system,
µNAS, that discovers resource-efﬁcient microcontrollerfriendly models for a variety of image classiﬁcation tasks.
7

(In progress. URL to be provided after review.)

µNAS: Constrained Neural Architecture Search for Microcontrollers

R EFERENCES
Cai, H., Zhu, L., and Han, S. ProxylessNAS: Direct neural
architecture search on target task and hardware. arXiv
preprint arXiv:1812.00332, 2018.
Chau, T., Dudziak, Ł., Abdelfattah, M. S., Lee, R., Kim, H.,
and Lane, N. D. BRP-NAS: Prediction-based NAS using
GCNs. arXiv preprint arXiv:2007.08668, 2020.
Cheng, H.-P., Zhang, T., Yang, Y., Yan, F., Li, S., Teague, H.,
Li, H., and Chen, Y. SwiftNet: Using graph propagation
as meta-knowledge to search highly representative neural
architectures. arXiv preprint arXiv:1906.08305, 2019.
Cheng, Y., Wang, D., Zhou, P., and Zhang, T. A survey
of model compression and acceleration for deep neural
networks. arXiv preprint arXiv:1710.09282, 2017.
Chowdhery, A., Warden, P., Shlens, J., Howard, A., and
Rhodes, R. Visual wake words dataset. arXiv preprint
arXiv:1906.05721, 2019.
De Campos, T. E., Babu, B. R., Varma, M., et al. Character
recognition in natural images. VISAPP (2), 7, 2009.
Elsken, T., Metzen, J. H., and Hutter, F. Efﬁcient multiobjective neural architecture search via Lamarckian evolution. arXiv preprint arXiv:1804.09081, 2018.
Elsken, T., Metzen, J. H., and Hutter, F. Neural architecture
search: A survey. Journal of Machine Learning Research,
20(55):1–21, 2019.
Falkner, S., Klein, A., and Hutter, F. Bohb: Robust and
efﬁcient hyperparameter optimization at scale. arXiv
preprint arXiv:1807.01774, 2018.
Fedorov, I., Adams, R. P., Mattina, M., and Whatmough,
P. SpArSe: Sparse architecture search for CNNs on
resource-constrained microcontrollers. In Advances in
Neural Information Processing Systems, pp. 4977–4989,
2019.
Fernandez-Marques, J., Whatmough, P. N., Mundy, A., and
Mattina, M. Searching for Winograd-aware quantized
networks. arXiv preprint arXiv:2002.10711, 2020.
Grand View Research. Microcontroller Market Size,
Share & Trends Analysis Report By Product (8bit, 16-bit, 32-bit), By Application (Automotive,
Consumer Electronics, Industrial, Medical Devices,
Military & Defense), And Segment Forecasts, 2020–
2027.
https://www.grandviewresearch.
com/industry-analysis/
microcontroller-market
(Accessed
Aug
2020), 2020.

Guo, Z., Zhang, X., Mu, H., Heng, W., Liu, Z., Wei, Y., and
Sun, J. Single path one-shot neural architecture search
with uniform sampling. arXiv preprint arXiv:1904.00420,
2019.
Gupta, C., Suggala, A. S., Goyal, A., Simhadri, H. V., Paranjape, B., Kumar, A., Goyal, S., Udupa, R., Varma, M.,
and Jain, P. ProtoNN: Compressed and accurate knn for
resource-scarce devices. In International Conference on
Machine Learning, pp. 1331–1340, 2017.
He, K., Zhang, X., Ren, S., and Sun, J. Deep residual learning for image recognition. In Proceedings of the IEEE
conference on computer vision and pattern recognition,
pp. 770–778, 2016.
Hsu, C.-H., Chang, S.-H., Liang, J.-H., Chou, H.-P., Liu,
C.-H., Chang, S.-C., Pan, J.-Y., Chen, Y.-T., Wei, W., and
Juan, D.-C. MONAS: Multi-objective neural architecture search using reinforcement learning. arXiv preprint
arXiv:1806.10332, 2018.
Iandola, F. N., Han, S., Moskewicz, M. W., Ashraf, K.,
Dally, W. J., and Keutzer, K. SqueezeNet: AlexNet-level
accuracy with 50x fewer parameters and < 0.5 MB model
size. arXiv preprint arXiv:1602.07360, 2016.
Jacob, B., Kligys, S., Chen, B., Zhu, M., Tang, M., Howard,
A., Adam, H., and Kalenichenko, D. Quantization
and training of neural networks for efﬁcient integerarithmetic-only inference. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition,
pp. 2704–2713, 2018.
Jin, H., Song, Q., and Hu, X. Auto-keras: An efﬁcient neural
architecture search system. In Proceedings of the 25th
ACM SIGKDD International Conference on Knowledge
Discovery & Data Mining, pp. 1946–1956, 2019.
Kandasamy, K., Krishnamurthy, A., Schneider, J., and
Póczos, B. Parallelised Bayesian optimisation via Thompson sampling. In International Conference on Artiﬁcial
Intelligence and Statistics, pp. 133–142, 2018a.
Kandasamy, K., Neiswanger, W., Schneider, J., Poczos, B.,
and Xing, E. P. Neural architecture search with bayesian
optimisation and optimal transport. In Advances in neural
information processing systems, pp. 2016–2025, 2018b.
Krizhevsky, A. Learning multiple layers of features from
tiny images. Technical report, 2009.
Kumar, A., Goyal, S., and Varma, M. Resource-efﬁcient
machine learning in 2 kb ram for the internet of things.
In International Conference on Machine Learning, pp.
1935–1944, 2017.

µNAS: Constrained Neural Architecture Search for Microcontrollers

LeCun, Y. and Cortes, C. MNIST handwritten digit
database. 2010. URL http://yann.lecun.com/
exdb/mnist/.

neural architecture search for mobile. In Proceedings of
the IEEE Conference on Computer Vision and Pattern
Recognition, pp. 2820–2828, 2019.

Liberis, E. and Lane, N. D. Neural networks on microcontrollers: saving memory at inference via operator reordering. arXiv preprint arXiv:1910.05110, 2019.

Warden, P.
Speech commands: A dataset for
limited-vocabulary speech recognition. arXiv preprint
arXiv:1804.03209, 2018.

Lin, J., Chen, W.-M., Lin, Y., Cohn, J., Gan, C., and Han,
S. Mcunet: Tiny deep learning on iot devices. arXiv
preprint arXiv:2007.10319, 2020a.

Xiao, H., Rasul, K., and Vollgraf, R. Fashion-MNIST: a
novel image dataset for benchmarking machine learning
algorithms. arXiv preprint arXiv:1708.07747, 2017.

Lin, T., Stich, S. U., Barba, L., Dmitriev, D., and Jaggi, M.
Dynamic model pruning with feedback. arXiv preprint
arXiv:2006.07253, 2020b.

Xie, S., Zheng, H., Liu, C., and Lin, L.
SNAS:
stochastic neural architecture search. arXiv preprint
arXiv:1812.09926, 2018.

Liu, H., Simonyan, K., and Yang, Y. DARTS: Differentiable
architecture search. arXiv preprint arXiv:1806.09055,
2018.

Zhang, Y., Suda, N., Lai, L., and Chandra, V. Hello Edge:
Keyword spotting on microcontrollers. arXiv preprint
arXiv:1711.07128, 2017.

Mei, J., Li, Y., Lian, X., Jin, X., Yang, L., Yuille, A., and
Yang, J. AtomNas: Fine-grained end-to-end neural architecture search. arXiv preprint arXiv:1912.09640, 2019.

Zhou, Y., Ebrahimi, S., Arık, S. Ö., Yu, H., Liu, H., and
Diamos, G. Resource-efﬁcient neural architect. arXiv
preprint arXiv:1806.07912, 2018.

Mocerino, L. and Calimera, A. CoopNet: Cooperative
convolutional neural network for low-power MCUs. In
2019 26th IEEE International Conference on Electronics,
Circuits and Systems (ICECS), pp. 414–417. IEEE, 2019.

Zoph, B. and Le, Q. V. Neural architecture search with
reinforcement learning. arXiv preprint arXiv:1611.01578,
2016.

Paria, B., Kandasamy, K., and Póczos, B. A ﬂexible framework for multi-objective bayesian optimization using random scalarizations. In Uncertainty in Artiﬁcial Intelligence, pp. 766–776. PMLR, 2020.
Pham, H., Guan, M., Zoph, B., Le, Q., and Dean, J. Efﬁcient neural architecture search via parameters sharing.
volume 80 of Proceedings of Machine Learning Research
(PMLR), pp. 4095–4104, 2018.
Real, E., Aggarwal, A., Huang, Y., and Le, Q. V. Regularized evolution for image classiﬁer architecture search. In
Proceedings of the AAAI conference on artiﬁcial intelligence, volume 33, pp. 4780–4789, 2019.
Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., and
Chen, L.-C. MobileNet V2: Inverted residuals and linear
bottlenecks. In Proceedings of the IEEE conference on
computer vision and pattern recognition, pp. 4510–4520,
2018.
Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S.,
Anguelov, D., Erhan, D., Vanhoucke, V., and Rabinovich,
A. Going deeper with convolutions. In Proceedings
of the IEEE conference on computer vision and pattern
recognition, pp. 1–9, 2015.
Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M.,
Howard, A., and Le, Q. V. MNasNet: Platform-aware

µNAS: Constrained Neural Architecture Search for Microcontrollers

A

E XPERIMENT CONFIGURATION

Dataset

Model

A.1

Resource bound conﬁgurations

Chars74K
CIFAR-10
(binary)

In µNAS, we control which area of the Pareto front gets
explored by specifying a preferred trade-off between objectives. The objective scalarisation (Equation 2) together with
coefﬁcient sampling force the search to highly penalise any
objectives that exceed their speciﬁed bound, and not preferentially penalise any objective that is within its bounds. We
give our requested bounds in Table 3.
Requested objective bounds
Error

Peak memory

Model size

MACs

MNIST
< 0.0350

< 2.5 KB

< 4.5 K

< 30 M

Chars74K
< 0.3000

< 10 KB

< 20 K

<1M

CIFAR-10
< 0.1800

< 75 KB

< 75 K

< 30 M

Speech Commands
< 0.0850
< 60 KB

< 40 K

< 20 M

Fashion MNIST
< 0.1000
< 64 KB

< 64 K

< 30 M

Table 3. Resource bounds requested from µNAS for each dataset.

A.2

Dataset preprocessing and model training
schedule

Dataset preprocessing, as well as model training and pruning
information, is given in Table 5 (see next page).
Additional notes: Models CIFAR-10 and Fashion MNIST
also have a Dropout layer w/ rate = 0.15 inserted before
every fully-connected layer, except the last one. The models
have been quantised for comparison against baselines in
Table 2 after training and, like Lin et al. (2020a), we observe no loss in accuracy. This is not surprising due to the
full-integer quantisation in TensorFlow Lite (Jacob et al.,
2018) being very expressive: at a cost of extra operations, it
allows to represent any ﬁnite range in 256 steps (for 8-bit
quantisation), and weight decay used during encourages
model weights to stay within reasonable bounds.

B

S PARSE MODELS

Sparse neural networks allow for an even more signiﬁcant
reduction of model size without sacriﬁcing accuracy. To
7
https://github.com/tensorflow/
tensorflow/blob/master/tensorflow/examples/
speech_commands/input_data.py

MNIST

Accuracy (%)

Size

SpArSe
µNAS (ours)

67.82
72.40

1.7 K
1.62 K

SpArSe
µNAS (ours)

81.77
82.69

3.2 K
2.23 K

SpArSe
µNAS (ours)

76.66
76.72

1.4 K
0.94 K

SpArSe
µNAS (ours)

99.16
99.19 (dense)

1K
480

Table 4. Sparse models found by µNAS vs others. Results show
an increased accuracy delivered by µNAS for a comparable
model size, or a smaller model size for comparable accuracy.

compare our models with the SpArSe NAS (Fedorov et al.,
2019), we also allow µNAS to perform unstructured pruning
using the same pruning method described in Section 3.6,
which results in models with sparse weight matrices. As
opposed to dense operations which had been assumed so far,
sparse models are executed using sparse matrix multiplications. Thus previously considered latency and peak memory
usage constraints would no longer be accurate and are not
included.
µNAS search results for sparse models are presented in
Table 4. Results show an increased accuracy delivered by
µNAS for a comparable model size (up to 4.6%), or a smaller
model size (up to two-fold) for comparable accuracy, depending on the task.

µNAS: Constrained Neural Architecture Search for Microcontrollers

Dataset

Data preprocessing
and augmentation

MNIST

SGDW:
• learning rate = 0.005,
• random rotate by +/- 0.2 rad with p = 0.3;
• momentum = 0.9,
• random shift (2, 2);
• weight decay = 4e-5;
• random ﬂip L/R
• epochs = 30;
• batch size = 128.

• target sparsity
in [0.05; 0.80];
• pruning between
epochs 3 and 18;

image size 48x48 (32x32 for binary)
random split into 5000, 705, 2000
• images for train, val. & test sets;
• random shift by ± 10% of H/W

SGDW:
• learning rate = 0.01,
0.005 from epoch 35,
• momentum = 0.9,
• weight decay = 1e-4,
• epochs = 60,
• batch size = 80.

• target sparsity
in [0.1; 0.85];
• pruning between
epochs 20 and 5

normalisation;
• random ﬂip L/R;
• random shift (4, 4);

SGDW:
• learning rate = 0.01,
0.005 from epoch 35,
0.001 from epoch 65,
• momentum = 0.9,
• weight decay = 1e-5,
• batch size = 128,
• epochs = 80.

• target sparsity
in [0.1; 0.9];
• pruning between
epochs 30 and 60;

AdamW:
• learning rate = 0.0005,
0.0001 from epoch 20,
2e-5 from epoch 40;
• weight decay = 1e-5;
• batch size = 50;
• epochs = 45.

• target sparsity
in [0.1; 0.85];
• pruning between
epochs 20 and 40

•

Chars74K

CIFAR-10

•

•

Speech
as given here8
Commands

Fashion
MNIST

Training and
optimiser conﬁguration

SGDW:
• learning rate = 0.01,
0.005
from epoch 20,
• random rotate by +/- 0.2 rad with p = 0.3;
0.001
from epoch 35;
• random shift (2, 2);
• momentum = 0.9,
• random ﬂip L/R
• weight decay = 1e-5,
• epochs = 45;
• batch size = 128.

Pruning
conﬁguration

• target sparsity
in [0.05; 0.90];
• pruning between
epochs 3 and 38

Table 5. Dataset preprocessing, model training and pruning conﬁgurations used in our experiments.

Overcoming catastrophic forgetting in neural
networks

arXiv:1612.00796v2 [cs.LG] 25 Jan 2017

James Kirkpatricka , Razvan Pascanua , Neil Rabinowitza , Joel Venessa , Guillaume Desjardinsa ,
Andrei A. Rusua , Kieran Milana , John Quana , Tiago Ramalhoa , Agnieszka Grabska-Barwinska a ,
Demis Hassabisa , Claudia Clopathb , Dharshan Kumarana , and Raia Hadsella
a

b

DeepMind, London, N1C 4AG, United Kingdom
Bioengineering department, Imperial College London, SW7 2AZ, London, United Kingdom

Abstract
The ability to learn tasks in a sequential fashion is crucial to the development of
artificial intelligence. Neural networks are not, in general, capable of this and it
has been widely thought that catastrophic forgetting is an inevitable feature of
connectionist models. We show that it is possible to overcome this limitation and
train networks that can maintain expertise on tasks which they have not experienced
for a long time. Our approach remembers old tasks by selectively slowing down
learning on the weights important for those tasks. We demonstrate our approach is
scalable and effective by solving a set of classification tasks based on the MNIST
hand written digit dataset and by learning several Atari 2600 games sequentially.

1

Introduction

Achieving artificial general intelligence requires that agents are able to learn and remember many
different tasks Legg and Hutter [2007]. This is particularly difficult in real-world settings: the
sequence of tasks may not be explicitly labelled, tasks may switch unpredictably, and any individual
task may not recur for long time intervals. Critically, therefore, intelligent agents must demonstrate a
capacity for continual learning: that is, the ability to learn consecutive tasks without forgetting how
to perform previously trained tasks.
Continual learning poses particular challenges for artificial neural networks due to the tendency for
knowledge of previously learnt task(s) (e.g. task A) to be abruptly lost as information relevant to the
current task (e.g. task B) is incorporated. This phenomenon, termed catastrophic forgetting [French,
1999, McCloskey and Cohen, 1989, McClelland et al., 1995, Ratcliff, 1990], occurs specifically when
the network is trained sequentially on multiple tasks because the weights in the network that are
important for task A are changed to meet the objectives of task B. Whilst recent advances in machine
learning and in particular deep neural networks have resulted in impressive gains in performance
across a variety of domains (e.g. [Krizhevsky et al., 2012, LeCun et al., 2015]), little progress has
been made in achieving continual learning. Current approaches have typically ensured that data from
all tasks are simultaneously available during training. By interleaving data from multiple tasks during
learning, forgetting does not occur because the weights of the network can be jointly optimized for
performance on all tasks. In this regime—often referred to as the multitask learning paradigm—deep
learning techniques have been used to train single agents that can successfully play multiple Atari
games [Rusu et al., 2015, Parisotto et al., 2015]. If tasks are presented sequentially, multitask learning
can only be used if the data are recorded by an episodic memory system and replayed to the network
during training. This approach (often called system-level consolidation [McClelland et al., 1995]),
is impractical for learning large numbers of tasks, as in our setting it would require the amount of
memories being stored and replayed to be proportional to the number of tasks. The lack of algorithms

to support continual learning thus remains a key barrier to the development of artificial general
intelligence.
In marked contrast to artificial neural networks, humans and other animals appear to be able to learn
in a continual fashion [Cichon and Gan, 2015]. Recent evidence suggests that the mammalian brain
may avoid catastrophic forgetting by protecting previously-acquired knowledge in neocortical circuits
[Cichon and Gan, 2015, Hayashi-Takagi et al., 2015, Yang et al., 2009, 2014]. When a mouse acquires
a new skill, a proportion of excitatory synapses are strengthened; this manifests as an increase in
the volume of individual dendritic spines of neurons [Yang et al., 2009]. Critically, these enlarged
dendritic spines persist despite the subsequent learning of other tasks, accounting for retention of
performance several months later [Yang et al., 2009]. When these spines are selectively “erased”, the
corresponding skill is forgotten [Hayashi-Takagi et al., 2015, Cichon and Gan, 2015]. This provides
causal evidence that neural mechanisms supporting the protection of these strengthened synapses
are critical to retention of task performance. Together, these experimental findings—together with
neurobiological models [Fusi et al., 2005, Benna and Fusi, 2016]—suggest that continual learning
in the mammalian neocortex relies on a process of task-specific synaptic consolidation, whereby
knowledge about how to perform a previously acquired task is durably encoded in a proportion of
synapses that are rendered less plastic and therefore stable over long timescales.
In this work, we demonstrate that task-specific synaptic consolidation offers a novel solution to the
continual learning problem for artificial intelligence. We develop an algorithm analogous to synaptic
consolidation for artificial neural networks, which we refer to as elastic weight consolidation (EWC
for short). This algorithm slows down learning on certain weights based on how important they are to
previously seen tasks. We show how EWC can be used in supervised learning and reinforcement
learning problems to train several tasks sequentially without forgetting older ones, in marked contrast
to previous deep-learning techniques.

2

Elastic weight consolidation

In brains, synaptic consolidation enables continual learning by reducing the plasticity of synapses that
are vital to previously learned tasks. We implement an algorithm that performs a similar operation in
artificial neural networks by constraining important parameters to stay close to their old values. In
this section we explain why we expect to find a solution to a new task in the neighbourhood of an
older one, how we implement the constraint, and finally how we determine which parameters are
important.
A deep neural network consists of multiple layers of linear projection followed by element-wise
non-linearities. Learning a task consists of adjusting the set of weights and biases θ of the linear
projections, to optimize performance. Many configurations of θ will result in the same performance
[Nielsen, 1989, Sussmann, 1992]; this is relevant for EWC: over-parameterization makes it likely that
∗
∗
there is a solution for task B, θB
, that is close to the previously found solution for task A, θA
. While
learning task B, EWC therefore protects the performance in task A by constraining the parameters to
∗
stay in a region of low error for task A centered around θA
, as shown schematically in Figure 1. This
constraint is implemented as a quadratic penalty, and can therefore be imagined as a spring anchoring
the parameters to the previous solution, hence the name elastic. Importantly, the stiffness of this
spring should not be the same for all parameters; rather, it should be greater for those parameters that
matter most to the performance during task A.
In order to justify this choice of constraint and to define which weights are most important for a task,
it is useful to consider neural network training from a probabilistic perspective. From this point of
view, optimizing the parameters is tantamount to finding their most probable values given some data
D. We can compute this conditional probability p(θ|D) from the prior probability of the parameters
p(θ) and the probability of the data p(D|θ) by using Bayes’ rule:
log p(θ|D) = log p(D|θ) + log p(θ) − log p(D)
(1)
Note that the log probability of the data given the parameters log p(D|θ) is simply the negative of the
loss function for the problem at hand −L(θ). Assume that the data is split into two independent parts,
one defining task A (DA ) and the other task B (DB ). Then, we can re-arrange equation 1:
log p(θ|D) = log p(DB |θ) + log p(θ|DA ) − log p(DB )
(2)
Note that the left hand side is still describing the posterior probability of the parameters given the
entire dataset, while the right hand side only depends on the loss function for task B log p(DB |θ).
2

Figure 1: elastic weight consolidation (EWC) ensures task A is remembered whilst training on task B. Training
trajectories are illustrated in a schematic parameter space, with parameter regions leading to good performance
∗
on task A (gray) and on task B (cream). After learning the first task, the parameters are at θA
. If we take gradient
steps according to task B alone (blue arrow), we will minimize the loss of task B but destroy what we have learnt
for task A. On the other hand, if we constrain each weight with the same coefficient (green arrow) the restriction
imposed is too severe and we can only remember task A at the expense of not learning task B. EWC, conversely,
finds a solution for task B without incurring a significant loss on task A (red arrow) by explicitly computing how
important weights are for task A.

All the information about task A must therefore have been absorbed into the posterior distribution
p(θ|DA ). This posterior probability must contain information about which parameters were important
to task A and is therefore the key to implementing EWC. The true posterior probability is intractable,
so, following the work on the Laplace approximation by Mackay [MacKay, 1992], we approximate
∗
the posterior as a Gaussian distribution with mean given by the parameters θA
and a diagonal precision
given by the diagonal of the Fisher information matrix F . F has three key properties [Pascanu and
Bengio, 2013]: (a) it is equivalent to the second derivative of the loss near a minimum, (b) it can
be computed from first-order derivatives alone and is thus easy to calculate even for large models,
and (c) it is guaranteed to be positive semi-definite. Note that this approach is similar to expectation
propagation where each subtask is seen as a factor of the posterior [Eskin et al., 2004]. Given this
approximation, the function L that we minimize in EWC is:
Xλ
∗
L(θ) = LB (θ) +
Fi (θi − θA,i
)2
(3)
2
i
where LB (θ) is the loss for task B only, λ sets how important the old task is compared to the new one
and i labels each parameter.
When moving to a third task, task C, EWC will try to keep the network parameters close to the
learned parameters of both task A and B. This can be enforced either with two separate penalties, or
as one by noting that the sum of two quadratic penalties is itself a quadratic penalty.
2.1

EWC allows continual learning in a supervised learning context

We start by addressing the problem of whether elastic weight consolidation could allow deep neural
networks to learn a set of complex tasks without catastrophic forgetting. In particular, we trained a
fully connected multilayer neural network on several supervised learning tasks in sequence. Within
each task, we trained the neural network in the traditional way, namely by shuffling the data and
processing it in small batches. After a fixed amount of training on each task, however, we allowed no
further training on that task’s dataset.
We constructed the set of tasks from the problem of classifying hand written digits from the MNIST
[LeCun et al., 1998] dataset, according to a scheme previously used in the continual learning literature
[Srivastava et al., 2013, Goodfellow et al., 2014]. For each task, we generated a fixed, random
permutation by which the input pixels of all images would be shuffled. Each task was thus of equal
difficulty to the original MNIST problem, though a different solution would be required for each.
Detailed description of the settings used can be found in Appendix 4.1.
Training on this sequence of tasks with plain stochastic gradient descent (SGD) incurs catastrophic
forgetting, as demonstrated in Figure 2A. The blue curves show performance on the testing sets of
two different tasks. At the point at which the training regime switches from training on the first
task (A) to training on the second (B), the performance for task B falls rapidly, while for task A it
climbs steeply. The forgetting of task A compounds further with more training time, and the addition
3

Figure 2: Results on the permuted MNIST task. A: Training curves for three random permutations A, B and C
using EWC(red), L2 regularization (green) and plain SGD(blue). Note that only EWC is capable of mantaining
a high performance on old tasks, while retaining the ability to learn new tasks. B: Average performance across
all tasks using EWC (red) or SGD with dropout regularization (blue). The dashed line shows the performance
on a single task only. C: Similarity between the Fisher information matrices as a function of network depth for
two different amounts of permutation. Either a small square of 8x8 pixels in the middle of the image is permuted
(grey) or a large square of 26x26 pixels is permuted (black). Note how the more different the tasks are, the
smaller the overlap in Fisher information matrices in early layers.

of subsequent tasks. This problem cannot be countered by regularizing the network with a fixed
quadratic constraint for each weight (green curves, L2 regularization): here, the performance in task
A degrades much less severely, but task B cannot be learned properly as the constraint protects all
weights equally, leaving little spare capacity for learning on B. However, when we use EWC, and thus
take into account how important each weight is to task A, the network can learn task B well without
forgetting task A (red curves). This is exactly the expected behaviour described diagrammatically in
Figure 1.
Previous attempts to solve the continual learning problem for deep neural networks have relied upon
careful choice of network hyperparameters, together with other standard regularization methods, in
order to mitigate catastrophic forgetting. However, on this task, they have only achieved reasonable
results on up to two random permutations [Srivastava et al., 2013, Goodfellow et al., 2014]. Using a
similar cross-validated hyperparameter search as [Goodfellow et al., 2014], we compared traditional
dropout regularization to EWC. We find that stochastic gradient descent with dropout regularization
alone is limited, and that it does not scale to more tasks (Figure 2B). In contrast, EWC allows a large
number of tasks to be learned in sequence, with only modest growth in the error rates.
Given that EWC allows the network to effectively squeeze in more functionality into a network with
fixed capacity, we might ask whether it allocates completely separate parts of the network for each
task, or whether capacity is used in a more efficient fashion by sharing representation. To assess this,
we determined whether each task depends on the same sets of weights, by measuring the overlap
between pairs of tasks’ respective Fisher information matrices (see Appendix 4.3). A small overlap
means that the two tasks depend on different sets of weights (i.e. EWC subdivides the network’s
weights for different tasks); a large overlap indicates that weights are being used for both the two tasks
(i.e. EWC enables sharing of representations). Figure 2C shows the overlap as a function of depth.
As a simple control, when a network is trained on two tasks which are very similar to each other
(two versions of MNIST where only a few pixels are permutated), the tasks depend on similar sets of
weights throughout the whole network (grey curve). When then the two tasks are more dissimilar
from each other, the network begins to allocate separate capacity (i.e. weights) for the two tasks
(black line). Nevertheless, even for the large permutations, the layers of the network closer to the
output are indeed being reused for both tasks. This reflects the fact that the permutations make the
input domain very different, but the output domain (i.e. the class labels) is shared.
2.2

EWC allows continual learning in a reinforcement learning context

We next tested whether elastic weight consolidation could support continual learning in the far
more demanding reinforcement learning (RL) domain. In RL, agents dynamically interact with
the environment in order to develop a policy that maximizes cumulative future reward. We asked
whether Deep Q Networks (DQNs)—an architecture that has achieved impressive successes in such
challenging RL settings [Mnih et al., 2015]—could be harnessed with EWC to successfully support
continual learning in the classic Atari 2600 task set [Bellemare et al., 2013]. Specifically, each
4

experiment consisted of ten games chosen randomly from those that are played at human level or
above by DQN. At training time, the agent was exposed to experiences from each game for extended
periods of time. The order of presentation of the games was randomized and allowed for returning to
the same games several times. At regular intervals we would also test the agent’s score on each of the
ten games, without allowing the agent to train on them (Figure 3A).
Notably, previous reinforcement learning approaches to continual learning have either relied on either
adding capacity to the network [Ring, 1998, Rusu et al., 2016] or on learning each task in separate
networks, which are then used to train a single network that can play all games[Rusu et al., 2015,
Parisotto et al., 2015]. In contrast, the EWC approach presented here makes use of a single network
with fixed resources (i.e. network capacity) and has minimal computational overhead.
In addition to using EWC to protect previously-acquired knowledge, we used the RL domain to
address a broader set of requirements that are needed for successful continual learning systems: in
particular, higher-level mechanisms are needed to infer which task is currently being performed,
detect and incorporate novel tasks as they are encountered, and allow for rapid and flexible switching
between tasks [Collins and Frank, 2013]. In the primate brain, the prefrontal cortex is widely viewed
as supporting these capabilities by sustaining neural representations of task context that exert topdown gating influences on sensory processing, working memory, and action selection in lower-level
regions [O’Reilly and Frank, 2006, Mante et al., 2013, Miller and Cohen, 2001, Doya et al., 2002].
Inspired by this evidence, we used an agent very similar to that described in [van Hasselt et al.,
2016] with few differences: (a) a network with more parameters, (b) a smaller transition table, (c)
task-specific bias and gains at each layer, (d) the full action set in Atari, (e) a task-recognition model,
and (e) the EWC penalty. Full details of hyper-parameters are described in Appendix app:atari. Here
we briefly describe the two most important modifications to the agent: the task-recognition module,
and the implementation of the EWC penalty.
We treat the task context as the latent variable of a Hidden Markov Model. Each task is therefore
associated to an underlying generative model of the observations. The main distinguishing feature of
our approach is that we allow for the addition of new generative models if they explain recent data
better than the existing pool of models by using a training procedure inspired by the forget me not
process[Kieran et al., 2016] (see Appendix 4.2).
In order to apply EWC, we compute the Fisher information matrix at each task switch. For each
task, a penalty is added with anchor point given by the current value of the parameters and with
weights given by the Fisher information matrix times a scaling factor λ which was optimized by
hyperparameter search. We only added an EWC penalty to games which had experienced at least 20
million frames.
We also allowed the DQN agents to maintain separate short-term memory buffers for each inferred
task: these allow action values for each task to be learned off-policy using an experience replay
mechanism [Mnih et al., 2015]. As such, the overall system has memory on two time-scales: over
short time-scales, the experience replay mechanism allows learning in DQN to be based on the
interleaved and uncorrelated experiences [Mnih et al., 2015]. At longer time scales, know-how across
tasks is consolidated by using EWC. Finally, we allowed a small number of network parameters to be
game-specific, rather than shared across games. In particular, we allowed each layer of the network
to have biases and per element multiplicative gains that were specific to each game.
We compare the performance of agents which use EWC (red) with ones that do not (blue) over sets
of ten games in Figure 3. We measure the performance as the total human-normalized score across
all ten games. We average across random seeds and over the choice of which ten games were played
(see Appendix 4.2). We also clip the human-normalized score for each game to 1. Our measure of
performance is therefore a number with a maximum of 10 (at least at human level on all games)
where 0 means the agent is as good as a random agent. If we rely on plain gradient descent methods
as in [Mnih et al., 2015], the agent never learns to play more than one game and the harm inflicted
by forgetting the old games means that the total human-normalized score remains below one. By
using EWC, however, the agents do indeed learn to play multiple games. As a control, we also
considered the benefit to the agent if we explicitly provided the agent with the true task label (Figure
3B, brown), rather than relying on the learned task recognition through the FMN algorithm (red). The
improvement here was only modest.

5

Figure 3: Results on Atari task. A: Schedule of games. Black bars indicate the sequential training periods
(segments) for each game. After each training segment, performance on all games is measured. The EWC
constraint is only activated to protect an agent’s performance on each game once the agent has experienced 20
million frames in that game. B: Total scores for each method across all games. Red curve denotes the network
which infers the task labels using the Forget Me Not algorithm; brown curve is the network provided with the
task labels. The EWC and SGD curves start diverging when games start being played again that have been
protected by EWC. C: Sensitivity of a single-game DQN, trained on Breakout, to noise added to its weights. The
performance on Breakout is shown as a function of the magnitude (standard deviation) of the weight perturbation.
The weight perturbation is drawn from a zero mean Gaussian with covariance that is either uniform (black; i.e.
targets all weights equally), the inverse Fisher ((F + λI)−1 ; blue; i.e. mimicking weight changes allowed by
EWC), or uniform within the nullspace of the Fisher (orange; i.e. targets weights that the Fisher estimates that
the network output is entirely invariant to). To evaluate the score, we ran the agent for ten full game episodes,
drawing a new random weight perturbation for every timestep.

While augmenting the DQN agent with EWC allows it to learn many games in sequence without
suffering from catastrophic forgetting, it does not reach the score that would have been obtained by
training ten separate DQNs (see Figure 1 in Appendix 4.2). One possible reason for this is that we
consolidated weights for each game based on a tractable approximation of parameter uncertainty, the
Fisher Information. We therefore sought to test the quality of our estimates empirically. To do so, we
trained an agent on a single game, and measured how perturbing the network parameters affected the
agent’s score. Regardless of which game the agent was trained on, we observed the same patterns,
shown in Figure 3C. First, the agent was always more robust to parameter perturbations shaped by the
inverse of the diagonal of the Fisher Information (blue), as opposed to uniform perturbations (black).
This validates that the diagonal of the Fisher is a good estimate of how important a certain parameter
is. Within our approximation, perturbing in the nullspace should have no effect on performance at
all on performance. Empirically, however, we observe that perturbing in this space (orange) has the
same effect as perturbing in the inverse Fisher space. This suggests that we are over-confident about
certain parameters being unimportant: it is therefore likely that the chief limitation of the current
implementation is that it under-estimates parameter uncertainty.

3

Discussion

We present a novel algorithm, elastic weight consolidation, that addresses the significant problem
continual learning poses for neural networks. EWC allows knowledge of previous tasks to be
protected during new learning, thereby avoiding catastrophic forgetting of old abilities. It does so by
selectively decreasing the plasticity of weights, and thus has parallels with neurobiological models of
synaptic consolidation. We implement EWC as a soft, quadratic constraint whereby each weight is
pulled back towards its old values by an amount proportional to its importance for performance on
previously-learnt tasks. To the extent that tasks share structure, networks trained with EWC reuse
shared components of the network. We further show that EWC can be effectively combined with
deep neural networks to support continual learning in challenging reinforcement learning scenarios,
such as Atari 2600 games.
The EWC algorithm can be grounded in Bayesian approaches to learning. Formally, when there
is a new task to be learnt, the network parameters are tempered by a prior which is the posterior
distribution on the parameters given data from previous task(s). This enables fast learning rates on
parameters that are poorly constrained by the previous tasks, and slow learning rates for those which
are crucial.
6

There has been previous work [French and Chater, 2002, Eaton and Ruvolo, 2013] using a quadratic
penalty to approximate old parts of the dataset, but these applications have been limited to small
models. Specifically, [French and Chater, 2002] used random inputs to compute a quadratic approximation to the energy surface. Their approach is slow, as it requires re-computing the curvature at
each sample. The ELLA algorithm described in [Eaton and Ruvolo, 2013] requires computing and
inverting matrices with a dimensionality equal to the number of parameters being optimized, therefore
it has been mainly applied to linear and logistic regressions. In contrast, EWC has a run time which is
linear in both the number of parameters and the number of training examples. We could only achieve
this low computational complexity by making several simplifications, most notably by approximating
the posterior distribution of the parameters on a task (i.e. the weight uncertainties) by a factorized
Gaussian, and by computing its variance using a point-estimate of the parameters, via the diagonal of
the Fisher Information matrix. Despite its low computational cost and empirical successes—even in
the setting of challenging RL domains—our use of a point estimate of the posterior’s variance (as in a
Laplace approximation) does constitute a significant weakness (see Fig 4C). Our initial explorations
suggest that one might improve on this local estimate by using Bayesian neural networks [Blundell
et al., 2015].
While this paper has primarily focused on building an algorithm out of neurobiological observations, it
is also instructive to consider whether the algorithm’s successes can feed back into our understanding
of the brain. In particular, we see considerable parallels between EWC and two computational
theories of synaptic plasticity.
In this respect, the perspective we offer here aligns with a recent proposal that each synapse not
only stores its current weight, but also an implicit representation of its uncertainty about that weight
[Aitchison and Latham, 2015]. This idea is grounded in observations that post-synaptic potentials are
highly variable in amplitude (suggestive of sampling from the weight posterior during computation),
and that those synapses which are more variable are more amenable to potentiation or depression
(suggestive of updating the weight posterior). While we do not explore the computational benefits
of sampling from a posterior here, our work aligns with the notion that weight uncertainty should
inform learning rates. We take this one step further, to emphasize that consolidating the high precision
weights enables continual learning over long time scales. With EWC, three values have to be stored
for each synapse: the weight itself, its variance and its mean. Interestingly, synapses in the brain also
carry more than one piece of information. For example, the state of the short-term plasticity could
carry information on the variance [Aitchison and Latham, 2015, Pfister et al., 2010]. The weight for
the early phase of plasticity [Clopath et al., 2008] could encode the current synaptic strength, whereas
the weight associated with the late-phase of plasticity or the consolidated phase could encode the
mean weight.
The ability to learn tasks in succession without forgetting is a core component of biological and
artificial intelligence. In this work we show that an algorithm that supports continual learning—which
takes inspiration from neurobiological models of synaptic consolidation—can be combined with deep
neural networks to achieve successful performance in a range of challenging domains. In doing so,
we demonstrate that current neurobiological theories concerning synaptic consolidation do indeed
scale to large-scale learning systems. This provides prima facie evidence that these principles may be
fundamental aspects of learning and memory in the brain.
Acknowledgements. We would like to thank P. Dayan, D. Wierstra, S. Mohamed, Yee Whye Teh
and K. Kavukcuoglu.

References
Laurence Aitchison and Peter E Latham. Synaptic sampling: A connection between psp variability
and uncertainty explains neurophysiological observations. arXiv preprint arXiv:1505.04544, 2015.
Marc G Bellemare, Yavar Naddaf, Joel Veness, and Michael Bowling. The arcade learning environment: An evaluation platform for general agents. Journal of Artificial Intelligence Research, 47:
253–279, 2013.
Marcus K Benna and Stefano Fusi. Computational principles of synaptic memory consolidation.
Nature neuroscience, 2016.
7

Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty
in neural network. In Proceedings of The 32nd International Conference on Machine Learning,
pages 1613–1622, 2015.
Joseph Cichon and Wen-Biao Gan. Branch-specific dendritic ca2+ spikes cause persistent synaptic
plasticity. Nature, 520(7546):180–185, 2015.
Claudia Clopath, Lorric Ziegler, Eleni Vasilaki, Lars Büsing, and Wulfram Gerstner. Tag-triggerconsolidation: a model of early and late long-term-potentiation and depression. PLoS Comput Biol,
4(12):e1000248, 2008.
Anne GE Collins and Michael J Frank. Cognitive control over learning: creating, clustering, and
generalizing task-set structure. Psychological review, 120(1):190, 2013.
DC Dowson and BV Landau. The fréchet distance between multivariate normal distributions. Journal
of multivariate analysis, 12(3):450–455, 1982.
Kenji Doya, Kazuyuki Samejima, Ken-ichi Katagiri, and Mitsuo Kawato. Multiple model-based
reinforcement learning. Neural computation, 14(6):1347–1369, 2002.
Eric Eaton and Paul L Ruvolo. Ella: An efficient lifelong learning algorithm. In International
Conference on Machine Learning, pages 507–515, 2013.
Eleazar Eskin, Alex J. Smola, and S.v.n. Vishwanathan. Laplace propagation. In Advances in Neural
Information Processing Systems 16, pages 441–448. MIT Press, 2004. URL http://papers.
nips.cc/paper/2444-laplace-propagation.pdf.
Robert M French. Catastrophic forgetting in connectionist networks. Trends in cognitive sciences, 3
(4):128–135, 1999.
Robert M French and Nick Chater. Using noise to compute error surfaces in connectionist networks:
a novel means of reducing catastrophic forgetting. Neural computation, 14(7):1755–1769, 2002.
Stefano Fusi, Patrick J Drew, and LF Abbott. Cascade models of synaptically stored memories.
Neuron, 45(4):599–611, 2005.
Ian J Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, and Yoshua Bengio. An empirical
investigation of catastrophic forgeting in gradient-based neural networks. Int’l Conf. on Learning
Representations (ICLR), 2014.
Akiko Hayashi-Takagi, Sho Yagishita, Mayumi Nakamura, Fukutoshi Shirai, Yi I. Wu, Amanda L.
Loshbaugh, Brian Kuhlman, Klaus M. Hahn, and Haruo Kasai. Labelling and optical erasure
of synaptic memory traces in the motor cortex. Nature, 525(7569):333–338, 09 2015. URL
http://dx.doi.org/10.1038/nature15257.
Milan Kieran, Joel Veness, Michael Bowling, James Kirkpatrick, Anna Koop, and Demis Hassabis.
The forget me not process. In Advances in Neural Information Processing Systems 26, page
accepted for publication, 2016.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, pages 1097–1105, 2012.
Yann LeCun, Corinna Cortes, and Christopher JC Burges. The mnist database of handwritten digits,
1998.
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521(7553):436–444,
2015.
Shane Legg and Marcus Hutter. Universal intelligence: A definition of machine intelligence. Minds
and Machines, 17(4):391–444, 2007.
David JC MacKay. A practical bayesian framework for backpropagation networks. Neural computation, 4(3):448–472, 1992.
8

Valerio Mante, David Sussillo, Krishna V Shenoy, and William T Newsome. Context-dependent
computation by recurrent dynamics in prefrontal cortex. Nature, 503(7474):78–84, 2013.
James L McClelland, Bruce L McNaughton, and Randall C O’Reilly. Why there are complementary
learning systems in the hippocampus and neocortex: insights from the successes and failures of
connectionist models of learning and memory. Psychological review, 102(3):419, 1995.
Michael McCloskey and Neal J Cohen. Catastrophic interference in connectionist networks: The
sequential learning problem. The psychology of learning and motivation, 24(109-165):92, 1989.
Earl K Miller and Jonathan D Cohen. An integrative theory of prefrontal cortex function. Annual
review of neuroscience, 24(1):167–202, 2001.
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G Bellemare,
Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, et al. Human-level control
through deep reinforcement learning. Nature, 518(7540):529–533, 2015.
Robert H. Nielsen. Theory of the backpropagation neural network. In Proceedings of the International
Joint Conference on Neural Networks, volume I, pages 593–605. Piscataway, NJ: IEEE, 1989.
Randall C O’Reilly and Michael J Frank. Making working memory work: a computational model of
learning in the prefrontal cortex and basal ganglia. Neural computation, 18(2):283–328, 2006.
Emilio Parisotto, Jimmy Lei Ba, and Ruslan Salakhutdinov. Actor-mimic: Deep multitask and
transfer reinforcement learning. arXiv preprint arXiv:1511.06342, 2015.
Razvan Pascanu and Yoshua Bengio. Revisiting natural gradient for deep networks. arXiv preprint
arXiv:1301.3584, 2013.
Jean-Pascal Pfister, Peter Dayan, and Máté Lengyel. Synapses with short-term plasticity are optimal
estimators of presynaptic membrane potentials. Nature neuroscience, 13(10):1271–1275, 2010.
Roger Ratcliff. Connectionist models of recognition memory: constraints imposed by learning and
forgetting functions. Psychological review, 97(2):285, 1990.
Mark B Ring. Child: A first step towards continual learning. In Learning to learn, pages 261–292.
Springer, 1998.
Andrei A Rusu, Sergio Gomez Colmenarejo, Caglar Gulcehre, Guillaume Desjardins, James Kirkpatrick, Razvan Pascanu, Volodymyr Mnih, Koray Kavukcuoglu, and Raia Hadsell. Policy
distillation. arXiv preprint arXiv:1511.06295, 2015.
Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray
Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. Progressive neural networks. arXiv preprint
arXiv:1606.04671, 2016.
Rupesh K Srivastava, Jonathan Masci, Sohrob Kazerounian, Faustino Gomez, and Juergen Schmidhuber. Compete to compute. In Advances in Neural Information Processing Systems 26,
pages 2310–2318. Curran Associates, Inc., 2013. URL http://papers.nips.cc/paper/
5059-compete-to-compute.pdf.
Héctor J. Sussmann. Uniqueness of the weights for minimal feedforward nets with a given inputoutput map. Neural Networks, 5:589–593, 1992.
Hado van Hasselt, Arthur Guez, and David Silver. Deep reinforcement learning with double q-learning.
Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, pages 2094–2100, 2016.
Joel Veness, Kee Siong Ng, Marcus Hutter, and Michael Bowling. Context tree switching. In 2012
Data compression conference., pages 327–336. IEEE, 2012.
Guang Yang, Feng Pan, and Wen-Biao Gan. Stably maintained dendritic spines are associated with
lifelong memories. Nature, 462(7275):920–924, 2009.
Guang Yang, Cora Sau Wan Lai, Joseph Cichon, Lei Ma, Wei Li, and Wen-Biao Gan. Sleep promotes
branch-specific formation of dendritic spines after learning. Science, 344(6188):1173–1178, 2014.
9

Hyperparameter
3A
10−3
no
no
2
400
20

learning rate
dropout
early stopping
n. hidden layers
width hidden layers
epochs / dataset

Reference figure
3B
3C
10−5 -10−3 10−3
yes
no
yes
no
2
6
400-2000
100
100
100

Table 1: Hyperparameters for each of the MNIST figures

4

Appendix

4.1

MNIST experiments

We carried out all MNIST experiments with fully-connected networks with rectified linear units.
In order to replicate the results of [Goodfellow et al., 2014], we compared to results obtained
using dropout regularization. As suggested in [Goodfellow et al., 2014], we applied dropout with a
probability of 0.2 to the input and of 0.5 to the other hidden layers. In order to give SGD with dropout
the best possible chance, we also used early stopping. Early stopping was implemented by computing
the test error on the validation set for all pixel permutations seen to date. Here, if the validation error
was observed to increase for more than five subsequent steps, we terminated this training segment and
proceeded to the next dataset; at this point, we reset the network weights to the values that had the
lowest average validation error on all previous datasets. Table 1 shows a list of all hyperparameters
used to produce the three graphs in Figure 3 of the main text. Where a range is present, the parameter
was randomly varied and the reported results were obtained using the best hyperparameter setting.
When random hyperparameter search was used, 50 combinations of parameters were attempted for
each number experiment.
4.2

Atari experiments

The agent architecture used is almost identical to that used in [van Hasselt et al., 2016]. In this section
we provide details on all the parameters used.
Images are preprocessed in the same way as in [Mnih et al., 2015], namely the 210x160 images from
the Atari emulator are downsampled to 84x84 using bilinear interpolation. We then convert the RGB
images to YUV and use the grayscale channel alone. The state used by the agent consists of the four
latest downsampled, grayscale observations concatenated together.
The network structure used is similar to the one from [Mnih et al., 2015], namely three convolutional
layers followed by a fully connected layer. The first convolution had kernel size 8, stride 4 and 32
filters. The second convolution had kernel size 4, stride 2 and 64 filters. The final convolution had
kernels size 3, stride 1 and 128 filters. The fully connected layer had 1024 units. Note that this
network has approximately four times as many parameters as the standard network, due to having
twice as many fully connected units and twice as many filters in the final convolution. The other
departure from the standard network is that each layer was allowed to have task-specific gains and
biases. For each layer, the transformation x → y computed by the network is therefore:


X
yi = 
Wij xj + bci  gic
(4)
j

where the biases b and the gains g. The network weights and biases where initialized by setting them
randomly with a uniform number between −σ and σ, with σ set to the square root of the incoming
hidden units (for a linear layer) or set to the area of the kernel times the number of incoming filters
(for convolutional layers). Biases and gains were initialized to 0 and 1 respectively.
We used an an -greedy exploration policy, where the probability of selecting random action, ,
decayed with training time. We kept a different timer for each of the tasks. We set  = 1 for 5 × 104
time steps, and then decayed this linearly to a value of 0.01 for the next 106 .
10

We trained the networks with the Double Q-learning algorithm [van Hasselt et al., 2016]. A training
step is carried out on a minibatch of 32 experiences every four steps. The target network is updated
every 3 × 104 time steps. We trained with RMSProp, with a momentum of 0., a decay of 0.95, a
learning rate of 2.5 × 10−4 , and a maximum learning rate of 2.5 × 10−3 .
Other hyperparameters that we changed from the reference implementation were: 1) using a smaller
replay buffer (5 × 105 past experiences), and 2) a scaling factor for the EWC penalty of 400. Another
subtle difference is that we used the full action set in the Atari emulator. In fact, although many
games only support a small subset of the 18 possible actions, in order to have a unified network
structure for all games we used 18 actions in each game.
We randomly chose the 10 games for each experiment from a pool of 19 Atari games for which the
standalone DQN could reach human-level performance in 50 × 106 frames. The scores for each of
these games for the baseline algorithm, for EWC and for plain SGD training, as a function of the
number steps played in that game are shown in Figure 4. In order to get an averaged performance,
we chose 10 sets of 10 games, and ran 4 different random seeds for each set.
The most significant departure from the published models is the automatic determination of the task.
We model each task by a generative model of the environment. In this work, for simplicity, we only
model the current observation. The current task is modelled as a categorical context c which is treated
as the hidden variable in an Hidden Markov Model that explain observations. In such a model the
probabilty of being in a particular context c at time t evolves according to:
p(c, t + 1) =

X

p(c0 , t)Γ(c, c0 )

c0
0

Γ(c, c ) = δ(c, c0 )(1 − α) + (1 − δ(c, c0 ))α
where δ is the Kronecker delta function and α is the probability of switching context. The task context
then conditions a generative model predicting the observation probability p(o|c, t). Given such
generative models, the probability of being in a task set at time t can be inferred by the observations
seen so far as:
X
p(c |o1 ...ot ) ∝
Γ(c, c0 ) p(c0 , t − 1)p(o|c, t)
c0

The maximal probability context is then taken to be the current task label.
In our implementation, the generative models consist of factored multinomial distributions explaining
the probability of the state of each pixel in the observation space. The model is a parametrized
Dirichlet distribution, which summarizes the data seen so far using Bayesian updates. In order to
encourage each model to specialize, we train the models as follows. We partition time into windows
of a particular width W . During each window, all the Dirichlet priors are updated with the evidence
seen so far. At the end of the window, the model best corresponding to the current task set is selected.
Since this model was the most useful to explain the current data, it keeps its prior, while all other
priors are reverted to their state at the beginning of the time window. We ensure that one hold-out
uniform (i.e. uninitialized) Dirichlet-multinomial is always available. Whenever the hold-out model
is selected a new generative model is created and a new task context is therefore created. This model
is Bayesian, in the sense that data is used to maintain beliefs over priors on the generative models,
and is non-parametric, in the sense that the model can grow in function of the observed data. It can
be seen as an implementation of the flat forget me not algorithm described in [Kieran et al., 2016].
The parameter α is not learnt. Instead we use the result from [Veness et al., 2012] where it is shown
that a time decaying switch rate α = 1/t
 guarantees good worst case asymptotic perfmance provided
n
the number of tasks grows as o log n .
Table 2 summarizes all hyper-parameters used for the Atari experiments. Except for the parameters
pertaining the EWC algorithm (Fisher multiplier, num. samples Fisher, EWC start) or pertaining
the task recognition models (model update period, model downscaling and size window), all the
parameters values are the same as from [van Hasselt et al., 2016] and have not been tuned for these
experiments.
11

Hyperparameter
action repeat

value
4

discount factor
no-op max

0.99
30

max. reward
scaled input
optimization algorithm
learning rate
max. learning rate
momentum
decay
clipδ
max. norm

1
84x84
RMSprop
0.00025
0.0025
0.
0.95
1.
50.

history length

4

minibatch size

32

replay period

4

memory size

50000

target update period

7500

min. history

50000

initial exploration
exploration decay start

1.
50000

exploration decay end
final exploration
model update period
model downscaling

1050000
0.01
4
2

size window
num. samples Fisher

4
100

Fisher multiplier
start EWC

400
20E6

brief description
Repeat the same action for four frames. Each agent step will
occur every fourth frame.
Discount factor used in the Q-learning algorithm.
Maximum number of do nothing operations carried out at the
beginning of each training episode to provide a varied training set.
Rewards are clipped to 1.
Input images are scaled to 84x84 with bilinear interpolation.
Optimization algorithm used.
The learning rate in RMSprop.
The maximum learning rate that RMSprop will apply.
The momentum used in RMSprop.
The decay used in RMSProp.
Each gradient from Q-learning is clipped to ± 1.
After clipping, if the norm of the gradient is greater
than 50., the gradient is renormalized to 50.
The four most recently experienced frames are taken to
form a state for Q-learning
The number of elements taken from the replay buffer to form
a mini-batch training example.
A mini-batch is loaded from the replay buffer every 4
steps (16 frames including action repeat).
The replay memory stores the last fify thousand
transitions experienced.
The target network in Q-learning is updated to the policy
network every 7500 step.
The agent will only start learning after fifty thousand
transitions have been stored into memory.
The value of the initial exploration rate.
The exploration rate will start decaying after fifty
thousand frames.
The exploration rate will decay over one million frames.
The value of the final exploration rate.
The Dirichlet model is updated every fourth step.
The Dirichlet model is downscaled by a factor of 2, that
is an image of size 42x42 is being modelled.
The size of the window for the task recognition model learning.
Whenever the diagonal of the Fisher is recomputed for a
task, one hundred mini-batches are drawn from the replay buffer.
The Fisher is scaled by this number to form the EWC penalty.
The EWC penalty is only applied after 5 million steps
(20 million frames).

Table 2: Hyperparameters for each of the MNIST figures

12

140000
120000
100000

crazy_climber
EWC
SGD
single game

12000
10000

6000

60000

4000

40000
20000

2000

0

0

8000

gopher
EWC
SGD
single game

6000
4000
2000
0

enduro

1400

EWC
SGD
single game

1200
1000

8000
7000
6000
5000
4000
3000
2000
1000
0
30
20

600

10

200

20

0

30

boxing

100

7000
6000

50

5000

0
50

EWC
SGD
single game

100

25

pong
EWC
SGD
single game

0

400

30

kangaroo
EWC
SGD
single game

10

800

35

400
350
300
250
200
150
100
50
0

8000

80000

10000

riverraid
EWC
SGD
single game

freeway
EWC
SGD
single game

40000

150
100
50
0

kung_fu_master
EWC
SGD
single game

20
0

40
60
80
100

star_gunner
EWC
SGD
single game

12000
10000

6000
4000
2000
0

road_runner
EWC
SGD
single game

25000
20000
15000
10000

10000

5000

1000
0
10000
8000
6000

2000
0

0

krull
EWC
SGD
single game

1600
1400
1200
1000
800
600
400
200
0

demon_attack
EWC
SGD
single game

8000

20000

2000

fishing_derby
EWC
SGD
single game

20

3000

4000

5

50000

breakout
EWC
SGD
single game

200

30000

15

0

EWC
SGD
single game

45000
40000
35000
30000
25000
20000
15000
10000
5000
0

300
250

4000

20
10

asterix

40000
35000
30000
25000
20000
15000
10000
5000
0

jamesbond
EWC
SGD
single game

defender
EWC
SGD
single game

0

space_invaders
EWC
SGD
single game

Figure 4: Score in the individual games as a function of steps played in that game. The black baseline curves
show learning on individual games alone.

4.3

Fisher overlap

To assess whether different tasks solved in the same network use similar sets of weights (Figure
3C in the mains text), we measured the degree of overlap between the two tasks’ Fisher matrices.
Precisely, we computed two tasks’ Fishers, F1 and F2 , normalized these to each have unit trace, F̂1
and F̂2 , then computed their Fréchet distance, a metric on the space of positive-semidefinite matrices
[Dowson and Landau, 1982]:

1 
d2 (F̂1 , F̂2 ) = tr F̂1 + F̂2 − 2(F̂1 F̂2 )1/2
2
1 1/2
1/2
= ||F̂1 − F̂2 ||F
2
which is bounded between zero and one. We then define the overlap as 1 − d2 , with a value of zero
indicating that the two tasks depend on non-overlapping sets of weights, and a value of one indicating
that F1 = αF2 for some α > 0.

13

F EDERATED O PTIMIZATION IN H ETEROGENEOUS N ETWORKS

arXiv:1812.06127v5 [cs.LG] 21 Apr 2020

Tian Li 1 Anit Kumar Sahu 2 Manzil Zaheer 3 Maziar Sanjabi 4 Ameet Talwalkar 1 5 Virginia Smith 1

A BSTRACT
Federated Learning is a distributed learning paradigm with two key challenges that differentiate it from traditional
distributed optimization: (1) significant variability in terms of the systems characteristics on each device in
the network (systems heterogeneity), and (2) non-identically distributed data across the network (statistical
heterogeneity). In this work, we introduce a framework, FedProx, to tackle heterogeneity in federated networks.
FedProx can be viewed as a generalization and re-parametrization of FedAvg, the current state-of-the-art
method for federated learning. While this re-parameterization makes only minor modifications to the method
itself, these modifications have important ramifications both in theory and in practice. Theoretically, we provide
convergence guarantees for our framework when learning over data from non-identical distributions (statistical
heterogeneity), and while adhering to device-level systems constraints by allowing each participating device to
perform a variable amount of work (systems heterogeneity). Practically, we demonstrate that FedProx allows
for more robust convergence than FedAvg across a suite of realistic federated datasets. In particular, in highly
heterogeneous settings, FedProx demonstrates significantly more stable and accurate convergence behavior
relative to FedAvg—improving absolute test accuracy by 22% on average.
1

I NTRODUCTION

Federated learning has emerged as an attractive paradigm
for distributing training of machine learning models in networks of remote devices. While there is a wealth of work
on distributed optimization in the context of machine learning, two key challenges distinguish federated learning from
traditional distributed optimization: high degrees of systems
and statistical heterogeneity1 (McMahan et al., 2017; Li
et al., 2019).
In an attempt to handle heterogeneity and tackle high communication costs, optimization methods that allow for local updating and low participation are a popular approach
for federated learning (McMahan et al., 2017; Smith et al.,
2017). In particular, FedAvg (McMahan et al., 2017) is
an iterative method that has emerged as the de facto optimization method in the federated setting. At each iteration,
FedAvg first locally performs E epochs of stochastic gra1
Carnegie Mellon University 2 Bosch Center for Artificial Intelligence 3 Goolge Research 4 Facebook AI 5 Determined AI. Correspondence to: Tian Li <tianli@cmu.edu>.

Proceedings of the 3 rd MLSys Conference, Austin, TX, USA,
2020. Copyright 2020 by the author(s).
1
Privacy is a third key challenge in the federated setting. While
not the focus of this work, standard privacy-preserving approaches
such as differential privacy and secure multiparty communication
can naturally be combined with the methods proposed herein—
particularly since our framework proposes only lightweight algorithmic modifications to prior work.

dient descent (SGD) on K devices—where E is a small
constant and K is a small fraction of the total devices in
the network. The devices then communicate their model
updates to a central server, where they are averaged.
While FedAvg has demonstrated empirical success in heterogeneous settings, it does not fully address the underlying
challenges associated with heterogeneity. In the context
of systems heterogeneity, FedAvg does not allow participating devices to perform variable amounts of local work
based on their underlying systems constraints; instead it
is common to simply drop devices that fail to compute E
epochs within a specified time window (Bonawitz et al.,
2019). From a statistical perspective, FedAvg has been
shown to diverge empirically in settings where the data is
non-identically distributed across devices (e.g., McMahan
et al., 2017, Sec 3). Unfortunately, FedAvg is difficult to
analyze theoretically in such realistic scenarios and thus
lacks convergence guarantees to characterize its behavior
(see Section 2 for additional details).
In this work, we propose FedProx, a federated optimization algorithm that addresses the challenges of heterogeneity both theoretically and empirically. A key insight we
have in developing FedProx is that an interplay exists
between systems and statistical heterogeneity in federated
learning. Indeed, both dropping stragglers (as in FedAvg)
or naively incorporating partial information from stragglers
(as in FedProx with the proximal term set to 0) implicitly
increases statistical heterogeneity and can adversely impact

Federated Optimization in Heterogeneous Networks

convergence behavior. To mitigate this issue, we propose
adding a proximal term to the objective that helps to improve
the stability of the method. This term provides a principled
way for the server to account for heterogeneity associated
with partial information. Theoretically, these modifications
allow us to provide convergence guarantees for our method
and to analyze the effect of heterogeneity. Empirically, we
demonstrate that the modifications improve the stability
and overall accuracy of federated learning in heterogeneous
networks—improving the absolute testing accuracy by 22%
on average in highly heterogeneous settings.
The remainder of this paper is organized as follows. In Section 2, we provide background on federated learning and
an overview of related work. We then present our proposed
framework, FedProx, in Section 3, and derive convergence
guarantees for the framework accounting for both statistical
and systems heterogeneity in Section 4. Finally, in Section 5,
we provide a thorough empirical evaluation of FedProx on
a suite of synthetic and real-world federated datasets. Our
empirical results help to illustrate and validate our theoretical analysis, and demonstrate the practical improvements of
FedProx over FedAvg in heterogeneous networks.

2

BACKGROUND AND R ELATED W ORK

Large-scale machine learning, particularly in data center
settings, has motivated the development of numerous distributed optimization methods in the past decade (see, e.g.,
Boyd et al., 2010; Dekel et al., 2012; Dean et al., 2012;
Zhang et al., 2013; Li et al., 2014a; Shamir et al., 2014;
Reddi et al., 2016; Zhang et al., 2015; Richtárik & Takáč,
2016; Smith et al., 2018). However, as computing substrates
such as phones, sensors, and wearable devices grow both in
power and in popularity, it is increasingly attractive to learn
statistical models locally in networks of distributed devices,
in contrast to moving the data to the data center. This problem, known as federated learning, requires tackling novel
challenges with privacy, heterogeneous data and devices,
and massively distributed networks (Li et al., 2019).
Recent optimization methods have been proposed that are
tailored to the specific challenges in the federated setting.
These methods have shown significant improvements over
traditional distributed approaches such as ADMM (Boyd
et al., 2010) or mini-batch methods (Dekel et al., 2012) by
allowing both for inexact local updating in order to balance
communication vs. computation in large networks, and for
a small subset of devices to be active at any communication
round (McMahan et al., 2017; Smith et al., 2017). For example, Smith et al. (2017) propose a communication-efficient
primal-dual optimization method that learns separate but
related models for each device through a multi-task learning
framework. Despite the theoretical guarantees and practical
efficiency of the proposed method, such an approach is not

generalizable to non-convex problems, e.g., deep learning,
where strong duality is no longer guaranteed. In the nonconvex setting, Federated Averaging (FedAvg), a heuristic
method based on averaging local Stochastic Gradient Descent (SGD) updates in the primal, has instead been shown
to work well empirically (McMahan et al., 2017).
Unfortunately, FedAvg is quite challenging to analyze due
to its local updating scheme, the fact that few devices are
active at each round, and the issue that data is frequently
distributed in a heterogeneous nature in the network. In particular, as each device generates its own local data, statistical
heterogeneity is common with data being non-identically
distributed between devices. Several works have made steps
towards analyzing FedAvg in simpler, non-federated settings. For instance, parallel SGD and related variants (Zhang
et al., 2015; Shamir et al., 2014; Reddi et al., 2016; Zhou &
Cong, 2018; Stich, 2019; Wang & Joshi, 2018; Woodworth
et al., 2018; Lin et al., 2020), which make local updates
similar to FedAvg, have been studied in the IID setting.
However, the results rely on the premise that each local
solver is a copy of the same stochastic process (due to the
IID assumption). This line of reasoning does not apply to
the heterogeneous setting.
Although some recent works (Yu et al., 2018; Wang et al.,
2019; Hao et al., 2019; Jiang & Agrawal, 2018) have explored convergence guarantees in statistically heterogeneous
settings, they make the limiting assumption that all devices
participate in each round of communication, which is often
infeasible in realistic federated networks (McMahan et al.,
2017). Further, they rely on specific solvers to be used on
each device (either SGD or GD), as compared to the solveragnostic framework proposed herein, and add additional
assumptions of convexity (Wang et al., 2019) or uniformly
bounded gradients (Yu et al., 2018) to their analyses. There
are also heuristic approaches that aim to tackle statistical
heterogeneity by sharing the local device data or server-side
proxy data (Jeong et al., 2018; Zhao et al., 2018; Huang
et al., 2018). However, these methods may be unrealistic: in
addition to imposing burdens on network bandwidth, sending local data to the server (Jeong et al., 2018) violates the
key privacy assumption of federated learning, and sending
globally-shared proxy data to all devices (Zhao et al., 2018;
Huang et al., 2018) requires effort to carefully generate or
collect such auxiliary data.
Beyond statistical heterogeneity, systems heterogeneity is
also a critical concern in federated networks. The storage,
computational, and communication capabilities of each device in federated networks may differ due to variability in
hardware (CPU, memory), network connectivity (3G, 4G,
5G, wifi), and power (battery level). These system-level
characteristics dramatically exacerbate challenges such as
straggler mitigation and fault tolerance. One strategy used

Federated Optimization in Heterogeneous Networks

in practice is to ignore the more constrained devices failing
to complete a certain amount of training (Bonawitz et al.,
2019). However (as we demonstrate in Section 5), this can
have negative effects on convergence as it limits the number
of effective devices contributing to training, and may induce
bias in the device sampling procedure if the dropped devices
have specific data characteristics.
In this work, inspired by FedAvg, we explore a broader
framework, FedProx, that is capable of handling heterogeneous federated environments while maintaining similar
privacy and computational benefits. We analyze the convergence behavior of the framework through a statistical
dissimilarity characterization between local functions, while
also taking into account practical systems constraints. Our
dissimilarity characterization is inspired by the randomized
Kaczmarz method for solving linear system of equations
(Kaczmarz, 1993; Strohmer & Vershynin, 2009), a similar
assumption of which has been used to analyze variants of
SGD in other settings (see, e.g., Schmidt & Roux, 2013;
Vaswani et al., 2019; Yin et al., 2018). Our proposed framework provides improved robustness and stability for optimization in heterogeneous federated networks.
Finally, in terms of related work, we note that two aspects
of our proposed work—the proximal term in FedProx and
the bounded dissimilarity assumption used in our analysis—
have been previously studied in the optimization literature,
though often with very different motivations and in nonfederated settings. For completeness, we provide a further
discussion in Appendix B on this background work.

3

F EDERATED O PTIMIZATION : M ETHODS

In this section, we introduce the key ingredients behind
recent methods for federated learning, including FedAvg,
and then outline our proposed framework, FedProx.
Federated learning methods (e.g., McMahan et al., 2017;
Smith et al., 2017) are designed to handle multiple devices
collecting data and a central server coordinating the global
learning objective across the network. In particular, the aim
is to minimize:
min f (w) =
w

N
X

pk Fk (w) = Ek [Fk (w)],

(1)

function based on the device’s data is used as a surrogate
for the global objective function. At each outer iteration,
a subset of the devices are selected and local solvers are
used to optimize the local objective functions on each of
the selected devices. The devices then communicate their
local model updates to the central server, which aggregates
them and updates the global model accordingly. The key to
allowing flexible performance in this scenario is that each of
the local objectives can be solved inexactly. This allows the
amount of local computation vs. communication to be tuned
based on the number of local iterations that are performed
(with additional local iterations corresponding to more exact
local solutions). We introduce this notion formally below,
as it will be utilized throughout the paper.
Definition 1 (γ-inexact solution). For a function
h(w; w0 ) = F (w) + µ2 kw − w0 k2 , and γ ∈ [0, 1],
we say w∗ is a γ-inexact solution of minw h(w; w0 )
if k∇h(w∗ ; w0 )k
≤
γk∇h(w0 ; w0 )k, where
∇h(w; w0 ) = ∇F (w) + µ(w − w0 ). Note that a
smaller γ corresponds to higher accuracy.
We use γ-inexactness in our analysis (Section 4) to measure the amount of local computation from the local solver
at each round. As discussed earlier, different devices are
likely to make different progress towards solving the local
subproblems due to variable systems conditions, and it is
therefore important to allow γ to vary both by device and
by iteration. This is one of the motivations for our proposed
framework discussed in the next sections. For ease of notation, we first derive our main convergence results assuming
a uniform γ as defined here (Section 4), and then provide
results with variable γ’s in Corollary 9.
3.1

Federated Averaging (FedAvg)

In Federated Averaging (FedAvg) (McMahan et al., 2017),
the local surrogate of the global objective function at device k is Fk (·), and the local solver is stochastic gradient
descent (SGD), with the same learning rate and number
of local epochs used on each device. At each round, a
subset K  N of the total devices are selected and run
SGD locally for E number of epochs, and then the resulting
model updates are averaged. The details of FedAvg are
summarized in Algorithm 1.

k=1

P
where N is the number of devices, pk ≥ 0, and k pk =1.
In general, the local objectives measure the local empirical risk over possibly differing data distributions Dk , i.e.,
Fk (w) := Exk ∼Dk [fk (w; xk )], with nk samples available
nk
at
P each device k. Hence, we can set pk = n , where n=
k nk is the total number of data points. In this work, we
consider Fk (w) to be possibly non-convex.
To reduce communication, a common technique in federated optimization is that on each device, a local objective

McMahan et al. (2017) show empirically that it is crucial to
tune the optimization hyperparameters of FedAvg properly.
In particular, the number of local epochs in FedAvg plays
an important role in convergence. On one hand, performing more local epochs allows for more local computation
and potentially reduced communication, which can greatly
improve the overall convergence speed in communicationconstrained networks. On the other hand, with dissimilar
(heterogeneous) local objectives Fk , a larger number of local
epochs may lead each device towards the optima of its local

Federated Optimization in Heterogeneous Networks

Algorithm 1 Federated Averaging (FedAvg)
0

Input: K, T , η, E, w , N , pk , k = 1, · · · , N
for t = 0, · · · , T − 1 do
Server selects a subset St of K devices at random (each
device k is chosen with probability pk )
Server sends wt to all chosen devices
Each device k ∈ St updates wt for E epochs of SGD
on Fk with step-size η to obtain wkt+1
Each device k ∈ St sends wkt+1 back to the server
P
Server aggregates the w’s as wt+1 = K1 k∈St wkt+1
end for
objective as opposed to the global objective—potentially
hurting convergence or even causing the method to diverge.
Further, in federated networks with heterogeneous systems
resources, setting the number of local epochs to be high
may increase the risk that devices do not complete training
within a given communication round and must therefore
drop out of the procedure (Bonawitz et al., 2019).
In practice, it is therefore important to find a way to set the
local epochs to be high (to reduce communication) while
also allowing for robust convergence. More fundamentally,
we note that the ‘best’ setting for the number of local epochs
is likely to change at each iteration and on each device—as
a function of both the local data and available systems resources. Indeed, a more natural approach than mandating a
fixed number of local epochs is to allow the epochs to vary
according to the characteristics of the network, and to carefully merge solutions by accounting for this heterogeneity.
We formalize this strategy in FedProx, introduced below.

accommodates variable γ’s for different devices and at different iterations. We formally define γkt -inexactness for
device k at iteration t below, which is a natural extension
from Definition 1.
Definition 2 (γkt -inexact solution). For a function
hk (w; wt ) = Fk (w) + µ2 kw − wt k2 , and γ ∈ [0, 1], we
say w∗ is a γkt -inexact solution of minw hk (w; wt )
if k∇hk (w∗ ; wt )k
≤
γkt k∇hk (wt ; wt )k, where
∇hk (w; wt ) = ∇Fk (w) + µ(w − wt ). Note that a
smaller γkt corresponds to higher accuracy.
Analogous to Definition 1, γkt measures how much local
computation is performed to solve the local subproblem
on device k at the t-th round. The variable number of
local iterations can be viewed as a proxy of γkt . Utilizing
the more flexible γkt -inexactness, we can readily extend
the convergence results under Definition 1 (Theorem 4) to
consider issues related to systems heterogeneity such as
stragglers (see Corollary 9).
Proximal term. As mentioned in Section 3.1, while tolerating nonuniform amounts of work to be performed across
devices can help alleviate negative impacts of systems heterogeneity, too many local updates may still (potentially)
cause the methods to diverge due to the underlying heterogeneous data. We propose to add a proximal term to the
local subproblem to effectively limit the impact of variable
local updates. In particular, instead of just minimizing the
local function Fk (·), device k uses its local solver of choice
to approximately minimize the following objective hk :
min hk (w; wt ) = Fk (w) +
w

3.2

Proposed Framework: FedProx

Our proposed framework, FedProx (Algorithm 2), is similar to FedAvg in that a subset of devices are selected at each
round, local updates are performed, and these updates are
then averaged to form a global update. However, FedProx
makes the following simple yet critical modifications, which
result in significant empirical improvements and also allow
us to provide convergence guarantees for the method.
Tolerating partial work. As previously discussed, different devices in federated networks often have different
resource constraints in terms of the computing hardware,
network connections, and battery levels. Therefore, it is unrealistic to force each device to perform a uniform amount
of work (i.e., running the same number of local epochs,
E), as in FedAvg. In FedProx, we generalize FedAvg
by allowing for variable amounts of work to be performed
locally across devices based on their available systems resources, and then aggregate the partial solutions sent from
the stragglers (as compared to dropping these devices). In
other words, instead of assuming a uniform γ for all devices throughout the training process, FedProx implicitly

µ
kw − wt k2 .
2

(2)

The proximal term is beneficial in two aspects: (1) It addresses the issue of statistical heterogeneity by restricting
the local updates to be closer to the initial (global) model
without any need to manually set the number of local epochs.
(2) It allows for safely incorporating variable amounts of
local work resulting from systems heterogeneity. We summarize the steps of FedProx in Algorithm 2.
Algorithm 2 FedProx (Proposed Framework)
Input: K, T , µ, γ, w0 , N , pk , k = 1, · · · , N
for t = 0, · · · , T − 1 do
Server selects a subset St of K devices at random (each
device k is chosen with probability pk )
Server sends wt to all chosen devices
Each chosen device k ∈ St finds a wkt+1
which is a γkt -inexact minimizer of: wkt+1 ≈
arg minw hk (w; wt ) = Fk (w) + µ2 kw − wt k2
Each device k ∈ St sends wkt+1 back to the server
P
Server aggregates the w’s as wt+1 = K1 k∈St wkt+1
end for

Federated Optimization in Heterogeneous Networks

We note that proximal terms such as the one above are a
popular tool utilized throughout the optimization literature;
for completeness, we provide a more detailed discussion
on this in Appendix B. An important distinction of the proposed usage is that we suggest, explore, and analyze such a
term for the purpose of tackling heterogeneity in federated
networks. Our analysis (Section 4) is also unique in considering solving such an objective in a distributed setting
with: (1) non-IID partitioned data, (2) the use of any local
solver, (3) variable inexact updates across devices, and (4) a
subset of devices being active at each round. These assumptions are critical to providing a characterization of such a
framework in realistic federated scenarios.
In our experiments (Section 5), we demonstrate that tolerating partial work is beneficial in the presence of systems heterogeneity and our modified local subproblem in
FedProx results in more robust and stable convergence
compared to vanilla FedAvg for heterogeneous datasets.
In Section 4, we also see that the usage of the proximal
term makes FedProx more amenable to theoretical analysis (i.e., the local objective may be more well-behaved). In
particular, if µ is chosen accordingly, the Hessian of hk may
be positive semi-definite. Hence, when Fk is non-convex,
hk will be convex, and when Fk is convex, it becomes µstrongly convex.
Finally, we note that since FedProx makes only
lightweight modifications to FedAvg, this allows us to
reason about the behavior of the widely-used FedAvg
method, and enables easy integration of FedProx into
existing packages/systems, such as TensorFlow Federated
and LEAF (TFF; Caldas et al., 2018). In particular, we
note that FedAvg is a special case of FedProx with (1)
µ = 0, (2) the local solver specifically chosen to be SGD,
and (3) a constant γ (corresponding to the number of local
epochs) across devices and updating rounds (i.e., no notion
of systems heterogeneity). FedProx is in fact much more
general in this regard, as it allows for partial work to be performed across devices and any local (possibly non-iterative)
solver to be used on each device.

4

F E D P R O X : C ONVERGENCE A NALYSIS

FedAvg and FedProx are stochastic algorithms by nature:
in each round, only a fraction of the devices are sampled
to perform the update, and the updates performed on each
device may be inexact. It is well known that in order for
stochastic methods to converge to a stationary point, a decreasing step-size is required. This is in contrast to nonstochastic methods, e.g., gradient descent, that can find a
stationary point by employing a constant step-size. In order to analyze the convergence behavior of methods with
constant step-size (as is usually implemented in practice),
we need to quantify the degree of dissimilarity among the

local objective functions. This could be achieved by assuming the data to be IID, i.e., homogeneous across devices.
Unfortunately, in realistic federated networks, this assumption is impractical. Thus, we first propose a metric that
specifically measures the dissimilarity among local functions (Section 4.1), and then analyze FedProx under this
assumption while allowing for variable γ’s (Section 4.2).
4.1

Local dissimilarity

Here we introduce a measure of dissimilarity between the
devices in a federated network, which is sufficient to prove
convergence. This can also be satisfied via a simpler and
more restrictive bounded variance assumption of the gradients (Corollary 10), which we explore in our experiments in
Section 5. Interestingly, similar assumptions (e.g., Schmidt
& Roux, 2013; Vaswani et al., 2019; Yin et al., 2018) have
been explored elsewhere but for differing purposes; we provide a discussion of these works in Appendix B.
Definition 3 (B-local dissimilarity). The
 local functions

Fk are B-locally dissimilar at w if Ek k∇Fk (w)k2 ≤
q
2
k (w)k ]
k∇f (w)k2 B 2 . We further define B(w) = Ek [k∇F
k∇f (w)k2
for2 k∇f (w)k 6= 0.
Here Ek [·] denotes the expectation over devices with masses
PN
pk = nk /n and k=1 pk = 1 (as in Equation 1). Definition 3 can be seen as a generalization of the IID assumption
with bounded dissimilarity, while allowing for statistical heterogeneity. As a sanity check, when all the local functions
are the same, we have B(w) = 1 for all w. However, in the
federated setting, the data distributions are often heterogeneous and B > 1 due to sampling discrepancies even if the
samples are assumed to be IID. Let us also consider the case
where Fk (·)’s are associated with empirical risk objectives.
If the samples on all the devices are homogeneous, i.e., they
are sampled in an IID fashion, then as mink nk → ∞, it
follows that B(w) → 1 for every w as all the local functions
converge to the same expected risk function in the large sample limit. Thus, B(w) ≥ 1 and the larger the value of B(w),
the larger is the dissimilarity among the local functions.
Using Definition 3, we now state our formal dissimilarity
assumption, which we use in our convergence analysis. This
simply requires that the dissimilarity defined in Definition 3
is bounded. As discussed later, our convergence rate is a
function of the statistical heterogeneity/device dissimilarity
in the network.
Assumption 1 (Bounded dissimilarity). For some  > 0,
there exists a B such that for all the points w ∈ Sc =
{w | k∇f (w)k2 > }, B(w) ≤ B .
2
we define B(w)
=
1 when
 As an exception

Ek k∇Fk (w)k2 = k∇f (w)k2 , i.e. w is a stationary solution that all the local functions Fk agree on.

Federated Optimization in Heterogeneous Networks

For most practical machine learning problems, there is no
need to solve the problem to highly accurate stationary solutions, i.e.,  is typically not very small. Indeed, it is wellknown that solving the problem beyond some threshold may
even hurt generalization performance due to overfitting (Yao
et al., 2007). Although in practical federated learning problems the samples are not IID, they are still sampled from
distributions that are not entirely unrelated (if this were the
case, e.g., fitting a single global model w across devices
would be ill-advised). Thus, it is reasonable to assume that
the dissimilarity between local functions remains bounded
throughout the training process. We also measure the dissimilarity metric empirically on real and synthetic datasets
in Section 5.3.3 and show that this metric captures realworld statistical heterogeneity and is correlated with practical performance (the smaller the dissimilarity, the better the
convergence).
4.2

require µ̄ > 0, which is a sufficient but not necessary condition for FedProx to converge. Hence, it is possible that
some other µ (not necessarily satisfying µ̄ > 0) can also
enable convergence, as we explore empirically (Section 5).
Theorem 4 uses the dissimilarity in Definition 3 to identify sufficient decrease of the objective value at each iteration for FedProx. In Appendix A.2, we provide a corollary characterizing the performance with a more common
(though slightly more restrictive) bounded variance assumption. This assumption is commonly employed, e.g., when
analyzing methods such as SGD. We next provide sufficient
(but not necessary) conditions that ensure ρ > 0 in Theorem
4 such that sufficient decrease is attainable after each round.
Remark 5. For ρ in Theorem 4 to be positive, we need
γB < 1 and √BK < 1. These conditions help to quantify
the trade-off between dissimilarity (B) and the algorithm
parameters (γ, K).

FedProx Analysis

Using the bounded dissimilarity assumption (Assumption 1),
we now analyze the amount of expected decrease in the
objective when one step of FedProx is performed. Our
convergence rate (Theorem 6) can be directly derived from
the results of the expected decrease per updating round. We
assume the same γkt for any k, t for ease of notation in the
following analyses.
Theorem 4 (Non-convex FedProx convergence: B-local
dissimilarity). Let Assumption 1 hold. Assume the functions
Fk are non-convex, L-Lipschitz smooth, and there exists
L− > 0, such that ∇2 Fk  −L− I, with µ̄ := µ − L− > 0.
Suppose that wt is not a stationary solution and the local
functions Fk are B-dissimilar, i.e. B(wt ) ≤ B. If µ, K,
and γ in Algorithm 2 are chosen such that
√
1 γB B(1+γ) 2 LB(1+γ)
√
−
ρ=
−
−
µ
µ
µ̄µ
µ̄ K


L(1+γ)2 B 2 LB 2 (1+γ)2 √
>0,
−
−
2 2K +2
2µ̄2
µ̄2 K
then at iteration t of Algorithm 2, we have the following
expected decrease in the global objective:


ESt f (wt+1 ) ≤f (wt )−ρk∇f (wt )k2 ,
where St is the set of K devices chosen at iteration t.
We direct the reader to Appendix A.1 for a detailed proof.
The key steps include applying our notion of γ-inexactness
(Definition 1) for each subproblem and using the bounded
dissimilarity assumption, while allowing for only K devices to be active at each round. This last step in particular
introduces ESt , an expectation with respect to the choice
of devices, St , in round t. We note that in our theory, we

Finally, we can use the above sufficient decrease to the characterize the rate of convergence to
 the set of approximate
stationary solutions Ss = {w | E k∇f (w)k2 ≤ } under
the bounded dissimilarity assumption, Assumption 1. Note
that these results hold for general non-convex Fk (·).
Theorem 6 (Convergence rate: FedProx). Given some
 > 0, assume that for B ≥ B , µ, γ, and K the assumptions of Theorem 4 hold at each iteration of FedProx.
∆
Moreover, f (w0 ) − f ∗ = ∆. Then, after T = O( ρ
) itera

P
T −1
1
t 2
tions of FedProx, we have T t=0 E k∇f (w )k ≤ .
While the results thus far hold for non-convex Fk (·), we
can also characterize the convergence for the special case
of convex loss functions with exact minimization in terms
of local objectives (Corollary 7). A proof is provided in
Appendix A.3.
Corollary 7 (Convergence: Convex case). Let the assertions of Theorem 4 hold. In addition, let Fk (·)’s be convex
and γkt = 0 for any k, t, i.e., all
√ the local problems are
solved exactly, if 1  B ≤ 0.5 K, then we can choose
1
µ ≈ 6LB 2 from which it follows that ρ ≈ 24LB
2.
Note that small  in Assumption 1 translates to larger B .
Corollary 7 suggests that, in order to solve the problem
with increasingly higher accuracies using FedProx, one
needs to increase µ appropriately. We empirically verify
that µ > 0 leads to more stable convergence in Section 5.3.
Moreover, in Corollary 7, if we plug in the upper bound
for B , under a bounded variance assumption (Corollary
10), the number of required steps to achieve accuracy  is
L∆σ 2
O( L∆
 +
2 ). Our analysis helps to characterize the
performance of FedProx and similar methods when local
functions are dissimilar.

Federated Optimization in Heterogeneous Networks

Remark 8 (Comparison with SGD). We note that
FedProx achieves the same asymptotic convergence guarantee as SGD: Under the bounded variance assumption, for
small , if we replace B with its upper-bound in Corollary
10 and choose µ large enough, the iteration complexity of
FedProx when the subproblems are solved exactly and
L∆σ 2
Fk (·)’s are convex is O( L∆
 +
2 ), the same as SGD
(Ghadimi & Lan, 2013).
To provide context for the rate in Theorem 6, we compare
it with SGD in the convex case in Remark 8. In general,
our analysis of FedProx does not yield convergence rates
that improve upon classical distributed SGD (without local
updating)—even though FedProx possibly performs more
work locally at each communication round. In fact, when
data are generated in a non-identically distributed fashion,
it is possible for local updating schemes such as FedProx
to perform worse than distributed SGD. Therefore, our theoretical results do not necessarily demonstrate the superiority
of FedProx over distributed SGD; rather, they provide
sufficient (but not necessary) conditions for FedProx to
converge. Our analysis is the first we are aware of to analyze
any federated (i.e., with local-updating schemes and low
device participation) optimization method for Problem (1)
in heterogeneous settings.
Finally, we note that the previous analyses assume no systems heterogeneity and use the same γ for all devices and iterations. However, we can extend them to allow for γ to vary
by device and by iteration (as in Definition 2), which corresponds to allowing devices to perform variable amounts
of work as determined by the local systems conditions. We
provide convergence results with variable γ’s below.
Corollary 9 (Convergence: Variable γ’s). Assume the functions Fk are non-convex, L-Lipschitz smooth, and there exists L− > 0, such that ∇2 Fk  −L− I, with µ̄ := µ−L− >
0. Suppose that wt is not a stationary solution and the local
functions Fk are B-dissimilar, i.e. B(wt ) ≤ B. If µ, K,
and γkt in Algorithm 2 are chosen such that
√
1 γ t B B(1+γ t ) 2 LB(1+γ t )
t
√
ρ =
−
−
−
µ
µ
µ̄µ
µ̄ K


t 2 2
2
t 2
√
L(1+γ ) B
LB (1+γ )
−
−
2 2K +2
>0,
2µ̄2
µ̄2 K
then at iteration t of Algorithm 2, we have the following
expected decrease in the global objective:


ESt f (wt+1 ) ≤f (wt )−ρt k∇f (wt )k2 ,
where St is the set of K devices chosen at iteration t and
γt =maxk∈St γkt .
The proof can be easily extended from the proof for Theorem 4 , noting the fact that Ek [(1 + γkt )k∇Fk (wt )k] ≤
(1 + maxk∈St γkt )Ek [k∇Fk (wt )k].

5

E XPERIMENTS

We now present empirical results for the generalized
FedProx framework. In Section 5.2, we demonstrate the
improved performance of FedProx tolerating partial solutions in the face of systems heterogeneity. In Section 5.3,
we show the effectiveness of FedProx in the settings with
statistical heterogeneity (regardless of systems heterogeneity). We also study the effects of statistical heterogeneity
on convergence (Section 5.3.1) and show how empirical
convergence is related to our theoretical bounded dissimilarity assumption (Assumption 1) (Section 5.3.3). We provide
thorough details of the experimental setup in Section 5.1 and
Appendix C. All code, data, and experiments are publicly
available at: github.com/litian96/FedProx.
5.1

Experimental Details

We evaluate FedProx on diverse tasks, models, and realworld federated datasets. In order to better characterize
statistical heterogeneity and study its effect on convergence,
we also evaluate on a set of synthetic data, which allows
for more precise manipulation of statistical heterogeneity.
We simulate systems heterogeneity by assigning different
amounts of local work to different devices.
Synthetic data. To generate synthetic data, we follow
a similar setup to that in Shamir et al. (2014), additionally imposing heterogeneity among devices. In particular,
for each device k, we generate samples (Xk , Yk ) according to the model y = argmax(softmax(W x + b)), x ∈
R60 , W ∈ R10×60 , b ∈ R10 . We model Wk ∼ N (uk , 1),
bk ∼ N (uk , 1), uk ∼ N (0, α); xk ∼ N (vk , Σ), where the
covariance matrix Σ is diagonal with Σj,j = j −1.2 . Each element in the mean vector vk is drawn from N (Bk , 1), Bk ∼
N (0, β). Therefore, α controls how much local models differ from each other and β controls how much the local data
at each device differs from that of other devices. We vary
α, β to generate three heterogeneous distributed datasets,
denoted Synthetic (α, β), as shown in Figure 2. We also
generate one IID dataset by setting the same W, b on all
devices and setting Xk to follow the same distribution. Our
goal is to learn a global W and b. Full details are given in
Appendix C.1.
Real data. We also explore four real datasets; statistics are
summarized in Table 1. These datasets are curated from
prior work in federated learning as well as recent federated learning benchmarks (McMahan et al., 2017; Caldas
et al., 2018). We study a convex classification problem with
MNIST (LeCun et al., 1998) using multinomial logistic regression. To impose statistical heterogeneity, we distribute
the data among 1,000 devices such that each device has
samples of only two digits and the number of samples per
device follows a power law. We then study a more complex 62-class Federated Extended MNIST (Cohen et al.,

Federated Optimization in Heterogeneous Networks

2017; Caldas et al., 2018) (FEMNIST) dataset using the
same model. For the non-convex setting, we consider a text
sentiment analysis task on tweets from Sentiment140 (Go
et al., 2009) (Sent140) with an LSTM classifier, where each
twitter account corresponds to a device. We also investigate
the task of next-character prediction on the dataset of The
Complete Works of William Shakespeare (McMahan et al.,
2017) (Shakespeare). Each speaking role in the plays is associated with a different device. Details of datasets, models,
and workloads are provided in Appendix C.1.

Table 1. Statistics of four real federated datasets.

Dataset

Devices

Samples

Samples/device

MNIST
FEMNIST
Shakespeare
Sent140

1,000
200
143
772

69,035
18,345
517,106
40,783

mean
69
92
3,616
53

stdev
106
159
6,808
32

Implementation. We implement FedAvg (Algorithm 1)
and FedProx (Algorithm 2) in Tensorflow (Abadi et al.,
2016). In order to draw a fair comparison with FedAvg, we
employ SGD as a local solver for FedProx, and adopt a
slightly different device sampling scheme than that in Algorithms 1 and 2: sampling devices uniformly and then averaging the updates with weights proportional to the number of
local data points (as originally proposed in McMahan et al.
(2017)). While this sampling scheme is not supported by our
analysis, we observe similar relative behavior of FedProx
vs. FedAvg whether or not it is employed. Interestingly,
we also observe that the sampling scheme proposed herein
in fact results in more stable performance for both methods
(see Appendix C.3.4, Figure 12). This suggests an additional benefit of the proposed framework. Full details are
provided in Appendix C.2.
Hyperparameters & evaluation metrics. For each
dataset, we tune the learning rate on FedAvg (with E=1
and without systems heterogeneity) and use the same learning rate for all experiments on that dataset. We set the
number of selected devices to be 10 for all experiments on
all datasets. For each comparison, we fix the randomly selected devices, the stragglers, and mini-batch orders across
all runs. We report all metrics based on the global objective f (w). Note that in our simulations (see Section 5.2
for details), we assume that each communication round corresponds to a specific aggregation time stamp (measured
in real-world global wall-clock time)—we therefore report
results in terms of rounds rather than FLOPs or wall-clock
time. See details of the hyper-parameters in Appendix C.2.

5.2

Systems Heterogeneity: Tolerating Partial Work

In order to measure the effect of allowing for partial solutions to be sent to handle systems heterogeneity with
FedProx, we simulate federated settings with varying system heterogeneity, as described below.
Systems heterogeneity simulations. We assume that there
exists a global clock during training, and each participating
device determines the amount of local work as a function of
this clock cycle and its systems constraints. This specified
amount of local computation corresponds to some implicit
value γkt for device k at the t-th iteration. In our simulations,
we fix a global number of epochs E, and force some devices
to perform fewer updates than E epochs given their current
systems constraints. In particular, for varying heterogeneous
settings, at each round, we assign x number of epochs (chosen uniformly at random between [1, E]) to 0%, 50%, and
90% of the selected devices, respectively. Settings where 0%
devices perform fewer than E epochs of work correspond to
the environments without systems heterogeneity, while 90%
of the devices sending their partial solutions corresponds to
highly heterogeneous environments. FedAvg will simply
drop these 0%, 50%, and 90% stragglers upon reaching
the global clock cycle, and FedProx will incorporate the
partial updates from these devices.
In Figure 1, we set E to be 20 and study the effects of aggregating partial work from the otherwise dropped devices. The
synthetic dataset here is taken from Synthetic (1,1) in Figure
2. We see that on all the datasets, systems heterogeneity has
negative effects on convergence, and larger heterogeneity
results in worse convergence (FedAvg). Compared with
dropping the more constrained devices (FedAvg), incorporating variable amounts of work (FedProx, µ = 0) is
beneficial and leads to more stable and faster convergence.
We also observe that setting µ > 0 in FedProx can further
improve convergence, as we discuss in Section 5.3.
We additionally investigate two less heterogeneous settings.
First, we limit the capability of all the devices by setting E
to be 1 (i.e., all the devices run at most one local epoch), and
impose systems heterogeneity in a similar way. We show
training loss in Figure 9 and testing accuracy in Figure 10
in the appendix. Even in these settings, allowing for partial
work can improve convergence compared with FedAvg.
Second, we explore a setting without any statistical heterogeneity using an identically distributed synthetic dataset
(Synthetic IID). In this IID setting, as shown in Figure 5
in Appendix C.3.2, FedAvg is rather robust under device
failure, and tolerating variable amounts of local work may
not cause major improvement. This serves as an additional
motivation to rigorously study the effect of statistical heterogeneity on new methods designed for federated learning,
as simply relying on IID data (a setting unlikely to occur in
practice) may not tell a complete story.

Federated Optimization in Heterogeneous Networks

0%
stragglers

50%
stragglers

90%
stragglers

Figure 1. FedProx results in significant convergence improvements relative to FedAvg in heterogeneous networks. We simulate
different levels of systems heterogeneity by forcing 0%, 50%, and 90% devices to be the stragglers (dropped by FedAvg). (1) Comparing
FedAvg and FedProx (µ = 0), we see that allowing for variable amounts of work to be performed can help convergence in the presence
of systems heterogeneity. (2) Comparing FedProx (µ = 0) with FedProx (µ > 0), we show the benefits of our added proximal term.
FedProx with µ > 0 leads to more stable convergence and enables otherwise divergent methods to converge, both in the presence of
systems heterogeneity (50% and 90% stragglers) and without systems heterogeneity (0% stragglers). Note that FedProx with µ = 0 and
without systems heterogeneity (no stragglers) corresponds to FedAvg. We also report testing accuracy in Figure 7, Appendix C.3.2, and
show that FedProx improves the test accuracy on all datasets.

5.3

Statistical Heterogeneity: Proximal Term

To better understand how the proximal term can be beneficial in heterogeneous settings, we first show convergence
can become worse as statistical heterogeneity increases.
5.3.1

Effects of Statistical Heterogeneity

In Figure 2 (the first row), we study how statistical heterogeneity affects convergence using four synthetic datasets
without the presence of systems heterogeneity (fixing E
to be 20). From left to right, as data become more heterogeneous, convergence becomes worse for FedProx with
µ = 0 (i.e., FedAvg). Though it may slow convergence
for IID data, we see that setting µ > 0 is particularly useful
in heterogeneous settings. This indicates that the modified
subproblem introduced in FedProx can benefit practical
federated settings with varying statistical heterogeneity. For
perfectly IID data, some heuristics such as decreasing µ
if the loss continues to decrease may help avoid the deceleration of convergence (see Figure 11 in Appendix C.3.3).
In the sections to follow, we see similar results in our nonsynthetic experiments.
5.3.2

Effects of µ > 0

The key parameters of FedProx that affect performance
are the amount of local work (as parameterized by the number of local epochs, E), and the proximal term scaled by µ.
Intuitively, large E may cause local models to drift too far

away from the initial starting point, thus leading to potential
divergence (McMahan et al., 2017). Therefore, to handle
the divergence or instability of FedAvg with non-IID data,
it is helpful to tune E carefully. However, E is constrained
by the underlying system’s environments on the devices,
and it is difficult to determine an appropriate uniform E for
all devices. Alternatively, it is beneficial to allow for devicespecific E’s (variable γ’s) and tune a best µ (a parameter
that can be viewed as a re-parameterization of E) to prevent
divergence and improve the stability of methods. A proper
µ can restrict the trajectory of the iterates by constraining
the iterates to be closer to that of the global model, thus
incorporating variable amounts of updates and guaranteeing
convergence (Theorem 6).
We show the effects of the proximal term in FedProx
(µ > 0) in Figure 1. For each experiment, we compare the
results between FedProx with µ = 0 and FedProx with
a best µ (see the next paragraph for discussions on how to
select µ). For all datasets, we observe that the appropriate µ
can increase the stability for unstable methods and can force
divergent methods to converge. This holds both when there
is systems heterogeneity (50% and 90% stragglers) and
there is no systems heterogeneity (0% stragglers). µ > 0
also increases the accuracy in most cases (see Figure 6
and Figure 7 in Appendix C.3.2). In particular, FedProx
improves absolute testing accuracy relative to FedAvg by
22% on average in highly heterogeneous environments (90%
stragglers) (see Figure 7).

 d ƌ Ă ŝ Ŷ ŝ Ŷ Ő  > Ž Ɛ Ɛ

Federated Optimization in Heterogeneous Networks
 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ Ͳ / / 
 & Ğ Ě  ǀ Ő  ; & Ğ Ě W ƌ Ž ǆ ͕   с Ϭ Ϳ
 & Ğ Ě W ƌ Ž ǆ ͕   х Ϭ

 Ϯ ͘ Ϭ
 ϭ ͘ ϱ

 ϭ

 Ϭ ͘ ϱ
 Ϭ

 s Ă ƌ ŝ Ă Ŷ Đ Ğ  Ž Ĩ  > Ž Đ Ă ů  ' ƌ Ă Ě ͘

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͘ ϱ ͕ Ϭ ͘ ϱ Ϳ

 Ϯ

 ϭ ͘ Ϭ
 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϭ ͘ Ϯ

 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ
 ϭ
 Ϭ

 ϱ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; ϭ ͕ ϭ Ϳ
 ϳ ϱ
 ϱ Ϭ

 Ϯ Ϭ
 ϱ Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 ϰ Ϭ

 Ϭ

 Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͘ ϱ ͕ Ϭ ͘ ϱ Ϳ

 ϯ Ϭ

 Ϯ Ϭ Ϭ

 ϭ Ϭ Ϭ

 ϲ Ϭ

 ϭ Ϭ
 ϱ Ϭ

 Ϯ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͕ Ϭ Ϳ

 Ϯ Ϭ
 Ϭ

 ϯ

 Ϯ Ϭ Ϭ

 ϰ Ϭ

 Ϭ ͘ ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; ϭ ͕ ϭ Ϳ

 ϯ

 ϭ

 Ϯ Ϭ Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ Ͳ / / 
 & Ğ Ě  ǀ Ő  ; & Ğ Ě W ƌ Ž ǆ ͕   с Ϭ Ϳ
 & Ğ Ě W ƌ Ž ǆ ͕   х Ϭ

 Ϭ ͘ ϯ

 Ϭ ͘ Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͕ Ϭ Ϳ

 ϯ

 Ϯ ϱ
 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

Figure 2. Effect of data heterogeneity on convergence. We remove the effects of systems heterogeneity by forcing each device to run the
same amount of epochs. In this setting, FedProx with µ = 0 reduces to FedAvg. (1) Top row: We show training loss (see results on
testing accuracy in Appendix C.3, Figure 6) on four synthetic datasets whose statistical heterogeneity increases from left to right. Note
that the method with µ = 0 corresponds to FedAvg. Increasing heterogeneity leads to worse convergence, but setting µ > 0 can help to
combat this. (2) Bottom row: We show the corresponding dissimilarity measurement (variance of gradients) of the four synthetic datasets.
This metric captures statistical heterogeneity and is consistent with training loss — smaller dissimilarity indicates better convergence.

 d ƌ Ă ŝ Ŷ ŝ Ŷ Ő  > Ž Ɛ Ɛ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ Ͳ / / 

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; ϭ ͕ ϭ Ϳ

 & Ğ Ě  ǀ Ő  ; & Ğ Ě W ƌ Ž ǆ ͕   с Ϭ Ϳ
 & Ğ Ě W ƌ Ž ǆ ͕  Ě Ǉ Ŷ Ă ŵ ŝ Đ 
 & Ğ Ě W ƌ Ž ǆ ͕   х Ϭ

 Ϯ ͘ Ϭ
 ϭ ͘ ϱ

5.3.3

 Ϯ

 ϭ ͘ Ϭ

 ϭ

 Ϭ ͘ ϱ
 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

Dissimilarity Measurement and Divergence

 ϯ

 Ϯ Ϭ Ϭ

 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

Figure 3. Effectiveness of setting µ adaptively based on the current
model performance. We increase µ by 0.1 whenever the loss
increases and decreases it by 0.1 whenever the loss decreases for
5 consecutive rounds. We initialize µ to 1 for Synthetic IID (in
order to be adversarial to our methods), and initialize µ to 0 for
Synthetic (1,1). This simple heuristic works well empirically.

Choosing µ. One natural question is to determine how to
set the penalty constant µ in the proximal term. A large µ
may potentially slow the convergence by forcing the updates
to be close to the starting point, while a small µ may not
make any difference. In all experiments, we tune the best
µ from the limited candidate set {0.001, 0.01, 0.1, 1}. For
the five federated datasets in Figure 1, the best µ values are
1, 1, 1, 0.001, and 0.01, respectively. While automatically
tuning µ is difficult to instantiate directly from our theoretical results, in practice, we note that µ can be adaptively
chosen based on the current performance of the model. For
example, one simple heuristic is to increase µ when seeing
the loss increasing and decreasing µ when seeing the loss
decreasing. In Figure 3, we demonstrate the effectiveness of
this heuristic using two synthetic datasets. Note that we start
from initial µ values that are adversarial to our methods. We
provide full results showing the competitive performance
of this approach in Appendix C.3.3. Future work includes
developing methods to automatically tune this parameter
for heterogeneous datasets, based, e.g., on the theoretical
groundwork provided here.

Finally, in Figure 2 (the bottom row), we demonstrate that
our B-local dissimilarity measurement in Definition 3 captures the heterogeneity of datasets and is therefore an appropriate proxy of performance. In particular, we track the variance of gradients on each device, Ek [k∇Fk (w)−∇f (w)k2 ],
which is lower bounded by B (see Bounded Variance Equivalence Corollary 10). Empirically, we observe that increasing µ leads to smaller dissimilarity among local functions
Fk , and that the dissimilarity metric is consistent with the
training loss. Therefore, smaller dissimilarity indicates better convergence, which can be enforced by setting µ appropriately. We also show the dissimilarity metric on real
federated data in Appendix C.3.2.

6

C ONCLUSION

In this work, we have proposed FedProx, an optimization
framework that tackles the systems and statistical heterogeneity inherent in federated networks. FedProx allows
for variable amounts of work to be performed locally across
devices, and relies on a proximal term to help stabilize
the method. We provide the convergence guarantees for
FedProx in realistic federated settings under a device dissimilarity assumption, while also accounting for practical
issues such as stragglers. Our empirical evaluation across a
suite of federated datasets has validated our theoretical analysis and demonstrated that the FedProx framework can
significantly improve the convergence behavior of federated
learning in realistic heterogeneous networks.

ACKNOWLEDGEMENTS
We thank Sebastian Caldas, Jakub Konečný, Brendan
McMahan, Nathan Srebro, and Jianyu Wang for their help-

Federated Optimization in Heterogeneous Networks

ful discussions. AT and VS are supported in part by DARPA
FA875017C0141, the National Science Foundation grants
IIS1705121 and IIS1838017, an Okawa Grant, a Google
Faculty Award, an Amazon Web Services Award, a JP Morgan A.I. Research Faculty Award, a Carnegie Bosch Institute
Research Award, and the CONIX Research Center, one of
six centers in JUMP, a Semiconductor Research Corporation (SRC) program sponsored by DARPA. Any opinions,
findings, and conclusions or recommendations expressed
in this material are those of the author(s) and do not necessarily reflect the views of DARPA, the National Science
Foundation, or any other funding agency.

R EFERENCES
Tensorflow federated: Machine learning on decentralized data. URL https://www.tensorflow.org/
federated.
Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean,
J., Devin, M., Ghemawat, S., Irving, G., Isard, M., Kudlur,
M. K., Levenberg, J., Monga, R., Moore, S., Murray,
D. G., Steiner, B., Tucker, P., Vasudevan, V., Warden, P.,
Wicke, M., Yu, Y., and Zheng, X. Tensorflow: A system
for large-scale machine learning. In Operating Systems
Design and Implementation, 2016.

Dekel, O., Gilad-Bachrach, R., Shamir, O., and Xiao, L. Optimal Distributed Online Prediction Using Mini-Batches.
Journal of Machine Learning Research, 2012.
Ghadimi, S. and Lan, G. Stochastic first-and zeroth-order
methods for nonconvex stochastic programming. SIAM
Journal on Optimization, 2013.
Go, A., Bhayani, R., and Huang, L. Twitter sentiment
classification using distant supervision. CS224N Project
Report, Stanford, 2009.
Goldblum, M., Reich, S., Fowl, L., Ni, R., Cherepanova,
V., and Goldstein, T. Unraveling meta-learning: Understanding feature representations for few-shot tasks. arXiv
preprint arXiv:2002.06753, 2020.
Hao, Y., Rong, J., and Sen, Y. On the linear speedup analysis
of communication efficient momentum sgd for distributed
non-convex optimization. In International Conference on
Machine Learning, 2019.
Huang, L., Yin, Y., Fu, Z., Zhang, S., Deng, H., and
Liu, D. Loadaboost: Loss-based adaboost federated
machine learning on medical data. arXiv preprint
arXiv:1811.12629, 2018.

Allen-Zhu, Z. How to make the gradients small stochastically: Even faster convex and nonconvex sgd. In Advances in Neural Information Processing Systems, 2018.

Jeong, E., Oh, S., Kim, H., Park, J., Bennis, M., and Kim, S.L. Communication-efficient on-device machine learning:
Federated distillation and augmentation under non-iid
private data. arXiv preprint arXiv:1811.11479, 2018.

Bonawitz, K., Eichner, H., Grieskamp, W., Huba, D., Ingerman, A., Ivanov, V., Kiddon, C., Konecny, J., Mazzocchi,
S., McMahan, H. B., Overveldt, T. V., Petrou, D., Ramage, D., and Roselander, J. Towards federated learning at
scale: system design. In Conference on Machine Learning and Systems, 2019.

Jiang, P. and Agrawal, G. A linear speedup analysis of distributed deep learning with sparse and quantized communication. In Advances in Neural Information Processing
Systems, 2018.

Boyd, S., Parikh, N., Chu, E., Peleato, B., and Eckstein, J.
Distributed optimization and statistical learning via the
alternating direction method of multipliers. Foundations
and Trends in Machine Learning, 2010.
Caldas, S., Wu, P., Li, T., Konečnỳ, J., McMahan, H. B.,
Smith, V., and Talwalkar, A. Leaf: A benchmark for federated settings. arXiv preprint arXiv:1812.01097, 2018.
Cohen, G., Afshar, S., Tapson, J., and van Schaik, A. Emnist: an extension of mnist to handwritten letters. arXiv
preprint arXiv:1702.05373, 2017.
Dean, J., Corrado, G., Monga, R., Chen, K., Devin, M., Le,
Q. V., Mao, M., Ranzato, M., Senior, A., Tucker, P., Yang,
K., and Ng, A. Large scale distributed deep networks.
In Advances in Neural Information Processing Systems,
2012.

Kaczmarz, S. Approximate solution of systems of linear
equations. International Journal of Control, 1993.
Khodak, M., Balcan, M.-F. F., and Talwalkar, A. S. Adaptive
gradient-based meta-learning methods. In Advances in
Neural Information Processing Systems, 2019.
LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P. Gradientbased learning applied to document recognition. Proceedings of the IEEE, 1998.
Li, M., Andersen, D. G., Smola, A. J., and Yu, K. Communication efficient distributed machine learning with
the parameter server. In Advances in Neural Information
Processing Systems, 2014a.
Li, M., Zhang, T., Chen, Y., and Smola, A. J. Efficient minibatch training for stochastic optimization. In Conference
on Knowledge Discovery and Data Mining, 2014b.

Federated Optimization in Heterogeneous Networks

Li, T., Sahu, A., Talwalkar, A., and Smith, V. Federated
learning: Challenges, methods, and future directions.
arXiv preprint arXiv:1908.07873, 2019.
Li, T., Sahu, A. K., Zaheer, M., Sanjabi, M., Talwalkar, A.,
and Smith, V. Feddane: A federated newton-type method.
arXiv preprint arXiv:2001.01920, 2020.
Lin, T., Stich, S. U., and Jaggi, M. Don’t use large minibatches, use local sgd. In International Conference on
Learning Representations, 2020.
McMahan, H. B., Moore, E., Ramage, D., Hampson, S.,
and Arcas, B. A. y. Communication-efficient learning of
deep networks from decentralized data. In International
Conference on Artificial Intelligence and Statistics, 2017.
Pennington, J., Socher, R., and Manning, C. Glove: Global
vectors for word representation. In Empirical Methods in
Natural Language Processing, 2014.
Reddi, S. J., Konečnỳ, J., Richtárik, P., Póczós, B., and
Smola, A. Aide: Fast and communication efficient distributed optimization. arXiv preprint arXiv:1608.06879,
2016.
Richtárik, P. and Takáč, M. Distributed coordinate descent
method for learning with big data. Journal of Machine
Learning Research, 2016.
Schmidt, M. and Roux, N. L. Fast convergence of stochastic
gradient descent under a strong growth condition. arXiv
preprint arXiv:1308.6370, 2013.
Shamir, O., Srebro, N., and Zhang, T. Communicationefficient distributed optimization using an approximate
newton-type method. In International Conference on
Machine Learning, 2014.

Wang, J. and Joshi, G.
Cooperative sgd: A
unified framework for the design and analysis of
communication-efficient sgd algorithms. arXiv preprint
arXiv:1808.07576, 2018.
Wang, S., Tuor, T., Salonidis, T., Leung, K. K., Makaya,
C., He, T., and Chan, K. Adaptive federated learning
in resource constrained edge computing systems. IEEE
Journal on Selected Areas in Communications, 2019.
Woodworth, B. E., Wang, J., Smith, A., McMahan, B.,
and Srebro, N. Graph oracle models, lower bounds, and
gaps for parallel stochastic optimization. In Advances in
Neural Information Processing Systems, 2018.
Yao, Y., Rosasco, L., and Caponnetto, A. On early stopping
in gradient descent learning. Constructive Approximation,
2007.
Yin, D., Pananjady, A., Lam, M., Papailiopoulos, D., Ramchandran, K., and Bartlett, P. Gradient diversity: a key
ingredient for scalable distributed learning. In International Conference on Artificial Intelligence and Statistics,
2018.
Yu, H., Yang, S., and Zhu, S. Parallel restarted sgd for
non-convex optimization with faster convergence and
less communication. In AAAI Conference on Artificial
Intelligence, 2018.
Zhang, S., Choromanska, A. E., and LeCun, Y. Deep learning with elastic averaging sgd. In Advances in Neural
Information Processing Systems, 2015.
Zhang, Y., Duchi, J. C., and Wainwright, M. J.
Communication-efficient algorithms for statistical optimization. Journal of Machine Learning Research, 2013.

Smith, V., Chiang, C.-K., Sanjabi, M., and Talwalkar, A. S.
Federated multi-task learning. In Advances in Neural
Information Processing Systems, 2017.

Zhao, Y., Li, M., Lai, L., Suda, N., Civin, D., and Chandra,
V. Federated learning with non-iid data. arXiv preprint
arXiv:1806.00582, 2018.

Smith, V., Forte, S., Ma, C., Takac, M., Jordan, M. I.,
and Jaggi, M. Cocoa: A general framework for
communication-efficient distributed optimization. Journal of Machine Learning Research, 2018.

Zhou, F. and Cong, G. On the convergence properties of
a k-step averaging stochastic gradient descent algorithm
for nonconvex optimization. In International Joint Conference on Artificial Intelligence, 2018.

Stich, S. U. Local sgd converges fast and communicates
little. In International Conference on Learning Representations, 2019.
Strohmer, T. and Vershynin, R. A randomized kaczmarz algorithm with exponential convergence. Journal of Fourier
Analysis and Applications, 2009.
Vaswani, S., Bach, F., and Schmidt, M. Fast and faster
convergence of sgd for over-parameterized models (and
an accelerated perceptron). In International Conference
on Artificial Intelligence and Statistics, 2019.

Zhou, P., Yuan, X., Xu, H., Yan, S., and Feng, J. Efficient
meta learning via minibatch proximal update. In Advances in Neural Information Processing Systems, 2019.

Federated Optimization in Heterogeneous Networks

A

C OMPLETE P ROOFS

A.1

Proof of Theorem 4

Proof. Using our notion of γ-inexactness for each local solver (Definition 1), we can define et+1
such that:
k
∇Fk (wkt+1 ) + µ(wkt+1 − wt ) − et+1
= 0,
k
t
ket+1
k k ≤ γk∇Fk (w )k .

(3)



Now let us define w̄t+1 = Ek wkt+1 . Based on this definition, we know
w̄t+1 − wt =

 1 

−1 
Ek ∇Fk (wkt+1 ) + Ek et+1
.
k
µ
µ

(4)

Let us define µ̄ = µ − L− > 0 and ŵkt+1 = arg minw hk (w; wt ). Then, due to the µ̄-strong convexity of hk , we have
kŵkt+1 − wkt+1 k ≤

γ
k∇Fk (wt )k.
µ̄

(5)

Note that once again, due to the µ̄-strong convexity of hk , we know that kŵkt+1 − wt k ≤ µ̄1 k∇Fk (wt )k. Now we can use
the triangle inequality to get
kwkt+1 − wt k ≤

1+γ
k∇Fk (wt )k.
µ̄

(6)

Therefore,



B(1 + γ)
1+γ 
1+γp
kw̄t+1 − wt k ≤ Ek kwkt+1 − wt k ≤
Ek k∇Fk (wt )k ≤
k∇f (wt )k,
Ek [k∇Fk (wt )k2 ] ≤
µ̄
µ̄
µ̄

where the last inequality is due to the bounded dissimilarity assumption.



Now let us define Mt+1 such that w̄t+1 − wt = −1
∇f (wt ) + Mt+1 , i.e. Mt+1 = Ek ∇Fk (wkt+1 ) − ∇Fk (wt ) − et+1
.
k
µ
We can bound kMt+1 k:


kMt+1 k ≤ Ek Lkwkt+1 − wkt k + ket+1
k k ≤

L(1 + γ)
+γ
µ̄

!


t



× Ek k∇Fk (w )k ≤

!
L(1 + γ)
+ γ Bk∇f (wt )k ,
µ̄

(7)

where the last inequality is also due to bounded dissimilarity assumption. Based on the L-Lipschitz smoothness of f and
Taylor expansion, we have
L t+1
kw̄
− wt k2
2
L(1 + γ)2 B 2
1
1
≤ f (wt ) − k∇f (wt )k2 − h∇f (wt ), Mt+1 i +
k∇f (wt )k2
µ
µ
2µ̄2


LB(1 + γ)
L(1 + γ)2 B 2
1 − γB
≤ f (wt ) −
−
−
× k∇f (wt )k2 .
µ
µ̄µ
2µ̄2

f (w̄t+1 ) ≤ f (wt ) + h∇f (wt ), w̄t+1 − wt i +

(8)

From the above inequality it follows that if we set the penalty parameter µ large enough, we can get a decrease in the
objective value of f (w̄t+1 ) − f (wt ) which is proportional to k∇f (wt )k2 . However, this is not the way that the algorithm
t
works.
In the

 algorithm, we only use K devices that are chosen randomly to approximate w̄ . So, in order to find the
E f (wt+1 ) , we use local Lipschitz continuity of the function f .
f (wt+1 ) ≤ f (w̄t+1 ) + L0 kwt+1 − w̄t+1 k,

(9)

where L0 is the local Lipschitz continuity constant of function f and we have
L0 ≤ k∇f (wt )k + L max(kw̄t+1 − wt k, kwt+1 − wt k) ≤ k∇f (wt )k + L(kw̄t+1 − wt k + kwt+1 − wt k).

Therefore, if we take expectation with respect to the choice of devices in round t we need to bound


ESt f (wt+1 ) ≤ f (w̄t+1 ) + Qt ,

(10)

Federated Optimization in Heterogeneous Networks



where Qt = ESt L0 kwt+1 − w̄t+1 k . Note that the expectation is taken over the random choice of devices to update.



Qt ≤ ESt k∇f (wt )k + L(kw̄t+1 − wt k + kwt+1 − wt k) × kwt+1 − w̄t+1 k






≤ k∇f (wt )k + Lkw̄t+1 − wt k ESt kwt+1 − w̄t+1 k + LESt kwt+1 − wt k · kwt+1 − w̄t+1 k






≤ k∇f (wt )k + 2Lkw̄t+1 − wt k ESt kwt+1 − w̄t+1 k + LESt kwt+1 − w̄t+1 k2

(11)

From (7), we have that kw̄t+1 − wt k ≤ B(1+γ)
k∇f (wt )k. Moreover,
µ̄

 p
ESt kwt+1 − w̄t+1 k ≤ ESt [kwt+1 − w̄t+1 k2 ]

(12)

and




1
ESt kwt+1 − w̄t+1 k2 ≤ Ek kwkt+1 − w̄t+1 k2
K




2
≤ Ek kwkt+1 − wt k2 , (as w̄t+1 = Ek wkt+1 )
K

2 (1 + γ)2 
Ek k∇Fk (wt )k2 (from (6))
≤
K
µ̄2
2B 2 (1 + γ)2
≤
k∇f (wt )k2 ,
K
µ̄2

(13)

where the first inequality is a result of K devices being chosen randomly to get wt and the last inequality is due to bounded
dissimilarity assumption. If we replace these bounds in (11) we get
Qt ≤

√

!
B(1 + γ) 2
LB 2 (1 + γ)2 √
√
2 2K + 2
+
k∇f (wt )k2
µ̄2 K
µ̄ K

(14)

Combining (8), (10), (9) and (14) and using the notation α = µ1 we get
√
B(1 + γ) 2
LB(1 + γ)
γB
1
√
−
−
−
µ
µ
µ̄µ
µ̄ K
!


L(1 + γ)2 B 2
LB 2 (1 + γ)2 √
−
−
2 2K + 2
k∇f (wt )k2 .
2
2µ̄
µ̄2 K



ESt f (wt+1 ) ≤ f (wt ) −

A.2

Proof for Bounded Variance

Corollary 10 (Bounded variance equivalence). Let Assumption 1 hold.
Then, in the case of bounded variance, i.e.,
q


2
2
2
Ek k∇Fk (w) − ∇f (w)k ≤ σ , for any  > 0 it follows that B ≤ 1 + σ .
Proof.

We have,
Ek [k∇Fk (w) − ∇f (w)k2 ] = Ek [k∇Fk (w)k2 ] − k∇f (w)k2 ≤ σ 2
⇒ Ek [k∇Fk (w)k2 ] ≤ σ 2 + k∇f (w)k2
s
r
Ek [k∇Fk (w)k2 ]
σ2
⇒ B =
≤ 1+
.
2
k∇f (w)k


With Corollary 10 in place, we can restate the main result in Theorem 4 in terms of the bounded variance assumption.

Federated Optimization in Heterogeneous Networks

Theorem 11 (Non-convex FedProx convergence: Bounded variance). Let the assertions of Theorem 4 hold. In addition,


2
let the iterate wt be such that k∇f (wt )k ≥ , and let Ek k∇Fk (w) − ∇f (w)k2 ≤ σ 2 hold instead of the dissimilarity
condition. If µ, K and γ in Algorithm 2 are chosen such that
!r
√




σ2
σ2
1
γ (1+γ) 2 L(1+γ)
L(1+γ)2 L(1+γ)2 √
√
1+
+
1+
ρ=
−
+
+
−
2 2K+2
>0,
µ
µ
µ̄µ

2µ̄2
µ̄2 K

µ̄ K
then at iteration t of Algorithm 2, we have the following expected decrease in the global objective:


ESt f (wt+1 ) ≤f (wt )−ρk∇f (wt )k2 ,
where St is the set of K devices chosen at iteration t.
The proof of Theorem 11 follows from the proof of Theorem 4 by noting the relationship between the bounded variance
assumption and the dissimilarity assumption as portrayed by Corollary 10.
A.3

Proof of Corollary 7

In the convex case, where L− = 0 and
√ µ̄ = µ, if γ = 0, i.e., all subproblems are solved
√ accurately, we can get a decrease
proportional to k∇f (wt )k2 if B < K. In such a case if we assume 1 << B ≤ 0.5 K, then we can write


3LB 2
1
ESt f (wt+1 ) / f (wt ) −
k∇f (wt )k2 +
k∇f (wt )k2 .
2µ
2µ2

(15)

In this case, if we choose µ ≈ 6LB 2 we get


ESt f (wt+1 ) / f (wt ) −

1
k∇f (wt )k2 .
24LB 2

(16)

Note that the expectation in (16) is a conditional expectation conditioned on the previous iterate. Taking expectation of both
sides, and telescoping, we have that the number of iterations to at least generate one solution with squared norm of gradient
2
less than  is O( LB ∆ ).

Federated Optimization in Heterogeneous Networks

B

C ONNECTIONS TO OTHER SINGLE - MACHINE AND DISTRIBUTED METHODS

Two aspects of the proposed work—the proximal term in FedProx, and the bounded dissimilarity assumption used in our
analysis—have been previously studied in the optimization literature, but with very different motivations. For completeness,
we provide a discussion below on our relation to these prior works.
Proximal term. The proposed modified objective in FedProx shares a connection with elastic averaging SGD
(EASGD) (Zhang et al., 2015), which was proposed as a way to train deep networks in the data center setting, and
uses a similar proximal term in its objective. While the intuition is similar to EASGD (this term helps to prevent large
deviations on each device/machine), EASGD employs a more complex moving average to update parameters, is limited to
using SGD as a local solver, and has only been analyzed for simple quadratic problems. The proximal term we introduce
has also been explored in previous optimization literature with different purposes, such as Allen-Zhu (2018), to speed up
(mini-batch) SGD training on a single machine, and in Li et al. (2014b) for efficient SGD training both in a single machine
and distributed settings. However, the analysis in Li et al. (2014b) is limited to a single machine setting with different
assumptions (e.g., IID data and solving the subproblem exactly at each round).
In addition, DANE (Shamir et al., 2014) and AIDE (Reddi et al., 2016), distributed methods designed for the data center
setting, propose a similar proximal term in the local objective function, but also augment this with an additional gradient
correction term. Both methods assume that all devices participate at each communication round, which is impractical
in federated settings. Indeed, due to the inexact estimation of full gradients (i.e., ∇φ(w(t−1) ) in Shamir et al. (2014, Eq
(13))) with device subsampling schemes and the staleness of the gradient correction term (Shamir et al., 2014, Eq (13)),
these methods are not directly applicable to our setting. Regardless of this, we explore a variant of such an approach in
federated settings and see that the gradient direction term does not help in this scenario—performing uniformly worse than
the proposed FedProx framework for heterogeneous datasets, despite the extra computation required (see Figure 4). We
refer interested readers to Li et al. (2020) for more detailed discussions.
Finally, we note that there is an interesting connection between meta-learning methods and federated optimization methods (Khodak et al., 2019), and similar proximal terms have recently been investigated in the context of meta-learning for
improved performance on few-shot learning tasks (Goldblum et al., 2020; Zhou et al., 2019).
 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ Ͳ / / 

 d ƌ Ă ŝ Ŷ ŝ Ŷ Ő  > Ž Ɛ Ɛ

 ϭ ͘ ϱ
 ϭ ͘ Ϭ

 ϯ Ϭ
 Ϯ ϱ

 ϭ ϱ

 Ϯ Ϭ

 ϱ Ϭ

 ϳ ϱ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ Ϯ ϱ

 ϭ ϱ Ϭ

 ϭ ϳ ϱ

 Ϯ Ϭ Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ Ͳ / / 

 ϭ ͘ ϱ

 Ϭ

 Ϯ ϱ

 ϱ Ϭ

 ϳ ϱ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ Ϯ ϱ

 ϭ ϱ Ϭ

 ϭ ϳ ϱ

 Ϯ Ϭ Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͕ Ϭ Ϳ

 Ϯ ϱ

 ϱ Ϭ

 ϳ ϱ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ Ϯ ϱ

 ϭ ϱ Ϭ

 ϭ ϳ ϱ

 Ϯ Ϭ Ϭ

 Ϯ ϱ

 ϭ ϱ

 Ϯ Ϭ

 Ϭ

 Ϭ

 Ϯ ϱ

 ϱ Ϭ

 ϳ ϱ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ Ϯ ϱ

 ϭ ϱ Ϭ

 ϭ ϳ ϱ

 Ϯ Ϭ Ϭ

 ϳ ϱ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ Ϯ ϱ

 ϭ ϱ Ϭ

 ϭ ϳ ϱ

 Ϯ Ϭ Ϭ

 Ϭ

 ϱ Ϭ

 ϳ ϱ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ Ϯ ϱ

 ϭ ϱ Ϭ

 ϭ ϳ ϱ

 Ϯ Ϭ Ϭ

 ϭ ϱ Ϭ

 ϭ ϳ ϱ

 Ϯ Ϭ Ϭ

 ϴ Ϭ
 ϲ Ϭ
 ϰ Ϭ
 Ϯ Ϭ

 ϱ
 ϱ Ϭ

 Ϯ ϱ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; ϭ ͕ ϭ Ϳ

 ϭ Ϭ

 Ϯ ϱ

 Ϭ

 ϭ Ϭ Ϭ

 ϭ ϱ

 Ϭ

 Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͘ ϱ ͕ Ϭ ͘ ϱ Ϳ

 ϯ Ϭ

 Ϯ Ϭ

 ϱ
 Ϭ

 Ϯ Ϭ

 ϯ ϱ

 ϭ Ϭ

 Ϭ ͘ ϱ

 Ϭ

 ϰ Ϭ

 Ϯ ϱ

 ϭ ͘ Ϭ

 ϰ Ϭ

 ϱ

 ϯ Ϭ

 с Ϭ ͕   с Ϯ Ϭ ͕  Đ с ϭ Ϭ ͕  & Ğ Ě W ƌ Ž ǆ
 с Ϭ ͕   с Ϯ Ϭ ͕  Đ с ϭ Ϭ ͕  & Ğ Ě   E 
 с Ϭ ͕   с Ϯ Ϭ ͕  Đ с Ϯ Ϭ ͕  & Ğ Ě   E 
 с Ϭ ͕   с Ϯ Ϭ ͕  Đ с ϯ Ϭ ͕  & Ğ Ě   E 

 Ϯ ͘ Ϭ

 ϲ Ϭ

 ϭ Ϭ

 ϱ
 Ϯ ϱ

 ϴ Ϭ

 ϭ ϱ

 ϭ Ϭ

 Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; ϭ ͕ ϭ Ϳ
 ϭ Ϭ Ϭ

 ϯ ϱ

 Ϯ Ϭ

 Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͘ ϱ ͕ Ϭ ͘ ϱ Ϳ

 ϰ Ϭ

 Ϯ ϱ

 Ϭ ͘ ϱ

 d ƌ Ă ŝ Ŷ ŝ Ŷ Ő  > Ž Ɛ Ɛ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͕ Ϭ Ϳ

 ϯ Ϭ

 с Ϭ ͕   с Ϯ Ϭ ͕  & Ğ Ě W ƌ Ž ǆ
 с ϭ ͕   с Ϯ Ϭ ͕  & Ğ Ě W ƌ Ž ǆ
 с Ϭ ͕   с Ϯ Ϭ ͕  & Ğ Ě   E 
 с ϭ ͕   с Ϯ Ϭ ͕  & Ğ Ě   E 

 Ϯ ͘ Ϭ

 Ϭ

 Ϯ ϱ

 ϱ Ϭ

 ϳ ϱ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ Ϯ ϱ

 ϭ ϱ Ϭ

 ϭ ϳ ϱ

 Ϯ Ϭ Ϭ

 Ϭ

 Ϭ

 Ϯ ϱ

 ϱ Ϭ

 ϳ ϱ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ Ϯ ϱ

Figure 4. DANE and AIDE (Shamir et al., 2014; Reddi et al., 2016) are methods proposed in the data center setting that use a similar
proximal term as FedProx as well as an additional gradient correction term. We modify DANE to apply to federated settings by allowing
for local updating and low participation of devices. We show the convergence of this modified method, which we call FedDane, on
synthetic datasets. In the top figures, we subsample 10 devices out of 30 on all datasets for both FedProx and FedDane. While
FedDane performs similarly as FedProx on the IID data, it suffers from poor convergence on the non-IID datasets. In the bottom
figures, we show the results of FedDane when we increase the number of selected devices in order to narrow the gap between our
estimated full gradient and the real full gradient (in the gradient correction term). Note that communicating with all (or most of the)
devices is already unrealistic in practical settings. We observe that although sampling more devices per round might help to some extent,
FedDane is still unstable and tends to diverge. This serves as additional motivation for the specific subproblem we propose in FedProx.

Federated Optimization in Heterogeneous Networks

Bounded dissimilarity assumption. The bounded dissimilarity assumption we discuss in Assumption 1 has appeared in
different forms, for example in Schmidt & Roux (2013); Yin et al. (2018); Vaswani et al. (2019). In Yin et al. (2018), the
bounded similarity assumption is used in the context of asserting gradient diversity and quantifying the benefit in terms of
scaling of the mean square error for mini-batch SGD for IID data. In Schmidt & Roux (2013); Vaswani et al. (2019), the
authors use a similar assumption, called strong growth condition, which is a stronger version of Assumption 1 with  = 0.
They prove that some interesting practical problems satisfy such a condition. They also use this assumption to prove optimal
and better convergence rates for SGD with constant step-sizes. Note that this is different from our approach as the algorithm
that we are analyzing is not SGD, and our analysis is different in spite of the similarity in the assumptions.

Federated Optimization in Heterogeneous Networks

C

S IMULATION D ETAILS AND A DDITIONAL E XPERIMENTS

C.1

Datasets and Models

Here we provide full details on the datasets and models used in our experiments. We curate a diverse set of non-synthetic
datasets, including those used in prior work on federated learning (McMahan et al., 2017), and some proposed in LEAF, a
benchmark for federated settings (Caldas et al., 2018). We also create synthetic data to directly test the effect of heterogeneity
on convergence, as in Section 5.1.
• Synthetic: We set (α, β)=(0,0), (0.5,0.5) and (1,1) respectively to generate three non-identical distributed datasets (Figure
2). In the IID data (Figure 5), we set the same W, b ∼ N (0, 1) on all devices and Xk to follow the same distribution
N (v, Σ) where each element in the mean vector v is zero and Σ is diagonal with Σj,j = j −1.2 . For all synthetic datasets,
there are 30 devices in total and the number of samples on each device follows a power law.
• MNIST: We study image classification of handwritten digits 0-9 in MNIST (LeCun et al., 1998) using multinomial
logistic regression. To simulate a heterogeneous setting, we distribute the data among 1000 devices such that each device
has samples of only 2 digits and the number of samples per device follows a power law. The input of the model is a
flattened 784-dimensional (28 × 28) image, and the output is a class label between 0 and 9.
• FEMNIST: We study an image classification problem on the 62-class EMNIST dataset (Cohen et al., 2017) using
multinomial logistic regression. To generate heterogeneous data partitions, we subsample 10 lower case characters (‘a’-‘j’)
from EMNIST and distribute only 5 classes to each device. We call this federated version of EMNIST FEMNIST. There
are 200 devices in total. The input of the model is a flattened 784-dimensional (28 × 28) image, and the output is a class
label between 0 and 9.
• Shakespeare: This is a dataset built from The Complete Works of William Shakespeare (McMahan et al., 2017). Each
speaking role in a play represents a different device. We use a two-layer LSTM classifier containing 100 hidden units
with an 8D embedding layer. The task is next-character prediction, and there are 80 classes of characters in total. The
model takes as input a sequence of 80 characters, embeds each of the characters into a learned 8-dimensional space and
outputs one character per training sample after 2 LSTM layers and a densely-connected layer.
• Sent140: In non-convex settings, we consider a text sentiment analysis task on tweets from Sentiment140 (Go et al.,
2009) (Sent140) with a two layer LSTM binary classifier containing 256 hidden units with pretrained 300D GloVe
embedding (Pennington et al., 2014). Each twitter account corresponds to a device. The model takes as input a sequence
of 25 characters, embeds each of the characters into a 300-dimensional space by looking up Glove and outputs one
character per training sample after 2 LSTM layers and a densely-connected layer.
C.2

Implementation Details

(Implementation) In order to draw a fair comparison with FedAvg, we use SGD as a local solver for FedProx, and adopt
a slightly different device sampling scheme than that in Algorithms 1 and 2: sampling devices uniformly and averaging
updates with weights proportional to the number of local data points (as originally proposed in McMahan et al. (2017)).
While this sampling scheme is not supported by our analysis, we observe similar relative behavior of FedProx vs. FedAvg
whether or not it is employed (Figure 12). Interestingly, we also observe that the sampling scheme proposed herein results in
more stable performance for both methods. This suggests an added benefit of the proposed framework.
(Machines) We simulate the federated learning setup (1 server and N devices) on a commodity machine with 2 Intel R
Xeon R E5-2650 v4 CPUs and 8 NVidia R 1080Ti GPUs.
(Hyperparameters) We randomly split the data on each local device into an 80% training set and a 20% testing set. We
fix the number of selected devices per round to be 10 for all experiments on all datasets. We also do a grid search on the
learning rate based on FedAvg. We do not decay the learning rate through all rounds. For all synthetic data experiments,
the learning rate is 0.01. For MNIST, FEMNIST, Shakespeare, and Sent140, we use the learning rates of 0.03, 0.003, 0.8,
and 0.3. We use a batch size of 10 for all experiments.
(Libraries) All code is implemented in Tensorflow Version 1.10.1 (Abadi et al., 2016).
github.com/litian96/FedProx for full details.

Please see

Federated Optimization in Heterogeneous Networks

C.3

Additional Experiments and Full Results

C.3.1

Effects of Systems Heterogeneity on IID Data

We show the effects of allowing for partial work on a perfect IID synthetic data (Synthetic IID).

 d Ğ Ɛ ƚ ŝ Ŷ Ő   Đ Đ Ƶ ƌ Ă Đ Ǉ

 d ƌ Ă ŝ Ŷ ŝ Ŷ Ő  > Ž Ɛ Ɛ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  / /   ; Ϭ й  Ɛ ƚ ƌ Ă Ő Ő ů Ğ ƌ Ɛ Ϳ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  / /   ; ϭ Ϭ й  Ɛ ƚ ƌ Ă Ő Ő ů Ğ ƌ Ɛ Ϳ

 & Ğ Ě  ǀ Ő
 & Ğ Ě W ƌ Ž ǆ  ;  с Ϭ Ϳ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  / /   ; ϱ Ϭ й  Ɛ ƚ ƌ Ă Ő Ő ů Ğ ƌ Ɛ Ϳ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  / /   ; ϵ Ϭ й  Ɛ ƚ ƌ Ă Ő Ő ů Ğ ƌ Ɛ Ϳ

 Ϯ ͘ Ϭ

 Ϯ ͘ Ϭ

 Ϯ ͘ Ϭ

 ϭ ͘ ϱ

 ϭ ͘ ϱ

 ϭ ͘ ϱ

 ϭ ͘ Ϭ

 ϭ ͘ Ϭ

 ϭ ͘ Ϭ

 ϭ ͘ Ϭ

 Ϭ ͘ ϱ

 Ϭ ͘ ϱ

 Ϭ ͘ ϱ

 Ϯ ͘ Ϭ
 ϭ ͘ ϱ

 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  / /   ; Ϭ й  Ɛ ƚ ƌ Ă Ő Ő ů Ğ ƌ Ɛ Ϳ

 Ϭ ͘ ϴ

 & Ğ Ě  ǀ Ő
 & Ğ Ě W ƌ Ž ǆ  ;  с Ϭ Ϳ

 Ϭ ͘ Ϯ
 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  / /   ; ϭ Ϭ й  Ɛ ƚ ƌ Ă Ő Ő ů Ğ ƌ Ɛ Ϳ

 Ϭ ͘ ϴ

 Ϭ ͘ ϲ
 Ϭ ͘ ϰ

 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϭ ͘ ϱ

 Ϯ Ϭ Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  / /   ; ϱ Ϭ й  Ɛ ƚ ƌ Ă Ő Ő ů Ğ ƌ Ɛ Ϳ

 Ϭ ͘ ϴ
 Ϭ ͘ ϲ

 Ϭ ͘ ϲ

 Ϭ ͘ ϰ

 Ϭ ͘ ϰ

 Ϭ ͘ ϰ

 Ϭ ͘ Ϯ
 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  / /   ; ϵ Ϭ й  Ɛ ƚ ƌ Ă Ő Ő ů Ğ ƌ Ɛ Ϳ

 Ϭ ͘ ϴ

 Ϭ ͘ ϲ
 Ϭ ͘ Ϯ

 Ϯ Ϭ Ϭ

 Ϭ

 Ϭ ͘ Ϯ

 Ϯ Ϭ Ϭ

 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

Figure 5. FedAvg is robust to device failure with IID data. In this case, whether incorporating partial solutions from the stragglers would
not have much effect on convergence.

C.3.2

Complete Results

 d ƌ Ă ŝ Ŷ ŝ Ŷ Ő  > Ž Ɛ Ɛ

In Figure 6, we present testing accuracy on four synthetic datasets associated with the experiments shown in Figure 2.
 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ Ͳ / / 
 & Ğ Ě  ǀ Ő  ; & Ğ Ě W ƌ Ž ǆ ͕   с Ϭ Ϳ
 & Ğ Ě W ƌ Ž ǆ ͕   х Ϭ

 Ϯ ͘ Ϭ
 ϭ ͘ ϱ
 ϭ ͘ Ϭ
 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 ϭ ϱ Ϭ

 d Ğ Ɛ ƚ ŝ Ŷ Ő   Đ Đ Ƶ ƌ Ă Đ Ǉ

 Ϯ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 Ϯ Ϭ Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ Ͳ / / 
 Ϭ ͘ ϲ

 & Ğ Ě  ǀ Ő  ; & Ğ Ě W ƌ Ž ǆ ͕   с Ϭ Ϳ
 & Ğ Ě W ƌ Ž ǆ ͕   х Ϭ

 Ϭ ͘ ϰ
 Ϭ ͘ Ϯ
 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ Ͳ / / 
 & Ğ Ě  ǀ Ő  ; & Ğ Ě W ƌ Ž ǆ ͕   с Ϭ Ϳ
 & Ğ Ě W ƌ Ž ǆ ͕   х Ϭ

 Ϭ ͘ ϯ
 Ϭ ͘ Ϯ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͕ Ϭ Ϳ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 Ϯ

 Ϯ
 ϭ
 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 Ϭ

 Ϭ ͘ ϲ

 Ϭ ͘ ϲ

 Ϭ ͘ ϰ

 Ϭ ͘ ϰ

 Ϭ ͘ ϰ

 Ϭ ͘ Ϭ

 Ϭ ͘ Ϯ
 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 ϳ ϱ
 ϱ Ϭ

 Ϯ Ϭ
 ϭ Ϭ Ϭ

 ϱ Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; ϭ ͕ ϭ Ϳ

 ϰ Ϭ

 ϱ Ϭ

 Ϯ Ϭ Ϭ

 ϭ Ϭ Ϭ

 ϲ Ϭ

 Ϭ

 Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͘ ϱ ͕ Ϭ ͘ ϱ Ϳ

 ϯ Ϭ

 ϭ ϱ Ϭ

 Ϭ ͘ Ϯ
 Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͕ Ϭ Ϳ
 ϰ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; ϭ ͕ ϭ Ϳ

 Ϭ ͘ ϲ
 Ϭ ͘ Ϯ

 ϱ Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͘ ϱ ͕ Ϭ ͘ ϱ Ϳ

 Ϭ ͘ ϴ

 ϭ Ϭ
 Ϭ

 ϯ

 Ϯ Ϭ Ϭ

 Ϯ Ϭ

 Ϭ ͘ ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; ϭ ͕ ϭ Ϳ

 ϯ

 ϭ
 Ϭ

 Ϭ ͘ ϴ

 Ϭ ͘ ϴ

 Ϭ

 s Ă ƌ ŝ Ă Ŷ Đ Ğ  Ž Ĩ  > Ž Đ Ă ů  ' ƌ Ă Ě ͘

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͘ ϱ ͕ Ϭ ͘ ϱ Ϳ

 ϭ

 Ϭ ͘ ϱ

 Ϭ ͘ Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͕ Ϭ Ϳ

 ϯ

 Ϯ ϱ
 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

Figure 6. Training loss, test accuracy, and dissimilarity measurement for experiments described in Fig. 2.

 Ϯ Ϭ Ϭ

Federated Optimization in Heterogeneous Networks

In Figure 7, we show the testing accuracy associated with the experiments described in Figure 1. We calculate the accuracy
improvement numbers by identifying the accuracies of FedProx and FedAvg when they have either converged, started
to diverge, or run sufficient number of rounds (e.g., 1000 rounds), whichever comes earlier. We consider the methods to
converge when the loss difference in two consecutive rounds |ft − ft−1 | is smaller than 0.0001, and consider the methods to
diverge when we see ft − ft−10 greater than 1.

0%
stragglers

50%
stragglers

90%
stragglers

Figure 7. The testing accuracy of the experiments in Figure 1. FedProx achieves on average 22% improvement in terms of testing
accuracy in highly heterogeneous settings (90% stragglers).

 s Ă ƌ ŝ Ă Ŷ Đ Ğ  Ž Ĩ  > Ž Đ Ă ů  ' ƌ Ă Ě ͘

In Figure 8, we report the dissimilarity measurement on five datasets (including four real datasets) described in Figure 1.
Again, the dissimilarity characterization is consistent with the real performance (the loss).
 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ
 & Ğ Ě  ǀ Ő  ; & Ğ Ě W ƌ Ž ǆ ͕   с Ϭ Ϳ
 & Ğ Ě W ƌ Ž ǆ  ;  х Ϭ Ϳ

 ϭ ϱ Ϭ
 ϭ Ϭ Ϭ

 D E / ^ d

 ϯ Ϭ

 &  D E / ^ d

 Ϯ Ϭ

 ϱ Ϭ

 ϭ Ϭ
 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 Ϭ

 ϭ Ϭ Ϭ

 Ϯ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϯ Ϭ Ϭ

 ϰ Ϭ Ϭ

 ^ Ś Ă Ŭ Ğ Ɛ Ɖ Ğ Ă ƌ Ğ

 Ϯ Ϭ Ϭ

 ϲ

 ϭ ϱ Ϭ

 ϰ

 ϭ Ϭ Ϭ

 Ϯ

 ϱ Ϭ

 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 Ϭ

 ^ Ğ Ŷ ƚ ϭ ϰ Ϭ

 ϯ Ϭ
 Ϯ Ϭ
 ϭ Ϭ

 Ϭ

 ϱ

 ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ

 Ϯ Ϭ

 Ϭ

 Ϭ

 Ϯ Ϭ Ϭ

 ϰ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϲ Ϭ Ϭ

 ϴ Ϭ Ϭ

Figure 8. The dissimilarity metric on five datasets in Figure 1. We remove systems heterogeneity by only considering the case when no
participating devices drop out of the network. Our dissimilarity assumption captures the data heterogeneity and is consistent with practical
performance (see training loss in Figure 1).

Federated Optimization in Heterogeneous Networks

In Figure 9 and Figure 10, we show the effects (both loss and testing accuracy) of allowing for partial solutions under
systems heterogeneity when E = 1 (i.e., the statistical heterogeneity is less likely to affect convergence negatively).

0%
stragglers

50%
stragglers

90%
stragglers

Figure 9. The loss of FedAvg and FedProx under various systems heterogeneity settings when each device can run at most 1 epoch at
each iteration (E = 1). Since local updates will not deviate too much from the global model compared with the deviation under large E’s,
it is less likely that the statistical heterogeneity will affect convergence negatively. Tolerating for partial solutions to be sent to the central
server (FedProx, µ = 0) still performs better than dropping the stragglers (FedAvg).

0%
stragglers

50%
stragglers

90%
stragglers

Figure 10. The testing accuracy of the experiments shown in Figure 9.

C.3.3

Adaptively setting µ

One of the key parameters of FedProx is µ. We provide the complete results of a simple heuristic of adaptively setting µ on
four synthetic datasets in Figure 11. For the IID dataset (Synthetic-IID), µ starts from 1, and for the other non-IID datasets,
µ starts from 0. Such initialization is adversarial to our methods. We decrease µ by 0.1 when the loss continues to decrease
for 5 rounds and increase µ by 0.1 when we see the loss increase. This heuristic allows for competitive performance. It
could also alleviate the potential issue that µ > 0 might slow down convergence on IID data, which rarely occurs in real
federated settings.

Federated Optimization in Heterogeneous Networks

 d ƌ Ă ŝ Ŷ ŝ Ŷ Ő  > Ž Ɛ Ɛ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ Ͳ / / 
 Ϯ ͘ Ϭ
 ϭ ͘ ϱ
 ϭ ͘ Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͕ Ϭ Ϳ

 ϯ

 & Ğ Ě  ǀ Ő  ; & Ğ Ě W ƌ Ž ǆ ͕   с Ϭ Ϳ
 & Ğ Ě W ƌ Ž ǆ ͕  Ě Ǉ Ŷ Ă ŵ ŝ Đ 
 & Ğ Ě W ƌ Ž ǆ ͕   х Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͘ ϱ ͕ Ϭ ͘ ϱ Ϳ

 Ϯ
 ϭ

 Ϭ ͘ ϱ
 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; ϭ ͕ ϭ Ϳ

 ϯ

 ϯ

 Ϯ

 Ϯ

 ϭ
 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 ϭ
 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 ϭ ϱ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 Ϯ Ϭ Ϭ

Figure 11. Full results of choosing µ adaptively on all the synthetic datasets. We increase µ by 0.1 whenever the loss increases and
decreases it by 0.1 whenever the loss decreases for 5 consecutive rounds. We initialize µ to 1 for the IID data (Synthetic-IID) (in order to
be adversarial to our methods), and initialize it to 0 for the other three non-IID datasets. We observe that this simple heuristic works well
in practice.

C.3.4

Comparing Two Device Sampling Schemes

We show the training loss, testing accuracy, and dissimilarity measurement of FedProx on a set of synthetic data using two
different device sampling schemes in Figure 12. Since our goal is to compare these two sampling schemes, we let each
device perform the uniform amount of work (E = 20) for both methods.

 d ƌ Ă ŝ Ŷ ŝ Ŷ Ő  > Ž Ɛ Ɛ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ Ͳ / / 

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͘ ϱ ͕ Ϭ ͘ ϱ Ϳ

 Ϯ ͘ Ϭ
 Ϯ

 ϭ ͘ ϱ
 ϭ ͘ Ϭ

 ϭ

 Ϭ ͘ ϱ
 Ϭ

 d Ğ Ɛ ƚ ŝ Ŷ Ő   Đ Đ Ƶ ƌ Ă Đ Ǉ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͕ Ϭ Ϳ

 ϯ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ
 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ Ͳ / / 

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 Ϭ ͘ ϲ
 Ϭ ͘ ϰ
 Ϭ ͘ Ϯ

 s Ă ƌ ŝ Ă Ŷ Đ Ğ  Ž Ĩ  > Ž Đ Ă ů  ' ƌ Ă Ě ͘

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϱ Ϭ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 ϭ ϱ Ϭ

 ϯ

 Ϯ

 Ϯ

 ϭ

 ϭ

 Ϯ Ϭ Ϭ

 Ϭ
 Ϭ ͘ ϴ

 ϭ Ϭ Ϭ

 ϭ ϱ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ
 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͘ ϱ ͕ Ϭ ͘ ϱ Ϳ

 Ϯ Ϭ Ϭ

 Ϭ ͘ ϲ

 Ϭ ͘ ϰ

 Ϭ ͘ ϰ

 Ϭ ͘ ϰ

 Ϭ ͘ Ϯ

 Ϭ ͘ Ϯ

 Ϭ ͘ Ϭ

 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 ϭ Ϭ Ϭ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 ϰ Ϭ

 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 ϱ Ϭ

 Ϯ Ϭ Ϭ

 с Ϭ ͕   с Ϯ Ϭ ͕  Ƶ Ŷ ŝ Ĩ Ž ƌ ŵ  Ɛ Ă ŵ Ɖ ů ŝ Ŷ Ő н ǁ Ğ ŝ Ő Ś ƚ Ğ Ě  Ă ǀ Ğ ƌ Ă Ő Ğ
 с ϭ ͕   с Ϯ Ϭ ͕  Ƶ Ŷ ŝ Ĩ Ž ƌ ŵ  Ɛ Ă ŵ Ɖ ů ŝ Ŷ Ő н ǁ Ğ ŝ Ő Ś ƚ Ğ Ě  Ă ǀ Ğ ƌ Ă Ő Ğ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 ϭ Ϭ Ϭ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; ϭ ͕ ϭ Ϳ

 ϱ Ϭ

 Ϯ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ
 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; ϭ ͕ ϭ Ϳ

 ϭ Ϭ Ϭ

 ϲ Ϭ

 Ϯ Ϭ

 ϱ Ϭ

 ϱ Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͘ ϱ ͕ Ϭ ͘ ϱ Ϳ

 Ϭ ͘ Ϯ

 Ϭ

 Ϭ

 Ϭ ͘ Ϯ
 Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͕ Ϭ Ϳ

 Ϭ ͘ ϭ

 ϱ Ϭ

 Ϭ ͘ ϲ

 ϰ Ϭ

 Ϭ ͘ Ϭ

 ϯ

 Ϭ ͘ ϲ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ Ͳ / / 

 Ϭ ͘ ϯ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ
 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; Ϭ ͕ Ϭ Ϳ

 Ϭ ͘ ϴ

 Ϭ ͘ ϴ

 Ϭ

 Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ  ; ϭ ͕ ϭ Ϳ

 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 Ϭ

 ϱ Ϭ

 ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ

 Ϯ Ϭ Ϭ

 с Ϭ ͕   с Ϯ Ϭ ͕  ǁ Ğ ŝ Ő Ś ƚ Ğ Ě  Ɛ Ă ŵ Ɖ ů ŝ Ŷ Ő н Ɛ ŝ ŵ Ɖ ů Ğ  Ă ǀ Ğ ƌ Ă Ő Ğ
 с ϭ ͕   с Ϯ Ϭ ͕  ǁ Ğ ŝ Ő Ś ƚ Ğ Ě  Ɛ Ă ŵ Ɖ ů ŝ Ŷ Ő н Ɛ ŝ ŵ Ɖ ů Ğ  Ă ǀ Ğ ƌ Ă Ő Ğ

Figure 12. Differences between two sampling schemes in terms of training loss, testing accuracy, and dissimilarity measurement. Sampling
devices with a probability proportional to the number of local data points and then simply averaging local models performs slightly better
than uniformly sampling devices and averaging the local models with weights proportional to the number of local data points. Under
either sampling scheme, the settings with µ = 1 demonstrate more stable performance than settings with µ = 0.

Federated Evaluation of On-device Personalization

arXiv:1910.10252v1 [cs.LG] 22 Oct 2019

Kangkang Wang
Google
kangkang@google.com
Chloé Kiddon
Google
loeki@google.com

Rajiv Mathews
Google
mathews@google.com

Hubert Eichner
Google
huberte@google.com

Françoise Beaufays
Google
fsb@google.com

Daniel Ramage
Google
dramage@google.com

Abstract
Federated learning is a distributed, on-device computation framework that enables
training global models without exporting sensitive user data to servers. In this work,
we describe methods to extend the federation framework to evaluate strategies
for personalization of global models. We present tools to analyze the effects
of personalization and evaluate conditions under which personalization yields
desirable models. We report on our experiments personalizing a language model
for a virtual keyboard for smartphones with a population of tens of millions of
users. We show that a significant fraction of users benefit from personalization.

1

Introduction

As users increasingly shift to mobile devices as their primary computing device (Anderson, 2015), we
hypothesize that the information on devices allows for personalizing global models to better suit the
needs of individual users. This can be achieved in a privacy-preserving way by fine-tuning a global
model using standard optimization methods on data stored locally on a single device. While we
expect personalization to be beneficial for most users, we need to make sure it doesn’t make things
worse for some users, e.g. by overfitting.
In this paper, we describe extensions to the Federated Learning (Bonawitz et al., 2019) (FL) framework
for evaluating the personalization of global models. We study this using an RNN language model for
the keyboard next-word prediction task (Hard et al., 2018). We show that we can derive and impose
conditions under which a personalized model is deployed if and only if it makes the user’s experience
better. We further show that it is possible to personalize models that benefit a significant fraction of
users.

2

Federated Personalization Evaluation

Federated Learning is a distributed model training paradigm where data never leaves users’ devices.
Only minimal and ephemeral updates to the model are transmitted by the clients to the server where
they are aggregated into a single update to the global model (McMahan et al., 2017). FL can be further
combined with other privacy-preserving techniques like secure multi-party computation (Bonawitz
et al., 2017) and differential privacy (McMahan et al., 2018; Agarwal et al., 2018; Abadi et al., 2016b).
Hard et al. (2018) showed that FL can be used to train an RNN language model that outperforms
Preprint. Under review.

an identical model trained using traditional server-side techniques, when evaluated on the keyboard
next-word prediction task.
Such a global model is necessarily a consensus
model, and it stands to reason that populationwide accuracy can be further improved through
personalization on individual users’ data. However, such on-device refinements cannot be
tested server-side because the training/eval data
is not collected centrally. It is reasonable to
expect that, given the nature of neural network
training, personalizing models might make the
experience of some users worse. We will show
that we can prevent such undesired effects by
carefully calibrating the model hyperparameters,
and by building a gating mechanism that accepts Figure 1: An illustration of Federated Personalizaor rejects personalized models for use in infer- tion Evaluation: (A) the global model (gray circle)
is sent to client devices, (B) the device computes
ence.
SGD updates on the train partition of the local
In this paper, we introduce an extension to the data, resulting in a personalized model (the green
FL framework for evaluating personalization ac- square), (C) the device computes a report of metcuracy and for determining the training and ac- rics for the global and personalized model on the
ceptance hyperparameters - Federated Person- test partition of the local data, (D) pairs of metric
alization Evaluation (FPE). As in the FL set- reports are sent by various devices to the server,
ting, mobile phones connect to a server when (E) the server computes histograms of various delta
idle, charging and on an unmetered network metrics.
(Bonawitz et al., 2019). Selected devices are
served a baseline model along with instructions on how to train it using the device’s dataset in the
form of a TensorFlow graph (Abadi et al., 2016a). In FL, the device would compute and send its
model update to the server for aggregation, but in FPE, the device instead does five steps: it splits the
local on-device dataset into a train and test partition using practitioner-defined criteria; it computes
metrics of the baseline model on the test data; it fine-tunes the model on the training set; it computes
metrics of the personalized model on the test set; and finally it computes and uploads the change in
metrics between the personalized and baseline variants. The server aggregates the metrics it receives
from various clients to compute histograms of various delta metrics.
Figure 1 illustrates this process. FPE allows us to evaluate the benefit of personalization and identify
good hyperparameters using the existing infrastructure for federated learning, without any user visible
impact. These conclusions can then be used for live inference using personalized models, though live
inference is beyond the scope of this paper.

3

Method

3.1

Network Architecture

The network architecture of the next-word prediction model is described in Hard et al. (2018).
We use a variant of the Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997)
recurrent neural network called the Coupled Input and Forget Gate (CIFG) (Greff et al., 2017). The
input embedding and output projection matrices are tied to reduce the model size (Press and Wolf,
2017; Inan et al., 2016). For a vocabulary of size V , a one-hot encoding v ∈ RV is mapped to
a dense embedding vector d ∈ RD by d = W v with an embedding matrix W ∈ RD×V . The
output projection of the CIFG, also in RD , is mapped to the output vector W T h ∈ RV . A softmax
layer converts the raw logits into normalized probabilities. Cross-entropy loss over the output and
target labels is used for training. We use a vocabulary of V = 10,000 words, including the special
beginning-of-sentence, end-of-sentence, and out-of-vocabulary tokens. The input embedding and
CIFG output projection dimension D is set to 96. A single layer CIFG with 670 units is used. The
network has 1.4 million parameters.
2

3.2

Global Model Training

The next-word prediction model is trained using FL on a population of users whose language is set to
US English, as described in Hard et al. (2018). The FederatedAveraging algorithm (McMahan
et al., 2017) is used to aggregate distributed client SGD updates. Training progresses synchronously
in “rounds”. Every client, indexed by k, participating in a given round, indexed by t, computes the
average gradient, gk , on its local data nk , with the current model wt using stochastic gradient descent
k
k
(SGD). For a client learning rate , the local client update, wt+1
, is given by wt − gk → wt+1
. The
server performs a weighted aggregation of the client models to obtain a new global model, wt+1 :
PK nk k
P
k=1 N wt+1 → wt+1 , where N =
k nk . The server update is achieved via the Momentum
optimizer, using Nesterov accelerated gradient (Nesterov, 1983; Sutskever et al., 2013), a momentum
hyperparameter of 0.9, and a server learning rate of 1.0. Training converges after 3000 training
rounds, over the course of which 600 million sentences are processed by 1.5 million clients. Training
typically takes 4 to 5 days.
3.3

Model Personalization Strategies

A personalization strategy consists of the model graph, the initial parameter values, and the training
hyperparameters - client learning rate, train batch size, and stopping criteria. Throughout our
experiments, the model graph and initial parameter values are set to be the federated trained next
word prediction model described in Section 3.2. The effect of the personalization learning on the
model is evaluated via various training hyperparameters.
Given a personalization strategy, the personalized model can then be trained from the initial global
model using individual client’s training cache data. Data are cached on mobile devices on which the
language is set to US English. During a training process, the client data first gets split into train and
test partitions (80% and 20% based on the temporal order). Stochastic gradient descent is used for
model training with specified learning rate (L) and batch size (B). The stopping criteria are based on
number of tokens (T ) observed and number of epochs (E) trained. The training process stops when
one of the criteria is satisfied.

4

Experiments

The performance of the personalized model is evaluated using the prediction accuracy metric, defined
as the ratio of the number of correct predictions to the total number of tokens.
Experiments are conducted to study the influence of client train batch size and learning rate
Hyperparameters
Accuracy delta
on the personalization performance. The stopping criteria are set to T ≥ 5000 or E ≥ 1.
B = 5, L = 0.01
0.012
We wish to assess the benefits brought by perB = 5, L = 0.1
0.024
sonalization across users. However, each user
B = 5, L = 1.0
-0.019
experiences a different baseline accuracy, deB = 10, L = 0.01
0.008
pending on their style, use of language register,
B = 10, L = 0.1
0.022
etc. Therefore, it makes sense to measure the
B = 10, L = 1.0
0.002
difference between prediction accuracies before
B = 20, L = 0.01
0.005
and after personalization for each user, and obB = 20, L = 0.1
0.018
serve the distribution of these differences in adB = 20, L = 1.0
0.015
dition to their average. The histograms report
only prediction-accuracy metrics and are comTable 1: The results from personalization eval puted over tens of thousands of users. Metric
experiments. Metrics are reported from over reports including the baseline accuracies and
500,000 clients. Mean of baseline accuracy is the personalized model accuracies from over
0.166 ± 0.001.
300,000 users’ devices are received. The delta
metrics between the personalized model and the
baseline model are summarized in Table 1.
The best accuracy improvement is achieved for B = 5, L = 0.1. It starts with a mean baseline
prediction accuracy of 0.166 and reaches a mean personalized accuracy of 0.19, resulting in a mean
relative accuracy increase of 14.5%.
3

(a)

(b)

(c)

Figure 2: Accuracy delta histograms for different learning rates (L) and batch sizes (B): (a) At B = 5
and L = 0.1, 47% of users achieve ≥ 0.02 accuracy improvement; (b) At B = 10 and L = 1.0, 39%
of users achieve ≥ 0.02 accuracy improvement; (c) At B = 10 and L = 0.1, 29% of users achieve ≥
0.02 accuracy improvement.

While the mean metrics show how much personalization improves the model performance in general,
the distribution reveals how personalization influences the experience of individual users. Histograms
of the sampled accuracy deltas are shown in Figure 2.
As shown in Figure 2a, with a small batch size, a large portion of users encounter model degradation
with learning rate 1.0. This is not entirely surprising, since high learning rates with small batch
size can cause the parameter update to jump over or even divert from the minima. In Figure 2b and
Figure 2c, with larger batch sizes, histograms of learning rate 1.0 tend to have heavier tails both on
the left and on the right, compared with histograms of learning rate 0.1. Though the average accuracy
improvement of learning rate 1.0 in batch size 20 is lower than learning rate 0.1 (0.015 vs. 0.018),
neither is clearly superior, since more users (39% vs. 29%) achieve significant accuracy improvement
(≥ 0.02) with learning rate 1.0.
All personalization evaluation experiments in our study use the data stored
in a user’s on-device training cache.
Variations in the quantity and quality
of training cache data across different devices are expected. We conduct
experiments to evaluate how model
personalization can be influenced by
factors associated with the user data.
Factors considered are the number of
(b)
training tokens and baseline accuracy
(a)
on the user data. The stopping criteria
are set to T ≥ 10000 or E ≥ 1. Sum- Figure 3: Analysis of accuracy deltas by learning rate (L)
maries of the greater improvement are and batch size (B) sliced by (a) number of user tokens and
(b) baseline accuracy.
illustrated in Figure 3.
In Figure 3a, user token counts are
placed into 4 buckets. As one might expect, we observe larger improvements for more data. For
a learning rate of 0.1, the accuracy improvements of the last two buckets get closer, indicating the
saturation of the improvement. A learning rate of 1.0 retrieves the best performance with very few
tokens. The graph suggests that adjusting the learning rate based on number of user tokens leads to
better results.
In Figure 3b, baseline accuracies of users are placed into 4 buckets. With learning rates 0.1 and 1.0,
accuracy improvement for users with the worst baseline accuracy (≤ 0.1) is greater than 0.25, while
accuracy improvement for users with best baseline accuracy (≥ 0.2) is smaller than 0.2. The results
indicate that users who deviate the most from the global model predictions are those benefiting the
most from it.
4

5

Conclusion

This work describes tools to perform Federated Personalization Evaluation and analyze results in
a privacy-preserving manner. Through experiments on live traffic, we show that personalization
benefits users across a large population. We explore personalization strategies and demonstrate how
they can be tuned to achieve better performance. To our knowledge, this represents the first evaluation
of personalization using privacy-preserving techniques on a large population of live users.
Acknowledgments
The authors would like to thank colleagues on the Google Assistant and Google AI teams for many
helpful discussions. We’re especially grateful to Emily Glanz and Brendan McMahan for help with
our experiments, and Andrew Hard for help editing the manuscript. We’re also grateful for the many
contributions made by researcher Jeremy Kahn to an early iteration of this work.

References
Martin Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay
Ghemawat, Geoffrey Irving, Michael Isard, Manjunath Kudlur, Josh Levenberg, Rajat Monga, Sherry Moore,
Derek G. Murray, Benoit Steiner, Paul Tucker, Vijay Vasudevan, Pete Warden, Martin Wicke, Yuan Yu,
and Xiaoqiang Zheng. 2016a. Tensorflow: A system for large-scale machine learning. In 12th USENIX
Symposium on Operating Systems Design and Implementation (OSDI 16), pages 265–283.
Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang.
2016b. Deep learning with differential privacy. In Proceedings of the 2016 ACM SIGSAC Conference on
Computer and Communications Security, pages 308–318. ACM.
Naman Agarwal, Ananda Theertha Suresh, Felix Yu, Sanjiv Kumar, and Brendan McMahan. 2018. cpsgd:
Communication-efficient and differentially-private distributed sgd. In Neural Information Processing Systems.
Monica Anderson. 2015. Technology device ownership: 2015. http://www.pewinternet.org/2015/10/
29/technology-device-ownership-2015/.
Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir Ivanov,
Chloé M Kiddon, Jakub Konečný, Stefano Mazzocchi, Brendan McMahan, Timon Van Overveldt, David
Petrou, Daniel Ramage, and Jason Roselander. 2019. Towards federated learning at scale: System design. In
SysML 2019. To appear.
Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H. Brendan McMahan, Sarvar Patel, Daniel
Ramage, Aaron Segal, and Karn Seth. 2017. Practical secure aggregation for privacy-preserving machine
learning. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security,
CCS ’17, pages 1175–1191, New York, NY, USA. ACM.
Klaus Greff, Rupesh Kumar Srivastava, Jan Koutník, Bas R. Steunebrink, and Jürgen Schmidhuber. 2017. LSTM:
A search space odyssey. IEEE Trans. Neural Netw. Learning Syst., 28(10):2222–2232.
Andrew Hard, Kanishka Rao, Rajiv Mathews, Françoise Beaufays, Sean Augenstein, Hubert Eichner, Chloé
Kiddon, and Daniel Ramage. 2018. Federated learning for mobile keyboard prediction. arXiv preprint
arXiv:1811.03604.
S. Hochreiter and J. Schmidhuber. 1997. Long short-term memory. Neural Computation, 9(8):1735–1780.
Hakan Inan, Khashayar Khosravi, and Richard Socher. 2016. Tying word vectors and word classifiers: A loss
framework for language modeling. CoRR, abs/1611.01462.
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Agüera y Arcas. 2017.
Communication-efficient learning of deep networks from decentralized data. In Proceedings of the 20th
International Conference on Artificial Intelligence and Statistics, AISTATS 2017, 20-22 April 2017, Fort
Lauderdale, FL, USA, pages 1273–1282.
Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li Zhang. 2018. Learning differentially private recurrent
language models. In International Conference on Learning Representations (ICLR).
Yurii Nesterov. 1983. A method for solving the convex programming problem with convergence rate o(1/k2 ).
Dokl. Akad. Nauk SSSR, 269:543–547.

5

Ofir Press and Lior Wolf. 2017. Using the output embedding to improve language models. In Proceedings of
the 15th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2017,
Valencia, Spain, April 3-7, 2017, Volume 2: Short Papers, pages 157–163.
Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton. 2013. On the importance of initialization
and momentum in deep learning. In Proceedings of the 30th International Conference on Machine Learning,
volume 28, pages 1139–1147, Atlanta, Georgia, USA.

6

arXiv:1908.07873v1 [cs.LG] 21 Aug 2019

Federated Learning:
Challenges, Methods, and Future Directions
Tian Li

Anit Kumar Sahu

Carnegie Mellon University

Bosch Center for Artificial Intelligence

tianli@cmu.edu

anit.sahu@gmail.com

Ameet Talwalkar

Virginia Smith

Carnegie Mellon University & Determined AI

Carnegie Mellon University

talwalkar@cmu.edu

smithv@cmu.edu

Abstract
Federated learning involves training statistical models over remote devices or siloed data centers, such
as mobile phones or hospitals, while keeping data localized. Training in heterogeneous and potentially
massive networks introduces novel challenges that require a fundamental departure from standard
approaches for large-scale machine learning, distributed optimization, and privacy-preserving data
analysis. In this article, we discuss the unique characteristics and challenges of federated learning, provide
a broad overview of current approaches, and outline several directions of future work that are relevant to
a wide range of research communities.

1

Introduction

Mobile phones, wearable devices, and autonomous vehicles are just a few of the modern distributed
networks generating a wealth of data each day. Due to the growing computational power of these devices—
coupled with concerns over transmitting private information—it is increasingly attractive to store data
locally and push network computation to the edge.
The concept of edge computing is not a new one. Indeed, computing simple queries across distributed,
low-powered devices is a decades-long area of research that has been explored under the purview of query
processing in sensor networks, computing at the edge, and fog computing [12, 29, 40, 49, 74]. Recent works
have also considered training machine learning models centrally but serving and storing them locally; for
example, this is a common approach in mobile user modeling and personalization [60, 90].
However, as the storage and computational capabilities of the devices within distributed networks grow, it is
possible to leverage enhanced local resources on each device. This has led to a growing interest in federated
learning [75], which explores training statistical models directly on remote devices1 . As we discuss in this
article, learning in such a setting differs significantly from traditional distributed environments—requiring
1 We use the term ‘device’ throughout the article to describe entities in the network, such as nodes, clients, sensors, or organizations.

1

local
updates

local data
local data

new global
model

local data

local data

learnt model:
next-word prediction

local
updates

local data
local data
local data

local data

Figure 1: An example application of federated learning for the task of next-word prediction on mobile
phones. To preserve the privacy of the text data and to reduce strain on the network, we seek to train a
predictor in a distributed fashion, rather than sending the raw data to a central server. In this setup, remote
devices communicate with a central server periodically to learn a global model. At each communication
round, a subset of selected phones performs local training on their non-identically-distributed user data,
and sends these local updates to the server. After incorporating the updates, the server then sends back the
new global model to another subset of devices. This iterative training process continues across the network
until convergence is reached or some stopping criterion is met.
fundamental advances in areas such as privacy, large-scale machine learning, and distributed optimization,
and raising new questions at the intersection of diverse fields, such as machine learning and systems [91].
Federated learning methods have been deployed by major service providers [11, 124], and play a critical
role in supporting privacy-sensitive applications where the training data are distributed at the edge [e.g.,
5, 46, 51, 89, 105, 127, 139]. Examples of potential applications include: learning sentiment, semantic
location, or activities of mobile phone users; adapting to pedestrian behavior in autonomous vehicles;
and predicting health events like heart attack risk from wearable devices [6, 52, 84]. We discuss several
canonical applications of federated learning below:
• Smart phones. By jointly learning user behavior across a large pool of mobile phones, statistical models
can power applications such as next-word prediction, face detection, and voice recognition [46, 89].
However, users may not be willing to share their data in order to protect their personal privacy or
to save the limited bandwidth/battery power of their phone. Federated learning has the potential
to enable predictive features on smart phones without diminishing the user experience or leaking
private information. Figure 1 depicts one such application in which we aim to learn a next-word
predictor in a large-scale mobile phone network based on users’ historical text data [46].
• Organizations. Organizations or institutions can also be viewed as ‘devices’ in the context of federated
learning. For example, hospitals are organizations that contain a multitude of patient data for
predictive healthcare. However, hospitals operate under strict privacy practices, and may face legal,
administrative, or ethical constraints that require data to remain local. Federated learning is a
promising solution for these applications [52], as it can reduce strain on the network and enable
private learning between various devices/organizations.
• Internet of things. Modern IoT networks, such as wearable devices, autonomous vehicles, or smart
homes, may contain numerous sensors that allow them to collect, react, and adapt to incoming data
in real-time. For example, a fleet of autonomous vehicles may require an up-to-date model of traffic,
2

construction, or pedestrian behavior to safely operate. However, building aggregate models in these
scenarios may be difficult due to the private nature of the data and the limited connectivity of each
device. Federated learning methods can help to train models that efficiently adapt to changes in these
systems while maintaining user privacy [84, 98].

1.1

Problem Formulation

The canonical federated learning problem involves learning a single, global statistical model from data stored
on tens to potentially millions of remote devices. We aim to learn this model under the constraint that
device-generated data is stored and processed locally, with only intermediate updates being communicated
periodically with a central server. In particular, the goal is typically to minimize the following objective
function:
m

min F (w) , where F (w) := ∑ pk Fk (w) .
w

(1)

k =1

Here, m is the total number of devices, pk ≥ 0 and ∑k pk = 1, and Fk is the local objective function for
the kth device. The local objective function is often defined as the empirical risk over local data, i.e.,
n
Fk (w) = n1 ∑ j k=1 f jk (w; x jk , y jk ), where nk is the number of samples available locally. The user-defined term
k

k

pk specifies the relative impact of each device, with two natural settings being pk = n1 or pk = nnk , where
n = ∑k nk is the total number of samples. We will reference problem (1) throughout the article, but, as
discussed below, we note that other objectives or modeling approaches may be appropriate depending on
the application of interest.

1.2

Core Challenges

We next describe four of the core challenges associated with solving the distributed optimization problem
posed in (1). These challenges make the federated setting distinct from other classical problems, such as
distributed learning in data center settings or traditional private data analyses.
Challenge 1: Expensive Communication. Communication is a critical bottleneck in federated networks,
which, coupled with privacy concerns over sending raw data, necessitates that data generated on each
device remain local. Indeed, federated networks are potentially comprised of a massive number of devices,
e.g., millions of smart phones, and communication in the network can be slower than local computation by
many orders of magnitude [50, 115]. In order to fit a model to data generated by the devices in the federated
network, it is therefore necessary to develop communication-efficient methods that iteratively send small
messages or model updates as part of the training process, as opposed to sending the entire dataset over the
network. To further reduce communication in such a setting, two key aspects to consider are: (i) reducing
the total number of communication rounds, or (ii) reducing the size of transmitted messages at each round.
Challenge 2: Systems Heterogeneity. The storage, computational, and communication capabilities of
each device in federated networks may differ due to variability in hardware (CPU, memory), network
connectivity (3G, 4G, 5G, wifi), and power (battery level). Additionally, the network size and systems-related
constraints on each device typically result in only a small fraction of the devices being active at once, e.g.,
hundreds of active devices in a million-device network [11]. Each device may also be unreliable, and it is
not uncommon for an active device to drop out at a given iteration due to connectivity or energy constraints.
3

These system-level characteristics dramatically exacerbate challenges such as straggler mitigation and fault
tolerance. Federated learning methods that are developed and analyzed must therefore: (i) anticipate a low
amount of participation, (ii) tolerate heterogeneous hardware, and (iii) be robust to dropped devices in the
network.
Challenge 3: Statistical Heterogeneity. Devices frequently generate and collect data in a non-identically
distributed manner across the network, e.g., mobile phone users have varied use of language in the context
of a next word prediction task. Moreover, the number of data points across devices may vary significantly,
and there may be an underlying structure present that captures the relationship amongst devices and
their associated distributions. This data generation paradigm violates frequently-used independent and
identically distributed (I.I.D.) assumptions in distributed optimization, increases the likelihood of stragglers,
and may add complexity in terms of modeling, analysis, and evaluation. Indeed, although the canonical
federated learning problem of (1) aims to learn a single global model, there exist other alternatives such as
simultaneously learning distinct local models via multi-task learning frameworks [cf. 106]. There is also a
close connection in this regard between leading approaches for federated learning and meta-learning [64].
Both the multi-task and meta-learning perspectives enable personalized or device-specific modeling, which is
often a more natural approach to handle the statistical heterogeneity of the data.
Challenge 4: Privacy Concerns. Finally, privacy is often a major concern in federated learning applications.
Federated learning makes a step towards protecting data generated on each device by sharing model
updates, e.g., gradient information, instead of the raw data [17, 31, 33]. However, communicating model
updates throughout the training process can nonetheless reveal sensitive information, either to a third-party,
or to the central server [76]. While recent methods aim to enhance the privacy of federated learning
using tools such as secure multiparty computation or differential privacy, these approaches often provide
privacy at the cost of reduced model performance or system efficiency. Understanding and balancing these
trade-offs, both theoretically and empirically, is a considerable challenge in realizing private federated
learning systems.
The remainder of this article is organized as follows. In Section 2, we introduce previous and current works
that aim to address the four discussed challenges of federated learning. In Section 3, we outline several
promising directions of future research.

2

Survey of Related and Current Work

The challenges in federated learning at first glance resemble classical problems in areas such as privacy,
large-scale machine learning, and distributed optimization. For instance, numerous methods have been
proposed to tackle expensive communication in the machine learning, optimization, and signal processing
communities. However, these methods are typically unable to fully handle the scale of federated networks,
much less the challenges of systems and statistical heterogeneity. Similarly, while privacy is an important
aspect for many machine learning applications, privacy-preserving methods for federated learning can be
challenging to rigorously assert due to the statistical variation in the data, and may be even more difficult
to implement due to systems constraints on each device and across the potentially massive network. In this
section, we explore in more detail the challenges presented in Section 1, including a discussion of classical
results as well as more recent work focused specifically on federated learning.

4

apply updates locally

mini-batch data

computation

communication

Figure 2: Left: Distributed (mini-batch) SGD. Each device, k, locally computes gradients from a mini-batch
of data points to approximate ∇ Fk (w), and the aggregated mini-batch updates are applied on the server.
Right: Local updating schemes. Each device immediately applies local updates, e.g., gradients, after they
are computed and a server performs a global aggregation after a variable number of local updates.
Local-updating schemes can reduce communication by performing additional work locally.

2.1

Communication-efficiency

Communication is a key bottleneck to consider when developing methods for federated networks. While it
is beyond the scope of this article to provide a self-contained review of communication-efficient distributed
learning methods, we point out several general directions, which we group into (1) local updating methods,
(2) compression schemes, and (3) decentralized training.

2.1.1

Local Updating

Mini-batch optimization methods, which involve extending classical stochastic methods to process multiple
data points at a time, have emerged as a popular paradigm for distributed machine learning in data center
environments [28, 88, 96, 102, 103]. In practice, however, they have been shown to have limited flexibility to
adapt to communication-computation trade-offs that would maximally leverage distributed data processing [107, 108]. In response, several recent methods have been proposed to improve communication-efficiency
in distributed settings by allowing for a variable number of local updates to be applied on each machine
in parallel at each communication round, making the amount of computation versus communication
substantially more flexible. For convex objectives, distributed local-updating primal-dual methods have
emerged as a popular way to tackle such a problem [54, 62, 72, 107, 128]. These approaches leverage
duality structure to effectively decompose the global objective into subproblems that can be solved in
parallel at each communication round. Several distributed local-updating primal methods have also been
proposed, which have the added benefit of being applicable to non-convex objectives [93, 136]. These
methods drastically improve performance in practice, and have been shown to achieve orders-of-magnitude
speedups over traditional mini-batch methods or distributed approaches like ADMM [14] in real-world
data center environments. We provide an intuitive illustration of local updating methods in Figure 2.
In federated settings, optimization methods that allow for flexible local updating and low client participation
have become the de facto solvers [65, 75, 106]. The most commonly used method for federated learning
is Federated Averaging (FedAvg) [75], a method based on averaging local stochastic gradient descent
(SGD) updates for the primal problem. FedAvg has been shown to work well empirically, particularly for
non-convex problems, but comes without convergence guarantees and can diverge in practical settings
when data are heterogeneous [65]. We discuss methods to handle such statistical heterogeneity in more
detail in Section 2.3.2.

5

Figure 3: Centralized vs. decentralized topologies. In the typical federated learning setting and as a focus of
this article, we assume a star network (left) where a server connects with all remote devices. Decentralized
topologies (right) are a potential alternative when communication to the server becomes a bottleneck.
2.1.2

Compression Schemes

While local updating methods can reduce the total number of communication rounds, model compression
schemes such as sparsification, subsampling, and quantization can significantly reduce the size of messages
communicated at each round. These methods have been extensively studied, both empirically and
theoretically, in previous literature for distributed training in data center environments; we defer the
readers to [119, 135] for a more complete review. In federated environments, the low participation of
devices, non-identically distributed local data, and local updating schemes pose novel challenges to
these model compression approaches. For instance, the commonly-used error compensation techniques
in classical distributed learning [101] cannot be directly extended to federated settings as the errors
accumulated locally may be stale if the devices are not frequently sampled. Nevertheless, several works
have provided practical strategies in federated settings, such as forcing the updating models to be sparse
and low-rank; performing quantization with structured random rotations [59]; using lossy compression
and dropout to reduce server-to-device communication [15]; and applying Golomb lossless encoding [99].
From a theoretical perspective, while prior work has explored convergence guarantees with low-precision
training in the presence of non-identically distributed data [e.g., 111], the assumptions made do not take
into consideration common characteristics of the federated setting, such as low device participation or
locally-updating optimization methods.

2.1.3

Decentralized Training

In federated learning, a star network (where a central server is connected to a network of devices, as
in the left panel of Figure 3) is the predominant communication topology; we therefore focus on the
star-network setting in this article. However, we briefly discuss decentralized topologies (where devices
only communicate with their neighbors, e.g., the right panel of Figure 3) as a potential alternative. In data
center environments, decentralized training has been demonstrated to be faster than centralized training
when operating on networks with low bandwidth or high latency; we defer readers to [47, 67] for a more
comprehensive review. Similarly, in federated learning, decentralized algorithms can in theory reduce the
high communication cost on the central server. Some recent works [47, 61] have investigated decentralized
training over heterogeneous data with local updating schemes. However, they are either restricted to linear
models [47] or assume full device participation [61]. Finally, hierarchical communication patterns have also
been proposed [68, 70] to further ease the burden on the central server, by first leveraging edge servers to
aggregate the updates from edge devices and then relying on a cloud server to aggregate updates from edge
servers. While this is a promising approach to reduce communication, it is not applicable to all networks,
as this type of physical hierarchy may not exist or be known a priori.
6

subsample devices

subsample devices
send model
updates

training
4G

send the
global model

training
send the
global model training

device failure
training

Figure 4: Systems heterogeneity in federated learning. Devices may vary in terms of network connection,
power, and hardware. Moreover, some of the devices may drop at any time during training. Therefore,
federated training methods must tolerate heterogeneous systems environments and low participation of
devices, i.e., they must allow for only a small subset of devices to be active at each round.

2.2

Systems Heterogeneity

In federated settings, there is significant variability in the systems characteristics across the network, as
devices may differ in terms of hardware, network connectivity, and battery power. As depicted in Figure 4,
these systems characteristics make issues such as stragglers significantly more prevalent than in typical
data center environments. We roughly group several key directions to handle systems heterogeneity into:
(i) asynchronous communication, (ii) active device sampling, and (ii) fault tolerance. As mentioned in
Section 2.1.3, we assume a star topology in our following discussions.

2.2.1

Asynchronous Communication

In traditional data center settings, synchronous and asynchronous schemes are both commonly used to
parallelize iterative optimization algorithms, with each approach having pros and cons. Synchronous
schemes are simple and guarantee a serial-equivalent computational model, but they are also more
susceptible to stragglers in the face of device variability. Asynchronous schemes are an attractive approach
to mitigate stragglers in heterogeneous environments, particularly in shared-memory systems [27, 30, 48, 92,
141]. However, they typically rely on bounded-delay assumptions to control the degree of staleness, which
for device k depends on the number of other devices that have updated since device k pulled from the
central server. While asynchronous parameter servers have been successful in distributed data centers [e.g.,
27, 48, 141], classical bounded-delay assumptions can be unrealistic in federated settings, where the delay
may be on the order of hours to days, or completely unbounded.

2.2.2

Active Sampling

In federated networks, typically only a small subset of devices participate at each round of training.
However, the vast majority of federated methods, e.g. those described in [11, 47, 65, 75, 106], are passive
in that they do not aim to influence which devices participate. An alternative approach involves actively
selecting participating devices at each round. For example, Nishio and Yonetani [83] explore novel device
sampling policies based on systems resources, with the aim being for the server to aggregate as many
device updates as possible within a pre-defined time window. Similarly, Kang et al. [57] take into account
7

systems overheads incurred on each device when designing incentive mechanisms to encourage devices
with higher-quality data to participate in the learning process. However, these methods assume a static
model of the systems characteristics of the network; it remains open how to extend these approaches to
handle real-time, device-specific fluctuations in computation and communication delays. Moreover, while
these methods primarily focus on systems variability to perform active sampling, we note that it is also
worth considering actively sampling a set of small but sufficiently representative devices based on the
underlying statistical structure.

2.2.3

Fault Tolerance

Fault tolerance has been extensively studied in the systems community and is a fundamental consideration
of classical distributed systems [19, 71, 110]. Recent works have also investigated fault tolerance specifically
for machine learning workloads in data center environments [e.g., 87, 112]. When learning over remote
devices, however, fault tolerance becomes more critical as it is common for some participating devices to
drop out at some point before the completion of the given training iteration [11]. One practical strategy is
to simply ignore such device failure [11], which may introduce bias into the device sampling scheme if the
failed devices have specific data characteristics. For instance, devices from remote areas may be more likely
to drop due to poor network connections and thus the trained federated model will be biased towards
devices with favorable network conditions. Theoretically, while several recent works have investigated
convergence guarantees of variants of federated learning methods [56, 123, 131, 132], few analyses allow
for low participation [e.g., 65, 106], or study directly the effect of dropped devices.
Coded computation is another option to tolerate device failures by introducing algorithmic redundancy. Recent
works have explored using codes to speed up distributed machine learning training [e.g., 20, 21, 63, 94, 109].
For instance, in the presence of stragglers, gradient coding and its variants [20, 21, 109] carefully replicate
data blocks (as well as the gradient computation on those data blocks) across computing nodes to obtain
either exact or inexact recovery of the true gradients. While this is a seemingly promising approach
for the federated setting, these methods face fundamental challenges in federated networks as sharing
data/replication across devices is often infeasible due to privacy constraints and the scale of the network.

2.3

Statistical Heterogeneity

Challenges arise when training federated models from data that is not identically distributed across devices,
both in terms of modeling the data (as depicted in Figure 5), and in terms of analyzing the convergence
behavior of associated training procedures. We discuss related work in these directions below.

2.3.1

Modeling Heterogeneous Data

There exists a large body of literature in machine learning that has modeled statistical heterogeneity
via methods such as meta-learning [114] and multi-task learning [18, 37]; these ideas have been recently
extended to the federated setting [24, 26, 35, 58, 106, 138]. For instance, MOCHA [106], an optimization
framework designed for the federated setting, can allow for personalization by learning separate but related
models for each device while leveraging a shared representation via multi-task learning. This method has
provable theoretical convergence guarantees for the considered objectives, but is limited in its ability to
8

(a) Learn personalized
models for each device; do
not learn from peers.

(b) Learn a global model;
learn from peers.

(c) Learn personalized
models for each device;
learn from peers.

Figure 5: Different modeling approaches in federated networks. Depending on properties of the data,
network, and application of interest, one may choose to (a) learn separate models for each device, (b) fit a
single global model to all devices, or (c) learn related but distinct models in the network.
scale to massive networks and is restricted to convex objectives. Another approach [26] models the star
topology as a Bayesian network and performs variational inference during learning. Although this method
can handle non-convex models, it is expensive to generalize to large federated networks. Khodak et al. [58]
provably meta-learn a within-task learning rate using multi-task information (where each task corresponds
to a device) and have demonstrated improved empirical performance over vanilla FedAvg. Eichner et al.
[35] investigate a pluralistic solution (adaptively choosing between a global model and device-specific
models) to address the cyclic patterns in data samples during federated training. Zhao et al. [138] explore
transfer learning for personalization by running FedAvg after training a global model centrally on some
shared proxy data. Despite these recent advances, key challenges still remain in making methods for
heterogeneous modeling that are robust, scalable, and automated in federated settings.
When modeling federated data, it may also be important to consider issues beyond accuracy, such as
fairness. In particular, naively solving an aggregate loss function such as in (1) may implicitly advantage
or disadvantage some of the devices, as the learned model may become biased towards devices with
larger amounts of data, or (if weighting devices equally), to commonly occurring groups of devices.
Recent works have proposed modified modeling approaches that aim to reduce the variance of the model
performance across devices. Some heuristics simply perform a varied number of local updates based
on local loss [52]. Other more principled approaches include Agnostic Federated Learning [80], which
optimizes the centralized model for any target distribution formed by a mixture of the client distributions
via a minimax optimization scheme. Another more general approach is taken by Li et al. [66], which
proposes an objective called q-FFL in which devices with higher loss are given higher relative weight to
encourage less variance in the final accuracy distribution. Beyond issues of fairness, we note that aspects
such as accountability and interpretability in federated learning are additionally worth exploring, but may
be challenging due to the scale and heterogeneity of the network.

2.3.2

Convergence Guarantees for Non-IID Data

Statistical heterogeneity also presents novel challenges in terms of analyzing the convergence behavior
in federated settings—even when learning a single global model. Indeed, when data is not identically
distributed across devices in the network, methods such as FedAvg have been shown to diverge in
practice [65, 75]. Parallel SGD and related variants, which make local updates similar to FedAvg, have been
9

analyzed in the I.I.D. setting [68, 93, 104, 108, 120, 121, 122, 125, 136, 140]. However, the results rely on
the premise that each local solver is a copy of the same stochastic process (due to the I.I.D. assumption),
which is not the case in typical federated settings. To understand the performance of FedAvg in statistically
heterogeneous settings, FedProx [65] has recently been proposed. FedProx makes a small modification
to the FedAvg method to help ensure convergence, both theoretically and in practice. FedProx can also
be interpreted as a generalized, reparameterized version of FedAvg that has practical ramifications in the
context of accounting for systems heterogeneity across devices. Several other works [56, 123, 131, 132] have
also explored convergence guarantees in the presence of heterogeneous data with different assumptions, e.g.,
convexity [123] or uniformly bounded gradients [131]. There are also heuristic approaches that aim to tackle
statistical heterogeneity, either by sharing local device data or some server-side proxy data [52, 55, 138].
However, these methods may be unrealistic: in addition to imposing burdens on network bandwidth,
sending local data to the server [55] violates the key privacy assumption of federated learning, and sending
globally-shared proxy data to all devices [52, 138] requires effort to carefully generate or collect such
auxiliary data.

2.4

Privacy

Privacy concerns often motivate the need to keep raw data on each device local in federated settings.
However, sharing other information such as model updates as part of the training process can also leak
sensitive user information [8, 17, 39, 78]. For instance, Carlini et al. [17] demonstrate that one can extract
sensitive text patterns, e.g., a specific credit card number, from a recurrent neural network trained on users’
language data. Given increasing interest in privacy-preserving learning approaches, in Section 2.4.1, we first
briefly revisit prior work on enhancing privacy in the general (distributed) machine learning setting. We
then review recent privacy-preserving methods specifically designed for federated settings in Section 2.4.2.

2.4.1

Privacy in Machine Learning

Privacy-preserving learning has been extensively studied by the machine learning [e.g., 76], systems [e.g.,
4, 11], and theory [e.g., 38, 69] communities. Three main strategies, each of which we will briefly review,
include differential privacy to communicate noisy data sketches, homomorphic encryption to operate on
encrypted data, and secure function evaluation or multiparty computation.
Among these various privacy approaches, differential privacy [32, 33, 34] is most widely used due to its strong
information theoretic guarantees, algorithmic simplicity, and relatively small systems overhead. Simply
put, a randomized mechanism is differentially private if the change of one input element will not result in
too much difference in the output distribution; this means that one cannot draw any conclusions about
whether or not a specific sample is used in the learning process. Such sample-level privacy can be achieved
in many learning tasks [2, 7, 22, 53, 85, 86]. For gradient-based learning methods, a popular approach is to
apply differential privacy by randomly perturbing the intermediate output at each iteration [e.g., 2, 7, 126].
Before applying the perturbation, e.g., via Gaussian noise [2], Laplacian noise [77], or Binomial noise [3], it
is common to clip the gradients in order to bound the influence of each example on the overall update.
There exists an inherent trade-off between differential privacy and model accuracy, as adding more noise
results in greater privacy, but may compromise accuracy significantly. Despite the fact that differential
privacy is the de facto metric for privacy in machine learning, there are many other privacy definitions,
such as k-anonymity [36], δ-presence [81] and distance correlation [117], that may be applicable to different
learning problems [118].
10

server

server

server

devices

devices

(a) Federated learning without additional privacy protection
mechanisms.

(b) Global privacy, where a trusted
server is assumed.

devices

(c) Local privacy, where the central server
might be malicious.

Figure 6: An illustration of different privacy-enhancing mechanisms in one round of federated learning. M
denotes a randomized mechanism used to privatize the data. With global privacy (b), the model updates
are private to all third parties other than a single trusted party (the central server). With local privacy (c),
the individual model updates are also private to the server.
Beyond differential privacy, homomorphic encryption can be used to secure the learning process by
computing on encrypted data, although it has currently been applied in limited settings, e.g., training
linear models [82] or involving only a few entities [133]. When the sensitive datasets are distributed
across different data owners, another natural option is to perform privacy-preserving learning via secure
function evaluation (SFE) or secure multiparty computation (SMC). The resulting protocols can enable
multiple parties to collaboratively compute an agreed-upon function without leaking input information
from any party except for what can be inferred from the output [e.g., 23, 43, 95]. Thus, while SMC cannot
guarantee protection from information leakage, it can be combined with differential privacy to achieve
stronger privacy guarantees. However, approaches along these lines may not be applicable to large-scale
machine learning scenarios as they incur substantial additional communication and computation costs.
Moreover, SMC protocols need to be carefully designed and implemented for each operation in the targeted
learning algorithm [25, 79]. We defer interested readers to [13, 97] for a more comprehensive review of the
approaches based on homomorphic encryption and SMC.

2.4.2

Privacy in Federated Learning

The federated setting poses novel challenges to existing privacy-preserving algorithms. Beyond providing rigorous privacy guarantees, it is necessary to develop methods that are computationally cheap,
communication-efficient, and tolerant to dropped devices—all without overly compromising accuracy.
Although there are a variety of privacy definitions in federated learning [8, 17, 41, 64, 76, 113], typically
they can be classified into two categories: global privacy and local privacy. As demonstrated in Figure 6,
global privacy requires that the model updates generated at each round are private to all untrusted third
parties other than the central server, while local privacy further requires that the updates are also private to
the server.
Current works that aim to improve the privacy of federated learning typically build upon previous classical
cryptographic protocols such as SMC [10, 42] and differential privacy [3, 8, 41, 76]. Bonawitz et al. [10]
introduce an SMC protocol to protect individual model updates. The central server is not able to see any
local updates, but can still observe the exact aggregated results at each round. SMC is a lossless method, and
can retain the original accuracy with a very high privacy guarantee. However, the resulting method incurs
significant extra communication cost. Other works [41, 76] apply differential privacy to federated learning

11

and offer global differential privacy. These approaches have a number of hyperparameters that affect
communication and accuracy that must be carefully chosen, though follow up work [113] proposes adaptive
gradient clipping strategies to help alleviate this issue. In the case where stronger privacy guarantees are
required, Bhowmick et al. [8] introduce a relaxed version of local privacy by limiting the power of potential
adversaries. It affords stronger privacy guarantees than global privacy, and has better model performance
than strict local privacy. Li et al. [64] propose locally differentially-private algorithms in the context of
meta-learning, which can be applied to federated learning with personalization, while also providing
provable learning guarantees in convex settings. In addition, differential privacy can be combined with
model compression techniques to reduce communication and obtain privacy benefits simultaneously [3].

3

Future Directions

Federated learning is an active and ongoing area of research. Although recent work has begun to
address the challenges discussed in Section 2, there are a number of critical open directions yet to be
explored. In this section, we briefly outline a few promising research directions surrounding the previously
discussed challenges (expensive communication, systems heterogeneity, statistical heterogeneity, and
privacy concerns), and introduce additional challenges regarding issues such as productionizing and
benchmarking in federated settings.
• Extreme communication schemes. It remains to be seen how much communication is necessary
in federated learning. Indeed, it is well-known that optimization methods for machine learning
can tolerate a lack of precision; this error can in fact help with generalization [129]. While oneshot or divide-and-conquer communication schemes have been explored in traditional data center
settings [73, 137], the behavior of these methods is not well-understood in massive or statistical
heterogeneous networks. Similarly, one-shot/few-shot heuristics [44, 45, 134] have recently been
proposed for the federated setting, but have yet to be theoretically analyzed or evaluated at scale.
• Communication reduction and the Pareto frontier. We discussed several ways to reduce communication in federated training, such as local updating and model compression. In order to create a
realistic system for federated learning, it is important to understand how these techniques compose
with one another, and to systematically analyze the trade-off between accuracy and communication for
each approach. In particular, the most useful techniques will demonstrate improvements at the Pareto
frontier—achieving an accuracy greater than any other approach under the same communication
budget, and ideally, across a wide range of communication/accuracy profiles. Similar comprehensive
analyses have been performed for efficient neural network inference [e.g., 9], and are necessary in
order to compare communication-reduction techniques for federated learning in a meaningful way.
• Novel models of asynchrony. As discussed in Section 2.2.1, two communication schemes most
commonly studied in distributed optimization are bulk synchronous approaches and asynchronous
approaches (where it is assumed that the delay is bounded). These schemes are more realistic in data
center settings—where worker nodes are typically dedicated to the workload, i.e., they are ready to
‘pull’ their next job from the central node immediately after they ‘push’ the results of their previous
job. In contrast, in federated networks, each device is often undedicated to the task at hand and most
devices are not active on any given iteration. Therefore, it is worth studying the effects of this more
realistic device-centric communication scheme—in which each device can decide when to ‘wake up’
and interact with the central server in an event-triggered manner.

12

• Heterogeneity diagnostics. Recent works have aimed to quantify statistical heterogeneity through
metrics such as local dissimilarity (as defined in the context of federated learning in [65] and used for
other purposes in works such as [100, 116, 130]) and earth mover’s distance [138]. However, these
metrics cannot be easily calculated over the federated network before training occurs. The importance
of these metrics motivates the following open questions: (i) Do simple diagnostics exist to quickly
determine the level of heterogeneity in federated networks a priori? (ii) Can analogous diagnostics be
developed to quantify the amount of systems-related heterogeneity? (iii) Can current or new definitions
of heterogeneity be exploited to further improve the convergence of federated optimization methods?
• Granular privacy constraints. The definitions of privacy outlined in Section 2.4.2 cover privacy
at a local or global level with respect to all devices in the network. However, in practice, it may
be necessary to define privacy on a more granular level, as privacy constraints may differ across
devices or even across data points on a single device. For instance, Li et al. [64] recently proposed
sample-specific (as opposed to user-specific) privacy guarantees, thus providing a weaker form of
privacy in exchange for more accurate models. Developing methods to handle mixed (device-specific
or sample-specific) privacy restrictions is an interesting and ongoing direction of future work.
• Beyond supervised learning. It is important to note that the methods discussed thus far have been
developed with the task of supervised learning in mind, i.e., they assume that labels exist for all of
the data in the federated network. In practice, much of the data generated in realistic federated
networks may be unlabeled or weakly labeled. Furthermore, the problem at hand may not be to fit a
model to data as presented in (1), but instead to perform some exploratory data analysis, determine
aggregate statistics, or run a more complex task such as reinforcement learning. Tackling problems
beyond supervised learning in federated networks will likely require addressing similar challenges of
scalability, heterogeneity, and privacy.
• Productionizing federated learning. Beyond the major challenges discussed in this article, there
are a number of practical concerns that arise when running federated learning in production. In
particular, issues such as concept drift (when the underlying data-generation model changes over
time); diurnal variations (when the devices exhibit different behavior at different times of the day or
week) [35]; and cold start problems (when new devices enter the network) must be handled with care.
We defer the readers to [11], which discusses some of the practical systems-related issues that exist in
production federated learning systems.
• Benchmarks. Finally, as federated learning is a nascent field, we are at a pivotal time to shape
the developments made in this area and ensure that they are grounded in real-world settings,
assumptions, and datasets. It is critical for the broader research communities to further build upon
existing implementations and benchmarking tools, such as LEAF [16] and TensorFlow Federated [1],
to facilitate both the reproducibility of empirical results and the dissemination of new solutions for
federated learning.

4

Conclusion

In this article, we have provided an overview of federated learning, a learning paradigm where statistical
models are trained at the edge in distributed networks. We have discussed the unique properties and
associated challenges of federated learning compared with traditional distributed data center computing
and classical privacy-preserving learning. We provided an extensive survey on classical results as well as
more recent work specifically focused on federated settings. Finally, we have outlined out a handful of open
13

problems worth future research effort. Providing solutions to these problems will require interdisciplinary
effort from a broad set of research communities.

Acknowledgement. We thank Jeffrey Li and Mikhail Khodak for helpful discussions and comments. This
work was supported in part by DARPA FA875017C0141, the National Science Foundation grants IIS1705121
and IIS1838017, an Okawa Grant, a Google Faculty Award, an Amazon Web Services Award, a JP Morgan
A.I. Research Faculty Award, a Carnegie Bosch Institute Research Award and the CONIX Research Center,
one of six centers in JUMP, a Semiconductor Research Corporation (SRC) program sponsored by DARPA.
Any opinions, findings, and conclusions or recommendations expressed in this material are those of the
author(s) and do not necessarily reflect the views of DARPA, the National Science Foundation, or any other
funding agency.

References
[1] Tensorflow federated: Machine learning on decentralized data. URL https://www.tensorflow.org/federated.
[2] M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and L. Zhang. Deep learning with
differential privacy. In Conference on Computer and Communications Security, 2016.
[3] N. Agarwal, A. T. Suresh, F. X. X. Yu, S. Kumar, and B. McMahan. cpSGD: Communication-efficient and
differentially-private distributed sgd. In Advances in Neural Information Processing Systems, 2018.
[4] R. Agrawal and R. Srikant. Privacy-preserving data mining. In International Conference on Management of Data,
2000.
[5] M. Ammad-ud din, E. Ivannikova, S. A. Khan, W. Oyomno, Q. Fu, K. E. Tan, and A. Flanagan. Federated collaborative filtering for privacy-preserving personalized recommendation system. arXiv preprint arXiv:1901.09888,
2019.
[6] D. Anguita, A. Ghio, L. Oneto, X. Parra, and J. L. Reyes-Ortiz. A public domain dataset for human activity
recognition using smartphones. In European Symposium on Artificial Neural Networks, Computational Intelligence and
Machine Learning, 2013.
[7] R. Bassily, A. Smith, and A. Thakurta. Private empirical risk minimization: Efficient algorithms and tight error
bounds. In Foundations of Computer Science, 2014.
[8] A. Bhowmick, J. Duchi, J. Freudiger, G. Kapoor, and R. Rogers. Protection against reconstruction and its
applications in private federated learning. arXiv preprint arXiv:1812.00984, 2018.
[9] T. Bolukbasi, J. Wang, O. Dekel, and V. Saligrama. Adaptive neural networks for efficient inference. In International
Conference on Machine Learning, 2017.
[10] K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, H. B. McMahan, S. Patel, D. Ramage, A. Segal, and K. Seth. Practical secure aggregation for privacy-preserving machine learning. In Conference on Computer and Communications
Security, 2017.
[11] K. Bonawitz, H. Eichner, W. Grieskamp, D. Huba, A. Ingerman, V. Ivanov, C. Kiddon, J. Konecny, S. Mazzocchi,
H. B. McMahan, T. V. Overveldt, D. Petrou, D. Ramage, and J. Roselander. Towards federated learning at scale:
system design. In Conference on Systems and Machine Learning, 2019.
[12] F. Bonomi, R. Milito, J. Zhu, and S. Addepalli. Fog computing and its role in the internet of things. In SIGCOMM
Workshop on Mobile Cloud Computing, 2012.

14

[13] R. Bost, R. A. Popa, S. Tu, and S. Goldwasser. Machine learning classification over encrypted data. In Network
and Distributed System Security Symposium, 2015.
[14] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein. Distributed optimization and statistical learning via the
alternating direction method of multipliers. Foundations and Trends R in Machine Learning, 3:1–122, 2011.
[15] S. Caldas, J. Konečny, H. B. McMahan, and A. Talwalkar. Expanding the reach of federated learning by reducing
client resource requirements. arXiv preprint arXiv:1812.07210, 2018.
[16] S. Caldas, P. Wu, T. Li, J. Konečnỳ, H. B. McMahan, V. Smith, and A. Talwalkar. Leaf: A benchmark for federated
settings. arXiv preprint arXiv:1812.01097, 2018.
[17] N. Carlini, C. Liu, J. Kos, Ú. Erlingsson, and D. Song. The secret sharer: Measuring unintended neural network
memorization & extracting secrets. arXiv preprint arXiv:1802.08232, 2018.
[18] R. Caruana. Multitask learning. Machine Learning, 28:41–75, 1997.
[19] M. Castro, B. Liskov, et al. Practical byzantine fault tolerance. In Operating Systems Design and Implementation,
1999.
[20] Z. Charles and D. Papailiopoulos. Gradient coding using the stochastic block model. In International Symposium
on Information Theory, 2018.
[21] Z. B. Charles, D. S. Papailiopoulos, and J. Ellenberg. Approximate gradient coding via sparse random graphs.
arXiv preprint arXiv:1711.0677, 2017.
[22] K. Chaudhuri, C. Monteleoni, and A. D. Sarwate. Differentially private empirical risk minimization. Journal of
Machine Learning Research, 12:1069–1109, 2011.
[23] D. Chaum. The dining cryptographers problem: Unconditional sender and recipient untraceability. Journal of
Cryptology, 1:65–75, 1988.
[24] F. Chen, Z. Dong, Z. Li, and X. He. Federated meta-learning for recommendation. arXiv preprint arXiv:1802.07876,
2018.
[25] V. Chen, V. Pastro, and M. Raykova. Secure computation for machine learning with spdz. arXiv preprint
arXiv:1901.00329, 2019.
[26] L. Corinzia and J. M. Buhmann. Variational federated multi-task learning. arXiv preprint arXiv:1906.06268, 2019.
[27] W. Dai, A. Kumar, J. Wei, Q. Ho, G. Gibson, and E. P. Xing. High-performance distributed ML at scale through
parameter server consistency models. In AAAI Conference on Artificial Intelligence, 2015.
[28] O. Dekel, R. Gilad-Bachrach, O. Shamir, and L. Xiao. Optimal distributed online prediction using mini-batches.
Journal of Machine Learning Research, 13:165–202, 2012.
[29] A. Deshpande, C. Guestrin, S. R. Madden, J. M. Hellerstein, and W. Hong. Model-based approximate querying
in sensor networks. The VLDB Journal, 14:417–443, 2005.
[30] J. Duchi, M. I. Jordan, and B. McMahan. Estimation, optimization, and parallelism when data is sparse. In
Advances in Neural Information Processing Systems, 2013.
[31] J. C. Duchi, M. I. Jordan, and M. J. Wainwright. Privacy aware learning. In Advances in Neural Information
Processing Systems, 2012.
[32] C. Dwork. A firm foundation for private data analysis. Communications of the ACM, 54:86–95, 2011.
[33] C. Dwork and A. Roth. The algorithmic foundations of differential privacy. Foundations and Trends in Theoretical
Computer Science, 9:211–407, 2014.

15

[34] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating noise to sensitivity in private data analysis. In
Theory of Cryptography Conference, 2006.
[35] H. Eichner, T. Koren, H. B. McMahan, N. Srebro, and K. Talwar. Semi-cyclic stochastic gradient descent. In
International Conference on Machine Learning, 2019.
[36] K. El Emam and F. K. Dankar. Protecting privacy using k-anonymity. Journal of the American Medical Informatics
Association, 15:627–637, 2008.
[37] T. Evgeniou and M. Pontil. Regularized multi–task learning. In Conference on Knowledge Discovery and Data
Mining, 2004.
[38] V. Feldman, I. Mironov, K. Talwar, and A. Thakurta. Privacy amplification by iteration. In Foundations of Computer
Science, 2018.
[39] M. Fredrikson, S. Jha, and T. Ristenpart. Model inversion attacks that exploit confidence information and basic
countermeasures. In Conference on Computer and Communications Security, 2015.
[40] P. Garcia Lopez, A. Montresor, D. Epema, A. Datta, T. Higashino, A. Iamnitchi, M. Barcellos, P. Felber, and
E. Riviere. Edge-centric computing: Vision and challenges. SIGCOMM Computer Communication Review, 45:37–42,
2015.
[41] R. C. Geyer, T. Klein, and M. Nabi. Differentially private federated learning: A client level perspective. arXiv
preprint arXiv:1712.07557, 2017.
[42] B. Ghazi, R. Pagh, and A. Velingker. Scalable and differentially private distributed aggregation in the shuffled
model. arXiv preprint arXiv:1906.08320, 2019.
[43] S. Goryczka and L. Xiong. A comprehensive comparison of multiparty secure additions with differential privacy.
IEEE Transactions on Dependable and Secure Computing, 14:463–477, 2015.
[44] N. Guha and V. Smith. Model aggregation via good-enough model spaces. arXiv preprint arXiv:1805.07782, 2018.
[45] N. Guha, A. Talwalkar, and V. Smith. One-shot federated learning. arXiv preprint arXiv:1902.11175, 2019.
[46] A. Hard, K. Rao, R. Mathews, F. Beaufays, S. Augenstein, H. Eichner, C. Kiddon, and D. Ramage. Federated
learning for mobile keyboard prediction. arXiv preprint arXiv:1811.03604, 2018.
[47] L. He, A. Bian, and M. Jaggi. Cola: Decentralized linear learning. In Advances in Neural Information Processing
Systems, 2018.
[48] Q. Ho, J. Cipar, H. Cui, S. Lee, J. K. Kim, P. B. Gibbons, G. A. Gibson, G. Ganger, and E. P. Xing. More effective
distributed ML via a stale synchronous parallel parameter server. In Advances in Neural Information Processing
Systems, 2013.
[49] K. Hong, D. Lillethun, U. Ramachandran, B. Ottenwälder, and B. Koldehofe. Mobile fog: A programming model
for large-scale applications on the internet of things. In SIGCOMM Workshop on Mobile Cloud Computing, 2013.
[50] J. Huang, F. Qian, Y. Guo, Y. Zhou, Q. Xu, Z. M. Mao, S. Sen, and O. Spatscheck. An in-depth study of lte: effect
of network protocol and application behavior on performance. SIGCOMM Computer Communication Review, 43:
363–374, 2013.
[51] L. Huang and D. Liu. Patient clustering improves efficiency of federated machine learning to predict mortality
and hospital stay time using distributed electronic medical records. arXiv preprint arXiv:1903.09296, 2019.
[52] L. Huang, Y. Yin, Z. Fu, S. Zhang, H. Deng, and D. Liu. Loadaboost: Loss-based adaboost federated machine
learning on medical data. arXiv preprint arXiv:1811.12629, 2018.
[53] R. Iyengar, J. P. Near, D. Song, O. Thakkar, A. Thakurta, and L. Wang. Towards practical differentially private
convex optimization. In Conference on Computer and Communications Security, 2019.

16

[54] M. Jaggi, V. Smith, M. Takác, J. Terhorst, S. Krishnan, T. Hofmann, and M. I. Jordan. Communication-efficient
distributed dual coordinate ascent. In Advances in Neural Information Processing Systems, 2014.
[55] E. Jeong, S. Oh, H. Kim, J. Park, M. Bennis, and S.-L. Kim. Communication-efficient on-device machine learning:
Federated distillation and augmentation under non-iid private data. arXiv preprint arXiv:1811.11479, 2018.
[56] P. Jiang and G. Agrawal. A linear speedup analysis of distributed deep learning with sparse and quantized
communication. In Advances in Neural Information Processing Systems, 2018.
[57] J. Kang, Z. Xiong, D. Niyato, H. Yu, Y.-C. Liang, and D. I. Kim. Incentive design for efficient federated learning
in mobile networks: A contract theory approach. arXiv preprint arXiv:1905.07479, 2019.
[58] M. Khodak, M.-F. Balcan, and A. Talwalkar. Adaptive gradient-based meta-learning methods. arXiv preprint
arXiv:1906.02717, 2019.
[59] J. Konečnỳ, H. B. McMahan, F. X. Yu, P. Richtárik, A. T. Suresh, and D. Bacon. Federated learning: strategies for
improving communication efficiency. arXiv preprint arXiv:1610.05492, 2016.
[60] T. Kuflik, J. Kay, and B. Kummerfeld. Challenges and solutions of ubiquitous user modeling. In Ubiquitous
Display Environments. 2012.
[61] A. Lalitha, X. Wang, O. Kilinc, Y. Lu, T. Javidi, and F. Koushanfar. Decentralized bayesian learning over graphs.
arXiv preprint arXiv:1905.10466, 2019.
[62] C.-P. Lee and D. Roth. Distributed box-constrained quadratic optimization for dual linear svm. In International
Conference on Machine Learning, 2015.
[63] K. Lee, M. Lam, R. Pedarsani, D. Papailiopoulos, and K. Ramchandran. Speeding up distributed machine
learning using codes. IEEE Transactions on Information Theory, 64:1514–1529, 2017.
[64] J. Li, M. Khodak, S. Caldas, and A. Talwalkar. Differentially-private gradient-based meta-learning. Technical
Report, 2019.
[65] T. Li, A. K. Sahu, M. Sanjabi, M. Zaheer, A. Talwalkar, and V. Smith. Federated optimization for heterogeneous
networks. arXiv preprint arXiv:1812.06127, 2018.
[66] T. Li, M. Sanjabi, and V. Smith. Fair resource allocation in federated learning. arXiv preprint arXiv:1905.10497,
2019.
[67] X. Lian, C. Zhang, H. Zhang, C.-J. Hsieh, W. Zhang, and J. Liu. Can decentralized algorithms outperform
centralized algorithms? a case study for decentralized parallel stochastic gradient descent. In Advances in Neural
Information Processing Systems, 2017.
[68] T. Lin, S. U. Stich, and M. Jaggi. Don’t use large mini-batches, use local sgd. arXiv preprint arXiv:1808.07217, 2018.
[69] Y. Lindell and B. Pinkas. Privacy preserving data mining. In Advances in Cryptology, 2000.
[70] L. Liu, J. Zhang, S. Song, and K. B. Letaief. Edge-assisted hierarchical federated learning with non-iid data. arXiv
preprint arXiv:1905.06641, 2019.
[71] Y. Liu, J. K. Muppala, M. Veeraraghavan, D. Lin, and M. Hamdi. Data center networks: Topologies, architectures and
fault-tolerance characteristics. Springer Science & Business Media, 2013.
[72] C. Ma, V. Smith, M. Jaggi, M. I. Jordan, P. Richtárik, and M. Takáč. Adding vs. averaging in distributed
primal-dual optimization. In International Conference on Machine Learning, 2015.
[73] L. W. Mackey, M. I. Jordan, and A. Talwalkar. Divide-and-conquer matrix factorization. In Advances in Neural
Information Processing Systems, 2011.
[74] S. R. Madden, M. J. Franklin, J. M. Hellerstein, and W. Hong. Tinydb: an acquisitional query processing system
for sensor networks. Transactions on Database Systems, 30:122–173, 2005.

17

[75] H. B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas. Communication-efficient learning of
deep networks from decentralized data. In Conference on Artificial Intelligence and Statistics, 2017.
[76] H. B. McMahan, D. Ramage, K. Talwar, and L. Zhang. Learning differentially private recurrent language models.
In International Conference on Learning Representations, 2018.
[77] L. Melis, G. Danezis, and E. D. Cristofaro. Efficient private statistics with succinct sketches. In Network and
Distributed System Security Symposium, 2016.
[78] L. Melis, C. Song, E. De Cristofaro, and V. Shmatikov. Exploiting unintended feature leakage in collaborative
learning. In IEEE Symposium on Security & Privacy, 2019.
[79] P. Mohassel and P. Rindal. Aby 3: a mixed protocol framework for machine learning. In Conference on Computer
and Communications Security, 2018.
[80] M. Mohri, G. Sivek, and A. T. Suresh. Agnostic federated learning. In International Conference on Machine Learning,
2019.
[81] M. E. Nergiz and C. Clifton. δ-presence without complete world knowledge. IEEE Transactions on Knowledge and
Data Engineering, 22:868–883, 2010.
[82] V. Nikolaenko, U. Weinsberg, S. Ioannidis, M. Joye, D. Boneh, and N. Taft. Privacy-preserving ridge regression
on hundreds of millions of records. In Symposium on Security and Privacy, 2013.
[83] T. Nishio and R. Yonetani. Client selection for federated learning with heterogeneous resources in mobile edge.
In International Conference on Communications, 2019.
[84] A. Pantelopoulos and N. G. Bourbakis. A survey on wearable sensor-based systems for health monitoring and
prognosis. IEEE Transactions on Systems, Man, and Cybernetics, 40:1–12, 2010.
[85] N. Papernot, M. Abadi, U. Erlingsson, I. Goodfellow, and K. Talwar. Semi-supervised knowledge transfer for
deep learning from private training data. In International Conference on Learning Representations, 2017.
[86] N. Papernot, S. Song, I. Mironov, A. Raghunathan, K. Talwar, and Ú. Erlingsson. Scalable private learning with
pate. In International Conference on Learning Representations, 2018.
[87] A. Qiao, B. Aragam, B. Zhang, and E. Xing. Fault tolerance in iterative-convergent machine learning. In
International Conference on Machine Learning, 2019.
[88] Z. Qu, P. Richtárik, and T. Zhang. Quartz: Randomized dual coordinate ascent with arbitrary sampling. In
Advances in Neural Information Processing Systems, 2015.
[89] S. Ramaswamy, R. Mathews, K. Rao, and F. Beaufays. Federated learning for emoji prediction in a mobile
keyboard. arXiv preprint arXiv:1906.04329, 2019.
[90] M. Rastegari, V. Ordonez, J. Redmon, and A. Farhadi. Xnor-net: Imagenet classification using binary convolutional
neural networks. In European Conference on Computer Vision, 2016.
[91] A. Ratner et al. SysML: The new frontier of machine learning systems. arXiv preprint arXiv:1904.03257, 2019.
[92] B. Recht, C. Re, S. Wright, and F. Niu. Hogwild: A lock-free approach to parallelizing stochastic gradient descent.
In Advances in Neural Information Processing Systems, 2011.
[93] S. J. Reddi, J. Konečnỳ, P. Richtárik, B. Póczós, and A. Smola. Aide: Fast and communication efficient distributed
optimization. arXiv preprint arXiv:1608.06879, 2016.
[94] A. Reisizadeh, S. Prakash, R. Pedarsani, and A. S. Avestimehr. Coded computation over heterogeneous clusters.
IEEE Transactions on Information Theory, 65:4227–4242, 2019.

18

[95] M. S. Riazi, C. Weinert, O. Tkachenko, E. M. Songhori, T. Schneider, and F. Koushanfar. Chameleon: A
hybrid secure computation framework for machine learning applications. In Asia Conference on Computer and
Communications Security, 2018.
[96] P. Richtárik and M. Takáč. Distributed coordinate descent method for learning with big data. Journal of Machine
Learning Research, 17:2657–2681, 2016.
[97] B. D. Rouhani, M. S. Riazi, and F. Koushanfar. Deepsecure: Scalable provably-secure deep learning. In Design
Automation Conference, 2018.
[98] S. Samarakoon, M. Bennis, W. Saad, and M. Debbah. Federated learning for ultra-reliable low-latency v2v
communications. In Global Communications Conference, 2018.
[99] F. Sattler, S. Wiedemann, K.-R. Müller, and W. Samek. Robust and communication-efficient federated learning
from non-iid data. arXiv preprint arXiv:1903.02891, 2019.
[100] M. Schmidt and N. L. Roux. Fast convergence of stochastic gradient descent under a strong growth condition.
arXiv preprint arXiv:1308.6370, 2013.
[101] F. Seide, H. Fu, J. Droppo, G. Li, and D. Yu. 1-bit stochastic gradient descent and its application to data-parallel
distributed training of speech dnns. In International Speech Communication Association, 2014.
[102] S. Shalev-Shwartz and T. Zhang. Accelerated mini-batch stochastic dual coordinate ascent. In Advances in Neural
Information Processing Systems, 2013.
[103] O. Shamir and N. Srebro. Distributed stochastic optimization and learning. In Allerton Conference on Communication,
Control, and Computing, 2014.
[104] O. Shamir, N. Srebro, and T. Zhang. Communication-efficient distributed optimization using an approximate
newton-type method. In International Conference on Machine Learning, 2014.
[105] S. Silva, B. Gutman, E. Romero, P. M. Thompson, A. Altmann, and M. Lorenzi. Federated learning in distributed
medical databases: Meta-analysis of large-scale subcortical brain data. arXiv preprint arXiv:1810.08553, 2018.
[106] V. Smith, C.-K. Chiang, M. Sanjabi, and A. Talwalkar. Federated multi-task learning. In Advances in Neural
Information Processing Systems, 2017.
[107] V. Smith, S. Forte, C. Ma, M. Takac, M. I. Jordan, and M. Jaggi. Cocoa: a general framework for communicationefficient distributed optimization. Journal of Machine Learning Research, 18:1–47, 2018.
[108] S. U. Stich. Local sgd converges fast and communicates little. In International Conference on Learning Representations,
2019.
[109] R. Tandon, Q. Lei, A. G. Dimakis, and N. Karampatziakis. Gradient coding: Avoiding stragglers in distributed
learning. In International Conference on Machine Learning, 2017.
[110] A. S. Tanenbaum and M. Van Steen. Distributed systems: principles and paradigms. Prentice-Hall, 2007.
[111] H. Tang, S. Gan, C. Zhang, T. Zhang, and J. Liu. Communication compression for decentralized training. In
Advances in Neural Information Processing Systems, 2018.
[112] H. Tang, C. Yu, C. Renggli, S. Kassing, A. Singla, D. Alistarh, J. Liu, and C. Zhang. Distributed learning over
unreliable networks. In International Conference on Machine Learning, 2019.
[113] O. Thakkar, G. Andrew, and H. B. McMahan. Differentially private learning with adaptive clipping. arXiv preprint
arXiv:1905.03871, 2019.
[114] S. Thrun and L. Pratt. Learning to learn. Springer Science & Business Media, 2012.
[115] C. Van Berkel. Multi-core for mobile phones. In Conference on Design, Automation and Test in Europe, 2009.

19

[116] S. Vaswani, F. Bach, and M. Schmidt. Fast and faster convergence of sgd for over-parameterized models (and an
accelerated perceptron). In Conference on Artificial Intelligence and Statistics, 2019.
[117] P. Vepakomma, O. Gupta, A. Dubey, and R. Raskar. Reducing leakage in distributed deep learning for sensitive
health data. arXiv preprint arXiv:1812.00564, 2019.
[118] I. Wagner and D. Eckhoff. Technical privacy metrics: a systematic survey. ACM Computing Surveys, 51:57, 2018.
[119] H. Wang, S. Sievert, S. Liu, Z. Charles, D. Papailiopoulos, and S. Wright. Atomo: Communication-efficient
learning via atomic sparsification. In Advances in Neural Information Processing Systems, 2018.
[120] J. Wang and G. Joshi. Cooperative sgd: A unified framework for the design and analysis of communicationefficient sgd algorithms. arXiv preprint arXiv:1808.07576, 2018.
[121] J. Wang and G. Joshi. Adaptive communication strategies to achieve the best error-runtime trade-off in localupdate sgd. In Conference on Systems and Machine Learning, 2019.
[122] S. Wang, F. Roosta-Khorasani, P. Xu, and M. W. Mahoney. Giant: Globally improved approximate newton method
for distributed optimization. In Advances in Neural Information Processing Systems, 2018.
[123] S. Wang, T. Tuor, T. Salonidis, K. K. Leung, C. Makaya, T. He, and K. Chan. Adaptive federated learning in
resource constrained edge computing systems. Journal on Selected Areas in Communications, 37:1205–1221, 2019.
[124] WeBank AI Group. Federated learning white paper v1.0. 2018.
[125] B. Woodworth, J. Wang, A. Smith, B. McMahan, and N. Srebro. Graph oracle models, lower bounds, and gaps for
parallel stochastic optimization. In Advances in Neural Information Processing Systems, 2018.
[126] X. Wu, F. Li, A. Kumar, K. Chaudhuri, S. Jha, and J. Naughton. Bolt-on differential privacy for scalable stochastic
gradient descent-based analytics. In International Conference on Management of Data, 2017.
[127] Q. Yang, Y. Liu, T. Chen, and Y. Tong. Federated machine learning: Concept and applications. ACM Transactions
on Intelligent Systems and Technology, 10:12, 2019.
[128] T. Yang. Trading computation for communication: Distributed stochastic dual coordinate ascent. In Advances in
Neural Information Processing Systems, 2013.
[129] Y. Yao, L. Rosasco, and A. Caponnetto. On early stopping in gradient descent learning. Constructive Approximation,
26:289–315, 2007.
[130] D. Yin, A. Pananjady, M. Lam, D. Papailiopoulos, K. Ramchandran, and P. Bartlett. Gradient diversity: a key
ingredient for scalable distributed learning. In Conference on Artificial Intelligence and Statistics, pages 1998–2007,
2018.
[131] H. Yu, S. Yang, and S. Zhu. Parallel restarted sgd for non-convex optimization with faster convergence and less
communication. In AAAI Conference on Artificial Intelligence, 2018.
[132] H. Yu, R. Jin, and S. Yang. On the linear speedup analysis of communication efficient momentum sgd for
distributed non-convex optimization. In International Conference on Machine Learning, 2019.
[133] J. Yuan and S. Yu. Privacy preserving back-propagation neural network learning made practical with cloud
computing. IEEE Transactions on Parallel and Distributed Systems, 25:212–221, 2013.
[134] M. Yurochkin, M. Agarwal, S. Ghosh, K. Greenewald, T. N. Hoang, and Y. Khazaeni. Bayesian nonparametric
federated learning of neural networks. In International Conference on Machine Learning, 2019.
[135] H. Zhang, J. Li, K. Kara, D. Alistarh, J. Liu, and C. Zhang. ZipML: Training linear models with end-to-end low
precision, and a little bit of deep learning. In International Conference on Machine Learning, 2017.
[136] S. Zhang, A. E. Choromanska, and Y. LeCun. Deep learning with elastic averaging sgd. In Advances in Neural
Information Processing Systems, 2015.

20

[137] Y. Zhang, J. Duchi, and M. Wainwright. Divide and conquer kernel ridge regression: A distributed algorithm
with minimax optimal rates. Journal of Machine Learning Research, 16:3299–3340, 2015.
[138] Y. Zhao, M. Li, L. Lai, N. Suda, D. Civin, and V. Chandra. Federated learning with non-iid data. arXiv preprint
arXiv:1806.00582, 2018.
[139] Y. Zhao, J. Zhao, L. Jiang, R. Tan, and D. Niyato. Mobile edge computing, blockchain and reputation-based
crowdsourcing iot federated learning: A secure, decentralized and privacy-preserving system. arXiv preprint
arXiv:1906.10893, 2019.
[140] F. Zhou and G. Cong. On the convergence properties of a k-step averaging stochastic gradient descent algorithm
for nonconvex optimization. In International Joint Conference on Artificial Intelligence, 2018.
[141] M. Zinkevich, M. Weimer, L. Li, and A. J. Smola. Parallelized stochastic gradient descent. In Advances in Neural
Information Processing Systems, 2010.

21

F LOWER : A F RIENDLY F EDERATED L EARNING F RAMEWORK

A BSTRACT
Federated Learning (FL) has emerged as a promising technique for edge devices to collaboratively learn a shared
prediction model, while keeping their training data on the device, thereby decoupling the ability to do machine
learning from the need to store the data in the cloud. However, FL is difficult to implement realistically, both
in terms of scale and systems heterogeneity. Although there are a number of research frameworks available to
simulate FL algorithms, they do not support the study of scalable FL workloads on heterogeneous edge devices.
In this paper, we present Flower – a comprehensive FL framework that distinguishes itself from existing platforms
by offering new facilities to execute large-scale FL experiments, and consider richly heterogeneous FL device
scenarios. Our experiments show Flower can perform FL experiments up to 15M in client size using only a pair of
high-end GPUs. Researchers can then seamlessly migrate experiments to real devices to examine other parts of
the design space. We believe Flower provides the community a critical new tool for FL study and development.

1

I NTRODUCTION

There has been tremendous progress in enabling the execution of deep learning models on mobile and embedded
devices to infer user contexts and behaviors (Fromm et al.,
2018; Chowdhery et al., 2019; Malekzadeh et al., 2019;
Lee et al., 2019; Yao et al., 2019; LiKamWa et al., 2016;
Georgiev et al., 2017). This has been powered by the increasing computational abilities of mobile devices as well
as novel algorithms which apply software optimizations to
enable pre-trained cloud-scale models to run on resourceconstrained devices. However, when it comes to the training
of these mobile-focused models, a working assumption has
been that the models will be trained centrally in the cloud,
using training data aggregated from several users.
Federated Learning (FL) (McMahan et al., 2017) is an
emerging area of research in the machine learning community which aims to enable distributed edge devices (or
users) to collaboratively train a shared prediction model
while keeping their personal data private. At a high level,
this is achieved by repeating three basic steps: i) local parameters update to a shared prediction model on each edge
device, ii) sending the local parameter updates to a central
server for aggregation, and iii) receiving the aggregated
1

Department of Computer Science and Technology, University
of Cambridge, UK 2 Adap, Hamburg, Hamburg, Germany 3 Nokia
Bell Labs, Cambridge, UK 4 Department of Computer Science,
University of Oxford, UK 5 Department of Physics and Astronomy,
University of Bologna, Italy 6 Laboratoire Informatique d’Avignon,
Avignon Université, France. Correspondence to: Daniel J. Beutel
<daniel@adap.com>.

1000

Others
FedScale
Flower

800

Concurrent # clients

arXiv:2007.14390v5 [cs.LG] 5 Mar 2022

Daniel J. Beutel 1 2 Taner Topal 1 2 Akhil Mathur 3 Xinchi Qiu 1 Javier Fernandez-Marques 4 Yan Gao 1
Lorenzo Sani 5 Kwing Hei Li 1 Titouan Parcollet 6 Pedro Porto Buarque de Gusmão 1 Nicholas D. Lane 1

600
400
200
0
10

1

10

2

10

3

10

4

10

5

10

6

Total # of clients in the pool

Figure 1. Survey of the number of FL clients used in FL research
papers in the last two years. Scatter plot of number of concurrent
clients participated in each communication round (y-axis) and total
number of clients in the client pool (x-axis). The x-axis is converted to log scale to reflect the data points more clearly. FedScale
can achieve 100 concurrent clients participated in each round out
of 10000 total clients (orange point), while Flower framework can
achieve 1000 concurrent clients out of a total 1 million clients
(green point). The plot shows that Flower can achieve both higher
concurrent participated client and larger client pool compared with
other experiments existing the the recent research papers. Appendix A.1 gives details of the papers considered.

model back for the next round of local updates.
From a systems perspective, a major bottleneck to FL
research is the paucity of frameworks that support scalable execution of FL methods on mobile and edge devices. While several frameworks including Tensorflow
Federated (Google, 2020; Abadi et al., 2016a) (TFF) and
LEAF (Caldas et al., 2018) enable experimentation on FL
algorithms, they do not provide support for running FL on

Flower: A Friendly Federated Learning Framework

edge devices. System-related factors such as heterogeneity
in the software stack, compute capabilities, and network
bandwidth, affect model synchronization and local training.
In combination with the choice of the client selection and
parameter aggregation algorithms, they can impact the accuracy and training time of models trained in a federated
setting. The systems’ complexity of FL and the lack of
scalable open-source frameworks can lead to a disparity between FL research and production. While closed productiongrade systems report client numbers in the thousands or even
millions (Hard et al., 2019), few research papers use populations of more than 100 clients, as can be seen in Figure 1.
Even those papers which use more than 100 clients rely on
simulations (e.g., using nested loops) rather than actually
implementing FL clients on real devices.
In this paper, we present Flower1 , a novel FL framework,
that supports experimentation with both algorithmic and
systems-related challenges in FL. Flower offers a stable, language and ML framework-agnostic implementation of the
core components of a FL system, and provides higher-level
abstractions to enable researchers to experiment and implement new ideas on top of a reliable stack. Moreover, Flower
allows for rapid transition of existing ML training pipelines
into a FL setup to evaluate their convergence properties
and training time in a federated setting. Most importantly,
Flower provides support for extending FL implementations
to mobile and wireless clients, with heterogeneous compute,
memory, and network resources.
As system-level challenges of limited compute, memory,
and network bandwidth in mobile devices are not a major
bottleneck for powerful cloud servers, Flower provides builtin tools to simulate many of these challenging conditions in
a cloud environment and allows for a realistic evaluation of
FL algorithms. Finally, Flower is designed with scalability
in mind and enables large-cohort research that leverages
both a large number of connected clients and a large number of clients training concurrently. We believe that the
capability to perform FL at scale will unlock new research
opportunities as results obtained in small-scale experiments
are not guaranteed to generalize well to large-scale problems.
In summary, we make the following contributions:
• We present Flower, a novel FL framework that supports
large-cohort training and evaluation, both on real edge
devices and on single-node or multi-node compute clusters. This unlocks scalable algorithmic research of realworld system conditions such as limited computational
resources which are common for typical FL workloads.
• We describe the design principles and implementation
details of Flower. In addition to being language- and
ML framework-agnostic by design, Flower is also fully
1

https://flower.dev

extendable and can incorporate emerging algorithms,
training strategies and communication protocols.
• Using Flower , we present experiments that explore both
algorithmic and system-level aspects of FL on five machine learning workloads with up to 15 million clients.
Our results quantify the impact of various system bottlenecks such as client heterogeneity and fluctuating
network speeds on FL performance.
• Flower is open-sourced under Apache 2.0 License
and adopted by major research organizations in both
academia and industry. The community is actively participating in the development and contributes novel baselines, functionality, and algorithms.

2

BACKGROUND AND R ELATED W ORK

FL builds on a vast body of prior work and has since been
expanded in different directions. McMahan et al. (2017)
introduced the basic federated averaging (FedAvg) algorithm and evaluated it in terms of communication efficiency.
There is active work on privacy and robustness improvements for FL: A targeted model poisoning attack using
Fashion-MNIST (Xiao et al., 2017) (along with possible mitigation strategies) was demonstrated by Bhagoji et al. (2018).
Abadi et al. (2016b) propose an attempt to translate the idea
of differential privacy to deep learning. Secure aggregation (Bonawitz et al., 2017) is a way to hide model updates
from “honest but curious” attackers. Robustness and faulttolerance improvements at the optimizer level are commonly
studied and demonstrated, e.g., by Zeno (Xie et al., 2019).
Finally, there is an increasing emphasis on the performance
of federated optimization in heterogeneous data and system
settings (Smith et al., 2017; Li et al., 2018; 2019).
The optimization of distributed training with and without
federated concepts has been covered from many angles
(Dean et al., 2012; Jia et al., 2018; Chahal et al., 2018;
Sergeev & Balso, 2018; Dryden et al., 2016). Bonawitz et
al. (2019) detail the system design of a large-scale Googleinternal FL system. TFF (Google, 2020), PySyft (Ryffel
et al., 2018), and LEAF (Caldas et al., 2018) propose open
source frameworks which are primarily used for simulations
that run a small number of homogeneous clients. Flower
unifies both perspectives by being open source and suitable
for exploratory research, with scalability to expand into
settings involving a large number of heterogeneous clients.
Most of the mentioned approaches have in common that they
implement their own systems to obtain the described results.
The main intention of Flower is to provide a framework
which would (a) allow to perform similar research using a
common framework and (b) enable to run those experiments
on a large number of heterogeneous devices.

Flower: A Friendly Federated Learning Framework

3

F LOWER OVERVIEW

Flower is a novel end-to-end federated learning framework
that enables a more seamless transition from experimental
research in simulation to system research on a large cohort
of real edge devices. Flower offers individual strength in
both areas (viz. simulation and real world devices); and offers the ability for experimental implementations to migrate
between the two extremes as needed during exploration and
development. In this section, we describe use cases that
motivate our perspective, design goals, resulting framework
architecture, and comparison to other frameworks.

Table 1. Excerpt of built-in FL algorithms available in Flower. New
algorithms can be implemented using the Strategy interface.
Strategy

Description

FedAvg

Vanilla Federated Averaging (McMahan et al., 2017)

Fault
Tolerant
FedAvg

A variant of FedAvg that can tolerate faulty client
conditions such as client disconnections or laggards.

FedProx

Implementation of the algorithm proposed by
Li et al. (2020) to extend FL to heterogenous
network conditions.

QFedAvg

Implementation of the algorithm proposed by
Li et al. (2019) to encourage fairness in FL.

The identified gap between FL research practice and industry reports from proprietary large-scale systems (Figure 1)
is, at least in part, related a number of use cases that are not
well-supported by the current FL ecosystem. The following
sections show how Flower enables those use cases.

FedOptim

A family of server-side optimizations that
include FedAdagrad, FedYogi, and FedAdam
as described in Reddi et al. (2021).

Scale experiments to large cohorts. Experiments need to
scale to both a large client pool size and a large number of
clients training concurrently to better understand how well
methods generalize. A researcher needs to be able launch
large-scale FL evaluations of their algorithms and design
using reasonable levels of compute (e.g., single-machine/a
multi-GPU rack), and have results at this scale have acceptable speed (wall-clock execution time).

The given uses cases identify a gap in the existing FL ecosystem that results in research that does not necessarily reflect
real-world FL scenarios. To adress the ecosystem gap, we
defined a set of independent design goals for Flower:

3.1

Use Cases

Experiment on heterogeneous devices. Heterogeneous
client environments are the norm for FL. Researchers need
ways to both simulate heterogeneity and to execute FL on
real edge devices to quantify the effects of system heterogeneity. Measurements about the performance of client
performance should be able to be easily collected, and deploying heterogeneous experiments is painless.
Transition from simulation to real devices. New methods
are often conceived in simulated environments. To understand their applicability to real-world scenarios, frameworks
need to support seamless transition between simulation and
on-device execution. Shifting from simulation to real devices, mixing simulated and real devices, and selecting certain elements to have varying levels of realism (e.g., compute or network) should be easy.
Multi-framework workloads. Diverse client environments naturally motivate the usage of different ML frameworks, so FL frameworks should be able to integrate updates
coming from clients using varying ML frameworks in the
same workload. Examples range from situations where
clients use two different training frameworks (pytorch and
tensorflow) to more complex situations where clients have
their own device- and OS-specific training algorithm.

3.2

Design Goals

Scalable: Given that real-world FL would encounter a large
number of clients, Flower should scale to a large number of
concurrent clients to foster research on a realistic scale.
Client-agnostic: Given the heterogeneous environment on
mobile clients, Flower should be interoperable with different
programming languages, operating systems, and hardware.
Communication-agnostic: Given the heterogeneous connectivity settings, Flower should allow different serialization
and communication approaches.
Privacy-agnostic: Different FL settings (cross-devic, crosssilo) have different privacy requirements (secure aggregation, differential privacy). Flower should support common
approaches whilst not be prescriptive about their usage.
Flexible: Given the rate of change in FL and the velocity
of the general ML ecosystem, Flower should be flexible to
enable both experimental research and adoption of recently
proposed approaches with low engineering overhead.
A framework architecture with those properties will increase
both realism and scale in FL research and provide a smooth
transition from research in simulation to large-cohort research on real edge devices. The next section describes how
the Flower framework architecture supports those goals.
3.3

Core Framework Architecture

FL can be described as an interplay between global and
local computations. Global computations are executed on
the server side and responsible for orchestrating the learning

Flower: A Friendly Federated Learning Framework

sages to and from the actual client. The FL loop is at the
heart of the FL process: it orchestrates the entire learning
process. It does not, however, make decisions about how
to proceed, as those decisions are delegated to the currently
configured Strategy implementation.
In summary, the FL loop asks the Strategy to configure the
next round of FL, sends those configurations to the affected
clients, receives the resulting client updates (or failures)
from the clients, and delegates result aggregation to the
Strategy. It takes the same approach for both federated
training and federated evaluation, with the added capability
of server-side evaluation (again, via the Strategy). The client
side is simpler in the sense that it only waits for messages
from the server. It then reacts to the messages received by
calling user-provided training and evaluation functions.

Figure 2. Flower core framework architecture with both Edge
Client Engine and Virtual Client Engine. Edge clients live on
real edge devices and communicate with the server over RPC.
Virtual clients on the other hand consume close to zero resources
when inactive and only load model and data into memory when
the client is being selected for training or evaluation.

process over a set of available clients. Local computations
are executed on individual clients and have access to actual
data used for training or evaluation of model parameters.
The architecture of the Flower core framework reflects that
perspective and enables researchers to experiment with
building blocks, both on the global and on the local level.
Global logic for client selection, configuration, parameter
update aggregation, and federated or centralized model evaluation can be expressed through the Strategy abstraction.
An implementation of the Strategy abstraction represents
a single FL algorithm and Flower provides tested reference implementations of popular FL algorithms such as
FedAvg (McMahan et al., 2017) or FedYogi (Reddi et al.,
2021) (summarized in table 1). Local logic on the other
hand is mainly concerned with model training and evaluation on local data partitions. Flower acknowledges the
breadth and diversity of existing ML pipelines and offers
ML framework-agnostic ways to federate these, either on
the Flower Protocol level or using the high-level Client
abstraction. Figure 2 illustrates those components.
The Flower core framework implements the necessary infrastructure to run these workloads at scale. On the server
side, there are three major components involved: the ClientManager, the FL loop, and a (user customizable) Strategy.
Server components sample clients from the ClientManager,
which manages a set of ClientProxy objects, each representing a single client connected to the server. They are
responsible for sending and receiving Flower Protocol mes-

A distinctive property of this architecture is that the server
is unaware of the nature of connected clients, which allows to train models across heterogeneous client platforms
and implementations, including workloads comprised of
clients connected through different communication stacks.
The framework manages underlying complexities such as
connection handling, client life cycle, timeouts, and error
handling in an for the researcher.
3.4

Virtual Client Engine

Built into Flower is the Virtual Client Engine (VCE): a tool
that enables the virtualization of Flower Clients to maximise
utilization of the available hardware. Given a pool of clients,
their respective compute and memory budgets (e.g. number
of CPUs, VRAM requirements) and, the FL-specific hyperparameters (e.g. number of clients per round), the VCE
launches Flower Clients in a resource-aware manner. The
VCE will schedule, instantiate and run the Flower Clients
in a transparent way to the user and the Flower Server. This
property greatly simplifies parallelization of jobs, ensuring
the available hardware is not underutilised and, enables porting the same FL experiment to a wide varying of setups
without reconfiguration: a desktop machine, a single GPU
rack or multi-node GPU cluster. The VCE therefore becomes a key module inside the Flower framework enabling
running large scale FL workloads with minimal overhead in
a scalable manner.
3.5

Edge Client Engine

Flower is designed to be open source, extendable and,
framework and device agnostic. Some devices suitable for
lightweight FL workloads such as Raspberry Pi or NVIDIA
Jetson require minimal or no special configuration. These
Python-enabled embedded devices can readily be used as
Flower Clients. On the other hand, commodity devices such
as smartphones require a more strict, limited and sometimes
proprietary software stack to run ML workloads. To circum-

Flower: A Friendly Federated Learning Framework
Table 2. Comparison of different FL frameworks.

Single-node simulation
Multi-node execution
Scalability
Heterogeneous clients
ML framework-agnostic
Communication-agnostic
Language-agnostic
Baselines

TFF
√
*
*

Syft
√
√

FedScale LEAF Flower
√
√
√
√
√
( )***
√
**
√
√
( )***
**
√
****
****
√
√
√
√
*

Labels: * Planned / ** Only simulated
*** Only Python-based / **** Only PyTorch and/or TF/Keras

vent this limitation, Flower provides a low-level integration
by directly handling Flower Protocol messages on the client.
3.6

Secure Aggregation

In FL the server does not have direct access to a client’s
data. To further protect clients’ local data, Flower provides
implementation of both SecAgg (Bonawitz et al., 2017) and
SecAgg+ (Bell et al., 2020) protocols for a semi-honest
threat model. The Flower secure aggregation implementation satisfies five goals: usability, flexibility, compatibility,
reliability and efficiency. The execution of secure aggregation protocols is independent of any special hardware
and ML framework, robust against client dropouts, and
has lower theoretical overhead for both communication and
computation than other traditional multi-party computation
secure aggregation protocol, which will be shown in 5.5.
3.7

FL Framework Comparison

We compare Flower to other FL toolkits, namely TFF
(Google, 2020), Syft (Ryffel et al., 2018), FedScale (Lai
et al., 2021) and LEAF (Caldas et al., 2018). Table 2 provides an overview, with a more detailed description of those
properties following thereafter.
Single-node simulation enables simulation of FL systems
on a single machine to investigate workload performance
without the need for a multi-machine system. Supported by
all frameworks.
Multi-node execution requires network communication
between server and clients on different machines. Multimachine execution is currently supported by Syft and Flower.
FedScale supports multi-machine simulation (but not real
deployment), TFF plans multi-machine deployments.
Scalability is important to derive experimental results that
generalize to large cohorts. Single-machine simulation is
limited because workloads including a large number of
clients often exhibit vastly different properties. TFF and
LEAF are, at the time of writing, constrained to singlemachine simulations. FedScale can simulate clients on mul-

tiple machines, but only scales to 100 concurrent clients.
Syft is able to communicate over the network, but only by
connecting to data holding clients that act as servers themselves, which limits scalability. In Flower, data-holding
clients connect to the server which allows workloads to
scale to millions of clients, including scenarios that require
full control over when connections are being opened and
closed. Flower also includes a virtual client engine for
large-scale multi-node simulations.
Heterogeneous clients refers to the ability to run workloads
comprised of clients running on different platforms using
different languages, all in the same workload. FL targeting
edge devices will clearly have to assume pools of clients
of many different types (e.g., phone, tablet, embedded).
Flower supports such heterogeneous client pools through
its language-agnostic and communication-agnostic clientside integration points. It is the only framework in our
comparison that does so, with TFF and Syft expecting a
framework-provided client runtime, whereas FedScale and
LEAF focus on Python-based simulations.
ML framework-agnostic toolkits allow researchers and
users to leverage their previous investments in existing ML
frameworks by providing universal integration points. This
is a unique property of Flower: the ML framework landscape is evolving quickly (e.g., JAX (Bradbury et al., 2018),
PyTorch Lightning (W. Falcon, 2019)) and therefore the
user should choose which framework to use for their local
training pipelines. TFF is tightly coupled with TensorFlow
and experimentally supports JAX, LEAF also has a dependency on TensorFlow, and Syft provides hooks for PyTorch
and Keras, but does not integrate with arbitrary tools.
Language-agnostic describes the capability to implement
clients in a variety of languages, a property especially important for research on mobile and emerging embedded
platforms. These platforms often do not support Python,
but rely on specific languages (Java on Android, Swift on
iOS) for idiomatic development, or native C++ for resource
constrained embedded devices. Flower achieves a fully
language-agnostic interface by offering protocol-level integration. Other frameworks are based on Python, with some
of them indicating a plan to support Android and iOS (but
not embedded platforms) in the future.
Baselines allow the comparison of existing methods with
new FL algorithms. Having existing implementations
at ones disposal can greatly accelerate research progress.
LEAF and FedScale come with a number of benchmarks
built-in with different datasets. TFF provides libraries for
constructing baselines with some datasets. Flower currently
implements a number of FL methods in the context of popular ML benchmarks, e.g., a federated training of CIFAR10 (Krizhevsky et al., 2005) image classification, and has
initial port of LEAF datasets such as FEMNIST and Shake-

Flower: A Friendly Federated Learning Framework

speare (Caldas et al., 2018).

4

I MPLEMENTATION

Flower has an extensive implementation of FL averaging
algorithms, a robust communication stack, and various examples of deploying Flower on real and simulated clients.
Due to space constraints, we only focus on some of the
implementation details in this section and refer the reader
to the Flower GitHub repository for more details.
Communication stack. FL requires stable and efficient
communication between clients and server. The Flower
communication protocol is currently implemented on top of
bi-directional gRPC (Foundation) streams. gRPC defines
the types of messages exchanged and uses compilers to then
generate efficient implementations for different languages
such as Python, Java, or C++. A major reason for choosing
gRPC was its efficient binary serialization format, which is
especially important on low-bandwidth mobile connections.
Bi-directional streaming allows for the exchange of multiple
message without the overhead incurred by re-establishing a
connection for every request/response pair.
Serialization. Independent of communication stack, Flower
clients receive instructions (messages) as raw byte arrays
(either via the network or throught other means, for example, inter-process communication), deserialize the instruction, and execute the instruction (e.g., training on local
data). The results are then serialized and communicated
back to the server. Note that a client communicates with the
server through language-independent messages and can thus
be implemented in a variety of programming languages, a
key property to enable real on-device execution. The useraccessible byte array abstraction makes Flower uniquely
serialization-agnostic and enables users to experiment with
custom serialization methods, for example, gradient compression or encryption.

One key design decision that makes Flower so flexible is
that ClientProxy is an abstract interface, not an implementation. There are different implementations of the ClientProxy
interface, for example, GrpcClientProxy. Each implementation encapsulates details on how to communicate with the
actual client, for example, to send messages to an actual
edge device using gRPC.
Virtual Client Engine (VCE). Resource consumption
(CPU, GPU, RAM, VRAM, etc.) is the major bottleneck
for large-scale experiments. Even a modestly sized model
easily exhausts most systems if kept in memory a million
times. The VCE enables large-scale single-machine or multimachine experiments by executing workloads in a resourceaware fashion that either increases parallelism for better
wall-clock time or to enable large-scale experiments on limited hardware resources. It creates a ClientProxy for each
client, but defers instantiation of the actual client object (including local model and data) until the resources to execute
the client-side task (training, evaluation) become available.
This avoids having to keep multiple client-side models and
datasets in memory at any given point in time.
VCE builds on the Ray (Moritz et al., 2018) framework to
schedule the execution of client-side tasks. In case of limited resources, Ray can sequence the execution of client-side
computations, thus enabling a much larger scale of experiments on common hardware. The capability to perform FL
at scale will unlock new research opportunities as results
obtained in small-scale experiments often do not generalize
well to large-cohort settings.

5

F RAMEWORK E VALUATION

In this section we evaluate Flower’s capabilities in supporting both research and implementations of real-world
FL workloads. Our evaluation focuses on three main aspects:

Alternative communication stacks. Even though the current implementation uses gRPC, there is no inherent reliance
on it. The internal Flower server architecture uses modular abstractions such that components that are not tied to
gRPC are unaware of it. This enables the server to support
user-provided RPC frameworks and orchestrate workloads
across heterogeneous clients, with some connected through
gRPC, and others through other RPC frameworks.

• Scalability: We show that Flower can (a) efficiently
make use of available resources in single-machine simulations and (b) run experiments with millions of clients
whilst sampling thousands in each training.

ClientProxy. The abstraction that enables communicationagnostic execution is called ClientProxy. Each ClientProxy
object registered with the ClientManager represents a single
client that is available to the server for training or evaluation. Clients which are offline do not have an associated
ClientProxy object. All server-side logic (client configuration, receiving results from clients) is built against the
ClientProxy abstraction.

• Realism: We show through a case study how Flower can
throw light on the performance of FL under heterogeneous clients with different computational and network
capabilities.

• Heterogeneity: We show that Flower can be deployed
in real, heterogeneous devices commonly found in crossdevice scenario and how it can be used to measure system statistics.

• Privacy: Finally, we show how our implementation of
Secure Aggregation matches the expected theoretical
overhead as expected.

Flower: A Friendly Federated Learning Framework

Large-Scale Experiment

Federated Learning receives most of its power from its ability to leverage data from millions of users. However, selecting large numbers of clients in each training round does
not necessarily translate into faster convergence times. In
fact, as observed in (McMahan et al., 2017), there is usually
an empirical threshold for which if we increase the number
of participating clients per round beyond that point, convergence will be slower. By allowing experiments to run
at mega-scales, with thousands of active clients per round,
Flower gives us the opportunity to empirically find such
threshold for any task at hand.
To show this ability, in this series of experiments we use
Flower to fine-tune a network on data from 15M users using
different numbers of clients per round. More specifically,
we fine-tune a Transformer network to correctly predict
Amazon book ratings based on text reviews from users.
Experimental Setup. We choose to use Amazon’s Book
Reviews Dataset (Ni et al., 2019) which contains over 51M
reviews from 15M different users. Each review from a
given user contains a textual review of a book along with its
given rank (1-5). We fine-tune the classifier of a pre-trained
DistilBERT model (Sanh et al., 2019) to correctly predict
ranks based on textual reviews. For each experiment we fix
the number of clients being sampled in each round (from
10 to 1000) and aggregate models using FedAvg. We test
the aggregated model after each round on a fixed set of 1M
clients. Convergence curves are reported in Figure 3 all our
experiments were run using two NVIDIA V100 GPUs on a
22-cores of an Intel Xeon Gold 6152 (2.10GHz) CPU.
Results. Figure 3 shows the expected initial speed-up in
convergence when selecting 10 to 500 clients per round in
each experiment. However, if we decide to sample 1k clients
in each round, we notice an increase in convergence time.
Intuitively, this behaviour is caused by clients’ data having
very different distributions; making it difficult for simple
Aggregation Strategies such as FedAvg to find a suitable
set of weights.
5.2

Single Machine Experiments

One of our strongest claims in this paper is that Flower
can be effectively used in Research. For this to be true,
Flower needs to be fast at providing reliable results when
experimenting new ideas, e.g. a new aggregation strategy.
In this experiment, we provide a head-to-head comparison
in term of training times between Flower and the four main
FL frameworks, namely FedScale, TFF, FedJax and the
original LEAF, when training with different FL setups.
Experimental Setup. We consider all three FL setups proposed by (Caldas et al., 2018) when training a CNN model

1000 clients
500 clients
100 clients
50 clients
10 clients

0.6
0.5
Accuracy

5.1

0.4
0.3
0.2
0.1

0

10

20

30
40
Rounds

50

60

Figure 3. Flower scales to even 15M user experiments. Each curve
shows successful convergence of the DistilBERT model under
varying amounts of clients per round, with the exception of the
two smallest client sizes: 50 and 10.

to correctly classify characters from the FEMNIST dataset.
More specifically, we consider the scenarios where the number of clients (c) and local epochs per round change (l) vary.
The total number of rounds and total number of clients are
kept constant at 2000 and 179, respectively. To allow for
a fair comparison, We run all our experiments using eight
cores of an Intel Xeon E5-2680 CPU (2.40GHz) equipped
with two NVIDIA RTX2080 GPUs and 20GB of RAM.
Results. Figure 4 shows the impact of choosing different
FL frameworks for the various tasks. On our first task,
when training using three clients per round (c = 3) for one
local epoch (l = 1), FedJax finishes training first (05:18),
LEAF finishes second (44:39) followed by TFF (58:29) and
Flower (59:19). In this simple case, the overhead of having
a multi-task system, like the Virtual Client Engine (VCE),
causes Flower to sightly under-perform in comparison to
loop-based simulators, like LEAF.
However, the benefits of having a VCE become more evident
if we train on more realistic scenarios. When increasing the
number of clients per round to 35 while keeping the single
local epoch, we notice that Flower (230:18) is still among
the fastest frameworks. Since the number of local epochs is
still one, most of the overhead comes from loading data and
models into memory rather than performing real training,
hence the similarity those LEAF and Flower.
The VCE allows us to specify the amount of GPU memory
we want to associate with each client, this allows for more
efficient data and model loading of different clients on the
same GPU, making the overall training considerably faster.
In fact, when we substantially increase the amount of work
performed by each client to 100 local epochs, while fixing
the number of active client to 3, we see a significant saving
in training time. In this task Flower outperforms all other. It

Flower: A Friendly Federated Learning Framework

10

2

10

1

(c=3, l=1)

(c=3, l=100)

FEMNIST Task

(c=35, l=1)

Figure 4. Training times (log scale in second) comparison of different FEMNIST tasks between different FL frameworks.

completes the task in just about 80 minutes, while the second
best performing framework (FedJax) takes over twice as
long (over 173 minutes).
It is also important to acknowledge the two extreme training
times we see in this experiment. FedJax seems to be very
efficient when training on few (1) local epochs; however, in
scenarios where communication-efficiency is key and larger
number of local epochs are required, FedJax performance
slightly degrades. FedScale, on the other hands, consistently
showed high training times across all training scenarios.
We believe this apparent inefficiency to be associated with
network overheads that are usually unnecessary in a singlecomputer simulation.
5.3

Flower enables FL evaluation on real devices

Flower can assist researchers in quantifying the system costs
associated with running FL on real devices and to identify
bottlenecks in real-world federated training. In this section,
we present the results of deploying Flower on six types of
heterogeneous real-world mobile and embedded devices, including Java-based Android smartphones and Python-based
Nvidia Jetson series devices and Raspberry Pi.
Experiment Setup. We run the Flower server configured
with the FedAvg strategy and host it on a cloud virtual
machine. Python-based Flower clients are implemented for
Nvidia Jetson series devices (Jetson Nano, TX2, NX, AGX)
and Raspberry Pi, and trained using TensorFlow as the ML
framework on each client. On the other hand, Android smartphones currently do not have extensive on-device training
support with TensorFlow or PyTorch. To counter this issue,
we leverage TensorFlow Lite to implement Flower clients

Results. Figure 5 shows the system metrics associated
with training a DeepConvLSTM (Singh et al., 2021) model
for a human activity recognition task on Python-enabled
Jetson and Raspberry Pi devices. We used the RealWorld
dataset (Sztyler & Stuckenschmidt, 2016) consisting of timeseries data from accelerometer and gyroscope sensors on
mobile devices, and partitioned it across 10 mobile clients.
The first takeaway from our experiments in that we could deploy Flower clients on these heterogeneous devices, without
requiring any modifications in the client-side Flower code.
The only consideration was to ensure that a compatible ML
framework (e.g., TensorFlow) is installed on each client.
Secondly, we show in Figure 5 how FL researchers can
deploy and quantify the training time and energy consumption of FL on various heterogeneous devices and processors.
Here, the FL training time is aggregated over 40 rounds,
and includes the time taken to perform local 10 local epochs
of SGD on the client, communicating model parameters
between the server and the client, and updating the global
model on the server. By comparing the relative energy
consumption and training times across various devices, FL
researchers can devise more informed client selection policies that can tradeoff between FL convergence time and
overall energy consumption. For instance, choosing Jetson
Nano-CPU based FL clients over Raspberry Pi clients may
increase FL convergence time by 10 minutes, however it
reduces the overall energy consumption by almost 60%.
Next, we illustrate how Flower can enable fine-grained profiling of FL on real devices. We deploy Flower on 10 Android clients to train a model with 2 convolutional layers
and 3 fully-connected layers (Flower, 2021) on the CIFAR10 dataset. TensorFlow Lite is used as the training ML
framework on the devices. We measure the time taken for
various FL operations, such as local SGD training, communication between the server and client, local evaluation on
the client, and the overhead due to the Flower framework.
FL Training Time

Energy

35
30

2500

25

2000

Total energy (J)

3

FL training time (mins)

Training Time (s)

10

on Android smartphones in Java. While TFLite is primarily
designed for on-device inference, we leverage its capabilities to do on-device model personalization to implement a
FL client application (Lite, 2020). The source code for both
implementations is available in the Flower repository.

FedJax
FedScale
Flower
LEAF
TFF

20

1500

15

1000

10
5
0

500
AGX-GPU NX-GPU TX2-GPU Nano-GPU AGX-CPU NX-CPU TX2-CPU Nano-CPU RPI-CPU

Figure 5. Flower enables quantifying the system performance of
FL on mobile and embedded devices. Here we report the training
times and energy consumption associated with running FL on
CPUs and GPUs of various embedded devices.

35
30
25
20
15
10
5
0

CPU clients are used for federated training (local epochs
E=10), the FL process would take 1.27× more time to converge as compared to training on Jetson TX2 GPU clients.

Flower Overhead = 0.1s

Training
Communication
Evaluation
Flower Overhead

Google Pixel 4

Device Names

Samsung Galaxy S9

Figure 6. Flower enables fine-grained profiling of FL performance
on real devices. The framework overhead is <100ms per round.

Table 3. Effect of computational heterogeneity on FL training
times. Using Flower, we can compute a hardware-specific cutoff τ (in minutes) for each processor, and find a balance between
FL accuracy and training time. τ = 0 indicates no cutoff time.
GPU
Accuracy
Training
time (mins)

0.67
80.32

CPU
(τ = 0)

CPU
(τ = 2.23)

CPU
(τ = 1.99)

0.67
102
(1.27×)

0.66
89.15
(1.11×)

0.63
80.34
(1.0×)

The overhead includes converting model gradients to GRPCcompatible buffers and vice-versa, to enable communication
between Java FL clients and a Python FL server. In Figure 6,
we report the mean latency of various FL operations over
40 rounds on two types of Android devices: Google Pixel 4
and Samsung Galaxy S9. We observe that on both devices,
local training remains the most time-consuming operation,
and that the total system overhead of the Flower framework
is less than 100ms per round.
5.4

Realism in Federated Learning

Flower facilitates the deployment of FL on real-world devices. While this property is beneficial for production-grade
systems, can it also assist researchers in developing better
federated optimization algorithms? In this section, we study
two realistic scenarios of FL deployment.
Computational Heterogeneity across Clients. In realworld, FL clients will have vastly different computational
capabilities. While newer smartphones are now equipped
with mobile GPUs, other phones or wearable devices may
have a much less powerful processor. How does this computational heterogeneity impact FL?
For this experiment, we use a Nvidia Jetson TX2 as the
client device, which has a Pascal GPU and six CPU cores.
We train a ResNet18 model on the CIFAR-10 dataset in a
federated setting with 10 total Jetson TX2 clients and 40
rounds of training. In Table 3, we observe that if Jetson TX2

Once we obtain this quantification of computational heterogeneity using Flower, we can design better federated
optimization algorithms. As an example, we implemented
a modified version of FedAvg where each client device is
assigned a cutoff time (τ ) after which it must send its model
parameters to the server, irrespective of whether it has finished its local epochs or not. This strategy has parallels with
the FedProx algorithm (Li et al., 2018) which also accepts
partial results from clients. However, the key advantage
of Flower’s on-device training capabilities is that we can
accurately measure and assign a realistic processor-specific
cutoff time for each client. For example, we measure that
on average it takes 1.99 minutes to complete a FL round
on the TX2 GPU. We then set the same time as a cutoff for
CPU clients (τ = 1.99 mins) as shown in Table 3. This
ensures that we can obtain faster convergence even in the
presence of CPU clients, at the expense of a 4% accuracy
drop. With τ = 2.23, a better balance between accuracy
and convergence time could be obtained for CPU clients.
Heterogeneity in Network Speeds. An important consideration for any FL system is to choose a set of participating
clients in each training round. In the real-world, clients are
distributed across the world and vary in their download and
upload speeds. Hence, it is critical for any FL system to
study how client selection can impact the overall FL training time. We now present an experiment with 40 clients
collaborating to train a 4-layer deep CNN model for the
FashionMNIST dataset. More details about the dataset and
network architecture are presented in the Appendix.
Using Flower, we instantiate 40 clients on a cloud platform
and fix the download and upload speeds for each client using
the W ONDERSHAPER library. Each client is representative
of a country and its download and upload speed is set based
on a recent market survey of 4G and 5G speeds in different
countries (OpenSignal, 2020).

120
FL time (in mins)

Time (in seconds)

Flower: A Friendly Federated Learning Framework

100
80
60
40
20
0

0

5

10

15

20

25

30

35

40

Country Index

Figure 7. Effect of network heterogeneity in clients on FL training
time. Using this quantification, we designed a new client sampling
strategy called FedFS (detailed in the Appendix).

Flower: A Friendly Federated Learning Framework
300

CPU running time (s)

system with an Intel Xeon E-2136 CPU (3.30GHz), with
256 GB of RAM. In our simulations, all entries of our local
vectors are of size 24 bits. We ignore communication latency. Moreover, all dropouts simulated happen after stage
2, i.e. Share Keys Stage. This is because this imposes the
most significant overhead as the server not only needs to
regenerate dropped-out clients’ secrets, but also compute
their pairwise masks generated between their neighbours.

0% dropout
5% dropout

250
200
150
100
50
0

0

1

2
3
4
Model vector size

5
·105

Figure 8. Performance of Secure Aggregation. Running time of
server with increasing vector size

The x-axis of Figure 7 shows countries arranged in descending order of their network speeds: country indices 1-20
represent the top 20 countries based on their network speeds
(mean download speed = 40.1Mbps), and indices 21-40 are
the bottom 20 countries (mean download speed = 6.76Mbps).
We observe that if all clients have the network speeds corresponding to Country 1 (Canada), the FL training finishes in
8.9 mins. As we include slower clients in FL, the training
time gradually increases, with a major jump around index =
17. On the other extreme, for client speeds corresponding to
Country 40 (Iraq), the FL training takes 108 minutes.
There are two key takeaways from this experiment: a) Using
Flower, we can profile the training time of any FL algorithm
under scenarios of network heterogeneity, b) we can leverage these insights to design sophisticated client sampling
techniques. For example, during subsequent rounds of federated learning, we could monitor the number of samples each
client was able to process during a given time window and
increase the selection probability of slow clients to balance
the contributions of fast and slow clients to the global model.
The FedFS strategy detailed in the appendix works on this
general idea, and reduces the convergence time of FL by up
to 30% over the FedAvg random sampling approach.
5.5

Secure Aggregation Overheads

Privacy is one of the cornerstones in FL, which inevitably
generates computational overhead during training. In
hardware-constrained systems, such as cross-device FL, it
is desirable not only to be able to measure such overheads,
but also to make sure that security protocols are well implemented and follow the expected protocol described in the
original papers. Flower’s implementation of Secure Aggregation, named Salvia, is based on the SecAgg (Bonawitz
et al., 2017) and SecAgg+ (Bell et al., 2020) protocols as
described in Section 3.6. To verify that Salvia’s behavior
matches the expected theoretical complexity, we evaluate
its impact on server-side computation and communication
overhead with the model vector size and clients dropouts.
Experiment Setup. The FL simulations run on a Linux

For our simulations, the n and t parameters of the t-outof-n secret-sharing scheme are set to 51 and 26, respectively. These parameters are chosen to reference SecAgg+’s
proven correctness and security guarantees, where we can
tolerate up to 5% dropouts and 5% corrupted clients with
correctness holding with probability 1 − 2−20 and security
holding with probability 1 − 2−40 .
Results. Fixing the number of sampled clients to 100, we
plotted CPU running times through aggregating a vector
of size 100k entries to aggregating one of size 500k entries in Figure 8. We also measured how the performance
would change after client dropouts by repeating the same
experiments with a 5% client dropout.
Both the running times and total data transfer of the server
increase linearly with the model vector size as the operations
involving model vectors are linear to the vectors’ sizes,
e.g. generating masks, sending vectors. We also note the
server’s running time increases when there are 5% clients
dropping out, as the server has to perform extra computation
to calculate all k pairwise masks for each client dropped.
Lastly, we observe that the total data transferred of the server
remains unchanged with client dropouts as each client only
communicates with the server plus exactly k neighbors,
regardless of the total number of clients and dropouts. We
conclude that all our experimental data matches the expected
complexities of SecAgg and SecAgg+.

6

C ONCLUSION

We have presented Flower – a novel framework that is specifically designed to advance FL research by enabling heterogeneous FL workloads at scale. Although Flower is broadly
useful across a range of FL settings, we believe that it will be
a true game-changer for reducing the disparity between FL
research and real-world FL systems. Through the provided
abstractions and components, researchers can federated existing ML workloads (regardless of the ML framework used)
and transition these workloads from large-scale simulation
to execution on heterogeneous edge devices. We further
evaluate the capabilities of Flower in experiments that target
both scale and systems heterogeneity by scaling FL up to
15M clients, providing head-to-head comparison between
different FL frameworks for single-computer experiments,
measuring FL energy consumption on a cluster of Nvidia

Flower: A Friendly Federated Learning Framework

Jetson TX2 devices, optimizing convergence time under
limited bandwidth, and illustrating a deployment of Flower
on a range of Android mobile devices in the AWS Device
Farm. Flower is open-sourced under Apache 2.0 License
and we look forward to more community contributions to it.

R EFERENCES
Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A.,
Dean, J., Devin, M., Ghemawat, S., Irving, G., Isard,
M., Kudlur, M., Levenberg, J., Monga, R., Moore, S.,
Murray, D. G., Steiner, B., Tucker, P., Vasudevan, V.,
Warden, P., Wicke, M., Yu, Y., and Zheng, X. Tensorflow:
A system for large-scale machine learning. In 12th
USENIX Symposium on Operating Systems Design and
Implementation (OSDI 16), pp. 265–283, 2016a. URL
https://www.usenix.org/system/files/
conference/osdi16/osdi16-abadi.pdf.
Abadi, M., Chu, A., Goodfellow, I., McMahan, B., Mironov,
I., Talwar, K., and Zhang, L. Deep learning with differential privacy. In 23rd ACM Conference on Computer and Communications Security (ACM CCS), pp.
308–318, 2016b. URL https://arxiv.org/abs/
1607.00133.
Bell, J. H., Bonawitz, K. A., Gascón, A., Lepoint, T., and
Raykova, M. Secure single-server aggregation with (poly)
logarithmic overhead. In Proceedings of the 2020 ACM
SIGSAC Conference on Computer and Communications
Security, pp. 1253–1269, 2020.
Bhagoji, A. N., Chakraborty, S., Mittal, P., and Calo, S. B.
Analyzing federated learning through an adversarial lens.
CoRR, abs/1811.12470, 2018. URL http://arxiv.
org/abs/1811.12470.
Bonawitz, K., Ivanov, V., Kreuter, B., Marcedone, A.,
McMahan, H. B., Patel, S., Ramage, D., Segal, A.,
and Seth, K. Practical secure aggregation for privacypreserving machine learning. In Proceedings of the 2017
ACM SIGSAC Conference on Computer and Communications Security, CCS ’17, pp. 1175–1191, New York,
NY, USA, 2017. ACM. ISBN 978-1-4503-4946-8. doi:
10.1145/3133956.3133982. URL http://doi.acm.
org/10.1145/3133956.3133982.
Bonawitz, K., Eichner, H., Grieskamp, W., Huba, D., Ingerman, A., Ivanov, V., Kiddon, C. M., Konečný, J., Mazzocchi, S., McMahan, B., Overveldt, T. V., Petrou, D.,
Ramage, D., and Roselander, J. Towards federated learning at scale: System design. In SysML 2019, 2019. URL
https://arxiv.org/abs/1902.01046. To appear.
Bradbury, J., Frostig, R., Hawkins, P., Johnson, M. J., Leary,
C., Maclaurin, D., Necula, G., Paszke, A., VanderPlas, J.,

Wanderman-Milne, S., and Zhang, Q. JAX: composable
transformations of Python+NumPy programs, 2018. URL
http://github.com/google/jax.
Caldas, S., Duddu, S. M. K., Wu, P., Li, T., Konečnỳ, J.,
McMahan, H. B., Smith, V., and Talwalkar, A. Leaf:
A benchmark for federated settings. arXiv preprint
arXiv:1812.01097, 2018.
Chahal, K. S., Grover, M. S., and Dey, K. A hitchhiker’s
guide on distributed training of deep neural networks.
CoRR, abs/1810.11787, 2018. URL http://arxiv.
org/abs/1810.11787.
Chowdhery, A., Warden, P., Shlens, J., Howard, A.,
and Rhodes, R. Visual wake words dataset. CoRR,
abs/1906.05721, 2019. URL http://arxiv.org/
abs/1906.05721.
Dean, J., Corrado, G. S., Monga, R., Chen, K., Devin, M.,
Le, Q. V., Mao, M. Z., Ranzato, M., Senior, A., Tucker, P.,
Yang, K., and Ng, A. Y. Large scale distributed deep networks. In Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume
1, NIPS’12, pp. 1223–1231, USA, 2012. Curran Associates Inc. URL http://dl.acm.org/citation.
cfm?id=2999134.2999271.
Dryden, N., Jacobs, S. A., Moon, T., and Van Essen, B.
Communication quantization for data-parallel training of
deep neural networks. In Proceedings of the Workshop
on Machine Learning in High Performance Computing
Environments, MLHPC ’16, pp. 1–8, Piscataway, NJ,
USA, 2016. IEEE Press. ISBN 978-1-5090-3882-4. doi:
10.1109/MLHPC.2016.4. URL https://doi.org/
10.1109/MLHPC.2016.4.
Flower.
Model architecture for android devices.
https://github.com/adap/flower/
blob/main/examples/android/tflite_
convertor/convert_to_tflite.py, 2021.
Foundation, C. N. C. grpc: A high performance, opensource universal rpc framework. URL https://grpc.
io. Accessed: 2020-03-25.
Fromm, J., Patel, S., and Philipose, M. Heterogeneous
bitwidth binarization in convolutional neural networks.
In Proceedings of the 32nd International Conference on
Neural Information Processing Systems, NIPS’18, pp.
4010–4019, Red Hook, NY, USA, 2018. Curran Associates Inc.
Georgiev, P., Lane, N. D., Mascolo, C., and Chu, D. Accelerating mobile audio sensing algorithms through on-chip
GPU offloading. In Choudhury, T., Ko, S. Y., Campbell, A., and Ganesan, D. (eds.), Proceedings of the

Flower: A Friendly Federated Learning Framework

15th Annual International Conference on Mobile Systems, Applications, and Services, MobiSys’17, Niagara
Falls, NY, USA, June 19-23, 2017, pp. 306–318. ACM,
2017. doi: 10.1145/3081333.3081358. URL https:
//doi.org/10.1145/3081333.3081358.
Google. Tensorflow federated: Machine learning on decentralized data. https://www.tensorflow.org/
federated, 2020. accessed 25-Mar-20.
Hard, A., Rao, K., Mathews, R., Ramaswamy, S., Beaufays,
F., Augenstein, S., Eichner, H., Kiddon, C., and Ramage,
D. Federated learning for mobile keyboard prediction,
2019.
Jia, X., Song, S., He, W., Wang, Y., Rong, H., Zhou, F.,
Xie, L., Guo, Z., Yang, Y., Yu, L., Chen, T., Hu, G., Shi,
S., and Chu, X. Highly scalable deep learning training
system with mixed-precision: Training imagenet in four
minutes. CoRR, abs/1807.11205, 2018. URL http:
//arxiv.org/abs/1807.11205.
Krizhevsky, A., Nair, V., and Hinton, G.
Cifar10 (canadian institute for advanced research). Online, 2005. URL http://www.cs.toronto.edu/
˜kriz/cifar.html.
Lai, F., Dai, Y., Zhu, X., and Chowdhury, M. Fedscale:
Benchmarking model and system performance of federated learning. arXiv preprint arXiv:2105.11367, 2021.
Lee, T., Lin, Z., Pushp, S., Li, C., Liu, Y., Lee, Y.,
Xu, F., Xu, C., Zhang, L., and Song, J. Occlumency:
Privacy-preserving remote deep-learning inference using sgx. In The 25th Annual International Conference on Mobile Computing and Networking, MobiCom
’19, New York, NY, USA, 2019. Association for Computing Machinery. ISBN 9781450361699. doi: 10.
1145/3300061.3345447. URL https://doi.org/
10.1145/3300061.3345447.
Li, T., Sahu, A. K., Zaheer, M., Sanjabi, M., Talwalkar, A.,
and Smith, V. Federated optimization in heterogeneous
networks. arXiv preprint arXiv:1812.06127, 2018.
Li, T., Sanjabi, M., and Smith, V. Fair resource allocation
in federated learning. arXiv preprint arXiv:1905.10497,
2019.
Li, T., Sahu, A. K., Zaheer, M., Sanjabi, M., Talwalkar, A.,
and Smith, V. Federated optimization in heterogeneous
networks, 2020.
LiKamWa, R., Hou, Y., Gao, J., Polansky, M., and Zhong,
L. Redeye: Analog convnet image sensor architecture
for continuous mobile vision. In Proceedings of the
43rd International Symposium on Computer Architecture, ISCA ’16, pp. 255–266. IEEE Press, 2016. ISBN

9781467389471. doi: 10.1109/ISCA.2016.31. URL
https://doi.org/10.1109/ISCA.2016.31.
Lite,
T.
On-device model personalization.
https://blog.tensorflow.org/2019/12/
example-on-device-model-personalization.
html, 2020.
Malekzadeh, M., Athanasakis, D., Haddadi, H., and Livshits,
B. Privacy-preserving bandits, 2019.
McMahan, B., Moore, E., Ramage, D., Hampson, S.,
and y Arcas, B. A. Communication-efficient learning of deep networks from decentralized data. In
Singh, A. and Zhu, X. J. (eds.), Proceedings of the
20th International Conference on Artificial Intelligence
and Statistics, AISTATS 2017, 20-22 April 2017, Fort
Lauderdale, FL, USA, volume 54 of Proceedings of
Machine Learning Research, pp. 1273–1282. PMLR,
2017. URL http://proceedings.mlr.press/
v54/mcmahan17a.html.
Moritz, P., Nishihara, R., Wang, S., Tumanov, A., Liaw, R.,
Liang, E., Elibol, M., Yang, Z., Paul, W., Jordan, M. I.,
and Stoica, I. Ray: A distributed framework for emerging
ai applications, 2018.
Ni, J., Li, J., and McAuley, J. Justifying recommendations
using distantly-labeled reviews and fine-grained aspects.
In Proceedings of the 2019 Conference on Empirical
Methods in Natural Language Processing and the 9th
International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 188–197, 2019.
OpenSignal.
The state of mobile network experience 2020: One year into the 5g era.
https:
//www.opensignal.com/reports/2020/05/
global-state-of-the-mobile-network,
2020. accessed 10-Oct-20.
Reddi, S., Charles, Z., Zaheer, M., Garrett, Z., Rush, K.,
Konečný, J., Kumar, S., and McMahan, H. B. Adaptive
federated optimization, 2021.
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S.,
Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein,
M., et al. Imagenet large scale visual recognition challenge. International journal of computer vision, 115(3):
211–252, 2015.
Ryffel, T., Trask, A., Dahl, M., Wagner, B., Mancuso,
J., Rueckert, D., and Passerat-Palmbach, J. A generic
framework for privacy preserving deep learning. CoRR,
abs/1811.04017, 2018. URL http://arxiv.org/
abs/1811.04017.
Sanh, V., Debut, L., Chaumond, J., and Wolf, T. Distilbert,
a distilled version of bert: smaller, faster, cheaper and
lighter. arXiv preprint arXiv:1910.01108, 2019.

Flower: A Friendly Federated Learning Framework

Sergeev, A. and Balso, M. D. Horovod: fast and
easy distributed deep learning in tensorflow. CoRR,
abs/1802.05799, 2018. URL http://arxiv.org/
abs/1802.05799.

Smith, V., Chiang, C.-K., Sanjabi, M., and Talwalkar, A. S.
Federated multi-task learning. In Advances in Neural
Information Processing Systems, pp. 4424–4434, 2017.
Sztyler, T. and Stuckenschmidt, H. On-body localization
of wearable devices: An investigation of position-aware
activity recognition. In 2016 IEEE International Conference on Pervasive Computing and Communications
(PerCom), pp. 1–9. IEEE Computer Society, 2016. doi:
10.1109/PERCOM.2016.7456521.
W. Falcon, e. a.
Pytorch lightning, 2019.
URL
https://github.com/williamFalcon/
pytorch-lightning.
Xiao, H., Rasul, K., and Vollgraf, R. Fashion-mnist: a
novel image dataset for benchmarking machine learning
algorithms. arXiv preprint arXiv:1708.07747, 2017.
Xie, C., Koyejo, S., and Gupta, I. Zeno: Distributed
stochastic gradient descent with suspicion-based faulttolerance. In Chaudhuri, K. and Salakhutdinov, R. (eds.),
Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine
Learning Research, pp. 6893–6901, Long Beach, California, USA, 09–15 Jun 2019. PMLR. URL http://
proceedings.mlr.press/v97/xie19b.html.
Yao, Y., Li, H., Zheng, H., and Zhao, B. Y. Latent backdoor attacks on deep neural networks. In Proceedings
of the 2019 ACM SIGSAC Conference on Computer
and Communications Security, CCS ’19, pp. 2041–2055,
New York, NY, USA, 2019. Association for Computing Machinery. ISBN 9781450367479. doi: 10.1145/
3319535.3354209. URL https://doi.org/10.
1145/3319535.3354209.

A

A PPENDIX

A.1

Survey on papers

From a systems perspective, a major bottleneck to FL research is the paucity of frameworks that support scalable

70
60

# papers

Singh, S. P., Sharma, M. K., Lay-Ekuakille, A., Gangwar, D., and Gupta, S. Deep convlstm with selfattention for human activity decoding using wearable
sensors. IEEE Sensors Journal, 21(6):8575–8582, Mar
2021. ISSN 2379-9153. doi: 10.1109/jsen.2020.
3045135. URL http://dx.doi.org/10.1109/
JSEN.2020.3045135.

85
80

50
40

35

30
20

16

10
0

<10

100

1k

10
10k

2

2

0

100k

1M

>1M

total # clients in the pool

Figure 9. Histograms of the number of total FL clients used in FL
research papers in the last two years. A vast majority of papers
only use up to 100 clients.

execution of FL methods on mobile and edge devices. Fig.
9 shows the histograms of total number of clients in the FL
pools in research papers. The research papers is gathered
from Google Scholar that is related to federated learning
from last 2 years which consists of total 150 papers in the
survey. We excluded papers that are using the framework
not available to reproduced the results. As we can see from
the histogram, the majority of experiments only use up to
100 total clients, which usually on datasets such as CIFAR10
and ImageNet. There are only 3 papers using the dataset
with a total clients pool up to 1 millions, and they are using
the Reddit and Sentiment140 dataset from leaf (Caldas et al.,
2018).
A.2

FedFS Algorithm

We introduce Federating: Fast and Slow (FedFS) to overcomes the challenges arising from heterogeneous devices
and non-IID data. FedFS acknowledges the difference in
compute capabilities inherent in networks of mobile devices
by combining partial work, importance sampling, and dynamic timeouts to enable clients to contribute equally to the
global model.
Partial work. Given a (local) data set of size mk on client
k, a batch size of B, and the number of local training
epochs E, FedAvg performs E mBk (local) gradient updates
θk ← θk − ηO`(b; θk ) before returning θk to the server.
The asynchronous setting treats the success of local update
computation as binary. If a client succeeds in computing
E mBk mini-batch updates before reaching a timeout ∆, their
weight update is considered by the server, otherwise it is discarded. The server then averages all successful θk∈{0,..,K}
updates, weighted by mk , the number of training examples
on client k.

Flower: A Friendly Federated Learning Framework

This is wasteful because a clients’ computation might be
discarded upon reaching ∆ even if it was close to computing
the full E mBk gradient updates. We therefore apply the
concept of partial work (Li et al., 2018) in which a client
submits their locally updated θk upon reaching ∆ along with
ck , the number of examples actually involved in computing
θk , even if ck < E mBk B. The server averages by ck , not
mk , because ck can vary over different rounds and devices
depending on a number of factors (device speed, concurrent
processes, ∆, mk , etc.).

Algorithm 1: FedFS
begin Server T, C, K, , rf , rs , ∆max , E, B,
initialise θ0
for round t ← 0, ..., T − 1 do
j ← max(bC · Kc, 1)
St ← (sample j distinct indices from {1, ..., K}
with 1 − wk + )
if fast round (rf , rs ) then
∆t = ∆f
else
∆t = ∆s
end
for k ∈ St do in parallel
k
θt+1
, ck , mk ← ClientTraining(k, ∆t , θt ,
E, B, ∆t )
end P
cr ← k∈St ck
P
k
θt+1 ← k∈St cckr θt+1
end
end

Intuitively, this leads to more graceful performance degradation with smaller values for ∆. Even if ∆ is set to an
adversarial value just below the completion time of the
fastest client, which would cause FedAvg to not consider
any update and hence prevent convergence, FedFS would
still progress by combining K partial updates. More importantly it allows devices which regularly discard their
updates because of lacking compute capabilities to have
their updates represented in the global model, which would
otherwise overfit the data distribution on the subset of faster
devices in the population.

Accuracy (%)

Importance sampling. Partial work enables FedFS to leverage the observed values for crk (with r ∈ {1, ..., t}, the
amount of work done by client k during all previous rounds
up to the current round t) and E r mk (with r ∈ {1, ..., t},
the amount of work client k was maximally allowed to do
during those rounds) for client selection during round t + 1.
c and m can be measured in different ways depending on the
use case. In vision, ctk could capture the number of image
examples processed, whereas in speech ctk could measure
the accumulated duration of all audio samples used for training on client k during round t. ctk < E t mk suggests that
client k was not able to compute E t mBk gradient updates
within ∆t , so its weight update θkt has less of an impact on
the global model θ compared to an update from client j with
ctj = E t mj . FedFS uses importance sampling for client
selection to mitigate the effects introduced by this difference in client capabilities. We define the work contribution
wk of client k as the ratio between
Pt the actual work done
during previous rounds ck = r=1 crk and the maximum
Pt
work possible ĉk = r=1 E r mk . Clients which have never
been selected before (and hence have no contribution history) have wk = 0. We then sample clients on the selection
probability 1 − wk +  (normalized over all k ∈ {1, ..., K}),
with  being the minimum client selection probability. 
is an important hyper-parameter that prevents clients with
ctk = E t mk to be excluded from future rounds. Basing the
client selection probability on a clients’ previous contributions (wk ) allows clients which had low contributions in
previous rounds to be selected more frequently, and hence
contribute additional updates to the global model. Synchronous FedAvg is a special case of FedFS: if all clients are
able to compute ctk = E t mk every round, then there will be

80
60
40
20

Top-1 Accuracy
Top-5 Accuracy

0
1 2 3 4 5
10
Training time (Days)

15

Figure 10. Training time reported in days and accuracies (Top-1
and Top-5) for an ImageNet federated training with Flower.

no difference in wk and FedFS samples amongst all clients
with a uniform client selection probability of k1 .
Alternating timeout. Gradual failure for clients which are
not able to compute E t mBk gradient updates within ∆t and
client selection based on previous contributions allow FedFS
to use more aggressive values for ∆. One strategy is to use
an alternating schedule for ∆ in which we perform rf “fast”
rounds with small ∆f ) and rs “slow” rounds with larger
∆s . This allows FedFS to be configured for either improved
convergence in terms of wall-clock time or better overall
performance (e.g., in terms for classification accuracy).
FedFS algorithm. The full FedFS algorithm is given in
Algorithm 1.
A.3

Scaling FedAvg to ImageNet-scale datasets

We now demonstrate that Flower can not only scale to a
large number of clients, but it can also support training of
FL models on web-scale workloads such as ImageNet. To
the best of our knowledge, this is the first-ever attempt at
training ImageNet in a FL setting.
Experiment Setup. We use the ILSVRC-2012 ImageNet

Flower: A Friendly Federated Learning Framework

partitioning (Russakovsky et al., 2015) that contains 1.2M
pictures for training and a subset composed of 50K images
for testing. We train a ResNet-18 model on this dataset
in a federated setting with 50 clients equipped with four
physical CPU cores. To this end, we partition the ImageNet
training set into 50 IID partitions and distribute them on
each client. During training, we also consider a simple
image augmentation scheme based on random horizontal
flipping and cropping.
Results. Figure 10 shows the results on the test set of
ImageNet obtained by training a ResNet-18 model. It is
worth to mention that based on 50 clients and 3 local epochs,
the training lasted for about 15 days demonstrating Flower’s
potential to run long-term and realistic experiments.
We measured top-1 and top-5 accuracies of 59.1% and
80.4% respectively obtained with FL compared to 63% and
84% for centralised training. First, it is clear from Figure
10 that FL accuracies could have increased a bit further at
the cost of a longer training time, certainly reducing the gap
with centralised training. Then, the ResNet-18 architecture
relies heavily on batch-normalisation, and it is unclear how
the internal statistics of this technique behave in the context
of FL, potentially harming the final results. As expected,
the scalability of Flower helps with raising and investing
new issues related to federated learning.
For such long-term experiments, one major risk is that client
devices may go offline during training, thereby nullifying
the training progress. Flower’s built-in support for keeping
the model states on the server and resuming the federated
training from the last saved state in the case of failures came
handy for this experiment.
A.4

Datasets and Network Architectures

We use the following datasets and network architectures for
our experiments.
CIFAR-10 consists of 60,000 images from 10 different object classes. The images are 32 x 32 pixels in size and in
RGB format. We use the training and test splits provided by
the dataset authors — 50,000 images are used as training
data and remaining 10,000 images are reserved for testing.
Fashion-MNIST consists of images of fashion items
(60,000 training, 10,000 test) with 10 classes such as
trousers or pullovers. The images are 28 x 28 pixels in
size and in grayscale format. We use a 2-layer CNN followed by 2 fully-connected layers for training a model on
this dataset.
ImageNet. We use the ILSVRC-2012 ImageNet (Russakovsky et al., 2015) containing 1.2M images for training
and 50K images for testing. A ResNet-18 model is used for
federated training this dataset.

High Performing Deep Learning Architectures
under Resource Constrained Platforms

Javier Fernández-Marqués
Linacre College
Univeristy of Oxford

DPhil Transfer Report
November 12, 2018

Contents
1 Research Proposal

2

1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2

1.2 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2

1.3 Challenges and Opportunities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4

1.3.1 Memory Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4

1.3.2 Energy Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5

1.3.3 Latency Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5

1.3.4 Accuracy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6

1.4 Proposed Research . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6

1.4.1 Approaches to Classification

. . . . . . . . . . . . . . . . . . . . . . . . . . .

7

1.4.2 Approaches to RNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

10

1.4.3 Approaches to Generative Networks . . . . . . . . . . . . . . . . . . . . . . .

10

2 Literature Review

11

2.1 Neural Network Design Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . .

12

2.1.1 Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

12

2.1.2 Popular Architectures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

13

2.2 Compressing Neural Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

16

2.2.1 Layer Design Approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

16

2.2.2 Post-Training Approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

19

2.2.3 Using Deterministic Elements . . . . . . . . . . . . . . . . . . . . . . . . . . .

21

2.3 Low Precision Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

22

3 Completed Work

25

Bibliography

41

1

Chapter 1

Research Proposal
1.1

Introduction

Neural Networks (NNs) are the preferred option when it comes to the design of robust artificial
intelligence applications such as those relying on computer vision and voice recognition systems
impacting areas like surveillance, health, entertainment or the automotive industry. As a parallel
phenomenon to the rise in popularity of NNs in recent years, Internet of Things (IoT) devices such
as smart speakers, thermostats or cameras, to name a few, have been embraced by our society
with the promise of making our lives easier. With very few exceptions, the development paths of
NNs and IoT have exclusively met in the cloud, where most of the data collected by these devices
gets processed. These devices, often equipped with very constrain CPUs or microcontrollers
(MCUs), are not a good fit for modern applications employing complex NNs systems primarily
due to the reliance of these on millions of parameters.
The aim of this DPhil thesis is to investigate and develop novel deep learning architectures
enabling the execution of NN-based applications in IoT devices. To this end, this thesis will
investigate as well compression techniques that make NNs rely more on operations and less
on parameters, effectively trading memory for compute. What’s the optimal neural network
architecture that, while maintaining accuracy levels and with relaxed latency constraints, energy
consumption during inference is significantly reduced?

1.2

Motivation

There would be approximately 35 billion MCUs devices sold next year alone and are already
flooding the places where we live, work and socialise (e.g. kitchens, supermarkets, factories,

2

CHAPTER 1. RESEARCH PROPOSAL

1.2. MOTIVATION

hospitals, airports or gyms) 1 . Today, most of these devices are used in sensing and control
applications. Despite their limited memory and compute resources (see Table 1.1), in recent years,
MCUs have become the default target platform of a popular deep learning application: Keyword
Spotting (KWS). KWS has become a popular always-on feature in smartphones, wearables and
smart home devices. It serves as the entry point for speech based applications once a predefined
command (e.g. “Ok Google“, “Hey Siri”, ”Alexa”) is detected from a continuous stream of audio.
MCUs have become the preferred target platform for these applications primarily due to their
good performance per watt profile.
The current state of the art for KWS (Zhang et al., 2017) relies on depth-wise convolutions and
results in a model size of 38.6 KB and requires 2.7 M MACs to analyse a one-second clip of audio.
These networks are sufficiently small that do not present a challenge when it comes to deployment
on constrained devices. Often, 8-bit quantisation is used in these setups as the majority of MCUs
do not come with floating-point units, or FPUs. Without built-in support for floating-point
these operations are still possible when relying on fix-point arithmetic. Despite their commercial
success 2 , KWS for personal assistant applications are the only family of DL applications that
have made their way into compute-constrained platforms. Other applications, such as those based
on vision (e.g. image classification, scene understanding, human pose estimation, etc) require at
least two orders of magnitude (see Table 2.1) more compute and memory resources, compared to
KWS systems, in order to deliver acceptable results.
Model
STM32L151C8T6A
STM32F107RCT6TR
STM32L496VET6
ATSAME53N20A-AU
MKV58F1M0VCQ24
ATSAMV71N21B-CB
STM32H743VIT6

Core
Cortex-M3
Cortex-M3
Cortex-M4
Cortex-M4
Cortex-M7
Cortex-M7
Cortex-M7

Frequency
32 MHz
72 MHz
80 MHz
120 MHz
240 MHz
300 MHz
400MHz

SRAM
32 KB
64 KB
320 KB
256 KB
256 KB
384 KB
1024KB

Flash
64 KB
250 KB
0.5 MB
1 MB
1 MB
2 MB
2MB

Table 1.1: Commercially available ARM Cortex-M based MCUs
For computer vision applications tasks such as image classification, the machine learning
community has been primarily driven by the goal of designing new algorithms that could
outperform the state of the art in terms of accuracy levels. This resulted in models with tens
of millions of parameters and MACs in the order of billions to analyse a single low resolution
256 × 256 RGB image. While novel lightweight neural network architectural designs have been
proposed, there’s a trend of increasing the network’s model size in order to surpass the previous

state of the art. The current state of the art for image classification requires 21% more parameters
than last year’s. This trend, although not a problem for smartphones as nowadays have 4 GB
1 The 2018 McClean Report: http://www.icinsights.com/data/articles/documents/1101.pdf
2 https://machinelearning.apple.com/2017/10/01/hey-siri.html

3

CHAPTER 1. RESEARCH PROPOSAL

1.3. CHALLENGES AND OPPORTUNITIES

of RAM or more, is a step in the wrong direction when it comes to the deployment of efficient
architectures in very constrain setups, primarily due to the reliance in more parameters which
exacerbated the memory and data movement challenges that MCUs face.
In addition to model size, latency might be one of the main concerns when designing machine
learning applications that require real-time processing (e.g. autonomous driving, text to speech
applications, etc). MCUs are suitable for real-time scenarios but not if those require the execution
of applications operating in high-dimensional (HD) spaces. However, there is a wide range of
applications without low-latency requirements that can be benefited from MCUs running deep
NNs architectures. A few examples are: on-device crops monitoring, where changes happen at a
slow pace, MCUs would be a good choice since they could execute NNs at very slow clock-speeds
while on batteries potentially lasting these several weeks; satellite imaging, on-device processing
would substantially reduce the amount of data streamed down to Earth, likely to extend satellite’s
life if running on batteries; medical imaging tests such as diabetic retinopathy 3 . For this task,
that NNs have proven to be useful at (Yang et al., 2017b; Zhou et al., 2018), a portable device
equipped with an MCU could execute such tests in locations with limited access to doctors or
hospitals, making the patients wait a few minutes for the image to get processed.

1.3

Challenges and Opportunities

There is an urge to design efficient DNN architectures that would enable the deployment of high
performing models in very constrained platforms (e.g. MCUs such ARM Cortex-M). However,
current NNs architectures aren’t designed to be deployed on these devices primarily due to their
reliance on millions of parameters. In this section, we present the main challenges that the design
of NNs needs to address when using MCUs as target platforms.

1.3.1

Memory Constraints

MCUs often exclusively rely on SRAM instead DRAM due to their lower energy requirements
and much faster read/write operations. This design choice comes at lower KB:$ ratios as well
as requiring more area per KB than DRAM does. As a consequence, SRAM in commercially
available MCUs is often found in the 32 KB to 1024 KB range. This is one of the primary
limitations when it comes to the deployment of complex DNNs-based applications. Existing
compression techniques focus on reducing the on-device memory requirements of models by
minimising the memory requirements of the network weights (whether this is by employing
quantisation, encoding, sparse formats, or other techniques). However, much less attention has
been paid to activations, which can easily require as much memory as the totality of the network
parameters do. Due to this, there is a need for a holistic NN architecture design by which
3 https://ai.googleblog.com/2016/11/deep-learning-for-detection-of-diabetic.html

4

CHAPTER 1. RESEARCH PROPOSAL

1.3. CHALLENGES AND OPPORTUNITIES

the entire of the inference process is taken into account. In this way, having a very compact
representation of the weights would matter as much as the memory footprint of the decoded
filters or as much as the memory footprint of the activations that would be generated in every
layer.

1.3.2

Energy Constraints

Any device that requires significant power faces a lot of barriers when it comes to its commercialisation. The advantages that smart products have to offer often get outweighed due to power-related
inconvenient installation and maintenance processes, whether because they require permanent
wiring or frequent docking to charge the battery. In MCUs, data movement is the primary source
of energy consumption. Inter-device data movement is costly, even when relying on low power
communication mechanisms such as BLE or ZigBee for close-range communications, with energy
consumptions in the order of hundreds of milliwatts (Siekkinen et al., 2012). On-device machine
learning applications would require fewer communications to a master node (e.g. home router,
phone, cloud) alleviating bandwidth bottlenecking issues and become a decisive design choice
for ensuring user data privacy. In addition, and unlike displays and radios, CPUs and sensors
could use considerably less power: real-time audio processing at 384 KHz requires between 10-25
mW (Hill et al., 2018) using a Cortex-M4; low-resolution image sensors suitable for object tracking
applications consume 277µW (Rusci et al., 2017).
Intra-device data movement also presents a similar distance-energy relationship. Fetching
values from DRAM requires over 128× more energy than reading that data from SRAM (Han
et al., 2016b). Applications having to rely on flash (i.e. paging) during inference would incur into
significant energy costs as well as an increase in latency. An example of such scenario would be a
NN which doesn’t fit in RAM and therefore only a few layers can be in memory at a given time.
The question this rises is can we replace memory accesses and allocations with more computations
in order to design a more energy efficient inference stage?

1.3.3

Latency Constraints

Compression techniques for image classification has driven a lot of attention in recent years and
some frameworks have been even able to reach 500× (Han et al., 2016a) compression ratios for
certain networks. However reducing model size alone is not a guarantee for faster inference stages
(e.g. Iandola et al. (2016) achieves the same accuracy as AlexNet but, while it has 50x fewer
parameters, it requires 33% more MACs to analyse a single 256 × 256 RGB image. A more
recent example, MobileNetV2 (Sandler et al., 2018) and AmoebaNet (Real et al., 2018) present a

similar behaviour, both require roughly the same number of MACs and offer the same accuracy
on ImageNet but the later results in 33% higher CPU latency when evaluated on Google’s Pixel-1
5

CHAPTER 1. RESEARCH PROPOSAL

1.4. PROPOSED RESEARCH

phone. These results evidence that not all OPs are created equal (Lai et al., 2018b).

1.3.4

Accuracy

State of the art compression techniques exhibit little to know accuracy degradation in NNs that
are overparameterized. When it comes to compressing smaller networks, such as those in the
range of 5-10M parameters down to sub-megabyte levels, the literature is very scarce. Even
works showcasing architectures relying on aggressive quantisation, i.e. ternary or binary networks,
generally do not result in smaller models without sacrificing accuracy (Lin et al., 2017), whether
because of the large amount of parameters needed or because the activations of every layer require
full-precision representations.
The landscape of NNs resulting in models of < 1 MB for complex applications, such as those
using computer vision, hasn’t been explored. As a consequence, it is difficult to estimate what’s
the best architecture or compression technique given the memory constraints of MCUs that
maximises that accuracy of the system. In very constrained setups, such as those with 2KB or
RAM (Kumar et al., 2017), traditional machine learning techniques outperform to NN-based
systems. A combination of both traditional ML and NNs could be a viable solution to ease high
dependence of parameters that applications solely relying on NNs have.

1.4

Proposed Research

The focus of this research is the development of novel neural network architectures with minimal
energy consumption but capable of achieving high accuracy rates in complex tasks such as image
classification when latency constraints are relaxed. Energy consumption, modelled as the amount
of data movement required during inference, would be reduced by limiting the number of model
parameters that describe the network and therefore the number of accesses to RAM or flash
needed (e.g.µSD card) to retrieve those values.
Concretely, in this thesis we are interested in the set of functions that could be used to
generate the elements that describe NNs on-the-fly, consequently reducing the impact of parameter
fetching in terms of energy consumption. Function Networks (FNs) are NNs whose elements (e.g.
filters, activations) are represented or constructed as a combination of parameters and functions.
They differ from regular NNs in the sense that the filters aren’t stored directly as part of the
model but need to be reconstructed at runtime. The prototypical example of FNs is the work
of Ha et al. (2016) in which HyperNetworks were introduced. HyperNetworks are NNs that use
another NN to construct the filters given a low-dimensional embedding of the filter. Here the
parameters are the filter embeddings and the function is the NN that inflates the filter given the
embedding. FNs enable, by increasing the number of operations during inference, the execution
of NNs that otherwise would not fit on the device. The design space for FNs hasn’t been explored
6

CHAPTER 1. RESEARCH PROPOSAL

1.4. PROPOSED RESEARCH

for constrained platforms and it requires addressing the challenges presented in Section 1.3.
This research will primarily be evaluated on image classification tasks since it’s a complex
problem with multiple applications that would greatly benefit from being capable of running on
MCUs. Our aim is to design application-agnostic architectures and compression techniques, but
because image classification systems often do not include other popular types of layers such as
LSTMs (Hochreiter and Schmidhuber, 1997) or up-scaling layers, this DPhil will also look, to a
lower extent, on to how RNNs and generative networks in applications such as GANs (Goodfellow
et al., 2014) and super-resolution, could benefit from using FNs for reasons that would be
introduced in 1.4.2 and 1.4.3 respectively.

1.4.1

Approaches to Classification

Classification is arguably one of the most common types of applications when it comes to the
analysis of images or sounds. It is also one of the most studied topics in the machine learning
community and has experienced a rapid development in recent years. In particular, CNNs have
proven to be the most suitable family of NN architectures for this task. We focus on CNN-based
architectures and how they could be deployed onto MCUs by making us of FNs.

1.4.1.1

Completed Project

In standard CNNs, filters are learnt end-to-end via back-propagation and stored as part of the
model. In certain architectures these can account for a sizeable portion of the total model size,
limiting the deployability of these networks in constrained devices. In Tseng et al. (2018) we
presented an approach to CNNs that learns weighting coefficients of predefined orthogonal binary
bases instead of the conventional approach of learning directly the convolutional filters. We
generate the filters as a linear combination of orthogonal binary codes that can be generated
very efficiently in real time. We employ a set of orthogonal variable spreading factor (OVSF4 )
codes that can be recursively generated on-the-fly in order to reconstruct the convolutional filters
for image classification CNNs. Our work lies in the intersection between compression techniques
and novel architectural designs. In Fernandez-Marques et al. (2018) we explored the suitability
of this approach for KWS applications. In addition, we analysed the costs of the filter generation,
presented alternative solutions and evaluated them on a Cortex-M7.

1.4.1.2

Current Project

The current project addresses the question: What are the most suitable set of functions to generate
the filters?. This question, raises another one and, as it will be argued later, both need to be
4 OVSF codes were introduced for 3G communication systems as channelizations codes aiming to
increase system capacity in multi-user access scenarios (Adachi et al., 1997)

7

CHAPTER 1. RESEARCH PROPOSAL

1.4. PROPOSED RESEARCH

answered jointly: How can we learn the parameters that define these functions?

The Choice of Functions
For the task of reconstructing the filters in a NN layer given a low-dimensional vector, the choice
of functions to perform this task isInput
of great importance and multiple approaches are possible.
Because NNs are often regarded as universal function approximators, these could be used in
order to generate the filters of our network (effectively resulting in a HyperNetwork). One of
OVSF Bases

the aims of FNs is to rely on those decoding schemes that
are efficient, lightweight and with
Generation
Convolution

enough representation capabilities to any filter suitable for a specific task, e.g. image classification.
Weights

+ these are two directions worth
Beyond NNs, which are known toReLu
rely on many parameters,
exploring:
• In-Training Filter Shaping:
Filters in NNs generally
Filter Banklive in very HD spaces. This
Convolution

property provides enough flexibility during the training process and results in NNs that,
ReLu
although different in terms of
parameters, are capable of performing equally well for a

given task. This can be used to our advantage by applying constraints on how the filters

+
are learnt and therefore
make them suitable to be reconstructed very cheaply. Results
from our initial explorationConvolution
of this idea on a two-layer NN trained on MNIST are shown in
Figure 1.2.
• Recursion: Relying on recursive
functions to reconstruct the filter could greatly reduce the
Output
dependence on model parameters. In addition, if it combines deterministically generated
elements the filter reconstruction process could be even more compact.
The challenge in
..
.

0.2

-0.4

-1.3

0.9

the design of recursively generatedbi1filters
is to add flexibility to the generation process.
= [b̃21 , b̃23, b̃3 , ...b̃NN ] bkk = [1, −1, 2, 1, ... − 1]
1.2
-0.4

1.7
-1.3

-1.3
0.7

-1.1

bi = [b̃i , b̃ii , b̃i i , ...
i b̃ i ] bii = [1, −1, 2, 1, ... − 11] 2
i
b = [b̃ , b̃ , b̃3 , ...b̃N ] w = [w 1 , w 2 , w 3 , ...w N ] bk = [1, −1, 2
0.2

i
i
+
i
i
i
i
i
i
i
Generation
How can we design
a recursive algorithm ...capable
of generating
-1 1 -1 -1
fi =very different types of filters?

OVSF Bases

-.03 -0.8
0.3
2.1
-0.5 -1.3
-0.5 -1.2
-2.8
1.2
1.7
1.2

-1 -1
1 1
-1 -1
1 -1
1 -1-1 11-1-111 -1
-1 1 2
1
1
2
3
N
k 2 = [1, 0, 0, 1, ...1]
2 −1,
N1 -1 ib
-1
13−1,
-1 -1
-1...−1]
i
i =iN ][b̃
, ...b
bik1=
[1,
1,
i
i bi i = [bi1 , bii2 , bi3b
-1
,
b̃
,
b̃
,
...
b̃
1
1
-1
i
i i = [1, −1, 2, 1, ... − 1]
i
i
i1] b
i
N
N
..
b
=
[0,
1,
1,
0,
...1]
1
1
-1
1
bi = [bi1 , bi2 , bi3 ,i ...biN ] bik = [1, −1, i−1, 1, ...−1] bi2 = [1, 0, 0, 1, ...1]-1 -1 1 1 .
-1 -1 1 1
N

1.7

-0.5

3.2

-1.3
-1.3
2.1
-0.4
-1.3
-0.5
-2.8
1.5

i

i

0.9

.
..

-0.5
-0.5
-2.8
-0.4
2.1
-0.4
-1.3
0.9

This could be framed as a few-to-many RNN-based decoding scheme in which the first
b = [b , b , b , ...b ] b = [1, 0, 1, 1, ...0] b = [1, 1, 0, 1, ...1]

2.1

-0.4

-1.3

0.0

b = [0, 1, 1, 0,and
...1] the final output after n iterations would be the reconstructed
input are the parameters
bi = [0, 1, 1, 0, ...1]

1

2

3

N

αi = [αi ,αi ,α
i ...αi ] in RNNs, these would need to
filter. However, due to the reliance
on fully-connected
layers
Reshape

..

.

3
bi1=, b̃
[b̃2i1,, b̃b̃i23, ,b̃...
, ...b̃NN ] b k = [1, −1, 2, 1, ... − 1]
bi = [b̃
i
i
i i b̃i i ] bii = [1, −1, 2, 1, ... − 1]
k

OVSF Bases
Generation

..

+

.

fi =

bi = [b̃i1 , b̃i2 , b̃i3 , ...b̃iN ] wi = [wi1 , wi2 , wi3 , ...wiN ] b
..

.

1 b 1= [1,2−1, 3
1
N
N [1, b
= 1,
[1,...1]
0, 0, 1, ...1]
bi =b[b
bii2, bii3, b...b
=i [1,
0, 1, 1, −1,
...0]. 1,
bi2...−1]
=
1,k0,
i =i ,[b
i i][b̃
i , i...b
b
i ]=b
i , b̃i , b̃i , .....b̃
i ] bii = [1, −1, 2, 1, ... − 1]
N
= 1,
[0,1,1,0,1,...1]
0, ...1]
biN b
=i [0,
1

2

3

N

k

2

αi = [αi1 ,αi2 ,αi3 ...αiN ]

Reshape

Figure 1.1: Filter generation by combining on-the-fly binary codes with a set of weights learnt.
Elements inside the dashed red rectangle are deterministic and therefore can be generated
on-the-fly without the need of parameters learnt during training.
8

CHAPTER 1. RESEARCH PROPOSAL

1.4. PROPOSED RESEARCH

DNNs with parameterised elements
be simplified first by using functions that require fewer parameters. Another possibility
would
be to
rely
notion
of fractals
and
use each
recursion as a multi-resolution filter
• Model:
2-layer
NN on
with the
32 filters
in the input
layer with 728
elements
• MNIST
dataset: 60k 28x28 grayscale images of 10 classes (0-9 digits)
design
stage.
• Parameterised learning: Fourier series & Gaussian smoothing across channels
32 parameterised fully-connected filters

32 fully-connected filters

Figure 1.2: On the left, a scatter plot of the filters learnt for the input layer in a
standard NN are shown. As expected, values are follow a normal distribution centred
at the origin. On the right, the filters of the input layer of the NN (same architecture
and hyper-parameters) that get smoothed with a 1-dimensional Gaussian kernel for
each filter individually and across the channel dimension. This smoothing, performed
during training, ensures little in the value of channel-contiguous weights. The filters on
the right can be generated using Fourier Series with very few components (16 or less
for the example here shown). On the other hand, trying to learn a function capable
of generating the filters on the left would be much more challenging. The filters on
the right result in a 3% drop in accuracy compared that achieved by the NN using the
filters on the left.

Training FNs
Depending on what family of functions are used to reconstruct the filters of a NN at run time,
the learning process of such functions or their parameters would vary. Choosing differentiable
functions or combinations of these would make the training process suitable for the standard
backpropagation algorithm. For any other arbitrary set of functions, where differentiability may
not be guaranteed continue. This is similar to AutoML approaches such as Neural Architecture
Search (Zoph and Le, 2017) in which the optimal network architecture is automatically found
given a number of constraints such as model size, number of OPs etc. AutoML techniques applied
to FNs differ from these approaches in the sense that it wouldn’t be an architecture search (which
could be seen as an automated hyperparameter tuning) but a function exploration approach
potentially leading to a novel type of NN layer.

9

CHAPTER 1. RESEARCH PROPOSAL

1.4.1.3

1.4. PROPOSED RESEARCH

Future Project

The natural steps to follow when using FNs would be to first load a certain number of parameters,
reconstruct the filters given parameters-function pairs and then process the input to the network
as any standard NN would do. Although this approach might be suitable for some NNs, it might
become a limiting factor when executing larger models. As the size of activations generally
increases with the network depth, requiring the entire filter to be allocated in memory might
result in having to page to disk/flash a portion of the activations tensor. This would greatly
increase the energy consumption and latency of the application. The need for explicit filter
reconstruction is the question that would be addressed in this project.

1.4.2

Approaches to RNNs

RNNs are known to depend on fully-connected layers resulting on little parameter re-use and the
need to remember large sequences of events, which translates into a substantial memory usage.
In addition to high memory usage during inference, training RNNs is memory intensive. To
make this process tractable, the standard training algorithm sets an upper limit to the number of
states the network can remember, effectively truncating back-propagation through time (TBPTT)
(Werbos, 1990). We believe Function Networks could be a good option to alleviate the memory
requirements of RNNs when using TBPTT enabling the training of sequences with dependencies
spanning longer time-scales.

1.4.3

Approaches to Generative Networks

Applications that make use of generative approaches, such as NNs for image super-resolution
(SR) tasks, require at least 100× more MACs than state of the art image classification NNs. SR
networks take as input a low-resolution image and output a high-resolution version of the input.
The challenge is to perform this upscaling without introducing image artefacts. In addition to
the dramatic increase in operations needed during inference, the size of the activations also gets
affected in a similar manner, especially when the input images are upscaled by 4× factors or
more. This translates into high run-time RAM usage and limiting the deployability of these
systems. Factorisation or compression of activations which, as mentioned in Sec 1.3.1, has not
received a lot of attention, would be addressed in this project.

10

Chapter 2

Literature Review
Neural Networks (NNs) are the preferred option when it comes to the design of robust artificial
intelligence (AI) applications such as those relying on computer vision (He et al., 2015; Ren et al.,
2015; Zhang et al., 2018b; Goodfellow et al., 2014) and voice recognition systems (Abdel-Hamid
et al., 2014; Zhang et al., 2016; van den Oord et al., 2016; Zhang et al., 2017) impacting areas like
surveillance, health, entertainment or the automotive industry. Despite their rise in popularity in
recent years, and in particular since the success of AlexNet (Krizhevsky et al., 2012) in winning
the ImageNet (Deng et al., 2009) competition, the history of NNs has been a roller coaster of
enthusiasm and disillusionment since they were first proposed by McCulloch and Pitts (1943).
Since their inception and for the following 70 years, four mayor advances paved the way for
the development of complex and deeper architectures we use nowadays, namely: the work of
Rosenblatt (1957), were the perceptron algorithm for binary classification was first proposed and
designed for image recognition tasks; the work of Minsky and Papert (1969), which identifies the
technical limitations that perceptrons networks would face with the hardware available at the
time, leading to the first AI winter ; the Back-propagation algorithm (Rumelhart et al., 1986),
which helped in making it easier to train NNs; and the work of Hochreiter (1991), which gave
insights on why it is hard to train NNs, specifically he identified the vanishing gradient problem
that results when designing deep NNs. In addition to these and other advancements from the
research community, the confluence of two other factors enabled the popularisation of NNs as
a viable generic algorithm for a variety of machine learning problems. These two factors are
the today’s availability of both compute capability (mainly in the form of Graphical Processing
Units, GPUs) and large datasets. These two factors enabled training large NNs efficiently and
well enough to generalise to unseen examples.
Although in this chapter we will focus on feed-forward networks designed for image classification tasks many of the contents here presented are utilised in greater or or lesser extent in

11

CHAPTER 2. LITERATURE REVIEW

2.1. NEURAL NETWORK DESIGN OVERVIEW

other applications. The remaining of this chapter is organised as follows: first, we will introduce
the most popular datasets used for image classification a long with the most popular DNNs
architectural designs and the reasons behind their design choices; second, a detailed overview of
the state of the art of techniques for network compression, from traditional methods like SVD to
more recent ones such as DeepCompression (Han et al., 2016a) or RedCNN (Wang et al., 2017);
third, and overview of the main advantages of low-precision networks and recent works in the
area; finally, several of the reference designs for NN accelerators will be presented.

2.1

Neural Network Design Overview

Modern NNs are designed as a stack of operations, often referred as layers, through which the
input (e.g. an image, a clip of audio) is sequentially transformed by the operation defined in
each layer. In this section we will present some of the popular architectural designs for image
classification as well as the three datasets that are commonly used to compare these architectures.

2.1.1

Datasets

Prior to describing how network architectures have evolved throughout the years, we should take
a look at the different datasets that the research community often employs to compare different
architectures to each other. A few images of these datasets are shown n Figure 2.1. From simple
to more challenging, the three main datasets are:
• MNIST: This dataset (Lecun et al., 1998) consists of 28×28 grayscale images of handwritten

digits, i.e. numbers 0 to 9, with 60k training images and 10k for test. Despite its simplicity,
this dataset is often still used by the research community. Most of modern DNNs can reach
over 99.5% accuracy on this dataset.

• CIFAR-10: This dataset (Krizhevsky et al., 2009) consist of 32 × 32 RGB images split
into ten classes with 6k images per class. There is a total of 50k training images and 10k

test images. The classes are common objects and animals, e.g., cat, dog, ship, airplane,
etc. This dataset is more challenging than MNIST and state of the art networks would be
capable of reaching +95% accuracy (e.g. Xie et al. (2017) achieves 96.42%)
• ImageNet: This dataset (Deng et al., 2009) consists of 256 × 256 RGB images of a thousand

categories. It is divided into training and test sets with 1.28 million and 50k images,
respectively. This dataset is by far the most challenging among the three. The current
state of the art (Hu et al., 2018) achieves Top-5 4.47% and Top-1 18.68% errors.

12

CHAPTER 2. LITERATURE REVIEW

(a) MNIST

2.1. NEURAL NETWORK DESIGN OVERVIEW

(b) CIFAR-10

(c) ImageNet

Figure 2.1: Sample images from three popular datasets for image classification.

2.1.2

Popular Architectures

The vast majority of DNNs are designed by combining the same set of layers1 . These fundamental
building blocks are: convolutional, fully-connected, pooling, activation, batch-normalisation layers.
Here we present some of the networks that resulted in significant improvement over the state of
the art with respect to their predecessors for the task of image classification. An overview of the
characteristics of each network architecture and their performance on the ImageNet dataset is
shown in Table 2.1.

AlexNet. This architecture is the first successful implementation of a deep convolutional
neural network (CNN) on the challenging task of classifying ImageNet images. It won the
2012 ImageNet competition by over 25% compared to the second placed. Up until then, the
best performing systems relied in hand-crafted image features such as Local Binary Patterns
(LBP) (Ojala et al., 1994), Histogram of Oriented Gradients (HOG) (Dalal and Triggs, 2005) or
Fisher Vectors (Perronnin and Dance, 2007), among others.

ResNet. This architecture proposed by He et al. (2015) won the ImageNet’15 competition
using a network with 152 layers. The main contribution of this work is the introduction residual
blocks as a way of mitigating the vanishing gradients problem that arises when back propagating
through many layers. Residual blocks characterise by adding the input of the block to its output,
H(x) := F(x) + x, which adds stability during training. The residual blocks admit different
designs, two of the most widely use are shown in Figure 2.2a and Figure 2.2b. The bottleneck

layer squeezes the input tensor into a lower dimensional space where is less compute intensive
to perform the spatial convolution (e.g. using 3 × 3 filters) and then it is expanded back to the
original dimensions so the residual can be added.

1 For a detailed description of the different types of layers and what their purpose is, we refer the reader

to Goodfellow et al. (2016)

13

CHAPTER 2. LITERATURE REVIEW

2.1. NEURAL NETWORK DESIGN OVERVIEW

NASNet. In recent years, the research community has shown interest in developing automated
frameworks for neural network discovery. The main contribution behind NASNet (Zoph et al.,
2018), which stands for Neural Architecture Search Network, is the transferability of the search
space for architectural search from one domain (e.g. a particular dataset) to another. By being
capable of finding high performing architectures on the relatively small CIFAR-10 dataset and
transfer them to larger networks, it is the current state of the art for image classification under
ImageNet as well as for object detection on the COCO (Lin et al., 2014) dataset. Networks that
rely on automatic architecture network discovery techniques, such as those originally presented
in Zoph and Le (2017), often result in fewer parameters and operation required during inference
as compared to those architectures designed by humans. This architectures often introduce a
higher degree of graph irregularity which could translate into overheads during inference.
256-d
256-d

64-d

64-d

ReLU
3x3, 64
ReLU

+
ReLU

1x1, 64

1x1, 64

64-d

3x3, 64

256-d

256-d

3x3, 64

3x3, 64

ReLU
ReLU
3x3,3x3,
64 64

ReLU
ReLU

++
ReLU
ReLU

(a) Basic residual Layer

1x1, 64
ReLU
1x1, 64
ReLU

ReLU
1x1,
64

3x3, 64
3x3, 64
ReLU
ReLU ReLU

1x1, 256

1x1, 256
1x1, 256

+
ReLU

+ +
ReLU ReLU

(b) Bottleneck Layer

1x1, 256

256-d

1x1, 64

ReLU

ReLU

3x3, 64

256-d

ReLU

3x3, 256

1x1, 2561x1, 256

ReLU

ReLU

3x3, 256 3x3, 256

ReLU
ReLUReLU

ReLU

Concatenate
Concatenate
Concatenate
512-d
512-d

512-d

(c) Fire Module

Figure 2.2: Different layer designs making use of residual connections. Layers (a) and (b) were
introduced with the ResNet architecture, and layer (c) in SqueezeNet.
The following architectures did not surpassed the previous state of the art in terms of
image classification accuracy but they are capable of reaching competitive accuracy levels while
significantly reducing the number of parameters in the model. In the case of MobileNets, the
number of MAC operations needed during inference is greatly reduced compared to standard
CNN architectures.

SqueezeNet. Inspired by ResNet, and in particular by its bottleneck layer (see Figure 2.2b),
Iandola et al. (2016) focused on reducing the computational cost of AlexNet while maintaining its
accuracy levels. This architecture is comprised of a total of nine Fire Modules (see Figure 2.2c)
containing three convolutional layers inside each. Their architectural design, that relies heavily in
3 × 3 and 1 × 1 convolutions, in combination with compression frameworks such as DeepCompression (Han et al., 2016a) results in a model size of 0.47M B compared to the original 240M B of

AlexNet. This is a 510× model size reduction while maintaining the same accuracy on ImageNet.
14

CHAPTER 2. LITERATURE REVIEW

2.1. NEURAL NETWORK DESIGN OVERVIEW

Architecture

#Layers

#params

MACs

Top-1 Acc.

Top-5 Acc.

AlexNet

8

61 M

0.72 B

57.2 %

80.3 %

VGG-16

16

138 M

15.5 B

71.5 %

90.1 %

ResNet-50

50

25.5 M

3.91 B

75.3 %

92.7 %

ResNet-152

152

60.2 M

11.3 B

77.0 %

93.3 %

264

∼33 M

∼15 B

79.2 %

94.7 %

∗

101

83.6 M

31.5 B

80.9 %

95.6 %

∗

NASNet-A(6 @ 4032)

-

88.9 M

23.8 B

82.7 %

96.2 %

SqueezeNet

29

1.25 M

0.84 B

57.2 %

80.3 %

0.75 MobileNet

28

2.6 M

0.33 B

68.4 %

-

ChannelNet-v2

28

2.7 M

-

69.5 %

-

ChannelNet-v1

28

3.7 M

0.41 B

70.5 %

-

1.0 MobileNet

28

4.2 M

0.57 B

70.6 %

89.9 %

ShuffleNet (1.5×)

18

-

0.29 B

71.5 %

-

MobileNetV2

24

3.4 M

0.30 B

71.8 %

91.0 %

ShuffleNet (2×)

18

∼5 M

0.53 B

73.7 %

-

NASNet-A(4 @ 1056)

-

5.3 M

0.56 B

74.0 %

91.6 %

MNasNet-92

-

4.4 M

0.39 B

74.8 %

92.1 %

DenseNet-264
ResNeXt-101 (64 x 4d)

Table 2.1: Performance on ImageNet classification. Architectures on the top half of the table
focus on achieving high accuracy levels, while those in the bottom half share the same aim while
focusing on reducing the model size and compute costs. ∗ Uses as input larger image patches,
instead of the conventional 224 × 224.
Despite being 50× smaller in terms of model size in its uncompressed form (i.e. without using
DeepCompression), it results in 33% in energy consumption (Yang et al., 2017a) during inference
compared to the original AlexNet.

MobileNets. Convolutions are important operations for vision applications but, despite their
simplicity, they are very compute intensive. MobileNets (Howard et al., 2017) replace conventional
convolutional layers with a two-layered convolutional module, often referred to as depth-wise
convolutional layer. These layers factorise a standard convolution with a depth-wise convolution
followed by a 1 × 1 convolution to combine the outputs of the previous. Suppose a standard
convolutional layer has as input a tensor with Cin channels and outputs a tensor with Cout

channels. Using depth-wise convolutions translates into convolving each input channel with a
different k × k filter (where k is generally 3) and then concatenate Cout linear combinations,
15

CHAPTER 2. LITERATURE REVIEW

2.2. COMPRESSING NEURAL NETWORKS

by means of 1 × 1 convolutions. Although not mathematically equivalent to the convolution

operation, depth-wise separable convolutional layers are capable of significantly reducing the
number of operations while still offering acceptable feature extraction capabilities. More recently,
MobileNetV2 (Sandler et al., 2018) further reduced the size and MACs of the original network by
designing depth-wise convolutional layers as the core of block a bottleneck residual block.
Table 2.1 shows the performance on ImageNet of various network architectures. Other
architectures not described in this section are included for completeness. These include: VGG (Simonyan and Zisserman, 2014) which significantly improved over AlexNet and introduced the
use of smaller 3 × 3 filters; DenseNet (Huang et al., 2017), which became the state of the art
by extensively using residual connections across the network as oppose to standard ResNets

where these were sparse; ResNeXt (Xie et al., 2017) which relies on wider residual layers that
learn multiple smaller filters whose activations get aggregated before the residual is added up;
ShuffleNet (Zhang et al., 2018a), in which activations are slitted into groups and different filters
are applied to each of them; and MNasNet (Tan et al., 2018), which relies on reinforcement
learning techniques to find the most suitable architecture given memory and compute constraints.

2.2

Compressing Neural Networks

Traditionally, the machine learning community has been primarily driven by the goal of designing
new algorithms that could outperform the state of the art in terms of accuracy levels. With the
rise in popularity of data-driven techniques, e.g. DNNs, such fixation on accuracy resulted in
algorithms with tens of millions of parameters. Deploying these models in the wild becomes a
challenge primarily because of two reasons: first, transferring the model parameters (i.e. the
weights) might require significant time and bandwidth. For example, VGG-16 weights result in
over 500 MB in file size. Secondly, due to the large amount of OPs needed for inference, without
the presence of a GPU these DNNs become unusable in applications where real-time or close to
real-time performance is required. In addition to this, having to rely on a GPU severely limits
the employability of DNNs-based systems primarily due to energy constrains (e.g. a NVIDIA
GTX 1060, a mid-range GPU, requires 120W). In this section we will present an overview of the
different approaches presented in recent years aiming to reduce both model size and compute
costs during inference.

2.2.1

Layer Design Approaches

The choice of layer designs (g.e. number of filters, size of the filters) and the overall network
architecture directly impacts both model size and inference costs. In 2.1.2 we presented some of
the widely use layer designs that ease the training of deeper networks (i.e. residual connections),
encourage weight sharing (i.e. bottleneck layer), rely on small-sized filters (i.e. 1 × 1 and 3 × 3)
16

CHAPTER 2. LITERATURE REVIEW

2.2. COMPRESSING NEURAL NETWORKS

and factorisation of the traditional convolutional layer design (i.e. depth-wise convolutions). Here
we present other layer designs that, although not widely implemented as a general approach
towards the design of lightweight architectures, prove the be advantageous in certain contexts.
Compared to a standard convolutional layer, depth-wise convolutions significantly reduce
the number of operations and parameters. Concretely, the number of operations is reduced by
a factor of r = 1/cout + 1/d2k , where cout is the number of output channels and dk is the filter
dimensions and becomes
dk × dk × cin × df × df + cin × cout × df × df

(2.1)

where df × df are the dimensions of the input tensor. The second term in Eq. 2.1 represents

the dense combination the of feature maps from the first convolution step (i.e. depth-wise). This
term is dominated by the number of channels in both input and output tensors. To alleviate this
issue, which in deeper layers of the network can result into 1M OPs or more, Gao et al. (2018)
propose to replace the dense point-wise operations with sparse ones. One approach would be
to dived the outputs of the depth-wise convolution into isolated g groups and then perform the
point-wise convolution by only fusing the feature maps within a group. This effectively splits
the feature maps of individually transformed channels and is know as group convolutions. Such
strict constrain results in a severe degradation in accuracy as observed by Zhang et al. (2018a).
ChannelNets address this issue by learning a fusing layer that combines the features in every
group with those in contiguous groups. This is efficiently implemented by convolving with a
stride s = g each of the feature maps resulting from the channel-wise convolutions. ChannelNets
results in similar performance to MobileNets while relying on fewer parameters and OPs for
inference. Results are shown in Figure 2.1.
The design space for NNs has grown considerably in recent years. With the aim of reducing
model size Ha et al. (2016) introduced HyperNetworks. A hypernetwork is a NN that generates
the weights of another NN. In their work, the usage of hypernetworks is framed as a tool to
enforce weight sharing across layers resulting in substantially more compact models at the cost
of an increase in OPs during both training and inference. Given a convolutional layer Li in
standard CNN architecture, the cin × k × k × cout tensor representing the filters, fi , can be
generated by using an embedding (i.e. a lower-dimensional representation) of the filter, zi , and a

hypernetwork. A hypernetwork is a two-layered NN that takes as input the embedding zi and
outputs an approximation of fi , fˆi ≈ fi . All the weight embeddings z = {z1 , z2 , ..., zN } have
the same dimensions making it possible to share the first layer of the hypernetwork across all
layers in the architecture. The second layer depends on the number of output channels cout
of each layers, therefore sharing these parameters is limited as in general cout increases with
i, the network’s depth. HyperNetworks have achieved relatively little success probably due to
the impact on latency of the filter generation process. Because of this, applications that require

17

CHAPTER 2. LITERATURE REVIEW

2.2. COMPRESSING NEURAL NETWORKS

real-time performance wouldn’t chose a hypernetowrk despite its compact model representation.
In complex real-world applications such as autonomous driving or activity recognition, image
classification usually is not the first task that the system has to accomplish. Other computer
vision techniques such as object detection may be required first. We know that standard CNNs
apply convolutions uniformly in the feature space regardless of its content, which translates
into high computational costs. This problem scales with the input’s dimensions and becomes a
challenge in real-time applications that requires the processing of high-resolution images. Sparse

roducts for
Dynamic
Computation
Block’s
Networks (Ren
et al., 2018) propose a mask-guided approach by which only regions of
interest
in
the
input
will
be transformed by a given convolutional layer. To this end, SBNet
Neural Network Inference
modifies the standard bottleneck layer (see Figure 2.2b) by adding a gather layer at the top
Surat Teerapittayanon

H.T. Kung
and a scatter layer before
the performing the residual addition. The use of these binary masks

Harvard University
Harvard University
Cambridge,could
MA, USA
Cambridge,
USA
also be categorised
as MA,
an attention
mechanism for faster inference. Other popular object
Email: steerapi@seas.harvard.edu
Email: kung@harvard.edu

detection architectures such as Faster-RCNN (Ren et al., 2015) rely on similar ideas but are often

implemented as a two-step process: first, detect potential locations where objects are present,

dot products (IDP)
these
are(CDP)
often referred to as object proposals; and then, evaluate a image classifying network
Standard
channels used in
Filters
uring feedforward
usingInput
as input Meach
ofwith
the imageOutput
patches where an object is believed to be present. SBNet’s main
easing coefficients,
N Channels
Channels
Channels
ring training. The
motivation is to exploit the sparse nature on LiDAR-based 3D readings on roads by using as
M
N
l in non-increasing
nnels used can be
mask map information and results in over 2× speed-up and better detections rates than methods
or lowered power
g only a beginning
densely scanning the entire scene. By relying on a two-step approach, where PSPNet (Zhao et al.,
a single network
nge, as opposed to
2017) generated object proposals, further speed-ups are achieved.
support different
extend the notion
Proposed (50% IDP)
e specific range of
on the computation
M
NFrozen Filters
Grown Filters
Paged-in Filters
Paged-out Filters
mage classification
Capacity #2
Grown Filters with Retrained Parameters
for MNIST and
Capacity #1
ntly, e.g., by 75%,
Model
Model
We argue that IDP
Upgrade
Downgrade
r devices to lower
ReFilter
Model
rrent computation
Training
Freezing
Input Growing
Channel (Used)
Output
Channel (Used)
th 50% IDP (using
Input Channel (Unused)
Approx. Output Channel (Used)
% in accuracy
on
Seed
Descendant Model
Descendant Model
Multi-Capacity
Output
Channel
(Unused)
ard network
Filter Channel (Used)
Model which
w/ Larger Capacity
w/ Smaller Capacity
Model
duced channel set.
Filter Channel (Unused)

Figure 5: Illustration of the details of model switching of multi-capacity
Fig. 1:ofContrasting
computation
using and
complete
dot product
Figure 4: Illustration
the details of
model freezing
filter growing.
(a) Effect
using the
topis 50%
ofproduct
the input
Multi-capacity
filteronly
sizeone
switching
in layer
NestDNN.
model.
For illustration purpose,
convolutional
is depicted.
(CDP)
inonly
standard
networks
andlayer
incomplete
dot
(IDP) (b)
For illustration purpose,
oneofconvolutional
depicted.
channels
and
filters
as proposed
inUnder
IDP.stanproposed
in this
paper
for a convolutional
layer.
Neural Networks dard CNN, for each filter at a given layer, N input channels are
One Model with Multiple Capabilities. Multi-capacity moceived
increasing used
in the
dotofproduct
computation
(CDP), to compute
the
accumulated
model
size
all the
pruned
models.
This isthat
Figure
2.3:
Two
layer
design
approaches
enable the execution of a NN inference stage capable
se sensor data as corresponding
output
channel.
Under,
forfilter
example,
50% IDP,
del is able to provide multiple capacities nested in a single
achieved
by
an
innovative
model
freezing
and
growing
of filter
adjusting
to 50%
the ofrequirements
application in terms of compute, memory and latency.
ice (see, e.g., [1]). the
uses the first
the input channelsofto the
compute
model. This eliminates the need of carrying potentially a
(i.e., freeze-&-grow)
approach.
ed accuracy,
size, the
corresponding
outputare
channel,
which is from
an approximation
These
diagrams
extracted
McDanel et
al. number
(2017b)ofand
Fang et model
al. (2018).
large
independent
variants with different
ber of In
layers
theand
remaining
of
this
subsection,
we
describe
the
details
of the CDP. Furthermore, only 50% of these filters are used
these
models
can
capacities.
Moreover,
by
sharing
parameters among descensince outputapproach
channels for
thehow
other the
filters
will not be utilized
of the freeze-&-grow
and
multi-capacity
when running on in the next
layer.PSPNets
This leads to aexploit
75% reduction
computation
While
the insparsity
of the
as the
a measure
to mask
uninteresting
dantscene
models,
multi-capacity
modelout
is able
to save potenmodel is iteratively
y requirements
of for 50%generated.
IDP.
tially
a
large
amount
of
memory
space
so
as
to
significantly
regions,
in
other
situations
using
saliency
to
decide
which
portions
of
the
image
to
analyse
might
urrent battery life
reduce its memory footprint.
vice. 4.2.2 Model Freezing and Filter Growing

be more challenging. As a general approach to dynamically adapt the latency of a given NNs,

ontexts is to train
Optimized Resource-Accuracy Profile at Each Capacity.
The generation
theamulti-capacity
model
from
train
single
CNN that could
scalethe
across
the ofwork
of McDanel
et dynamically
al.starts
(2017b)
provides
a simple
mechanism
so. Incomplete
ch as by varying instead
Each
capacity
provided bytothedomulti-capacity
modelDot
has a
a
computation
range
in
high
resolution,
trading
off
accuracy
seed
model
derived
from
filter
pruning.
By
following
the
in MobileNet [2],
Products
(ICP) and
enables
dynamic
adjustment unique
of the optimized
number ofresource-accuracy
feature maps that
a layer
would
profile.
Our
TRR
apfor
power
consumption
latency
as
desired.
sed on
the pruning
current roadmap and the freeze-&-grow approach, the
filter
proach provides
state-of-the-art
performance
identifying
approach
requires
To provide
aIn
solution
for
dynamic scaling
a compu- budget,
produce.
other
words,
givenover
a compute
ICP adjust
the number
of filtersat used
in
multi-capacity
model
is iteratively
created.
upport the desired tation range, we propose to modify CNN training, by adding
and pruning less important filters. As a result, multi-capacity
Figure 4 illustrates the details of freeze-&-grow during the
deally, we would a profile of monotonically non-increasing channel coefficients
18
model
is able to deliver state-of-the-art inference accuracy

first iteration. For illustration purpose, only one convolutional layer is depicted. Specifically, given the seed model,
we first apply model freezing to freeze the parameters of all

under a given resource budget.
Efficient Model Switching. Because of parameter sharing, multi-capacity model is able to switch models with lit-

CHAPTER 2. LITERATURE REVIEW

2.2. COMPRESSING NEURAL NETWORKS

each layer that maximise accuracy while maintaining the overall number of OPs within the
budget. This is possible with the introduction of a profile γ = {γ1 , γ2 , ..., γN } of non-increasing

coefficients that weights each input channel differently. This would result in a model that has
learnt to rely more on the first channels of the inputs instead of relying on all channels equally.
ICP’s principles are architecture agnostic and therefore can be equally used in fully-connected,
convolutional and depth-wise convolutional layers. Although ICP was evaluated by McDanel
et al. (2017b) on relatively simple networks and only MNIST and CIFAR-10 datasets, they
present a simple yet effective way of trading accuracy for compute without having to modify the
network architecture. In Figure 2.3a it is illustrated the impact of using the top 50% channels of
the activations in a given convolutional layer. A more holistic approach was recently proposed
in NestDNN (Fang et al., 2018). This framework enables the deployment of multi-capacity
concurrent NN-based applications on devices depending on memory and compute budget of
these at a given time. The motivation is that real world applications (e.g. scene understanding)
require the execution of multiple sub-applications (e.g. object detection, image classification)
and it would be intractable to design networks of different complexity for the wide variety of
devices available. NestDNN enables the execution of NNs in a multi-resolution fashion depending
on the application requirements and the latency budget of the system. A diagram is shown in
Figure 2.3b illustrating this idea.

2.2.2

Post-Training Approaches

The design space of DNNs allows great flexibility on how we stack layers primarily due to high
dimensional (HD) nature of the operations performed in those. Despite this flexibility, it has been
proven to be a challenge is to design compact architectures that achieve high accuracy levels. To
address this, several techniques aim to relax the choice of architecture design following a two-step
approach: first, design an architecture that is capable of achieving the desired accuracy levels; and
then, once the model has been trained, discard those elements in the network that are redundant
while maintaining (or marginally decreasing) the accuracy levels. Because this compression
techniques use a pre-trained network, we call them post-training compression techniques.
Network pruning (Hassibi and Stork, 1993; Ström, 1997; Han et al., 2015) and factorisation
methods (Kim et al., 2016; Denton et al., 2014) have been widely used to compress CNNbased models. DeepCompression (Han et al., 2016a) could be seen as the first compression
framework that aggregates classical compression methods, i.e. pruning, clustering and encoding,
capable of yielding significant model size reduction rates with no or small drop in accuracy. The
DeepCompression framework is split into three stages: the first stage performs standard weight
pruning by which connections with magnitude below a threshold value, this reduces weights
by 10× when making use of compressed sparse row (CSR) format; next, weights of similar
values are clustered together and a code book is generated in order to decode the weights during

19

CHAPTER 2. LITERATURE REVIEW

2.2. COMPRESSING NEURAL NETWORKS

inference, this results in an additional 15× to 20× model reduction; the final stage makes use
of Huffman encoding (Huffman, 1952) to encode both weight values and look up table indices.
DeepCompression is capable of reducing the model size of networks such as AlexNet or VGG-16
by 35× and 49× respectively incurring in a decrease of Top-1 accuracy on Imagenet of less than
1%. In addition, this framework was successfully used in SqueezeNet resulting in an architecture
offering AlexNet performance with a 500× smaller model size. A similar framework was proposed
by Wang et al. (2016), here the processing was done in the frequency domain and relying on
discrete cosine transforms. Despite the high compression rates achievable by these methods in
certain networks, it is unclear from the literature how does the decoding process of the weights
Beyond Filters:
Compact
Map fortables
Portable
Model
impact latency. In particular,
the impact
ofFeature
the look-up
to Deep
decode
the Huffman codes and

of the
code book
to retrievemethods
the original
eachcompression
clustered and
weight.
Table the
3. Anuse
overall
comparison
of state-of-the-art
for deep value
neural of
network
speed-up, where rc1 is the compression ratio of convolution filters, rc2 is the compression ratio of feature maps, and rs is the speed-up ratio.
Model

AlexNet
Filters (232 MB)
Maps (2.5MB)
Multiplications
(7.24 ⇥ 108 )

VGGNet-16
Filters (572 MB)
Maps (52 MB)
Multiplications
(1.54 ⇥ 1010 )

ResNet-50

Filters (97 MB)
Maps (40 MB)
Multiplications
(5.82 ⇥ 109 )

Evaluation
r c1
r c2
rs
top-1 err
top-5 err
r c1
r c2
rs
top-1 err
top-5 err
r c1
r c2
rs
top-1 err
top-5 err

Original
1⇥
1⇥
1⇥
41.8%
19.2%
1⇥
1⇥
1⇥
28.5%
9.9%
1⇥
1⇥
1⇥
24.6%
7.7%

SVD
5⇥
1⇥
2⇥
44.0%
20.5%
-

XNOR
32⇥
32⇥
64⇥
56.8%
31.8%
-

Pruning
35⇥
1⇥
42.7%
19.7%
49⇥
1⇥
3.5⇥
31.1%
10.9%
-

Perforation
1.7⇥
1⇥
2⇥
44.7%
1.7⇥
1⇥
1.9⇥
31.0%
-

CNNpack
39⇥
1⇥
25⇥
41.6%
19.2%
46⇥
1⇥
9.4⇥
29.7%
10.4%
12.2⇥
1⇥
4⇥
7.8%

RedCNN
5.12⇥
2.45⇥
4.31⇥
42.1%
19.3%
6.87⇥
3.07⇥
9.63⇥
29.3%
10.2%
4.35⇥
3.71⇥
5.82⇥
25.7%
8.2%

fecting the accuracy of the original network. If we adopt
were significantly reduced. The results are extremely enFigurestrategy,
2.4: An
comparison
of somera-of the
state ofe.g.,
thethe
artcompressed
post training
this similar
the overall
convolution
filter compression
couraging,
ResNetcompression
can recognize over
Herescheme
Pruning
to the
DeepCompression
framework.
Rc1This
stands
for compression
tio rctechniques.
of the proposed
can refers
be further
multiplied
a
500 images
per second.
efficiency
can also be inher1
for convolutional
filters,
for compression
ration
of fine-tuning
feature maps,
andtherefore,
rs for speed-up
c2 almost
factorratio
of around
4⇥, e.g., we can
obtainRan
17.4⇥
ited
into the
process,
the compressed
Results
foronboth
Pruning
and which
CNNPack
have 8-bit
those
forapplied
RedCNN
filter ratio.
compression
ratio
ResNet-50
model,
is su- shown
networks
can bequantisation,
quickly adjusted
when
them to a
kept
32-bit.
RedCNN
is theHowever,
only compression
technique
reducesthe
thepractical
memoryspeed-up
foot-print
periorare
to all
theat
other
comparison
methods.
8-bit
new
dataset. that
In addition,
ratios of
of activations
without
having
rely be
ondirectly
heavy quantisation.
This
tablelower
is extracted
from Wang theo(or other
unconventional
format)
value to
cannot
runtimes were
slightly
than the corresponding
used et
in generic
devices (e.g., GPU cards, mobile phones),
retical speed-up ratios rs due to the costs incurred by data
al. (2017).
and thus we did not try them in the experiments of this
transmission, pooling, padding, etc.. Note that, the runtime
paper. In summary, the proposed RedCNN can achieve
reported here is a bit higher than that in (Vedaldi & Lenc,
To alleviate
theand
additional
required
undodue
or decode
the weights,
otherand
approaches
considerable
compression
speed-upprocessing
ratios, which
can to2015),
to different
configurations
hardware envia RedCNN
(Wang
et al., 2017) focused on discarding
makesuch
existing
deep models
portable.
ronments.redundant filters instead of redundant

individual weights. The intuition behind this work is that the most compact representation of

Table 4. Runtime of the proposed deep neural network compres7. Conclusions and Discussions
the weights
in a layer
that
that results in uncorrelated activations coming from different filters.
sion algorithm
on different
modelsisper
image.

Compression
methods
for learningbetween
portable feature
CNNs are urAn optimal
projection
of the inputs
should thus not
only remove
redundancy
time
Original
RedCNN
speed-up
gently required so that neural networks can be used on moLeNet
0.17 msorthogonality
0.04 ms
4.3⇥ them, but also preserve the discriminability of the filters
maps
by preserving
among
bile devices. Besides convolution filters, the storage of feaAlexNet
1.28 ms
0.74 ms
1.7⇥
that
generated
them.
This
framework
trained
anda iteratively
modifies
ture amaps
also network
accounts for
larger proportion
of the onVGGNet-16
16.67 ms
3.38 ms
4.9⇥takes as input
line
memory
usage,
we
thus
no
longer
search
useless conResNet-50
9.03
ms
1.84
ms
4.9⇥
the filters in each layer by minimising the projection between activation maps until convergence.
nections or weights of filters. In this paper, we present a
UnlikeInprevious
approaches,
RedCNN
does
result in a compression in activations which translates
Runtime.
fact, most
of comparison
methods
cannot
feature map dimensionality reduction method by excavatsignificantly accelerate the deep network for various addiing and removing redundancy in feature maps generated by
tional operations. For example, (Han et al., 2016) needs 20 different filters. Although the portable network learned by
to decode the CSR data before testing, which slows down
our approach has significantly fewer parameters, its feathe online inference and will not achieve the comparable
ture maps can also preserve intrinsic information of the
compression and speed-up ratios with those of the prooriginal network. Experiments conducted on benchmark

CHAPTER 2. LITERATURE REVIEW

2.2. COMPRESSING NEURAL NETWORKS

into a reduction of run-time memory during inference. This and the previous techniques described
in this section are compared in Figure 2.4 for three popular architectures on the ImageNet dataset.
Similarly to Wang et al. (2017), the work of Louizos et al. (2017) proposes a Bayesian approach
to prune filters (instead of weights) and assign per-layer quantisation profiles. This work builds
on top previous approaches: the work of Kingma et al. (2015), which was the first successful
application of Bayesian techniques to inferring the posterior probability of the weights efficiently
by making use of the reparameterisation trick ; and more recently the work of Molchanov et al.
(2017) which enabled learning high dropout rates (previous works were limited to maximum
dropout rates of r = 0.5) for each filter in the network leading to high sparsity rates.
All the methodologies here presented focus on compressing large networks such as AlexNet or
VGG, or are only evaluated on relatively simple datasets such as MNIST, SVHN or CIFAR-10. We
could argue that part of the success of these techniques comes from the fact that the starting point
in the compressing pipeline is a heavily overparametersied network. Little attention has been paid
to compressing networks that are by design small. Network designs that lie in this category would
be those with number of parameters in the range of two to five million, as is the case of MobileNets
and other networks shown in the lower part of Table 2.1. AutoML for Model Compression, or
AMC (He and Han, 2018), which leverages reinforcement learning (RL) for efficient search given
scenario-specific policies. These policies vary between latency-critical, resource-constrained and
quality-critical applications. This framework, in addition to be evaluated on large networks such
as VGG-16 and ResNets of different depth, it’s also evaluated on MobileNet. It is evidenced
from the reported results that compressing compact network architectures is considerably more
challenging than doing so with an overparameterised net. AMC achieves speed-ups for MobileNet
of around 1.5× and 2× when deployed on a NVIDIA TItan XP GPU or Google’s Pixel-1 phone
respectively with no accuracy degradation.

2.2.3

Using Deterministic Elements

In recent months a few NN-based algorithms that introduce deterministic elements in the network
have been presented in top-rated venues. They all share the same motivation for this decision:
reduce model size. In the next few lines we will be presenting a few of these works a long with
their advantages and limitations.
In convolutional neural networks for image classification, a large portion of the model size
account for the convolutional filters of each layer. Reducing the number of filters could damage
the performance of the network. In order to do so, Juefei-Xu et al. (2017) propose to replace
standard convolutional layers with a two-step convolutional layer. The first step convolves the
input with a set of deterministically generated filters that match the design of hand-crafted local
binary patterns (LBP) traditionally used as a texture descriptor (Ojala et al., 1994; Dalal and
Triggs, 2005). This approach receives the name Local Binary Convolutional Neural Networks, or
21

CHAPTER 2. LITERATURE REVIEW

2.3. LOW PRECISION NETWORKS

LBCNNs. This first step doesn’t require any learnable parameter. The second step applies a
linear combination of the activations of the first by learning a single 1 × l array of scalars, where l

is the number of LBP filters used in the first stage. These scalars are learnt via back-propagation
and achieves competitive results in datasets of the level of complexity of CIFAR-10. A similar idea
was presented in DFCNet (Qiu et al., 2018) in which the convolutional filters are constructed as a
dense combination of a set of deterministically generated Fourier Bessels basis. This approach is
capable of maintaining the accuracy levels of the baseline networks on MNIST and LFW (Huang
et al., 2007) while reducing the number of operations required during inference by 3×. Both
DFCNet and LBCNNs replace standard convolutional layers in which filters are learnt entirely
during back-propagation with a factored convolutional layers in which of term is deterministic and
the other has to be learnt. Similarly, in WSNet (Jin et al., 2018) the filters are not learnt directly.
However, unlike the previous two methods that rely on factorisation, here the deterministic
element in the layer is the sampling process by which each individual filter is generated. WSNet
learns a single A × B × N filter that is deterministically sample to generated Cout filters of shape

Cin × K × K, where K < A and K < B. The sampling induces weight sharing in both spatial

and channel dimensions and, by making use of integral image it saves computing redundant
operations. Because the sampling process is deterministic, WSNets can be trained with standard
back-propagation. It results in 9× model size reduction on ResNet-50 with a drop of 1% in
accuracy on CIFAR-10.
The techniques presented in this section offer an interesting new approach to designing
compact architectures for CNN-based image classification applications. However, as evidenced
from the results, the reliance on deterministic elements comes at the cost of a drop in how flexible
these networks are to unseen images. In other words, it limits the generalisation capabilities of
the networks. None of the approaches here presented are capable of providing significant model
size reductions while maintaining acceptable accuracy levels on more challenging tasks such as
those of the level of complexity as the ImageNet dataset. Similarly to what was stated in 1.4.1.2,
the choice of which deterministic elements to use is not trivial.

2.3

Low Precision Networks

Complementary to the compression techniques proposed by the machine learning community
in recent years, the design of low-precision networks has attracted considerable interest. This
section presents several of the most popular approaches making use of aggressive quantisation
with the aim of reducing model size and latency. We will begin by introducing binary networks,
then ternary networks, hybrid networks that combine both binary and not-binary weights and
finally networks that rely on integer-only arithmetic.
In binary networks, parameters are represented with only one bit, reducing the model size
by 32×. Expectation BackPropagation (EBP) (Soudry et al., 2014) proposes a variational
22

CHAPTER 2. LITERATURE REVIEW

2.3. LOW PRECISION NETWORKS

Bayes method for training deterministic Multilayer Neural Networks, using binary weights and
activations. This and a similar approach (Esser et al., 2015) give great speed and energy efficiency
improvements. However, the improvement is still limited as binarised parameters were only
used for inference. Many other proposed binary networks suffer from the problem of not having
enough representational power for complex computer vision tasks, e.g. BNN (Courbariaux and
Bengio, 2016), DeepIoT (Yao et al., 2017), eBNN (McDanel et al., 2017a) are unable to support
the complex ImageNet dataset. On the other hand, BinaryConnect (Courbariaux et al., 2015)
and Binary-Weight-Networks (BWN) (Rastegari et al., 2016), were capable of achieving state of
the art results on CIFAR-10 and ImageNet datasets respectively. XNORNet (Rastegari et al.,
2016) employed the sign function as the non-linearity to achieve binary activations in addition to
binary parameters. With this approach, 32-bit precision operations in convolutional layers could
be replaced with binary XNOR and POPCOUNT operations in supported hardware resulting
in a 58× speed-up. BinaryConnect extends the probabilistic concept of EBP, it trains a DNN
with binary weights during forward and backward propagation, done by putting a threshold
for real-valued weights. It is a common practice in the design of binary networks to not learn
the binary weights directly; instead, full-precision weights are maintained and learned during
the training as proxies for the binary weights. Because the sign function is non-differentiable,
binary NNs often employ the Straight-Through-Estimator (STE) (Bengio et al., 2013) in order to
enable gradient flow during back-propagation and consequently update the full-precision proxies.
The literature of binary networks presents a variety of ad-hoc techniques with the promise of
improving training stability and generalisation. Some of these are: the choice of optimiser,
clipping weights and/or gradients and the choice momentum for batch-normalisation layers. We
refer the interested reader to Anonymous (2019) for a systematic study of these techniques.
Despite the success of binary networks to match the performance of networks such as AlexNet
or VGG-16, they haven’t been able to maintain the rapid development seen in regular full-precision
networks in terms of accuracy. A series of works have explored the increase in weight resolution
as a measure to improve overall accuracy. In TernaryNet (Zhu et al., 2016) quantised parameters
to one and a half bits and represented weights using {−1, 0, +1}. Having zero allows efficient
hardware implementations when kernels are sparse. The usage of ternary networks has also been

used as a measure to dramatically (over 99.5% in some cases) reduce the number of multiplications
needed during inference (Tschannen et al., 2018). Other works, such as ABCNet (Lin et al., 2017)
make use of an ensemble of binary convolutional layers as a measure to maintain the accuracy
levels of 32-bit precision networks. By doing this, ABCNet achieves ImageNet accuracies of Top-1
68.4% and Top-5 of 88.2% for ResNet-34, a drop of 4.9% and 3.1% compared to the full-precision
version of the network.
In addition to the challenges of training binary neural networks and the apparent limitation
they have to achieve state of the art results, the lack of efficient software packages that take
advantage of binary operations is another reason why binary networks are not widely used
23

CHAPTER 2. LITERATURE REVIEW

2.3. LOW PRECISION NETWORKS

beyond research. For this reason, part of the machine learning community believe that 8-bit
networks is the right balance between data precision, accuracy and efficient compute. Jacob
et al. (2018) present a training framework by which networks can be trained end-to-end using
integer-arithmetic only with minimal loss in accuracy compared to their full-precision counterpart
networks. This is possible by quantising during training to 8-bits both weights and activations
while enabling the bias terms (which represent a negligible portion of the total parameters) as
32-bit integers. An efficient implementation, part of Arm’s CMSIS library (Lai et al., 2018a), that
takes advantage of 8-bit quantised networks on 32-bit capable hardware enables the execution of
NNs on Arm Cortex-M based systems that support SIMD instructions.

24

Chapter 3

Completed Work
This section presents a novel technique to model compression that enables the generation of
convolutional filters on-the-fly by making use of a set of codes that can be generated deterministically and form a base for the filter. This technique has been validated for keyword spotting
applications resulting in models of 15.8kB while still achieving over 91% accuracy on Google’s
Speech Commands Dataset (Warden, 2017). This work was first presented in SysML-18 and
in the International Workshop on Embedded and Mobile Deep Learning co-located with ACM
MobiSys-18. It has been also validated for image classification tasks and published in IJCAI-18.

25

On-the-fly deterministic binary filters for memory efficient
keyword spotting applications on embedded devices
Javier Fernández-Marqués† , Vincent W.-S. Tseng‡ , Sourav Bhattacharya∗ , Nicholas D. Lane†∗
†

University of Oxford, ‡ Cornell University, ∗ Nokia Bell Labs

ABSTRACT
Lightweight keyword spotting (KWS) applications are often
used to trigger the execution of more complex speech recognition algorithms that are computationally demanding and
therefore cannot be constantly running on the device. Often KWS applications are executed in small microcontrollers
with very constrained memory (e.g. 128kB) and compute capabilities (e.g. CPU at 80MHz) limiting the complexity of
deployable KWS systems. We present a compact binary architecture with 60% fewer parameters and 50% fewer operations (OP) during inference compared to the current state of
the art for KWS applications at the cost of 3.4% accuracy
drop. It makes use of binary orthogonal codes to analyse
speech features from a voice command resulting in a model
with minimal memory footprint and computationally cheap,
making possible its deployment in very resource-constrained
microcontrollers with less than 30kB of on-chip memory.
Our technique offers a different perspective to how filters
in neural networks could be constructed at inference time
instead of directly loading them from disk.

CCS Concepts

convolutional filters from the model, resulting in models
with smaller memory footprint and a more efficient inference stage. Inspired by ResNet’s bottleneck layer [15] and
LBCNN [19], where the suitability of sparse binary filters for
image classification tasks is proven, we present a vastly reduced architecture from those generally use for vision problems and adjusted it at both macroarchitectural and microarchitectural levels to better capture the temporal dimension of input audio commands. Here we make use of Deterministic Binary Filters, DBFs [29], that are constructed as
a linear combination of deterministic binary codes.
We compare our work to HelloEdge [34] following their
microcontroller classification scheme and particularly focusing on the Small (S) group, where the model size limit is
set to 80kB and the maximum number or OPs during inference is 6M. Likewise, we use Google’s Speech Commands
Dataset [33] to train and evaluate our architecture. BinaryCmd requires significantly less parameters and OPs than
the best architecture in [34] that relies in depthwise separable convolutional neural networks (DS-CNN) [16, 9] and
that is, to the best of our knowledge, the current state of the
art for KWS applications. This work is an extension of [12]
and offers the following contributions:

•Computing methodologies → Speech recognition; Neural networks; •Theory of computation → Network optimization;

• In [29] we introduced and validated the usage of DBFs
in medium sized networks for image classification, here
we demonstrate their suitability for audio on architectures with a extremely small memory-footprint.

1. INTRODUCTION
KWS has become a popular always-on feature in smartphones, wearables and smart home devices. It serves as the
entry point for speech based applications once a predefined
command (e.g. “Ok Google“, “Hey Siri”, ”Alexa”) is detected
from a continuous stream of audio. Because KWS applications are always running they follow a very efficient architectural design and are often implemented on small dedicated
microcontrollers. These devices are constrained in terms of
memory and compute capabilities, limiting the complexity
and memory footprint of the deployed model.
We present BinaryCmd, read as “binary command”, a
novel neural network (NN) architecture for audio that represents the weights as a combination of predefined orthogonal binary basis that can be generate very efficiently onthe-fly. This property would enable the off-loading of the
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.

EMDL’18, June 15, 2018, Munich, Germany
c 2018 ACM. ISBN 978-1-4503-5844-6/18/06. . . $15.00
DOI: https://doi.org/10.1145/3212725.3212731

• We show that our architecture leads to state of the art
results in the set of architectures with fewer than 3M
OPs and 30kB of model size. We compare BinaryCmd
to all the baselines in [34].
• We implemented our deterministic binary code generator on an ARM Cortex-M7 microcontroller and showed
that on-the-fly filter generation results in an overhead
of just 13ms for our top performer network.

2.

RELATED WORK

Deep learning for embedded devices has become increasingly popular in recent years for a variety of applications including image classification, speech recognition and health.
Energy efficiency and low computational complexity are two
properties that are specially important in memory and compute restricted platforms [22] and they become a major concern when considering the commercialization of such applications. It has proven to be a challenge for the research
community to design algorithms and architectures that meet
those requirements simultaneously for complex tasks [23].
The existing research addressing these issues can be classified into three categories: NN compressing techniques, novel
NN layer architectures and novel system architectures.

Compression techniques. Most techniques fixate their
efforts in reducing the number of weights and in exploiting sparsity. Existing compression techniques such as DeepCompression [14] and CNNPack [30] are a conglomerate of
clustering, quantisation and word encoding techniques. A
step further is taken by [31] in which, for a given convolutional layer, filters are restricted to produce feature maps
with minimal redundancy.
Layer architectures. Works lying in this category include bottleneck [15] layers, that reduce the number of channels of the input tensor by using 1 × 1 filters prior to to convolve it with a spatially larger kernel with the aim of reduce
the number or of OPs. Along the same lines, depthwise [16]
convolutional layers split the standard convolutional layer
into two convolutional layers achieving a reduction in operations of 1/N + 1/Dk2 , where N is the number of output
channels and Dk is the kernel spatial dimensions. [24] proposes a technique to dynamically adjust the number of input
channels and filters to use during inference time. [6] exploits
kernel sparsification and separation allowing large NN-based
models run efficiently on embedded hardware.
System architectures. DRAM accesses severely impact both throughput and energy efficiency [8]. A number of works [13, 7, 11] explore parallel architectures combined with several levels of local memory hierarchy in order
to reduce the accesses to DRAM. Such systems, often designed as a coprocessor (FPGA or ASIC) that sits next to
the CPU, reach unseen power efficiency levels, as is the case
of Origami [7] promising 803 GOp/s/W at 0.8 V. It uses
an SRAM module of 344 Kbit to store image patches loaded
from DRAM and two sectors of registers to temporally store
convolutional filters and rows of pixels from the patches in
the SRAM, respectively. For a broad evaluation of the current advances in the field of efficient DNNs we refer the
interested reader to the Eyeriss Project’s survey paper [8].
With respect to KWS, several approaches have been explored including the use of DNN [32], LSTM [27], CNN [28]
or CRNN [5], being this last technique able to offer a good
trade-off between accuracy, model size and inference costs.
[34] provides a complete comparison between several approaches to KWS on constrained platforms in addition to
show the suitability of depthwise convolutions for this task
with lowest memory usage and the highest accuracy rates
among the previously mentioned techniques.

3.

A BINARY NETWORK FOR KWS

In this section we describe the design of the evaluated
KWS architecture, including how the convolutional filters
are constructed and how this novel filter design differs from
those found in standard CNN-based architectures.
System Overview. The implemented KWS system is
comprised of two fundamental blocks where speech features
are first extracted from a 1s input voice command and are
then fed to a NN-based block that outputs the id of the
detected voice command. The system’s macroarchitecture
is depicted in Figure 1. We follow the same strategy as
in [34] to extract an array of 49×10 MFCC 1 speech features
from the input speech signal and feed them to our network,
BinaryCmd. This NN-based block hierarchically transforms
1
Mel-frequency cepstral coefficients (MFCCs) are commonly
used as features in speech recognition systems. They are
part of the ETSI [10] standard for mobile phones.

the audio features input into a keyword id that identifies the
command detected by the KWS system.
Architecture. We present a novel NN block containing
the following elements: three nested on-the-fly convolutional
layers (they represent BinaryCmd’s core, as seen in Figure 2)
followed by a standard convolutional with filter dimensions
inCh × 3 × 3 × numCls (where numCls, is the number of
classes in the dataset and inCh the number of channels of the
input tensor. This parameter varies between each evaluated
configuration), max-pooling and fully connected layers. All
convolutional layers use ReLu as activation functions and
have been trained using batch normalization [17].

Figure 1: System arch.

Figure 2: BinaryCmd core.

On-the-fly convolutions. Unlike standard CNNs, our
architecture does not learn convolutional filters directly. Instead, it learns weighting coefficients of deterministic binary
basis that are combined in a linear fashion manner to generate the filters [29]. We call this filters deterministic binary
filters, or DBFs. We use orthogonal variable spreading factor, OVSF2 , binary codes of length 2n , n ∈ N, to generate
these basis. OVSF codes are designed in such a way that for
any given code length L, there are L different OVSF codes
and that are orthogonal to each other. Therefore, to generate a filter of dimensions dim = W × H × C, our OVSF
code generator could output at most dim different codes that
would form a basis of the Rdim space. Intuitively, by combining all OVSF codes of a given dimension dim we could
perfectly represent any filter of that dimension. On the other
hand, using fewer OVSF codes would result in a coarser representation of the target filter. Mathematically, the quality
of a filter generated by combination of OVSF codes could
be measured as:
Ek =

2
fk0 − fk 2 =

bρ·lc

X
i=0

2

αki Bki − fk

< ,

(1)

2

where ρ ∈ [0, 1] is the ratio of codes to use in order to approximate filter fk , l is the total number of OVSF codes of
length l = W HC, Bki is the ith OVSF code and αji ∈ R its
associated weight. During training, we learn those weights.
 is the difference between the the approximated, fk0 and the
real filter, fk . Here fk0 represents a DBF. Intuitively,  → 0
as we increase the ratio of binary codes used. When ρ 6= 1,
the product p · l is rounded to the nearest integer value.
2
OVSF codes were introduced for 3G communication systems as channelizations codes aiming to increase system capacity in multi-user access scenarios[2]. They have been extensively studied in the wireless community [4, 26, 20, 25]
and widely used commercially in 3G mobile systems.

+
Convolution

Output
These codes can be
generated efficiently by a recursive algorithm similarly to how Hadamard matrices are constructed.
A detailed explanation of how OVSF codes are generated in
our system is presented at the end of this section.

..

OVSF Bases
Generation

.

-1.3

0.9

0.2
-0.4
-1.3
0.7
3
bi1=, b̃
[b̃2i1,, b̃b̃i23, ,b̃...
bikk ==[1,[1,
−1,
2, 1,2,
... 1,
− 1]
bi = [b̃
b̃b̃NiN]] b
−1,
... -0.8
− 11]
i , ...
-.03
0.3 22.1 3

-1.1

i

i

i

i

.
.. -1 1 -1 -1

i

-0.4

fi =

-1 -1
1 1
-1 -1
1 -1
1 -1 -1 1

1.7

-1.3

Each row of these matrices are OVSF codes. By design,
they are orthogonal to each other, making it possible to use
them as basis of R . Therefore, each Hadamard matrix
verifies the following property:

1
2
3
N
N
k
bi =1.2 [b̃1.7
2, 1, ... − 2]
-0.5 , -1.3
-0.5 , -1.2
-2.8 , ...
i b̃
i b̃
i 3.2 b̃i ] wi = [wi , wi , wi , ...wi ] bi = [1, −1,L
1.2
1.7
-1.3
-1.3

-1 11 -11 -1-1 1 2
1
N
bi = [bi1 , bi2 , bbi i3=, [b...b
=] b[1,
1,131,
...0]
b
== [1,
[1,0,−1,
1,
k1 0,
1
2 ] 3 bi N
2 −1,
-1
-1...−1]
, ...b
= [1,
−1,
1,
0, 1,0,
...1]
-1
-1
,-1...-1
b̃iN11] -1
biikbi2=
[1,
2,1,1,...1]
... − 1]
i , bii , bib
i =i [b̃ii , b̃i ,1b̃i 1
N
..
[0, 1, 1, 0, 2...1]
1 1 -1 1
=N [0,
0,iN =...1]
k 1, 1, b
3i
-1 -1 1 1 .
bi = [bi1 , bi2 , bb
i , ...bi ] bi = [1, −1, −1, 1, ...−1] bi = [1, 0, 0, 1, ...1]
-1 -1 1 1
N
bi = [0, 1, 1, 0, ...1]
1 2 3
N

Reshape

0.2
1.2

+



1 1
1
1



 
1 1
1 −1 1 −1

H0 = 1 , H 1 =
, H2 = 
1 1 −1 −1 (3)
1 −1
1 −1 −1 1

-1.3
1.5

0.9

-0.5 -0.5
-2.8
-0.4
2.1
-0.4
-1.3
0.9

..

-0.5

2.1

2.1
-0.5

-0.4

-0.4
-2.8

-1.3

.

0.0

Hn Hn| = 2n In

αi = [αi ,αi ,αi ...αi ]

Figure 3: From OVSF codes to DBFs. Each code bki is
first reshaped to match the final filter dimensions, becoming b̃ki . Then, the reshaped codes in b̃i are combined
using the learnt weights αi .

C4,1=(1,1,1,1)
codes creation process
TheOVSF
filter
Weightsusing the OVSF basis can be
basis
= {[1, 1, 1, 1], [1, 1, -1, -1]}
didactically illustrated as{0.5,in-0.7}Figure 3: First the generator
Convolutional
"
#$
1 1
outputs a set of!"12n1#−dimensional
arrays
Filter of [+1, −1] elements;
,
1 1
-1 -1
!
"
-0.2 -0.2
then Reshape
the arrays get reshaped
the dimensions of
+ to match
1.2 1.2
the convolutional filter (a 4-dimensional tensor); and finally
they get combined using the learned weights. We use the
generated filters in our convolutional layers. Training filters that are a weighted combination of binary basis can be
done using standard backpropagation. Once the OVSF basis and their associated weights are combined, the forward
pass evaluation is done in the same way as a standard CNN.
During backpropagation, the filters are decomposed in basis and weights pairs and these last ones get updated while
maintaining the basis constant.
Network quantisation. Is not uncommon to find embedded devices without floating point units and that are
therefore restricted to integer arithmetic. Even though training is generally done at 32-bit precision, existing works [18,
23, 14] have proven the suitability of using 8-bit quantisation in order to reduce model size. Motivated by this,
we implemented 8-bit quantisation using Tensorflow’s fakequantization operation when training our KWS system. In
Section 4 we provide accuracy results of all of our experiments with and without quantisation. A common criticism
to systems the take advantage of 8-bit precision for their
weights and activations is the lack of support from hardware manufacturers to efficiently operate with low precision
arithmetic. The existing software kernels for ARM’s Cortex
microcontrollers, CMSIS-NN [21], makes it possible to take
advantage of using 8-bit words resulting in higher throughputs and more energy efficient inference stages.
Generating OVSF codes.
DBFs can be generated
on-the-fly by combining OVSF codes. The choice of using
OVSF is not arbitrary. These codes have the property of
being able to be constructed recursively given a seed code
in the form of a squared matrix:

C2,1=(1,1)

OVSF

Hn =



Hn−1
Hn−1

Hn−1
−Hn−1



(2)

where Hn is the L × L Hadamard matrix, with L = 2n ,
n ∈ N. An example of constructing Hn=2 is shown below:

(4)

where In is the n × n identity matrix. These codes can
be also generated as a recursive process in a binary tree [3]
form making it possible to retrieve individual (leaf or node)
codes without having to explicitly generate the entire tree.
We use this approach in our implementation.

C4,2=(1,1,-1,-1)
C1,1=(1)
C4,3=(1,-1,1,-1)
C2,2=(1,-1)
C4,4=(1,-1,-1,1)
L=1

L=2

L=4

C8,1=(1,1,1,1,1,1,1,1)
C8,2=(1,1,1,1,-1,-1,-1,-1)
C8,3=(1,1,-1,-1,1,1,-1,-1)
C8,3=(1,1,-1,-1,-1,-1,1,1)
C8,5=(1,-1,1,-1,1,-1,1,-1)
C8,6=(1,-1,1,-1,-1,1,-1,1)
C8,7=(1,-1,-1,1,1,-1,-1,1)
C8,8=(1,-1,-1,1,-1,1,1,-1)
L=8

Figure 4: Code Tree for OVSF code generation. Note
that the codes of the first three levels are exactly those
in Eq. 3.

Mutual orthogonality and “recursiveness” were the two
properties that made these codes an attractive option to
fit our purpose of generating DBFs. In Section 4.4 we analyse the costs of generating OVSF codes and in Section 5 we
highlight some limitations of these codes.

4.

EVALUATION

4.1 Dataset and Method
The Google’s Speech Commands dataset is comprised of
65k one-second long single-word audio clips from thousands
of different people. There are 30 different keywords that
can be classified into three groups: know expression, commands like “yes”, “no” or “up”, “down”; silence (i.e. a audio
clip with only background noise); and unknown commands
(e.g. “happy”, “Sheila”, “cat”) for the remaining 20 keyword
classes. Summarising, this results in 12 different classes.
We evaluate three configurations of BinaryCmd with a
focus on reducing on-device memory footprint and number
of OPs per inference pass while maintaining acceptable accuracy rates that outperform other models [32, 28, 5, 27]
found in the recent literature with comparable number of
OPs. The three configurations share the majority of network parameters and only differ in the number of filters,
stride and ratio parameters used in our on-the-fly convolutional layers. The parameters used in our experiments are
shown in Table 1. The spatial dimensions of the filters in
the on-the-fly module kept fixed at: 4 × 8, 4 × 4 and 4 × 4.

Config

#Filters

Strides [x, y]

Ratios (ρ)

Model

Acc.

Memory

OPs

A2S/A2OPs

A

[64, 8, 32]

[2, 2], [2, 2], [1, 1]

[1.0, 1.0, 1.0]

B

[64, 16, 16]

[2, 2], [2, 2], [1, 1]

[1.0, 0.5, 1.0]

C

[16, 16, 16]

[2, 2], [1, 1], [1, 1]

[1.0, 1.0, 1.0]

DS-CNN [34]
CRNN [34]
GRU [34]
LSTM [34]
Basic LSTM [34]
CNN [34]
BinaryCmd-A
BinaryCmd-B
BinaryCmd-C
DNN [34]

94.4%
94.0%
93.5%
92.9%
92.0%
91.6%
91.4%
91.2%
91.0%
84.6%

38.6kB
79.7kB
78.8kB
79.5kB
63.3kB
79.0kB
24.5kB
22.8kB
15.8kB
80.0kB

5.4M
3.0M
3.8M
3.9M
5.9M
5.0M
1.8M
2.3M
2.6M
0.16M

2.45/17.48
1.18/31.33
1.19/24.6
1.17/23.82
1.45/15.59
1.16/18.32
3.73/50.78
4.00/39.57
5.76/34.96
1.05/528.75

Table 1: Parameters in BinaryCmd for each configuration. All parameters are given in triplets since there are
three on-the-fly convolutional layers (see Figure 2).

This work has been implemented in TensorFlow [1] using as base the source code provided in [34]. We therefore
maintained the use of Adam optimizer, batch size of 100,
30K learning iterations and initial learning rate of 5 × 10−4
and decreased by factors 0.2 and 0.5, after 10k iteration and
20k iterations respectively. We maintained the same dataset
splitting ratios where 80% of the commands are used for
training, for 10% validation and the remaining for testing.

4.2

Tuning BinaryCmd

Unlike in [34], where each architecture has been optimally
trained after performing an exhaustive search for feature
extraction and NN model hyperparameters, the work here
presented only modifies the number of training steps from
the default parameters provided in [34] source code, leaving room for more efficient training set-ups. Furthermore,
our implementation applies 8-bit quantisation to all layers
except the first convolutional layer, meaning that further
reducing the model’s memory footprint is also possible. In
Table 2 we present the accuracy values reached by each of
the evaluated configurations with and without 8-bit quantisation.
Configuration
BinaryCmd-A
BinaryCmd-B
BinaryCmd-C

Train
95.64
96.22
96.37

32-bit
Val.
92.24
92.69
92.76

Test
92.83
93.05
92.86

Train
94.47
93.97
94.97

8-bit
Val.
90.79
91.11
90.53

Test
91.40
91.21
90.97

Table 2: Accuracies of each set for each of the evaluated
configurations with and without 8-bit quantisation.

4.3

Table 3: Comparison of three BinaryCmd configurations
against DS-CNN, the current state of the art for KWS
applications, and other baselines presented in [34].

Comparisons to State of the Art

We compare BinaryCmd against DS-CNN and all the baselines analysed in [34]. Our configurations explore the void
space of 1M-3M OPs and 10kB-25kB. Our preliminary results, Figure 5, show the potential of our binary architecture:
up to 59% model size and 67% number of OPs reduction at
the expense of no more than 3.4% accuracy loss when compared to DS-CNN. All three of our configurations simultaneously achieve top accuracy-to-size (A2S) and accuracy-toOPs (A2OPs) ratios meaning that BinaryCmd is a good first
step towards the design of architecture capable of providing
over 90% accuracy levels with minimal memory footprint
and low computational costs.
We believe it is worth pointing out that while the DNN
baseline model requires an order of magnitude less OPs during inference, the levels of accuracy reached by this system
are considerable below the rest of the baselines. This is capture by the large gap between A2OPs and A2S ratios. We
maintained it in our evaluation for the shake of completeness
when comparing to [34].

Figure 5: Results comparison against architectures in
[34] for the category of small microcontrollers. DS-CNN
has never been tuned below 38.6kB and 5.4M OPs. All
other configurations in [34] result in larger and computationally more expensive models.

4.4 Filter Generation Overhead
In Sec. 3 we described the creation process of DBFs: a
convolutional layer with N K × K filters and whose inputs
have C channels, requires a 4-dimensional tensor of shape
dimf = N × C × K × K. Such tensor can be generated by
combining OVSF codes of that dimensions. Because of the
recursive construction process of Hadamard matrices, there
are a total of L = N CKK codes of shape dimf , as shown
in Fig. 4. Given these premises, we could generate our DBF
of dimensions dimf , DBFdimf , by combining L codes of
dimensions dimf . The complexity of such operation grows
quadratically with dimf , i.e. O((N CKK)2 ), and would significantly slowdown the inference process when generating
the filters on-the-fly, as observable in Fig. 6 and Fig. 7.
The computational costs of generation process described
(that we will refer to as naive), can be easily reduced by
making a few small modifications. Instead of combining
OVSF codes of dimf we could split the generation process
and generate N filters of dimensions C × K × K separately
and then concatenate them so we obtain a final tensor/filter
of dimensions dimf . This fast approach is O(N (W HC)2 ).
We can even better by splitting each filter of dimensions
C × K × K into C matrices of dimensions K × K and then
concatenate them. This faster approach is O(N C(W H)2 ).
Figure 6 shows the computational costs for each technique
at different filter dimensions. In Figure 7 we show the execu-

tion time measured on the ARM Cortex-M7 microcontroller
when generating each of the filters.

1010

Naive

Fast

Faster
21.5

OPs

109
18.7

15.9

15.2

14.6

6

10

105

13.1

12.4

11.7

5.
13.8

16x16x4x4 32x16x4x4 64x16x4x4 64x32x4x4
Filter Tensor Dimensions

Figure 6: Number of OPs required for each filter generation method for different filter dimensions.

103

Naive

Fast

Faster
4.05

Seconds

102
2.6

101
100

10−1
10−2

OPs Inference
Forward Generation
1.77M
0.40M
2.27M
0.40M
2.63M
0.25M

Time Inference
Forward Generation
32.67ms
13.6 ms
41.9ms
13.6 ms
48.6ms
10.3 ms

17.3

7

10

BinaryCmd-A
BinaryCmd-B
BinaryCmd-C

Table 4: Inference costs of running each BinaryCmd configuration on an ARM Cortex-M7 using 32-bit weights.
Forward inference time is approximated using the baselines measurements in [21].

20.1

108 17.3

Model

1.2
−0.2
−2.8

−2.2
−4.2

−1.5
−3.5

−0.15
−2.8

−5.1
16x16x4x4 32x16x4x4 64x16x4x4 64x32x4x4
Filter Tensor Dimensions
Figure 7: Execution time (seconds) required for each
filter generation method for different filter dimensions
on ARM Cortex-M7.

It is worth mentioning that the execution times shown in
Figure 7 include both the filter generation itself (i.e. performing the linear combination of OVSF codes) and the creation of those OVSF codes as a recursive tree (see Figure 4).
Because faster needs to generate OVSF codes of dimensions
K × K, we only need (KK)2 bits to store all of them. In
other works, by caching the OVSF codes we were able to
further reduce the filter generation stage by ∼50%.
These measurements use a lightly optimised OVSF code
generator written in C and using 32-bit weights. We believe
further optimisations are possible, including the usage of 8bit weights for filter generation.
Finally, in Table 4 we show the total number of operations
required for our BinaryCmd configurations when generating
filters on the fly. By using the faster filter generation technique and caching the OVSF codes, we are able to generate
filters by increasing the inference time less than 14ms. We
also estimated the execution time required for inference (excluding filter generation) in the M7.

LIMITATIONS AND FUTURE WORK

Implicit in Section 4 and Section 3, the usage of OVSF
codes comes with two limitations:
OVSF dimensionality.
The nature of OVSF codes
limits them to be of length L = 2l , l ∈ N. This means that
commonly used filter dimensions such as 3 × 3 or 5 × 5 are
not a possibility. This is a reason why our filters are 4 × 8
and 4×4. Note that a 4×4 filter has 1.78× more parameters
than a 3 × 3 filter. We think this is an important limitation
of our approach.
Using OVSF codes efficiently. Being able to generate
very cheaply a basis of RL , where L = 2l , l ∈ N, makes OVSF
codes a powerful tool. However, we find that this usage of
OVSF codes to build a basis comes with a no negligible
drawback: the need to assign (learn) a magnitude to each
of the basis, as shown in Eq. 1. To effectively reduce the
number of learnable parameters we will need to set ρ <
1 and, as shown in [29], it is a viable solution for larger
networks.
The next iteration of this work will explore two main paths
that we believe would make OVSF codes more advantageous:
Less paging.
Microncontrollers often have less than
1MB of memory and slightly more flash storage (e.g. our
Nucleo-144 comes with an ARM Cortex-M7 has 512 kB of
SRAM and 2MB of flash) severely limiting the complexity
of the application that these devices can run. Although in a
normal scenarios we would like the totality of our network
to fit in memory, we might be interested in running a larger
model to perform, for example, a more complex task. Running such application would require paging (i.e. temporally
storing main memory data in flash memory) the network
parameters (i.e. filters) and such I/O operations would considerably slowdown the inference process. By using OVSF
codes, ρ < 1 and generating the filters as described in this
work, we could reduce the time taxing access to flash memory without changing the structure of the network.
New architectures. In this work we have limited our
study of DBFs in a “traditional” CNN. Giving the binary
and deterministic nature of OVSF codes, we believe a more
in-depth search for a better architectural design should be
carried out. We are particularly interested in designing binary end to end architectures that can exploit the construction simplicity of Hadamard matrices. In addition, we used
as input MFCC hand-crafted features as they have become
standard for KWS applications. The performance of other
features or the usage of the raw audio waveform should be
evaluated.

6.

CONCLUSION

We have applied a new type of convolutional layer to KWS
and shown that they are capable of giving near start of the
art accuracy levels even in architectures requiring a frac-

tion of model parameters and considerable less operations
per inference pass compared to architectures of similar complexity. We make this possible by crafting convolutional
filters on-the-fly using binary orthogonal codes that can be
generated efficiently and can reduce the number of trainable
parameters. We believe our approach offers a simple yet
powerful technique that could evolve into an new network
architecture capable of reducing memory accesses by relying
on deterministic data structures, the OVSF codes.

Acknowledgements
This work was supported in part by the UK’s Engineering
and Physical Sciences Research Council (EPSRC).

7.

REFERENCES

[1] Abadi, M., et al. TensorFlow: Large-scale machine
learning on heterogeneous systems, 2015. Software available
from tensorflow.org.
[2] Adachi, F., et al. Wideband ds-cdma for next-generation
mobile communications systems. IEEE communications
Magazine 36, 9 (1998), 56–69.
[3] Adachi, F., Sawahashi, M., and Okawa, K.
Tree-structured generation of orthogonal spreading codes
with different lengths for forward link of ds-cdma mobile
radio. Electronics Letters 33, 1 (Jan 1997), 27–28.
[4] Andreev, B. D., et al. Orthogonal code generator for 3g
wireless transceivers. In Proceedings of the 13th ACM Great
Lakes Symposium on VLSI (New York, NY, USA, 2003),
GLSVLSI ’03, ACM, pp. 229–232.
[5] Arik, S. Ö., et al. Convolutional recurrent neural
networks for small-footprint keyword spotting. CoRR
abs/1703.05390 (2017).
[6] Bhattacharya, S., and Lane, N. D. Sparsification and
separation of deep learning layers for constrained resource
inference on wearables. In Proceedings of the 14th ACM
Conference on Embedded Network Sensor Systems
CD-ROM (New York, NY, USA, 2016), SenSys ’16, ACM,
pp. 176–189.
[7] Cavigelli, L., et al. Origami: A convolutional network
accelerator. CoRR abs/1512.04295 (2015).
[8] Chen, Yu-Hsin and others. Eyeriss: An Energy-Efficient
Reconfigurable Accelerator for Deep Convolutional Neural
Networks. In IEEE International Solid-State Circuits
Conference, ISSCC 2016, Digest of Technical Papers
(2016), pp. 262–263.
[9] Chollet, F. Xception: Deep learning with depthwise
separable convolutions. CoRR abs/1610.02357 (2016).
[10] David Pearce, C. d. Speech processing, transmission and
quality aspects (stq); distributed speech recognition;
front-end feature extraction algorithm; compression
algorithms.
[11] Du, Z., et al. Shidiannao: Shifting vision processing closer
to the sensor. SIGARCH Comput. Archit. News 43, 3
(June 2015), 92–104.
[12] Fernández-Marqués, J., Vincent, W.-S. T.,
Bhattachara, S., and Lane, N. D. Binarycmd: Keyword
spotting with deterministic binary basis. SysML (2018).
[13] Gokhale, V., Jin, J., Dundar, A., Martini, B., and
Culurciello, E. A 240 g-ops/s mobile coprocessor for
deep neural networks. In 2014 IEEE Conference on
Computer Vision and Pattern Recognition Workshops
(June 2014), pp. 696–701.
[14] Han, S., Mao, H., and Dally, W. J. Deep compression:
Compressing deep neural network with pruning, trained
quantization and huffman coding. CoRR abs/1510.00149
(2015).
[15] He, K., et al. Deep residual learning for image
recognition. CoRR abs/1512.03385 (2015).

[16] Howard, A. G., et al. Mobilenets: Efficient convolutional
neural networks for mobile vision applications. CoRR
abs/1704.04861 (2017).
[17] Ioffe, S., and Szegedy, C. Batch normalization:
Accelerating deep network training by reducing internal
covariate shift. CoRR abs/1502.03167 (2015).
[18] Jacob, B., et al. Quantization and training of neural
networks for efficient integer-arithmetic-only inference.
CoRR abs/1712.05877 (2017).
[19] Juefei-Xu, F., et al. Local binary convolutional neural
networks. CoRR abs/1608.06049 (2016).
[20] Kim, S., Kim, M., Shin, C., Lee, J., and Kim, Y. Efficient
implementation of ovsf code generator for umts systems. In
2009 IEEE Pacific Rim Conference on Communications,
Computers and Signal Processing (Aug 2009), pp. 483–486.
[21] Lai, L., Suda, N., and Chandra, V. CMSIS-NN: efficient
neural network kernels for arm cortex-m cpus. CoRR
abs/1801.06601 (2018).
[22] Lane, N. D., Bhattacharya, S., Georgiev, P.,
Forlivesi, C., and Kawsar, F. An early resource
characterization of deep learning on wearables,
smartphones and internet-of-things devices. In Proceedings
of the 2015 International Workshop on Internet of Things
Towards Applications (New York, NY, USA, 2015),
IoT-App ’15, ACM, pp. 7–12.
[23] Lane, N. D., Bhattacharya, S., Mathur, A., Georgiev,
P., Forlivesi, C., and Kawsar, F. Squeezing deep
learning into mobile and embedded devices. IEEE
Pervasive Computing 16, 3 (2017), 82–88.
[24] McDanel, B., et al. Incomplete dot products for dynamic
computation scaling in neural network inference. CoRR
abs/1710.07830 (2017).
[25] Purohit, G., Chaubey, V. K., Raju, K. S., and Reddy,
P. V. Fpga based implementation and testing of ovsf code.
In 2013 International Conference on Advanced Electronic
Systems (ICAES) (Sept 2013), pp. 88–92.
[26] Rintakoski, T., Kuulusa, M., and Nurmi, J. Hardware
unit for ovsf/walsh/hadamard code generation [3g mobile
communication applications]. In 2004 International
Symposium on System-on-Chip, 2004. Proceedings. (Nov
2004), pp. 143–145.
[27] Sun, M., et al. Max-pooling loss training of long
short-term memory networks for small-footprint keyword
spotting. CoRR abs/1705.02411 (2017).
[28] Tara N. Sainath, C. P. Convolutional neural networks for
small-footprint keyword spotting. Sixteenth Annual
Conference of the International Speech Communication
Association (2015).
[29] Tseng, V. W.-S., et al. Deterministic binary filters for
convolutional neural networks. In Proceedings of the
Twenty-Seventh International Joint Conference on
Artificial Intelligence, IJCAI-18 (2018).
[30] Wang, Y., et al. Cnnpack: Packing convolutional neural
networks in the frequency domain. In Advances in Neural
Information Processing Systems 29, D. D. Lee,
M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett,
Eds. Curran Associates, Inc., 2016, pp. 253–261.
[31] Wang, Y., et al. Beyond filters: Compact feature map for
portable deep model. In Proceedings of the 34th
International Conference on Machine Learning
(International Convention Centre, Sydney, Australia, 06–11
Aug 2017), D. Precup and Y. W. Teh, Eds., vol. 70 of
Proceedings of Machine Learning Research, PMLR,
pp. 3703–3711.
[32] Wang, Z., et al. Small-footprint keyword spotting using
deep neural network and connectionist temporal classifier.
CoRR abs/1709.03665 (2017).
[33] Warden, P. Speech commands: A public dataset for
single-word speech recognition.
[34] Zhang, Y., et al. Hello edge: Keyword spotting on
microcontrollers. CoRR abs/1711.07128 (2017).

Deterministic Binary Filters for Convolutional Neural Networks
Vincent W.-S. Tseng‡ , Sourav Bhattacharya† , Javier Fernández-Marqués∗ ,
Milad Alizadeh∗ , Catherine Tong∗ and Nicholas D. Lane†∗
‡
Cornell University
†
Nokia Bell Labs
∗
University of Oxford
Abstract
We propose Deterministic Binary Filters, an approach to Convolutional Neural Networks that
learns weighting coefficients of predefined orthogonal binary basis instead of the conventional approach of learning directly the convolutional filters. This approach results in architectures offering significantly fewer parameters (4× to 16×) and
smaller model sizes (up to 32× due to the use of binary rather than floating point precision). We show
our deterministic filter design can be integrated into
well-known network architectures (such as ResNet
and SqueezeNet) with as little as 2% loss of accuracy under datasets like CIFAR-10. Under ImageNet, they are used in an architectures 3× smaller
compared to sub-megabyte binary networks while
reaching comparable accuracy levels.

1 Introduction
Since the success of AlexNet [Krizhevsky et al., 2012], convolutional neural networks (CNN) have become the preferred option for computer vision related tasks. While traditionally the research community has been fixated on goals
such as model generalization and accuracy in detriment of
model size. Recently, multiple approaches attempt to reduce
model’s on-device memory footprint while still maintaining
high levels of accuracy. Such approaches could be subdivided
into two main categories: new network compression techniques and novel layer architectural designs. Multiple network compression techniques [Wang et al., 2016; Han et al.,
2015; Frosst and Hinton, 2017] have been proposed as posttraining stages. In addition, several approaches, [Courbariaux
and Bengio, 2016; Rastegari et al., 2016], proved the suitability of aggressive data quantisation techniques as a way to
reduce the memory and compute requirements during inference by replacing 32-bit parameters with 8-bit and/or binary
values. Examples of novel layer design are [He et al., 2015;
Howard et al., 2017] aiming all of them to offer alternative
approaches to the traditional convolutional layers, being their
advantages more noticeable when operating with very highdimensional feature maps in deeper layers of the network.
In this work, we present Deterministic Binary Filters
(DBF), an approach to Convolutional Neural Networks that

learns weighting coefficients of predefined orthogonal binary
bases instead of the conventional approach of learning directly the convolutional filters. We generate the filters as a
linear combination of orthogonal binary codes that can be
generated very efficiently on real time. We achieve this by using a popular orthogonal binary code generator that has been
extensively studied for over two decades in the wireless community and widely used in mobile cellular systems. Our work
lies in the intersection between the previously mentinoned
categories: compression techniques and novel architectural
designs.
Our approach results in 4× to 16× reduction in the number of convolutional layer parameters to be learned, and more
than 32× savings in model size due to the use of binary
weights instead of floating point parameters. Unlike most
of the network compression techniques, our method allows
learning compressed models directly. We demonstrate our
deterministic filter design can be integrated into well-known
network architectures (such as ResNet [He et al., 2015] and
SqueezeNet [Iandola et al., 2016]) with as little as 2% loss
of accuracy under CIFAR-10. With fewer parameters such
models are less prone to over-fitting and can be potentially
trained with significantly less compute operations and memory needs. DBFs can also offer improved efficiency for inference on microprocessors and embedded devices. Experiments show the suitability of DBFs and their usage in networks with model size up to 3× smaller compared to already optimized binary networks while offering comparable
accuracy levels for datasets like ImageNet, which has 1000
classes.
We believe DBFs are a first step in the development of efficient architectures relying less on large amounts of trainable
parameters and more on deterministic data structures. Models with such characteristics would be more suitable for applications on resource constrained embedded devices requiring
high accuracy rates but minimal compute complexity. In this
work we offer the following contributions:
• A new module that performs convolution filters using a
weighted combination of orthogonal binary bases that
offers significantly reductions on the amount of learnable parameters required for the network.
• We find that such a module is able to offer nearly equal
accuracy levels under common network architectures

and datasets, making it a viable model choice, and providing insights into filter design moving forward.
• The ability to trade-off model size for low-complexity
compute, this is a unique characteristic important for
low-memory platforms.
• The number of parameters needed to be updated during
training can be greatly reduced since we only need to
update the weights and not the entire filter, leading to a
faster training and inferences stages.

2 Related Work
Our study of DBFs for CNNs touch upon the following areas
of deep neural network research.
Novel Filter Design. The design of filters within convolutional networks is critical to the effectiveness of such networks in discriminative tasks, and have significant downstream implications for efficiency (e.g., requirements for
memory and compute). Earlier work [Jarrett et al., 2009]
showed random kernels with no learning achieving decent
performance in Caltech-101. Similarly, other works [Saxe
et al., 2011; Pinto et al., 2009] make use of random filters
to show that in addition to the convolutional filters, the network architecture plays a fundamental role in the learning
process. Moreover, [Saxe et al., 2011] argued that some performance of certain state-of-the-art methods can be attributed
to the their architecture alone. All of these demonstrate the
ability for filters despite not being learned from data during
training. More closely to our filter design is the LBCNN (Local Binary CNN) module [Juefei-Xu et al., 2017] that use
pre-defined sparse local binary filters that also do not need to
be updated during training. However, a critical difference in
our design is our ability to generate DBFs on the fly through
efficient algorithms that enable significantly smaller model
sizes as light-weight compute operations replaces in-memory
overhead (critical for embedded and mobile scenarios with
low memory footprints). LBCNN modules also cannot directly replace conventional filters in existing architectures as
requires a two stage approximation of convolution. This may
not be applicable to all architectural designs. In comparison,
our DBFs can be trivially applied to common architectures.
Binary Networks.
Adoption of network architecture designs that include binary filters and weights are also a promising direction. Under this approach parameters are represented
with only one bit, reducing the model size by 32×. Although such methods offer small model size and inference
efficiency they do not necessarily reduce the amount of parameters as offered by our deterministic binary filters. Expectation BackPropagation (EBP) [Soudry et al., 2014] proposes a variational Bayes method for training deterministic
Multilayer Neural Networks, using binary weights and activations. This and a similar approach [Esser et al., 2015]
give great speed and energy efficiency improvements. However, the improvement is still limited as binarised parameters
were only used for inference. Many other proposed binary

networks suffer from the problem of not having enough representational power for complex computer vision tasks, e.g.
BNN [Courbariaux and Bengio, 2016], DeepIoT [Yao et al.,
2017], eBNN [McDanel et al., 2017] are unable to support
the complex ImageNet dataset seen in our results.
Network Architecture Optimization. Many attempts towards optimizing network architectures for more efficient
training, inference and parameter exist. One direction in
quantization involves taking a pre-trained model and normalizing its weights to a certain range. This is done in [Vanhoucke et al., 2011] which uses an 8 bits quantization to store
activations and weights. Other works such as [Han et al.,
2015] and [Wang et al., 2016] are a conglomerate of multiple
clustering, quantisation and word encoding techniques that
have been proven to work well in large architectures such as
AlexNet and ResNet. In addition to compressing weights in
neural networks, researchers have also been exploring more
light-weight architectures: SqueezeNet uses 1 × 1 filters in
combination with 3 × 3 filters, reducing the model to 50×
smaller than AlexNet while maintaining the same accuracy
levels; bottleneck layers, introduced in ResNet, that aims to
reduce the number operations and parameters of convolutional layers by reducing the number of channels of the input
tensor using 1×1 filters; or MobileNets [Howard et al., 2017]
that make use of depthwise convolutional layers and result in
lightweight networks suitable for embedded vision applications. SparseSep [Bhattacharya and Lane, 2016b] adds sparsification to both convolutional and dense layers resulting in
highly compact model representations.
Deep Learning for embedded platforms.
Energy efficiency and low computational complexity are two major requirements that algorithms must fulfil when deploying them
in memory and compute restricted platforms [Lane et al.,
2015] and they become a major concern when considering
the commercialization of such applications. Embedded deep
learning applications, often instantiated as wearables, exist
for a diverse range applications including vision [Mathur et
al., 2017; Suleiman et al., 2017], audio [Fernandez-Marques
et al., 2018; Georgiev et al., 2017] and activity recognition [Tahavori et al., 2017; Bhattacharya and Lane, 2016a].
We refer the interested reader to [Lane et al., 2017] and [Sze
et al., 2017] for a deeper evaluation of the challenges associated with this area of research.

3

Deterministic Binary Filters

In this section, we introduce a novel approach of performing
convolution operations and present an efficient algorithm for
training the parameters. Specifically, we design a convolution layer, where all filter kernels are generated using a linear superposition of a predefined bases set of binary orthogonal vectors. Fewer number of tunable parameters generates a
model with a smaller memory footprint, which is particularly
suitable for deployment on resource-constrained wearable or
IoT devices. The properties of the binary codes used to generate the filters also makes it possible to implement convolu-

Binary basis vectors
2.9

-5.2

0.0

C4,1=(1,1,1,1)

-1.0

C2,1=(1,1)
C4,2=(1,1,-1,-1)
Convolutional
Kernel

4.4

5.8

-2.3

-8.3

C1,1=(1)
C4,3=(1,-1,1,-1)

-1.1

1.1

-1.1

8.1

-10.1

12.9

C2,2=(1,-1)

-0.2

C4,4=(1,-1,-1,1)
L=1

-1.9

L=2

L=4

C8,1=(1,1,1,1,1,1,1,1)
C8,2=(1,1,1,1,-1,-1,-1,-1)
C8,3=(1,1,-1,-1,1,1,-1,-1)
C8,3=(1,1,-1,-1,-1,-1,1,1)
C8,5=(1,-1,1,-1,1,-1,1,-1)
C8,6=(1,-1,1,-1,-1,1,-1,1)
C8,7=(1,-1,-1,1,1,-1,-1,1)
C8,8=(1,-1,-1,1,-1,1,1,-1)
L=8

Figure 2: Code Tree for OVSF Code Generation
Figure 1: Overview of representing a convolution kernel using a
set of binary mutually orthogonal basis vectors. The convolutional
kernel (on the left) can be represent accurately using linear superposition of all the binary vectors (patches) presented on the right. The
coefficient or strength of a binary vector used in the reconstruction
is given on top of the patches.

tions without explicitly having the filters allocated in RAM,
therefore allowing efficient runtime on embedded devices.
In this work we employ orthogonal variable spreading factor (OVSF) codes to generate filters for the convolution layer.
The presented technique can also be applied to the fully connected layer parameters, however, we only focus on convolution layers in this work. In the following three sub-sections
we present the main intuition behind representing convolution
kernels with OVSF codes, present technique to efficiently use
the codes to generate kernels and lastly describe the featuremaps generation process.

3.1

OVSF Codes: Overview

A point x ∈ RN can be represented by the span of a set of N
mutually orthogonal set of vectors or bases {Bi }N
i=1 (Bi ∈
RN ), where ∀i, j, and i 6= j, Bi ⊥ Bj . In other words, any
point in RN can be presented as a linear combination of the
basis vectors as:
N
X
x=
αi · Bi ,
(1)
i=1

where, αi is the coefficient or strength for the ith basis vector.
Without a loss of generality, we can apply the same linear superposition strategy when generating the hypermatrix
or tensor that would become our convolutional filter. To
gain computational or representational benefits, we can enforce certain properties on the bases set. For instance, in
this work we only consider binary basis vectors, i.e., Bi ∈
{−1, +1}N , ∀i. For illustration, in Figure 1 we present a scenario when a random filter of dimension 4 × 4 is represented
accurately by a set of 16 binary and mutually orthogonal basis vectors. The coefficients for individual binary vectors are
presented on the top of each patches. Note that, for illustration purpose we only consider 2D filters, whereas in practice
the filters used in convolution layers are 3D.

To achieve this filter representation, we require a techniques for efficiently generating the basis vector set. Specifically, given the dimensionality of a filter, the bases generation
technique should output all the orthogonal binary vectors for
the convolution parameter space. This bases generator should
have the following properties: (i) capable of generating all
the bases for any space regardless of its dimensionality, (ii)
employs a deterministic procedure, i.e., for a given dimension, the basis vectors set remains invariant, (iii) being efficient such that it can be used in real-time applications on
embedded devices.
OVSF Codes
For the purpose of generating convolutional kernels, while
meeting the above mentioned conditions, we use the algorithm presented in [Adachi et al., 1998]. The OVSF codes
have been extensively studied in the wireless community [Andreev et al., 2003; Rintakoski et al., 2004; Kim et al., 2009;
Purohit et al., 2013] and widely used in W-CDMA based 3G1
mobile cellular systems to provide multi-user network access.
Their simplicity and efficiency on-silicon implementation
makes them suitable for real-time implementation on powerconstrained devices. OVSF codes are binary {−1, +1}, orthogonal to each other and of length L = 2l , l ∈ N. Figure 2
shows OVSF bases at different l values generated as a recursive process in a binary tree [Adachi et al., 1997].

3.2

Filter Generation Process

Unlike in standard CNNs, our architecture does not learn convolutional filters directly. Instead, it learns the coefficient for
the basis vectors needed to generate the convolutional filters.
Note that the dimension of the OVSF code is the same as the
N filters, which is W ×H ×C, where W and H are the width
and height of the filters2 , and C is the number of channels.
For any given code length L, there are L different OVSF
codes (as observable in Figure 2). Therefore, to generate a
filter of dimensions dim = W × H × C, our generator could
output at most dim different codes that would form a basis of Rdim . Intuitively, by combining all OVSF codes of
1
3GPP TS 25.213, v 3.0.0, Spreading and modulation (FDD),
Oct. 1999
2
In this work we only consider square filters with dimension of
the form 2l .

.

-0.5

-1 -1
1 -1
1 -1
1 -1
1 -1 -1 1

-1 -1 1

biN = [0, 1, 1, 0, ...1]

Reshape

1

-0.5

-2.8

1.5

-0.5
-0.5
-2.8
-0.4
2.1
-0.4
-1.3
0.9

-1 1 2
-1 11 -11 -1
1
N
2.1
k1 0,
bi = [bi1 , bi2 , bbi i3=, [b...b
1,131,
...0]
bikbi2=
== [1,
[1, 1,
1, ...1]
1
2 ] 3b N
2 −1,
N1 -1
-1
-1...−1]
i =] b[1,
, ...b
= [1,
−1,
1,
0, 1,0,
...1]
-1
-1
i , bii , bib
,-1...-1
b̃
[1,0,−1,
2, 1, ... − 1]
i =i [b̃ii , b̃i ,1b̃i 1
i
i 1] b
N
[0, 1, 1, 0, ...1]
..
1 1 -1 1
=N ][0,
0,iN =...1]
k 1, 1, b
2
-1 -1 1 1 .
bi = [bi1 , bi2 , bbi3i, ...b
i bi = [1, −1, −1, 1, ...−1] bi = [1, 0, 0, 1, ...1]

-0.4

-1.3

..

.

0.0

αi = [αi1 ,αi2 ,αi3 ...αiN ]

would first generate OVSF codes of length 4 × 4 × 1 × 1; then
keep 9 out of the 16 dimensions; and proceed with the reshape
and combination stages as shown in Figure 3. This approach
fi =
results in pseudo-OVSF codes that are no longer orthogonal
.
..
1 12, b 23, b 3 , ...b
N N1] b k1= [1,2−1, 3
2...−1]
N [1, b1,i2k0,
[1,[1,
0, 0,−1,
1, ...1]2, 1, ... − 1]
bi =b[b
bii ii ...b
=i [1,
0, 1, 1, −1,
...0].. 1,
bb̃
...1]
i =i ,[b
i i[b̃
i ii ]=b
b
bi ==1,
i =]
to each other. We call these codes square-pseudo OVSF, spi , b̃i , b̃i , ....
i
N b N = [0, 1, 1, 0, ...1]
bi =i [0, 1, 1, 0, ...1]
OVSF for brevity. In Section 4, we empirically show that the
1 2 3
N
αi = [αi ,αi ,αi ...αi ]
Reshape
generated filters perform well even though the codes used are
no longer mutually orthogonal.

OVSF Bases
Generation

..

.

23 3
bi1=, b̃
[b̃2i1,, b̃
, b̃i , ...
bik ==[1,[1,
−1,
2, 1,2,
... 1,
− 1]
bi = [b̃
b̃b̃iNiN]] b
−1,
... − 1]
i
i
i b̃i i , ...
k

+

.
..

bi = [b̃i1 , b̃i2 , b̃i3 , ...b̃iN ] wi = [wi1 , wi2 , wi3 , ...wiN ] bik = [1, −1, 2, 1, ... − 2]

Figure 3: From OVSF codes to DBFs. Each code bki is first reshaped to match the final filter dimensions, becoming b̃ki . Then, the
reshaped codes in b̃i are combined using the weights αi .
OVSF codes

Weights

a given dimension dim we
could perfectly represent any fil{0.5, -0.7}
Convolutional
!"
# "
#$
ter of that dimension.
On the other
hand, using fewer OVSF
1 1
1 1
Filter
,
1 1
-1 -1
!
"
codes
would
result
in
a
coarser
representation
of the target fil-0.2 -0.2
Reshape
+
1.2 1.2
ter. Mathematically, the quality of a filter generated by combination of OVSF codes could be measured as:

basisOVSF = {[1, 1, 1, 1], [1, 1, -1, -1]}

2
Ek = kfk0 − fk k2 =

bρ·lc

X
i=0

2

αki Bki − fk

< ,

(2)

2

where ρ ∈ [0, 1] is the ratio of codes to use in order to approximate filter fk , l is the total number of OVSF codes of
length l = W HC, Bki is the ith OVSF code and αji ∈ R its
associated weight.  is the difference between the the approximated DBF, fk0 , and the real filter, fk . Intuitively,  → 0 as
we increase the ratio of binary codes used. When ρ 6= 1, the
product p · l is rounded to the nearest integer value.
Filter Generation Stages
During training, the set of weights {α}N
i=1 that pre-multiply
each of the OVSF codes are learnt via backpropagation [LeCun et al., 1989]. At inference time, the generated filter fk0
can be treated as any other standard floating-valued convolutional filter. The filter generation process using OVSF bases
and the learned weights is didactically illustrated in Figure 3.
This process involves: generation of bρ · lc OVSF codes of
length l = W × H × C; reshape each code in order to match
the shape of the filter; and combine them using the learnt
weights {α}N
i=1 .

The Importance of Ratios
One of the main focus of our evaluation is the study of how
ρ impacts on the performance of our models. This parameter,
that can be independently set for each convolutional layer in
the network, is directly proportional to the number of learnable parameters N in a given layer. As an example, when
ρ = 0.5, the filter would be generated using half of the OVSF
codes and, therefore, our network would only require to learn
half to the weights.
OVSF Limitations
By design, OVSF codes must be of length L = 2l , l ∈ N.
This means that commonly used filter dimensions such as 3 ×
3 or 5 × 5 are not a possibility. We overcome this limitation
by only using a portion of the elements in each OVSF code.
For example, in order to construct a 3 × 3 × 1 × 1 filter, we

Algorithm 1 Training with DBFs
Input: A minibatch of inputs labels and labels(X, Y ), a dictionary of orthogonal binary bases {B1 , B2 , ..., Bk } for each convolution filter and learning rate η.
Output: Updated coefficients {α1t+1 , α2t+1 , ..., αkt+1 } for each of
the binary filters.
for l = 1 to L do
1. Forward Propagation:
{B1 , B2 , . . . , Bk } ← OVSF(n, k)
f t ← α1t B1 + α2t B2 + . . . + αkt Bk
Compute X ∗ f t
. ∗ is the convolution operation.
2. Backward Propagation:
for i=1 to k, do
t
P
∂L
∂L ∂fj
= n
j=1 ∂f t ∂αt
∂αt
i

j

i

3. Coefficient Update:
for i=1 to k
∂L
αit+1 ← αit − η ∂α
t
i

3.3

Model Training and Optimization

In the following we describe the main steps involved in the
training of the proposed architecture. We use stochastic gradient descent (SDG) to update all the tunable parameters in
the architecture and an overview of the training process is
presented in Algorithm 1. During the forward pass, we first
generate individual filters, and then follow the conventional
CNN inferencing to compute the loss. However, during the
backward pass, we only update the coefficients {α}N
i=1 , but
not the binary basis vectors. The loss propagates to each of
the layers from the output layer, and the gradient of each coefficient with respect to the the total loss is calculated using
chain rule, i.e.:
n
X
∂L ∂fj
∂L
=
∂αi
∂f
j ∂αi
j=1

(3)

where L is the loss, fj is the convolution filter. During the
forward propagation in the next iteration, the filters is generated using the updated coefficients.
Convolution kernel generation using OVSF codes as binary
basis vectors can be easily integrated to existing architectures,
such as fully CNNs, ResNet or any architecture employing
convolutions. Therefore, existing architectures can be trained
faster, as we have smaller number of free parameters to update, and can have better inference time.

3.4

Inference

4.1

The convolution operations within a layer, using the set of
OVSF codes, can be summarized as:


bρ·lc
X
O
i
i

Fk =
αk · Bk ∗ F I ,
(4)
i=1

where, F I is the input feature-map and FkO is the output
feature-map for filter k, Bki and αki are the binary vector and
corresponding coefficient while representing the k th filter. Interestingly, we can use the linearity of the convolution operation and compute the same output feature-map as follows:
FkO =

bρ·lc

X
i=1


αki · Bki ∗ F I ,

(5)

These two formulations allow two distinct architecture deployment methods that are suitable in two different application scenarios. In the first case, we generate a static version of
the model, employing Equation 4, and in the latter case, for
resource constrained devices, we instantiate a dynamic version of the architecture where the OVSF codes are generated
on the fly and then used during convolution convolutions as
in Equation 5. In the following we describe the two cases.
Explicit Filter Generation. In scenarios with sufficient ondevice memory to store the model in memory, the DBFs could
be generated, and therefore allocated in memory, as part of a
initialization stage during model deployment and set-up. After this, the inference stage would be identical to that of any
other CNN architecture.
On-the-fly convolutions. Due to the nature of the filter generation process by combining OVSF codes using weighting
coefficients learned during training we could bypass the generation and allocation of the filters during model deployment.
These filters would no longer need to be explicitly generated.
Instead, since our model has the weighting coefficient and we
can generate OVSF codes very efficiently, we can subdivide
the operations of a convolutional layer into smaller operations
that are less memory taxing. Effectively, this strategy trades
memory for computations.

4

Evaluation

In this section we validate the usage of DBFs in convolutional
networks for the task of image classification. Here we:
• Compare the performance of two popular CNNs architectures when using filters generated from OVSF codes
against standard fully-learnable filters.
• Make use of DBFs a as model size reduction strategy.

• Validate the usage of sp-OVSF codes that would permit
the usage of filter with arbitrary dimensionality.

Datasets

We conducted our experiments on three popular datasets, ImageNet, CIFAR-10 and MNIST. ImageNet is a large-scale image classification dataset, which contains 1000 categories and
a total of 1.33 million color images. These images vary in dimension and resolution and are generally resized and cropped
to 224×224 images. The dataset is divided into training and
validation data, with 1.28 million images and 50,000 images,
respectively. The CIFAR-10 dataset contains 60,000 32×32
color images in 10 classes, with 6,000 images per class. There
are 50,000 training images and 10,000 test images, with equal
number of images per class in both training set and test set.
The MNIST dataset consists of 28×28 grayscale images of
handwritten digits, with 60,000 training images and 10,000
test images.

4.2

Experimental Setup

Filters generated using OVSF codes can be used in any CNN
for both training and inference. In order to validate the representation capabilities of these filters, we substitute the standard convolutional layers of two popular CNN architectures,
ResNet and SqueezeNet, and train them on CIFAR-10 for 250
epochs. We used batch size of 128, initial learning rate of 0.1
with decay factor of 0.1 at epochs {90, 150, 190, 220}. We
applied standard dat augmentation: random image cropping,
random mirroing and image normalization. We evaluate our
architecture on two configuration of ResNet with 18 and 34
layers. The architectures evaluated in this section were originally designed for ImageNet, here, they have been adapted
to the dimensionality of the CIFAR-10 dataset. This adaptation consist on reducing the filter dimensions and stride of the
input convolutional layer.
Quality of OVSF filters. Given that OVSF codes are limited to be of length 2l , l ∈ N, we have modified the spatial
dimensions (width and height) of all the 3×3 and 7×7 the
convolutional filters in ResNet and SqueezeNet, and replace
them with 4×4 and 8×8 filters, respectively. In Table 1 (right)
we compare the accuracy levels reached for each architecture
when learning filters directly and when using the proposed
OVSF filter generation stage.
sp-OVSF: Overcoming 2l limitation. Despite not being
the focus of this work, we evaluated the suitability of OVSF
codes to generate filters whose dimensions are not a 2l , e.g.
those with spatial dimensions 3 × 3 or 5 × 5. To achieve this,
each time we require an OVSF code of l0 , we first generate the
shortest OVSF code of dimensionality 2l > l0 , and then clip
it. The resulting set of sp-OVSF codes are no longer orthogonal to each other, limiting the performance of the generated
filters. In Table 1 (left) we should that these codes can still be
use to generate convolutional filters.
The impact of ratios. The nature of the filter generation
process using OVSF codes permits, by means of a hyperparameter, choose how many bases use to generate each convolutional filter. This hyperparamter is represented in Eq. 2

Output

Input

Conv ReLu

Conv ReLu

Filter
Generator

Conv

+

Output

Weights

OVSF codes
generator

Figure 4: A three layers DBF Module.

as ρ. Lower ρ values results in fewer trainable parameters
and a more efficient inference stage at the cost of generating
coarser filters and a potential drop in accuracy. We evaluated
the effect of using coarser filters on ResNet-18, ResNet-34
and SqueezeNet. These results are shown in Table 2. Reducing ρ effectively reduces the number of weights, α in
Eq.2, needed to generate the filter and therefore resulting in
a smaller model, as shown in Table 3. An architecture with
DBF and ρ = 1 has the same model size as it would have
with standard filters.
A new CNN architecture. We designed a new CNN architecture using DBFs. We will refer to it as DBFNet. Macroarchitecturally, it borrows from SqueezeNet in the sense that after an initial convolution and max-pooling layer, the remaining of the pipeline is comprised of a three cascades of convolutional modules separated by max-pooling layers. We call
these blocks DBF Modules and consist of three stacked OVSF
convolutional layers with a bypass connection. Our network
is comprised of eight DBF Moudles arranged similarly to
SqueezeNet’s FireModules. Figure 4 shows a generic DBF
Module in isolation with explicit filter generation. When part
of a network, a single OVSF code generator is enough to generate the convolutional filters of the entire network. This architecture is evaluated on MNIST, CIFAR-10 and ImageNet
at different ρ values. The results are shown in Table 4. On
ImageNet we used learning rate of 0.1 and decay factor of
0.1 every 30 epochs for a total of 100 epochs using bach size
64. For CIFAR-10 and MNIST datasets we used batch size
of 128, the same initial learning rate and decay factor but decaying it at epochs {40, 70, 90}. No pre-processing or data
augmentation was applied.

4.3

Results

We have proven that, despite the simplicity of the filter generation process using binary OVSF codes, CNNs can perform
as well as if filters were learnt directly, like most CNNs do.
As we described in Eq.2, the proposed DBFs are as good as
any other standard convolutional filter. This is shown in Table 1 (left). We have validated this on two popular deep convolutional architectures, ResNet and SqueezeNet.
Using Coarser DBFs
Networks using DBFs in their convolutional layers can adjust
their memory footprint by tuning ρ. This parameter can be set
independently for each convolutional layer and is used to determine the number of OVSF codes a generator should output

Architecture
ResNet-18
ResNet-18DBF
ResNet-34
ResNet-34DBF
SqueezeNet
SqueezeNetDBF

Acc. (%)
91.15
91.02
92.46
92.32
91.16
91.33

Architecture
ResNet-18
ResNet-18sp-OVSF
ResNet-34
ResNet-34sp-OVSF
SqueezeNet
SqueezeNetsp-OVSF

Acc. (%)
90.68
89.12
92.53
91.30
91.22
90.25

Table 1: Evaluation on CIFAR-10 when filters are (left) either of
dimensionality 2l and (right) when maintaining the original filter
dimensions. DBFs are generated with ρ = 1. In each table, every
pair of architectures (e.g. ResNet-18 and ResNet-18DBF ) uses the
same filter dimensions accross layers and the same model size.

in order to generate a given convolutional filter. We demonstrate that even a 4× reduction in the number of parameters
of popular architectures such as ResNet and SqueezeNet can
result in only 2% accuracy loss. In our experiments we found
that reducing ρ for deeper convolutional layer has a lesser impact on accuracy than in the first layers of the network. Concretely, ρ was set to 6.25% for the last two layers in ResNet34DBF in the set up where, on average, ρ = 0.25. On the other
hand, shallower layers kept ρ = 1.
Architecture
ResNet-18DBF
ResNet-34DBF
SqueezeNetDBF

100%
91.02
92.32
91.33

75%
90.46
92.92
91.28

50%
89.34
91.43
91.17

35%
89.11
91.31
89.89

25%
88.02
89.88
89.22

Table 2: Evaluation of different architectures using DBFs generated
with different average ρ values (%) on CIFAR-10.

Architecture
ResNet-18DBF
ResNet-34DBF
SqueezeNetDBF

100%
1.37
3.39
4.41

75%
1.02
2.54
3.31

50%
0.69
1.70
2.21

35%
0.48
1.19
1.54

25%
0.34
0.85
1.10

Table 3: Model size (MB) of architectures using DBFs with different
average ρ values (%). Accuracy values are shown in Table 2.

To our advantage, ρ and the number of learnable parameters are tightly correlated for any architecture using DBFs.
This is evidenced in Table 3. Convolutional filters of deeper
layers tend to be considerably larger than those in shallower
layers, as is the case in ResNet and SqueezeNet. Consequently, these filters represent a seizable portion of the total model size. By means of the parameter ρ their impact in
model size can be lessened and, as previously exemplified for
the case of ResNet-34DBF , it is possible to achieve 16× memory impact reduction of certain layers while maintaining good
accuracy results.
Finally, we show that the benefits of using an architecture
with OVSF-based filters are also applicable when the image
classification task is considerable more challenging, as is the
case with in the ImageNet dataset. Table 4 shows the performance of DBFNet on various image classification dataset at
different ρ values.

Dataset
MNIST
CIFAR-10
ImageNet
Size (MB)

100%
99.6
89.7
55.1/78.5
10.32

70%
99.6
88.3
53.3/77.3
7.25

50%
99.6
88.0
50.4/74.8
5.16

25%
99.5
85.5
40.5/65.7
2.58

Table 4: Accuracy (%) of our DBFNet in three popular image
datasets at different ρ values (expressed as %). For ImageNet, accuracy values are shown as Top-1/Top-5.

5 Benefits of Deterministic Binary Filters
In the following section we present the main benefits of using
the binary basis vectors for the construction of convolution
filters and its effect during inference and training time.

5.1 Fewer Parameters
Results from Section 4 show that networks using DBFs offer
significant parameter savings. Table 2 shows that 4× reduction in the number of total learnable parameters is possible.
By means of parameter ρ we can adjust the memory impact
of each layer individually, resulting in 16× memory savings
in the deeper layers of the networks while maintaining their
dimensionality. We believe these results can be improved by
forcing the set of coefficients that pre-multiply each OVSF
bases to be sparse in a layer by layer.
We demonstrated the feasibility of DBFs to reduce the
model size of already small architectures, in the order of 1-4
MB in size. Our technique brings model size to levels achievable by binary networks. In Table 5 we compare ResNet18 using DBFs to two popular binary networks. BinaryConnect’s results use deterministic binarization. Our technique is
capable of providing similar levels of accuracy while reducing the model size to sub-MB levels. Similarly, we compare
in Table 6 BinaryConnect and BWN [Rastegari et al., 2016]
against our DBFNet when evaluated on ImageNet. DBFNet
performs better than BinaryConnect while being 3× smaller.
Architecture
BinaryConnect
BNN
ResNet-18DBF (ρ = 0.35)

Accuracy (%)
90.1
89.85
89.11

Size (MB)
0.73
0.73
0.48

Table 5: Comparison in terms of accuracy and model size of binary
architectures and floating-valued architectures using DBF. Results
are shown for CIFAR-10.

Architecture
BinaryConnect
DBFNet (ρ = 0.125)
BWN
DBFNet (ρ = 0.7)

Top-1 (%)
35.4
36.5
56.8
53.3

Top-5 (%)
61.0
61.9
79.4
77.3

Size (MB)
7.8
2.2
7.8
7.3

Table 6: Comparison in terms of accuracy and model size of binary
architectures and DBFNet. Results are shown for ImageNet.

5.2

Inference Efficiency

During inference, the overhead of using binary bases is
marginal. Bases can be generated once and used across all

convolutional layers. This does not impose a big memory
footprint as bases are binary and they can be densely packed
into bytes and occupy 8× less space.
When these bases are expanded and combined to form the
full-precision kernel we do not need to store any of the intermediate values and the run-time memory required is the
same as any normal convolutional layer. However, since convolution operation is distributive and associative with scalar
multiplication one can change the order of operations and do
convolution of input with binary bases first and then scale
and combine the results. While this approach normally does
not make sense given the significant cost of convolution operation, it can be efficient in architectures with binary inputs
where the convolution operation is reduced to XORing and
bit counting [Rastegari et al., 2016].

5.3

Training Efficiency

The main benefits of using Deterministic Binary Filters come
from their ability to reduce memory and computation footprints without a significant drop in the recognition accuracy.
From the previous section we see that across different datasets
the proposed architecture can achieve high accuracy while
only considering a fraction of the OVSF codes. This allows
for a significant reduction int the number of tunable convolution parameters, in our case only the coefficients, and generates a very compact model size, which is ideal for embedded
deployment. As we need a smaller number of parameters to
tune, the model becomes less prone to overfitting than the corresponding static version of the architecture. An architecture
with DBFs runs faster backward pass, thereby reducing the
overall training procedure significantly.

6 Conclusion
We have presented Deterministic Binary Filters, an new approach to constructing modules within CNNs that only requires learning of weighting coefficients with respect to a
predefined orthogonal binary basis. Significant savings result in comparison to conventional convolutional filters that
are learned entirely from data. With fewer parameters such
models are less prone to over-fitting and can be potentially
trained with significantly less compute operations and memory needs. DBFs provides important new insights in the
design of low-complexity models that maintain high accuracy level for discriminative image tasks with implications
for training and inference efficiency.

Acknowledgements
This work was supported in part by the UK’s Engineering and
Physical Sciences Research Council (EPSRC) with grants
EP/M50659X/1, EP/N509711/1 and EP/R512333/1.

References
[Adachi et al., 1997] F. Adachi, M. Sawahashi, and
K. Okawa. Tree-structured generation of orthogonal
spreading codes with different lengths for forward link of
ds-cdma mobile radio. Electronics Letters, 33(1):27–28,
Jan 1997.

[Adachi et al., 1998] Fumiyuki Adachi, Mamoru Sawahashi,
and Hirohito Suda. Wideband ds-cdma for next-generation
mobile communications systems. IEEE communications
Magazine, 36(9):56–69, 1998.
[Andreev et al., 2003] Boris D. Andreev, Edward L. Titlebaum, and Eby G. Friedman. Orthogonal code generator
for 3g wireless transceivers. In Proceedings of the 13th
ACM Great Lakes Symposium on VLSI, GLSVLSI ’03,
pages 229–232, New York, NY, USA, 2003. ACM.
[Bhattacharya and Lane, 2016a] S. Bhattacharya and N. D.
Lane. From smart to deep: Robust activity recognition on
smartwatches using deep learning. In 2016 IEEE International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops), pages 1–6, March
2016.
[Bhattacharya and Lane, 2016b] Sourav Bhattacharya and
Nicholas D. Lane. Sparsification and separation of deep
learning layers for constrained resource inference on wearables. In Proceedings of the 14th ACM Conference on Embedded Network Sensor Systems CD-ROM, SenSys ’16,
pages 176–189, New York, NY, USA, 2016. ACM.
[Courbariaux and Bengio, 2016] Matthieu Courbariaux and
Yoshua Bengio. Binarynet: Training deep neural networks with weights and activations constrained to +1 or
-1. CoRR, abs/1602.02830, 2016.
[Esser et al., 2015] Steve K Esser, Rathinakumar Appuswamy, Paul Merolla, John V. Arthur, and Dharmendra S Modha.
Backpropagation for energy-efficient
neuromorphic computing. In Advances in Neural Information Processing Systems 28, pages 1117–1125. Curran
Associates, Inc., 2015.
[Fernandez-Marques et al., 2018] Javier
FernandezMarques, Vincent T.-S. Tseng, Sourav Bhattacharya,
and Nicholas D. Lane. On-the-fly deterministic binary
filters for memory efficient keyword spotting applications
on embedded devices. In Proceedings of the 2nd International Workshop on Deep Learning for Mobile Systems
and Applications, EMDL ’18. ACM, 2018.
[Frosst and Hinton, 2017] Nicholas Frosst and Geoffrey E.
Hinton. Distilling a neural network into a soft decision
tree. CoRR, abs/1711.09784, 2017.
[Georgiev et al., 2017] Petko Georgiev, Nicholas D. Lane,
Cecilia Mascolo, and David Chu. Accelerating mobile audio sensing algorithms through on-chip gpu offloading. In
Proceedings of the 15th Annual International Conference
on Mobile Systems, Applications, and Services, MobiSys
’17, pages 306–318, New York, NY, USA, 2017. ACM.
[Han et al., 2015] Song Han, Huizi Mao, and William J.
Dally. Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding. CoRR, abs/1510.00149, 2015.
[He et al., 2015] Kaiming He, Xiangyu Zhang, Shaoqing
Ren, and Jian Sun. Deep residual learning for image recognition. CoRR, abs/1512.03385, 2015.

[Howard et al., 2017] Andrew G. Howard, Menglong Zhu,
Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias
Weyand, Marco Andreetto, and Hartwig Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications. CoRR, abs/1704.04861, 2017.
[Iandola et al., 2016] Forrest N. Iandola, Matthew W.
Moskewicz, Khalid Ashraf, Song Han, William J. Dally,
and Kurt Keutzer. Squeezenet: Alexnet-level accuracy
with 50x fewer parameters and <1mb model size. CoRR,
abs/1602.07360, 2016.
[Jarrett et al., 2009] Kevin Jarrett, Koray Kavukcuoglu,
Marc’Aurelio Ranzato, and Yann LeCun. What is the best
multi-stage architecture for object recognition? In IEEE
12th International Conference on Computer Vision, ICCV
2009, 2009.
[Juefei-Xu et al., 2017] Felix Juefei-Xu, Vishnu Naresh
Boddeti, and Marios Savvides. Local binary convolutional
neural networks. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on, volume 1, 2017.
[Kim et al., 2009] S. Kim, M. Kim, C. Shin, J. Lee, and
Y. Kim. Efficient implementation of ovsf code generator for umts systems. In 2009 IEEE Pacific Rim Conference on Communications, Computers and Signal Processing, pages 483–486, Aug 2009.
[Krizhevsky et al., 2012] Alex Krizhevsky, Ilya Sutskever,
and Geoffrey E Hinton. Imagenet classification with deep
convolutional neural networks. In Advances in Neural Information Processing Systems 25, pages 1097–1105. Curran Associates, Inc., 2012.
[Lane et al., 2015] Nicholas D. Lane, Sourav Bhattacharya,
Petko Georgiev, Claudio Forlivesi, and Fahim Kawsar. An
early resource characterization of deep learning on wearables, smartphones and internet-of-things devices. In Proceedings of the 2015 International Workshop on Internet
of Things Towards Applications, IoT-App ’15, pages 7–12,
New York, NY, USA, 2015. ACM.
[Lane et al., 2017] N. D. Lane, S. Bhattacharya, A. Mathur,
P. Georgiev, C. Forlivesi, and F. Kawsar. Squeezing deep
learning into mobile and embedded devices. IEEE Pervasive Computing, 16(3):82–88, 2017.
[LeCun et al., 1989] Y. LeCun, B. Boser, J. S. Denker,
D. Henderson, R. E. Howard, W. Hubbard, and L. D.
Jackel. Backpropagation applied to handwritten zip code
recognition. Neural Comput., 1(4):541–551, December
1989.
[Mathur et al., 2017] Akhil Mathur, Nicholas D. Lane,
Sourav Bhattacharya, Aidan Boran, Claudio Forlivesi, and
Fahim Kawsar. Deepeye: Resource efficient local execution of multiple deep vision models using wearable commodity hardware. In Proceedings of the 15th Annual International Conference on Mobile Systems, Applications,
and Services, MobiSys ’17, pages 68–81, New York, NY,
USA, 2017. ACM.
[McDanel et al., 2017] Bradley McDanel, Surat Teerapittayanon, and H. T. Kung. Embedded binarized neural net-

works. In Proceedings of the 2017 International Conference on Embedded Wireless Systems and Networks, EWSN
2017, Uppsala, Sweden, February 20-22, 2017, pages
168–173, 2017.
[Pinto et al., 2009] Nicolas Pinto, David Doukhan, James J.
DiCarlo, and David D. Cox. A high-throughput screening approach to discovering good forms of biologically
inspired visual representation. PLOS Computational Biology, 5:1–12, 11 2009.
[Purohit et al., 2013] G. Purohit, V. K. Chaubey, K. S. Raju,
and P. V. Reddy. Fpga based implementation and testing of
ovsf code. In 2013 International Conference on Advanced
Electronic Systems (ICAES), pages 88–92, Sept 2013.
[Rastegari et al., 2016] Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, and Ali Farhadi. Xnor-net: Imagenet classification using binary convolutional neural networks. CoRR, abs/1603.05279, 2016.
[Rintakoski et al., 2004] T. Rintakoski, M. Kuulusa, and
J. Nurmi. Hardware unit for ovsf/walsh/hadamard code
generation [3g mobile communication applications]. In
2004 International Symposium on System-on-Chip, 2004.
Proceedings., pages 143–145, Nov 2004.
[Saxe et al., 2011] Andrew Saxe, Pang W. Koh, Zhenghao
Chen, Maneesh Bhand, Bipin Suresh, and Andrew Y. Ng.
On random weights and unsupervised feature learning. In
Proceedings of the 28th International Conference on Machine Learning (ICML-11). ACM, 2011.
[Soudry et al., 2014] Daniel Soudry, Itay Hubara, and Ron
Meir. Expectation backpropagation: Parameter-free training of multilayer neural networks with continuous or discrete weights. In Advances in Neural Information Processing Systems 27, pages 963–971. Curran Associates, Inc.,
2014.
[Suleiman et al., 2017] A. Suleiman, Y. H. Chen, J. Emer,
and V. Sze. Towards closing the energy gap between hog
and cnn features for embedded vision. In 2017 IEEE International Symposium on Circuits and Systems (ISCAS),
pages 1–4, May 2017.
[Sze et al., 2017] Vivienne Sze, Yu-Hsin Chen, Tien-Ju
Yang, and Joel S. Emer. Efficient processing of deep neural
networks: A tutorial and survey. CoRR, abs/1703.09039,
2017.
[Tahavori et al., 2017] Fatemeh Tahavori, Emma Stack,
Veena Agarwal, Malcolm Burnett, Ann Ashburn,
Seyed Amir Hoseinitabatabaei, and William Harwin.
Physical activity recognition of elderly people and people
with parkinson’s (pwp) during standard mobility tests
using wearable sensors. In Smart Cities Conference
(ISC2), 2017 International, pages 1–4. IEEE, 2017.
[Vanhoucke et al., 2011] Vincent Vanhoucke, Andrew Senior, and Mark Z. Mao. Improving the speed of neural
networks on cpus. In Deep Learning and Unsupervised
Feature Learning Workshop, NIPS 2011, 2011.
[Wang et al., 2016] Yunhe Wang, Chang Xu, Shan You,
Dacheng Tao, and Chao Xu. Cnnpack: Packing convolutional neural networks in the frequency domain. In D. D.

Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett, editors, Advances in Neural Information Processing
Systems 29, pages 253–261. Curran Associates, Inc., 2016.
[Yao et al., 2017] Shuochao Yao, Yiran Zhao, Aston Zhang,
Lu Su, and Tarek F. Abdelzaher. Compressing deep neural
network structures for sensing systems with a compressorcritic framework. CoRR, abs/1706.01215, 2017.

Bibliography
Abdel-Hamid, O., Mohamed, A., Jiang, H., Deng, L., Penn, G., and Yu, D. (2014). Convolutional
neural networks for speech recognition. IEEE/ACM Transactions on Audio, Speech, and
Language Processing, 22(10), 1533–1545.
Adachi, F., Sawahashi, M., and Okawa, K. (1997). Tree-structured generation of orthogonal
spreading codes with different lengths for forward link of ds-cdma mobile radio. Electronics
Letters, 33(1), 27–28.
Anonymous (2019). A systematic study of binary neural networks’ optimisation. In Submitted to
International Conference on Learning Representations. under review.
Bengio, Y., Léonard, N., and Courville, A. C. (2013). Estimating or propagating gradients
through stochastic neurons for conditional computation. CoRR, abs/1308.3432.
Courbariaux, M. and Bengio, Y. (2016). Binarynet: Training deep neural networks with weights
and activations constrained to +1 or -1. CoRR, abs/1602.02830.
Courbariaux, M., Bengio, Y., and David, J. (2015). Binaryconnect: Training deep neural networks
with binary weights during propagations. CoRR, abs/1511.00363.
Dalal, N. and Triggs, B. (2005). Histograms of oriented gradients for human detection. In
Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern
Recognition (CVPR’05) - Volume 1 - Volume 01 , CVPR ’05, pages 886–893, Washington, DC,
USA. IEEE Computer Society.
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L. (2009). ImageNet: A Large-Scale
Hierarchical Image Database. In CVPR09 .
Denton, E., Zaremba, W., Bruna, J., LeCun, Y., and Fergus, R. (2014). Exploiting linear structure
within convolutional networks for efficient evaluation. In Proceedings of the 27th International
Conference on Neural Information Processing Systems - Volume 1 , NIPS’14, pages 1269–1277,
Cambridge, MA, USA. MIT Press.

41

BIBLIOGRAPHY

BIBLIOGRAPHY

Esser, S. K., Appuswamy, R., Merolla, P., Arthur, J. V., and Modha, D. S. (2015). Backpropagation for energy-efficient neuromorphic computing. In Advances in Neural Information
Processing Systems 28 , pages 1117–1125. Curran Associates, Inc.
Fang, B., Zeng, X., and Zhang, M. (2018). Nestdnn: Resource-aware multi-tenant on-device
deep learning for continuous mobile vision. In Proceedings of the 24th Annual International
Conference on Mobile Computing and Networking, MobiCom ’18, pages 115–127, New York,
NY, USA. ACM.
Fernandez-Marques, J., T.-S. Tseng, V., Bhattacharya, S., and Lane, N. D. (2018). On-the-fly
deterministic binary filters for memory efficient keyword spotting applications on embedded
devices. In Proceedings of the 2nd International Workshop on Deep Learning for Mobile Systems
and Applications, EMDL ’18. ACM.
Gao, H., Wang, Z., and Ji, S. (2018). Channelnets: Compact and efficient convolutional neural
networks via channel-wise convolutions. In Advances in Neural Information Processing Systems
31 . Curran Associates, Inc.
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A.,
and Bengio, Y. (2014). Generative adversarial nets. In Z. Ghahramani, M. Welling, C. Cortes,
N. D. Lawrence, and K. Q. Weinberger, editors, Advances in Neural Information Processing
Systems 27 , pages 2672–2680. Curran Associates, Inc.
Goodfellow, I., Bengio, Y., and Courville, A. (2016). Deep Learning. MIT Press. http:
//www.deeplearningbook.org.
Ha, D., Dai, A., and Le, Q. (2016). Hypernetworks.
Han, S., Pool, J., Tran, J., and Dally, W. J. (2015). Learning both weights and connections
for efficient neural networks. In Proceedings of the 28th International Conference on Neural
Information Processing Systems - Volume 1 , NIPS’15, pages 1135–1143, Cambridge, MA, USA.
MIT Press.
Han, S., Mao, H., and Dally, W. J. (2016a). Deep compression: Compressing deep neural networks
with pruning, trained quantization and huffman coding. International Conference on Learning
Representations (ICLR).
Han, S., Liu, X., Mao, H., Pu, J., Pedram, A., Horowitz, M. A., and Dally, W. J. (2016b).
Eie: Efficient inference engine on compressed deep neural network. In 2016 ACM/IEEE 43rd
Annual International Symposium on Computer Architecture (ISCA), pages 243–254.
Hassibi, B. and Stork, D. G. (1993). Second order derivatives for network pruning: Optimal
brain surgeon. In S. J. Hanson, J. D. Cowan, and C. L. Giles, editors, Advances in Neural
Information Processing Systems 5 , pages 164–171. Morgan-Kaufmann.
42

BIBLIOGRAPHY

BIBLIOGRAPHY

He, K., Zhang, X., Ren, S., and Sun, J. (2015). Deep residual learning for image recognition.
CoRR, abs/1512.03385.
He, Y. and Han, S. (2018). ADC: automated deep compression and acceleration with reinforcement
learning. CoRR, abs/1802.03494.
Hill, A. P., Prince, P., Piña Covarrubias, E., Doncaster, C. P., Snaddon, J. L., and Rogers, A.
(2018). Audiomoth: Evaluation of a smart open acoustic device for monitoring biodiversity
and the environment. Methods in Ecology and Evolution, 9(5), 1199–1211.
Hochreiter, S. (1991). Untersuchungen zu dynamischen neuronalen Netzen. Diploma thesis,
Institut für Informatik, Lehrstuhl Prof. Brauer, Technische Universität München.
Hochreiter, S. and Schmidhuber, J. (1997). Long short-term memory. Neural Comput., 9(8),
1735–1780.
Howard, A. G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M.,
and Adam, H. (2017). Mobilenets: Efficient convolutional neural networks for mobile vision
applications. CoRR, abs/1704.04861.
Hu, J., Shen, L., and Sun, G. (2018). Squeeze-and-excitation networks. In IEEE Conference on
Computer Vision and Pattern Recognition.
Huang, G., Liu, Z., van der Maaten, L., and Weinberger, K. Q. (2017). Densely connected
convolutional networks. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition.
Huang, G. B., Ramesh, M., Berg, T., and Learned-Miller, E. (2007). Labeled faces in the wild: A
database for studying face recognition in unconstrained environments. Technical Report 07-49,
University of Massachusetts, Amherst.
Huffman, D. A. (1952). A method for the construction of minimum-redundancy codes. Proceedings
of the IRE , 40(9), 1098–1101.
Iandola, F. N., Moskewicz, M. W., Ashraf, K., Han, S., Dally, W. J., and Keutzer, K. (2016).
Squeezenet: Alexnet-level accuracy with 50x fewer parameters and <1mb model size. CoRR,
abs/1602.07360.
Jacob, B., Kligys, S., Chen, B., Zhu, M., Tang, M., Howard, A., Adam, H., and Kalenichenko,
D. (2018). Quantization and training of neural networks for efficient integer-arithmetic-only
inference. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).
Jin, X., Yang, Y., Xu, N., Yang, J., Jojic, N., Feng, J., and Yan, S. (2018). WSNet: Compact and
efficient networks through weight sampling. In J. Dy and A. Krause, editors, Proceedings of
43

BIBLIOGRAPHY

BIBLIOGRAPHY

the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine
Learning Research, pages 2352–2361, Stockholmsmässan, Stockholm Sweden. PMLR.
Juefei-Xu, F., Boddeti, V. N., and Savvides, M. (2017). Local binary convolutional neural
networks. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on,
volume 1.
Kim, Y.-D., Park, E., Yoo, S., Choi, T., Yang, L., and Shin, D. (2016). Compression of deep
convolutional neural networks for fast and low power mobile applications.
Kingma, D. P., Salimans, T., and Welling, M. (2015). Variational dropout and the local
reparameterization trick. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and
R. Garnett, editors, Advances in Neural Information Processing Systems 28 , pages 2575–2583.
Curran Associates, Inc.
Krizhevsky, A., Nair, V., and Hinton, G. (2009). Cifar-10 (canadian institute for advanced
research).
Krizhevsky, A., Sutskever, I., and Hinton, G. E. (2012). Imagenet classification with deep
convolutional neural networks. In Advances in Neural Information Processing Systems 25 ,
pages 1097–1105. Curran Associates, Inc.
Kumar, A., Goyal, S., and Varma, M. (2017). Resource-efficient machine learning in 2 KB RAM
for the internet of things. In D. Precup and Y. W. Teh, editors, Proceedings of the 34th
International Conference on Machine Learning, volume 70 of Proceedings of Machine Learning
Research, pages 1935–1944, International Convention Centre, Sydney, Australia. PMLR.
Lai, L., Suda, N., and Chandra, V. (2018a). CMSIS-NN: efficient neural network kernels for arm
cortex-m cpus. CoRR, abs/1801.06601.
Lai, L., Suda, N., and Chandra, V. (2018b).

Not all ops are created equal!

CoRR,

abs/1801.04326.
Lecun, Y., Bottou, L., Bengio, Y., and Haffner, P. (1998). Gradient-based learning applied to
document recognition. Proceedings of the IEEE , 86(11), 2278–2324.
Lin, T., Maire, M., Belongie, S. J., Bourdev, L. D., Girshick, R. B., Hays, J., Perona, P., Ramanan,
D., Dollár, P., and Zitnick, C. L. (2014). Microsoft COCO: common objects in context. CoRR,
abs/1405.0312.
Lin, X., Zhao, C., and Pan, W. (2017). Towards accurate binary convolutional neural network. In
I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett,
editors, Advances in Neural Information Processing Systems 30 , pages 345–353. Curran
Associates, Inc.
44

BIBLIOGRAPHY

BIBLIOGRAPHY

Louizos, C., Ullrich, K., and Welling, M. (2017). Bayesian compression for deep learning. In
I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett,
editors, Advances in Neural Information Processing Systems 30 , pages 3288–3298. Curran
Associates, Inc.
McCulloch, W. S. and Pitts, W. (1943). A logical calculus of the ideas immanent in nervous
activity. The bulletin of mathematical biophysics, 5(4), 115–133.
McDanel, B., Teerapittayanon, S., and Kung, H. T. (2017a). Embedded binarized neural
networks. In Proceedings of the 2017 International Conference on Embedded Wireless Systems
and Networks, EWSN 2017, Uppsala, Sweden, February 20-22, 2017 , pages 168–173.
McDanel, B., Teerapittayanon, S., and Kung, H. (2017b). Incomplete dot products for dynamic
computation scaling in neural network inference. In 2017 16th IEEE International Conference
on Machine Learning and Applications (ICMLA), pages 186–193.
Minsky, M. and Papert, S. (1969). Perceptrons: An Introduction to Computational Geometry.
MIT Press, Cambridge, MA, USA.
Molchanov, D., Ashukha, A., and Vetrov, D. (2017). Variational dropout sparsifies deep neural
networks. In D. Precup and Y. W. Teh, editors, Proceedings of the 34th International Conference
on Machine Learning, volume 70 of Proceedings of Machine Learning Research, pages 2498–2507,
International Convention Centre, Sydney, Australia. PMLR.
Ojala, T., Pietikainen, M., and Harwood, D. (1994). Performance evaluation of texture measures
with classification based on kullback discrimination of distributions. In Proceedings of 12th
International Conference on Pattern Recognition, volume 1, pages 582–585 vol.1.
Perronnin, F. and Dance, C. (2007). Fisher kernels on visual vocabularies for image categorization.
In 2007 IEEE Conference on Computer Vision and Pattern Recognition, pages 1–8.
Qiu, Q., Cheng, X., robert Calderbank, and Sapiro, G. (2018). DCFNet: Deep neural network
with decomposed convolutional filters. In J. Dy and A. Krause, editors, Proceedings of the 35th
International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning
Research, pages 4198–4207, Stockholmsmässan, Stockholm Sweden. PMLR.
Rastegari, M., Ordonez, V., Redmon, J., and Farhadi, A. (2016). Xnor-net: Imagenet classification
using binary convolutional neural networks. CoRR, abs/1603.05279.
Real, E., Aggarwal, A., Huang, Y., and Le, Q. V. (2018). Regularized evolution for image classifier
architecture search. CoRR, abs/1802.01548.
Ren, M., Pokrovsky, A., Yang, B., and Urtasun, R. (2018). Sbnet: Sparse blocks network for fast
inference. CoRR, abs/1801.02108.
45

BIBLIOGRAPHY

BIBLIOGRAPHY

Ren, S., He, K., Girshick, R., and Sun, J. (2015). Faster R-CNN: Towards real-time object
detection with region proposal networks. In Advances in Neural Information Processing Systems
(NIPS).
Rosenblatt, F. (1957). The perceptron, a perceiving and recognizing automaton : (Project Para).
Cornell Aeronautical Laboratory, Buffalo, NY.
Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1986). Learning representations by
back-propagating errors. Nature, 323, 533 EP –.
Rusci, M., Rossi, D., Farella, E., and Benini, L. (2017). A sub-mw iot-endnode for always-on
visual monitoring and smart triggering. IEEE Internet of Things Journal , 4(5), 1284–1295.
Sandler, M., Howard, A. G., Zhu, M., Zhmoginov, A., and Chen, L. (2018). Inverted residuals
and linear bottlenecks: Mobile networks for classification, detection and segmentation. CoRR,
abs/1801.04381.
Siekkinen, M., Hiienkari, M., Nurminen, J. K., and Nieminen, J. (2012). How low energy is
bluetooth low energy? comparative measurements with zigbee/802.15.4. In 2012 IEEE Wireless
Communications and Networking Conference Workshops (WCNCW), pages 232–237.
Simonyan, K. and Zisserman, A. (2014). Very deep convolutional networks for large-scale image
recognition. CoRR, abs/1409.1556.
Soudry, D., Hubara, I., and Meir, R. (2014). Expectation backpropagation: Parameter-free
training of multilayer neural networks with continuous or discrete weights. In Advances in
Neural Information Processing Systems 27 , pages 963–971. Curran Associates, Inc.
Ström, N. (1997). Phoneme probability estimation with dynamic sparsely connected artificial
neural networks.
Tan, M., Chen, B., Pang, R., Vasudevan, V., and Le, Q. V. (2018). Mnasnet: Platform-aware
neural architecture search for mobile. CoRR, abs/1807.11626.
Tschannen, M., Khanna, A., and Anandkumar, A. (2018). StrassenNets: Deep learning with a
multiplication budget. In J. Dy and A. Krause, editors, Proceedings of the 35th International
Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research,
pages 4985–4994, Stockholmsmässan, Stockholm Sweden. PMLR.
Tseng, V. W.-S., Bhattacharya, S., Marqués, J. F., Alizadeh, M., Tong, C., and Lane, N. D.
(2018). Deterministic binary filters for convolutional neural networks. In IJCAI .
van den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner,
N., Senior, A., and Kavukcuoglu, K. (2016). Wavenet: A generative model for raw audio. In
Arxiv .
46

BIBLIOGRAPHY

BIBLIOGRAPHY

Wang, Y., Xu, C., You, S., Tao, D., and Xu, C. (2016). Cnnpack: Packing convolutional neural
networks in the frequency domain. In D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and
R. Garnett, editors, Advances in Neural Information Processing Systems 29 , pages 253–261.
Curran Associates, Inc.
Wang, Y., Xu, C., Xu, C., and Tao, D. (2017). Beyond filters: Compact feature map for portable
deep model. In D. Precup and Y. W. Teh, editors, Proceedings of the 34th International
Conference on Machine Learning, volume 70 of Proceedings of Machine Learning Research,
pages 3703–3711, International Convention Centre, Sydney, Australia. PMLR.
Warden, P. (2017). Speech commands: A public dataset for single-word speech recognition.
Werbos, P. J. (1990). Backpropagation through time: what it does and how to do it. Proceedings
of the IEEE , 78(10), 1550–1560.
Xie, S., Girshick, R. B., Dollár, P., Tu, Z., and He, K. (2017). Aggregated residual transformations for deep neural networks. In 2017 IEEE Conference on Computer Vision and Pattern
Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017 , pages 5987–5995.
Yang, T., Chen, Y., and Sze, V. (2017a). Designing energy-efficient convolutional neural networks
using energy-aware pruning. IEEE Conference on Computer Vision and Pattern Recognition.
Yang, Y., Li, T., Li, W., Wu, H., Fan, W., and Zhang, W. (2017b). Lesion detection and
grading of diabetic retinopathy via two-stages deep convolutional neural networks. CoRR,
abs/1705.00771.
Yao, S., Zhao, Y., Zhang, A., Su, L., and Abdelzaher, T. F. (2017). Compressing deep
neural network structures for sensing systems with a compressor-critic framework. CoRR,
abs/1706.01215.
Zhang, X., Zhou, X., Lin, M., and Sun, J. (2018a). Shufflenet: An extremely efficient convolutional
neural network for mobile devices. IEEE Conference on Computer Vision and Pattern
Recognition.
Zhang, Y., Pezeshki, M., Brakel, P., Zhang, S., Laurent, C., Bengio, Y., and Courville, A. (2016).
Towards end-to-end speech recognition with deep convolutional neural networks. In Interspeech
2016 , pages 410–414.
Zhang, Y., Suda, N., Lai, L., and Chandra, V. (2017). Hello edge: Keyword spotting on
microcontrollers. arXiv preprint arXiv:1711.07128 .
Zhang, Y., Li, K., Li, K., Wang, L., Zhong, B., and Fu, Y. (2018b). Image super-resolution using
very deep residual channel attention networks. In ECCV .

47

BIBLIOGRAPHY

BIBLIOGRAPHY

Zhao, H., Shi, J., Qi, X., Wang, X., and Jia, J. (2017). Pyramid scene parsing network. In CVPR.
Zhou, K., Gu, Z., Liu, W., Luo, W., Cheng, J., Gao, S., and Liu, J. (2018). Multi-cell multi-task
convolutional neural networks for diabetic retinopathy grading kang. CoRR, abs/1808.10564.
Zhu, C., Han, S., Mao, H., and Dally, W. J. (2016). Trained ternary quantization. arXiv preprint
arXiv:1612.01064 .
Zoph, B. and Le, Q. V. (2017). Neural architecture search with reinforcement learning. International Conference on Learning Representations (ICLR).
Zoph, B., Vasudevan, V., Shlens, J., and Le, Q. V. (2018). Learning transferable architectures
for scalable image recognition. In Computer Vision and Pattern Recognition (CVPR), 2018
IEEE Conference on, volume 1.

48

L41: Lab 2
Alexandru-Andrei Iacob<aai30>
March 16, 2022

1

Introduction

The process model serves as both a means of isolating program execution [Saltzer and Schroeder, 1975] and as
the primary computational abstraction of the system [Silberschatz et al., 2018, pg.105]. The goal of this work is
to understand the overhead of Inter-Process Communication (IPC) in the case of the FreeBSD implementation of
the UNIX pipe IPC. Given that transferring data through this method requires two copies [McKusick et al., 2014,
pg.62], the most relevant implementation aspects of this procedure is whether the data is passed by value or if one
copy is elided by pining a page, marking it as copy-on-write (COW) and directly sharing it with the receiver. This
report intends to explore the performance impact of buffer sizes on pipe IPC as well as the effectiveness of VM
optimisations with regards to the memory threshold from which they are applied.
The experimental design is organised on three levels all based on an IPC benchmark transferring data between
two processes with a given buffer size. First, the bandwidth of buffer sizes between 32B and 64MiB is measured
with the default VM threshold, as well as with the VM optimisation always turned off and always turned on. Second,
DTrace [Cantrill et al., 2004] is used to profile the memory returns of write() and read(), the time spent in either as
well their scheduling behaviour. Third, source code inspection and hardware performance counters are used to
construct a working model of the overall pipe IPC implementation and its interactions with the microarchitecture
of the ARM A72 processor, especially its memory hierarchy. Overall the results show both that large benchmark
buffersizes VM optimisations are beneficial in reducing pipe IPC overhead, although severe limitation arise
both from the pipe IPC implementation limiting data transfer and from the L2 cache becoming overwhelmed as
benchmark buffers grow too large. Furthermore, properly setting the threshold for using VM optimisations has
sever impact on performance as memory transfers result in too many context switches. Although promising, these
results often draw upon Hardware Performance Counters (HWPMC) for justification, which incur a statistically
significant and very large effect on performance. This fear is well-founded, however analysis shows that the broad
behavioural trends are largely unaffected by the probe effect and the conclusions can be tentatively trusted.

2

Experimental setup and methodology

Given the security and abstraction benefits of process isolation, operating systems tend to disallow by-default direct
memory accesses between the virtual address spaces of different processes. The overhead incurred by having to
transfer data using pipe IPC is significant as it must pass through the kernel which itself must create an extra-copy
for security reasons. The primary goals of this report is to understand what can be done to reduce this overhead
either explicitly by the user-space program (larger buffers) or transparently by the kernel (VM optimisations).

2.1

Hypotheses

1. Larger pipe buffer sizes improve IPC performance.
2. Page-borrowing virtual-memory optimisations:
(a) Are well tuned to current microarchitectures
(b) Always achieve a performance improvement, when enabled at or above the default 8KiB threshold,
over the unoptimised baseline.
3. The probe effect associated with using HWPMC to explore this workload is negligible. (L41 only)
1

2.2

Platform

All experiments are run on a Raspberry Pi 4 - Broadcom 2711. It uses a with a Quad-core Cortex-A72 (ARM v8)
64-bit SoC @ 1.5 GHz under-clocked at 600 MHz running FreeBSD. Only one of the cores is used for the purposes
of this report. Main memory is 8GiB LPDDR4-2400 SDRAM while external memory is maintained in a 64GiB
SDCard. Importantly for this report, the processor has a 32KiB data cache, 48KiB instruction L1 cache per core,
and 2MiB shared L2 cache. It supports page sizes of 4KiB, 2MiB, and 1GiB.

2.3

Benchmark

The IPC benchmark sets up two processes with access to a pair of IPC endpoints referencing a shared pipe. It tests
the performance of the pipe IPC by carrying out write() and read() system calls to send and receive a given amount
of bytes. The benchmark pegs itself to one CPU in order to avoid interference from concurrent execution. The
amount of data sent at each step—until the total number of bytes has been moved—is based on the benchmark
buffersize. It is important to note that both write() and read() may return partial results. The provided benchmark,
despite this, throws an exception if the sender’s write() operation fails to write the expected amount, however, the
read() operation of the receiving process is allowed to be re-invoked if it fails to read the requested amount.
The benchmark can return the average bandwidth across the IPC object as well as time, system-time (stime),
user-time (utime), number of messages sent (msgsnd) or received (msgrcv) and the number of voluntary (nvcsw)
and involuntary (nivcsw) context switches. It can also gather a number of HWPMCs split across four modes
arch|dcache|instr|tlbmem. The specific counters used for the analysis will be introduced in Sec.2.4.4.

2.4

Experiments

2.4.1

Statistics and error mitigation

All non-DTrace experiments bellow use 10 benchmark iterations while throwing away the first iteration to avoid
startup effects. They were all ran one-after another on a freshly rebooted system with a single ipykernel and
ssh connection running. The median is used as the primary summarisation tool given its resistance to skewed
distributions alongside the semi-inter-quartile range (SIQR) as the measure of error [Jain, 1991, sec.12.3 and
sec.12.8]. The secondary summary statistic is the mean with its standard deviation as the error, it is used when
effect sizes are reported. When the exact same measure with different lines is shown side-by-side the y-axis is
scaled to the maximum of the two as to allow comparison. The x axis is always the buffersizes and shared. DTrace
experiments are only run for 1 iteration, however, their results are used merely as high-level pointers for research
directions—and relegated to the appendix.
Results relating to the effects of VM optimisation or to the HWPMC probe effect are statically verified through
either a statistical significance test or an effect size calculation for each buffersize. This is done because many of
the observable behaviours are buffersize-dependent and could easily become indiscernible if all buffersize data
was combined before the test. The test used is the two-tailed Student’s t-test [Student, 1908] with a significance
threshold set to α = 0.05. All plotted p-values are capped at 0.1 to allow for easy viewing—their magnitude is not
to be considered relevant outside of passing or not passing α. The ttest is paired with the Hedge’s g [Enzmann,
2015] effect size that measures the gap between the mean of the two groups divided by the pooled standard
deviation—tuned for small sample sizes. The author is not aware of any strong general guidelines for interpreting
such effect sizes in computer science, as such the interpretation is based on the generalisable argument of Wilcox
[2019, Concerns about Cohen’s d, pg.4] which uses the standard deviation gap to determine how exceptional a
result is in terms of its quantile—e.g by Chebyshev’s inequality (A.4).
2.4.2

Performance

This set of experiments measures the benchmark performance when transferring 16MiB = 224 B of data using
power-of-two user-space buffers ranging from 32B to 16MiB and the default VM optimisation threshold in order
to directly evaluate H.1. For analysing the overall benefits of VM optimisation, the benchmark will be ran with
thresholds th ∈ {32B, 8KiB, 32MiB} signifying the VM optimisation being always-on (Always-Opt), starting at
the default threshold (Default), or always off (No-Opt). A ttest is performed between Default and No-Opt to test
H.2b at each buffersize for the standard FreeBSD configuration and between Always-Opt and No-Opt to test the
effects of VM optimisation overall.

2

2.4.3

Tracing and profiling

The performance analysis in Sec.2.4.2 is complemented by tracing and profiling the behaviour of the write() and
read() system calls. The first level of this investigation includes counting the number of write() and read() calls and
aggregate statistics of the memory (buffersize) they are called with as well as the actual memory they report as
having written/read. Alongside these aggregations, the exact memory values are saved. The second level inspects
the scheduling behaviour of the CPU, specifically when are the threads running each of the system calls on/off cpu
as well as when they go to sleep while waiting for data to be written into/read from the kernel pipe IPC buffer.
2.4.4

Hardware behaviour investigation

These experiments only use thresholds th ∈ {32B, 32MiB} as the behaviour of the Default condition is a mixture
of No-Opt and Always-Opt. This allows for an easier focus on the interaction between VM optimisation and the
hardware while testing H.2a.
The expected cause of copy elision’s difference in performance is a reduction in executed instructions. However,
most executed instructions are going to be unrelated to the behaviour impacted by VM optimisation as a significant
portion of them may not be loads/stores. Additionally, many loads and stores are not themselves related to
transferring data between buffers and may in fact be the result of other system behaviour such as context switches
or unrelated procedure calls. As such we would expect only the portion of load/stores related to buffer data transfer
to be reduced. To quantify, this the ratio of loads+store between Always-Opt and No-Opt is compared against the
bandwidth ratio and total instructions retired ratio. This leads to further dives into the cycles per instruction (CPI)
of each threshold as well as their memory access patterns in terms of L1D and L2D cache hits rates. Finally, main
memory usage is quantified by proxy through memory bus accesses.

2.5

Measuring the probe effect

Given the three relevant HWMPC modes as well as the two VM optimisation conditions are explored in Sec.3.4,
showing graphs for the un-probed and probed-version behaviour for Always-Opt and No-Opt for all HWMPC
modes is unfeasible. Consequently, the bandwidths obtained when running in one of the three HWPMC modes
for a given buffersize and number of iterations are combined into one data series. Since the Hedge’s effect size
relies on the mean and not the median, this series is summarised via its mean and standard deviation for easy
correlation with the chosen effect size. This has the added advantage of pooling data from all HWPMC bandwidths
regardless of where they stand in the sorted order of the series. With the number of modes effectively reduced to
one, the mean bandwidth of HWPMC modes is compared against the non-probed condition for both Always-Opt
and No-Opt. The statistical and practical significance is then assesd via a ttest, effect size calculation and by
comparing inflection points in the two graphs. The overall goal of this investigation is not to test H.3 in terms of
the general absolute HWPMC performance impact, but for each buffersize in particular as to allow for a direct
comparison of performance trends and inflection points against the non-probed conditions.

3

Results and discussion

The initial results of the performance analysis (Sec.2.4.2) shown in fig.1, partially confirm H.1 as they show a clear
improvement in band-with as buffersize increases. However, the bandwidth peaks at a buffer size of 216 B and then
declines. The decline is independent of VM optimisation as it is present for all conditions. The No-Opt threshold
outperforms Default for buffer sizes b = 213 B and b = 214 B, while nearly matching performance for b = 215 B.
The difference between them is statistically significant as p < α = 0.05 for b ≥ 213 . As such, the strongest version
of H.2b stating the VM optimisation above the default threshold always outperforms the non-optimised version can
be rejected. However, it does indeed appear that VM optimisation tends to either improve or not harm performance
with the default threshold, fact confirmed by the statistically significant bandwidth improvements of Default and
Always-Opt over No-Opt at 215 B ≤ b ≤ 219 B.
It must be noted that the p-value graph does reveal experimental limitation, its large oscillations when comparing
Default and No-Opt for b ≤ 8KiB are unexpected as the two should have near-identical performances with only
random differences. The limitation may be caused by the sample-size being too low or by running the No-Opt
experiments right after the Default ones, thus having long-term system effects—e.g heat, memory segmentation
e.t.c—impact results.

3

0.4
0.2

0.10
0.09
0.08
0.07
0.06
0.05
0.04
0.03
0.02
0.01
0.00
106

nvcsw (log)

p-value (linear)

0.0

105
msgsnd (log)

0.6

106
104
103
102
101
100

Always-Opt_vs_No-Opt
Default_vs_No-Opt
Significance-Threshold
buffer size (Bytes) (log)

104
103
102
101
100

105

105

104

104

103
102

buffer size (Bytes) (log)

103
102
101

101
100

buffer size (Bytes) (log)

105
msgrcv (log)

0.8

PIPE_MINDIRECT
L1D-CACHE
L1I-CACHE
L2D-CACHE
PIPE-IPC-LIMIT
L1D-TLB
L1I-TLB
L2-TLB
Always-Opt
Default-Thresh-2^13
No-Opt
buffer size (Bytes) (log)

nivcsw (log)

bandwidth (Bytes/s) (linear)

1e6
1.0

100

25 26 27 28 29 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224
buffer size (Bytes) (log)

25 26 27 28 29 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224
buffer size (Bytes) (log)

Figure 1: Benchmark measures sans msgsnd show the same extremum at b = 216 B. P-values are capped (Sec.2.4.1).
VM optimisation overhead Given the previous test of H2b, from this point onward most experiments will refer
to Always-Opt and No-Opt given that Default behaviour is a mixture of the two. The bandwidth differences between
Always-Opt and No-Opt are always statistically significant for b ≤ 223 B. For small buffer sizes, the unremarkable
performance of Always-Opt correlates with the number of voluntary and involuntary context switches up until
b = 216 B where they plateau and bandwidth peaks.
Pipe IPC and VM optimisation limitations Since the primary benefit of VM optimisation for this benchmark is
eliding the copy when write() is called, the decline of both Always-Opt and No-Opt towards the same bandwidth
serves as an indicator that increasing overhead in data transfer to the receiving process may hide any improvements
brought by VM optimisation at large buffer sizes. This is further supported by the plateau in IPC messages received
at the same b = 216 B, meaning that increases in user-space buffer-size do not lead to decreases in the number of
messages received—which should correspond to read() calls.

3.1

Memory usage at a syscall level

All results in this section serve purely as starting points for investigation, the DTrace output is show in A.1. When
inspecting the system-call behaviour—by investigating only the parameters and return values—of write() and
read() using DTrace, it becomes clear that the number of write() and read() system calls exactly follow the number
of messages sent and received from fig.1. Furthermore, the aggregate memory behaviour of write() is entirely
predictable as it never fails to send the exact amount of memory it is called with.
The aggregate memory behaviour of read() is identical up until a buffersize of b = 216 B is reached, at which
point the amount of memory that read() can return plateaus at 216 B. For any buffersize b past these values, read()
24
will have to be repeatedly called exactly b/216 times, with a total of 2 /216 calls for the transferring all the data. This
is further confirmed by the exact memory values returned by read() equaling the maximal return amount.

3.2

Pipe IPC implementation and benchmark execution

Investigating the implementation of pipe IPC in the FreeBSD kernel reveals that the kernel buffers used for data
transfer are capped. The system maintains a maximal total amount of memory for all pipes. If total pipe memory
4

usage exceeds 50% of max, the kernel caps pipe size to 212 B. For usage less than 50% pipes are allowed to grow
by doubling from the default 214 B up until a hard-coded limit of 216 B is reached. While the VM optimisation
could avoid this limitation, the implementation chooses to enforce only allowing data transfer up to the kernel pipe
IPC buffer size to keep the optimisation transparent. In the case of the synthetic benchmark used for this evaluation,
the steps taken to eliminate all non-necessary work in the system make reaching the 50% limit highly unlikely.
At a system-call level the sender calls write() repeatedly until the entire data amount has been sent. If the
underlying “pipe write” implementation does not use VM optimisation then the user-space buffer contents get
copied into the pipe IPC buffer, calls to write() execute until the buffer has been filled at which point write must call
the receiving process to empty the buffer and receive the data. If VM optimisation is turned on write(), immediately
tells the receiving process to copy data directly from the pinned pages. After all the data has been transferred,
read() is explicitly called in the receiving process to put data into its user-space buffer. Even if that data is already
available, read() still only returns chunks upwards of the max pipe IPC data transfer.

3.3

The context switch overhead of VM optimisation

The gap in voluntary and involuntary context switches observed between the No-Opt and Always-Opt conditions in
fig.1 potentially explains part of the initial performance disadvantage incurred by Always-Opt. In the case of not
using VM optimisation, data is copied from the user-space buffer to the pipe buffer by each consecutive write()
call. Once the buffer is full and must be emptied, write() puts itself to sleep with msleep() and causes a voluntary
context switch to the receiving process. The receiving process then empties the buffer and wakes up the write thread
which is then ran by the scheduler after the receiver returns—causing an involuntary context switch. This behaviour
means that the number of context switches for No-Opt is proportional to the total number of bytes divided by the
24
max kernel pipe IPC buffer size 2 /216 . This max kernel pipe IPC buffer size is always reached as no read() syscall
is executed until after all write() calls are complete, meaning that the buffer can repeatedly grow and copy-over its
previous content.
For a user-space buffer size which triggers the usage of VM optimisation, each write() call cause an immediate
context switch. The receiving process must copy the page data directly. Before the maximum pipe IPC data
transfer is reached, the number of context switches required for the benchmark is proportional to the total amount
24
of data divided by the user-space buffer size 2 /b. After the user-space buffer size reaches the maximum pipe
IPC data transfer, write() calls always cause a context switch even without VM optimisation since the kernel pipe
IPC buffer is instantly filled. Consequently, the number of context switches is equalised. This behaviour is not
sufficient to explain the gap between using and not using VM optimisation for smaller buffersizes, given that in
fig.1 the crossover point is actually at a buffersize of 215 B rather than the maximum pipe IPC transfer rate of
216 B—indicating that copy elision benefits overtake context switch overhead. However, context switching is stated
as the main reason for introducing a VM optimisation threshold in the implementation.
To confirm that the implementation of pipe IPC as well as the benchmark itself behave as described above,
DTrace can be used to compare the system-call interface against the actual work carried out by the sender and
receiver threads. The first step is to inspect how the distribution of system call execution time changes as buffer
size increases—purely for observing the trend given that specific DTrace timestamps will be affected by the probe
effect. All results for this are shown in A.2 due to space constraints. When applying quantize() to the system call
time for a given buffer size below the pipe IPC max transfer, the No-Opt condition has a number of long write()
calls approximately equal to the number of context switches—to empty the buffer—as well as approximately
224/b − nvcsw calls which can be several order of magnitude shorter. On the other hand, for Always-Opt transferring
amounts of data below the pipe IPC limit no extreme skew is present. After the maximal IPC data transfer size is
reached any differences in quantize() distribution largely disappear. Similar results, shown in A.3, are obtained
when using the DTrace sched provider to track how often the sender or receiver thread goes to sleep/wake or
on/off-cpu. Both align, as expected, with the context switching behaviour presented in Sec.3.3

3.4

Hardware behaviour

Fig.2 presents the ratio of speculative loads+stores between Always-Opt and No-Opt, it starts off extremely high
because of context switching, becomes optimal (≈ 25% lower at b = 216 B) and then decline until a < 5%
difference remains. This behaviour mirrors that of bandwidth in fig.1 and should be considered the primary source
of benefits from VM optimisation. The benefits of this reduction come despite total instructions retired being
near-equal for b ≥ 216 B. Nonetheless, the bandwidth performance improvement is less than would be expected
based on the overall decrease in loads+stores as it peaks at a mere ≈ 11%.
5

0.6
0.4
0.2

0.8
0.6
0.4
0.2
0.0

BUS_ACCESS_CNT (log)

buffer size (Bytes) (log)

105
104
103
102
101
25 26 27 28 29 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224
buffer size (Bytes) (log)

LD_ST
bandwidth
INST_RETIRED

buffer size (Bytes) (log)

0.8
0.6
0.4
0.2
0.0

buffer size (Bytes) (log)

106

100

2.00
1.75
1.50
1.25
1.00
0.75
0.50
0.25
0.00
1.0

L1D_HIT_RATE (linear)

L2D_HIT_RATE (linear)

0.0
1.0

RATIO (linear)

0.8

PIPE_MINDIRECT
L1D-CACHE
L1I-CACHE
L2D-CACHE
PIPE-IPC-LIMIT
L1D-TLB
L1I-TLB
L2-TLB
Always-Opt
No-Opt

CPI (linear)

bandwidth (Bytes/s) (linear)

1e6
1.0

1.75
1.50
1.25
1.00
0.75
0.50
0.25
0.00

buffer size (Bytes) (log)

25 26 27 28 29 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224
buffer size (Bytes) (log)

Figure 2: HWPMC results. The y-axis for ratios is capped as the initial values may be exceedingly large at ≈ 5.
The number of loads and stores cannot indicate anything about how efficiently each one of the instructions is
executed. The first indication that VM optimisation may also impacts the efficiency of each load/store comes from
the benchmark CPI. Always-Opt maintain a fairly constant CPI for each buffersize before peaking for buffersizes
218 B ≤ b ≤ 220 B and then declining. No-Opt CPI increases throughout until b = 220 B followed by a decline.
Given that the primary difference between Always-Opt and No-Opt is in their usage of loads/stores, one potential
explanation is that these CPI changes are caused by changes between the memory access efficiency of the two
conditions. This can be inspected by looking at levels of the memory hierarchy.
Overall, some of the cost of having to create two copies without VM optimisation could be reduced via caching.
Loads and stores are the triggers for cache accesses, as such the number of L1D and L2D cache accesses follow
the number of load/stores and likely do not carry additional information. However, the L1D cache overall hit rate,
fig.2 , shows a distinct advantage for No-Opt over the entire benchmark. Given that the task is to repetitively and
sequentially read data into a kernel buffer, cache misses should also happen one-after-another in a predictable
pattern that triggers hardware prefetching. Hardware prefetching can pull data regardless of the specific bounds on
the benchmark buffer [Drepper, 2007, sec.6.3], meaning that it can potentially help improve performance of future
write() calls . Furthermore, FreeBSD data copying functions such as the arm-optimised assembly memcpy make use
of explicit instructions to cause prefetching when reading from a buffer. These mechanisms make memory access
far less costly and thus may be responsible for the smaller bandwidth boost compared to the reduction in load-stores
at the peak throughput point. Importantly, the L1D hit-rate for No-Opt remain lower than for Always-Opt even at
the max kernel pipe size despite the fact that context switches and total instructions have equalised by this point.
This shows that parts of the data may still be in cache when the sender makes the receiver empty the kernel buffer
as the ARM-specific cpu switch implementation does not flush the cache during switching.
While the L2D cache size is 2MiB = 220 B and could thus hold a significant portion of the benchmark, the steep
decline in L2D hit-rate after a buffer-size of 218 B indicates that larger benchmark buffersizes tend to overwhelm
the L2D cache before b = 220 B. This corresponds to both the stepest part of the bandwidth decline, CPI increase,
and the (later-discussed) increase in BUS usage shown in fig.2. Overall, L2D cache exhaustion can be considered
one of the primary causes of the decline in performance at large buffer sizes discussed in Sec.3.5 and Sec.3.
The final piece of the memory puzzle comes in the form of memory accesses at levels higher up than the cache
in the memory hierarchy. Overall, as can be seen in fig.2, both Always-Opt and No-Opt require similar access to
the memory bus throughout. Importantly, when the L2D cache performance begins to collapse at b = 218 B, bus
6

0.8
0.6
0.4
0.2

Significance-Threshold
No-Opt-Probe-E

150

No-Opt-Probe-E

75
50
25
25 26 27 28 29 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224
buffer size (Bytes) (log)

Always-Opt
Mean-HWPMC

0.8
0.6
0.4
0.2

0.10
0.09
0.08
0.07
0.06
0.05
0.04
0.03
0.02
0.01
0.00

Hedges'g-eff-size (linear)

100

1.0

0.0

buffer size (Bytes) (log)

125

0

1e6

p-value (linear)

0.10
0.09
0.08
0.07
0.06
0.05
0.04
0.03
0.02
0.01
0.00

Hedges'g-eff-size (linear)

p-value (linear)

0.0

PIPE_MINDIRECT
L1D-CACHE
L1I-CACHE
PIPE-IPC-LIMIT
L2D-CACHE-EXHAUST
L2D-CACHE
L1D-TLB
L1I-TLB
L2-TLB
No-Opt
Mean-HWPMC
buffer size (Bytes) (log)

bandwidth (Bytes/s) (linear)

bandwidth (Bytes/s) (linear)

1e6
1.0

140
120
100
80
60
40
20

buffer size (Bytes) (log)
Significance-Threshold
Always-Opt-Probe-E

buffer size (Bytes) (log)

Always-Opt-Probe-E

25 26 27 28 29 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224
buffer size (Bytes) (log)

Figure 3: The non-probed Always-Opt and No-Opt behaviour vs the mean HWPMC probe effect.
access see an immediate increase together with CPI and bandwidth. All performance counters which were excluded
from this analysis followed very similar trends and were deemed unlikely to offer additional information for the
current report.
These hardware effects complement the previously realised report on software behavioral changes for memory
copying techniques as buffer sizes increase. For small buffers, the anterior analysis revealed a dominance of trap
servicing time as the data transfers were dwarfed by procedure calls and spinlocks. Addditionally, it revealed that
while buffersize increases are generally correlated with improved data transfer performance up to a peak, a decline
comes as the system spends more time servicing page faults and page zeroing. The system must also transition from
using lightweight copying routines like copycommon to heavy memcpy. These effects are also present here and
likely pay a large role in the homogenisation of Always-Opt and No-Opt performance at large buffers as overhead
hides the benefits of a medium-sized copy elision per write() call.
On the basis of these results, H.2a can be accepted given that VM optimisations do help reduce the number of
loads and stores sufficiently as to produce a performance improvement despite all of the advantages that caching
and the organisation of the memory hierarchy in general provides for repeated copies/access of data. Although the
default VM optimisation threshold proved imperfect for this benchmark, it did land close to the crossover point
of b = 215 B in fig.1 on a modern system with a benchmark that heavily favours copying compared to real-world
use-cases—as it always fills the kernel pipe IPC buffer with writes to completion rather than interleaving write()
and read() calls and thus causing additional context switches for No-Opt.

3.5

Measuring the HWPMC probe effect

To draw final conclusions, it must be established whether the probe effect has affected any of the findings from the
previous section. For the No-Opt condition (fig.3) there isn’t a strong trend for statistical significance at buffer
seizes smaller than 28 , potentially because system-call and context switch overhead dominate the run-time in a
manner which is not strongly reflected by the HWPMC or because the previously mentioned small sample size is
insufficient to detect it. Consequently, the null hypothesis that there is no probe effect for HWPMC counters when
not using VM optimisations cannot be rejected for small buffers. For larger buffer sizes than 28 No-Opt consistently
show a statistically significant probe effect. As such, the effect size can also be meaningfully discussed for larger
buffers. The non-probed No-Opt mean being 50 standard deviations higher than the mean of the probed condition

7

would correspond to it being at least in the top 0.0004 of values for the probability distribution of bandwidths at
that given buffer size—by Chebyshev’s inequality. This is far beyond what would be considered a “large effect” in
any field, as is the case for the effect size seen at every buffer size on the graph.
For the Always-Opt condition (fig.3), the probe effect always passes the statistical significance threshold.
Consequently, the effect size is always meaningful to discuss and it confirms the visual intuition that the HWPMC
probe effect is much more impactful for Always-Opt than No-Opt, at least until a buffer size larger than 220 B
is reached. Additionally, its graph has a more meaningful shape as it shows how the probe effect is remarkably
high for small buffers in particular, potentially because of heightened system activity caused by the repeated
system calls, context switches and pipe IPC data transfer causing more architectural and micro-architectural events
where the probe effect can significantly impact results(supported by the very large initial instruction retired ratio
between Always-Opt and No-Opt discussed in sec.3.4). The decay in effect size at large buffer sizes for both
conditions follows from main-memory transfer becoming the main bottleneck as it is beyond the scope of CPU
HWPMC—besides simply counting how many bus accesses are done which should have an insignificant cost.
This analysis makes it clear that the probe effect is present and potentially very large in magnitude. As such,
the most direct interpretation of being “negligible” would lead to the outright rejection of H.3. However, while the
bandwidth difference are indeed large, the probed Always-Opt and No-Opt performance in fig.3 follow the same
overall behaviours and trends as the non-probed versions. To be precise, the same initial performance gap between
No-Opt and Always-Opt is present and the crossover point is still in the neighbourhood of the maximum pipe IPC
size. Furthermore, the same clear decline happens once the L2D cache becomes overwhelmed. All of this being
taken into account, H.3 is quantitatively rejected but holds true in the sense that the probe effect is unlikely to have
impacted any conclusions drawn on the basis of the HWPMC.

4

Conclusion

This investigation started with the goal of understanding, in the form of a case study on the pipe IPC implementation
in FreeBSD, the IPC overhead caused by process isolation and how the OS and system may work to lower them.
To achieve this, three hypotheses were constructed and tested with the following outcomes.
1. Larger pipe buffer sizes improve IPC performance.
This hypothesis was rejected in its strongest form since the performance benefits of VM-optimisation peak
at a buffersize equal to the maximum pipe IPC data transfer of 64KiB = 216 B and then plateau and finally
decline. A lighter form of the hypothesis stating that larger buffer sizes tend to be associated with better IPC
performance until the fast levels of the memory hierarchy become unable to service them can be accepted.
2. Page-borrowing virtual-memory optimisations:
(a) Are well tuned to current microarchitectures.
This sub-hypothesis can be accepted as VM optimisations do succeed in lowering loads and stores to
cause a noticeable and statistically significant improvement in benchmark performance for buffersizes
larger than 215 B. This is despite copying being advantaged by both benchmark structure and caching.
(b) Always achieve a performance improvement, when enabled at or above the default 8KiB threshold,
over the unoptimised baseline.
As written, this hypothesis must be rejected since a performance improvement is not seen for all
buffersizes equal to or larger than the default threshold. However, the imperfect timing of the default
8KiB threshold is not cause for concern as the benchmark is unrepresentative of realistic workloads.
3. The probe effect associated with using HWPMC to explore this workload is negligible.
This hypothesis is quantitatively rejected as experiments show that the probe effect of HWPMC is very large.
However, the behaviour of the benchmark follows the same overall trends as without HWPMC enabled. Thus
the probe effect is unlikely to affect the conclusions of this analysis.
Several shortcomings of current work and future research avenues remain. First, more samples are needed for this
kind of investigation in order to avoid noise interfering with the statistical significance of results (Sec.3.5). Second,
attempting an intervention to modify the kernel max pipe IPC buffer and data transfer size would reveal if the
current limit is the primary cause of the performance peak or if the cache exhaustion would have caused a decline
too soon for it to matter—it could also show if VM optimisations are particularly held back by the limit. Third,
tracing the HWPMC behaviour to specific parts of the kernel would likely be quite revealing.
8

References
Bryan Cantrill, Michael W Shapiro, Adam H Leventhal, et al. Dynamic instrumentation of production systems. In USENIX Annual Technical
Conference, General Track, pages 15–28, 2004.
Ulrich Drepper. What every programmer should know about memory. 01 2007.
Dirk Enzmann. Notes on effect size measures for the difference of means from two independent groups: The case of cohen’s d and hedges’ g, 01
2015.
R. Jain. The art of computer systems performance analysis: techniques for experimental design, measurement, simulation, and modeling. Wiley
New York, 1991.
Marshall Kirk McKusick, George V Neville-Neil, and Robert NM Watson. The design and implementation of the FreeBSD operating system.
Pearson Education, 2014.
J.H. Saltzer and M.D. Schroeder. The protection of information in computer systems. Proceedings of the IEEE, 63(9):1278–1308, 1975. doi:
10.1109/PROC.1975.9939.
Abraham Silberschatz, Peter Baer Galvin, and Greg Gagne. Operating System Concepts, 10th Edition. Wiley, 2018. ISBN 978-1-118-06333-0.
URL http://os-book.com/OS10/index.html.
Student. The probable error of a mean. Biometrika, pages 1–25, 1908.
Rand Wilcox. A robust nonparametric measure of effect size based on an analog of cohen’s d, plus inferences about the median of the typical
difference. Journal of Modern Applied Statistical Methods, 17(2):1, 2019.

Appendix

A.1

Syscall memory
106
104
103
102
101
100
225
220
215
210
25
20
write_return_max_mem (log)

224

105

216
212
28
24

104
103
102
101
100
230
220
215
210
25
224

buffer size (Bytes) (log)

220
216
212
28
24
20

25 26 27 28 29 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224
buffer size (Bytes) (log)

buffer size (Bytes) (log)

225

20

buffer size (Bytes) (log)

220

20

106

read_entry_tmem (log)

write_entry_tmem (log)

230

PIPE_MINDIRECT
L1D-CACHE
L1I-CACHE
PIPE-IPC-LIMIT
L2D-CACHE
L1D-TLB
L1I-TLB
L2-TLB
Always-Opt
Default-Tresh-2^13
No-Opt
buffer size (Bytes) (log)

read_return_max_mem (log)

write_cnt (log)

105

read_cnt (log)

A

25 26 27 28 29 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224
buffer size (Bytes) (log)

Figure 4: Aggregate metrics for write and read calls and memory writes/requests as well as their return values.
From fig.4 we can indeed see that write() always returns as much memory as it requests—max returned memory
and total requested memory are identical—while read() plateaus at 216 B, the maximum pipe IPC data transfer.
24
Read attempts to return the entire requested size each time and must make 2 /216 calls after the plateau—thus

9

accumulating more total requested memory than the benchmark actually contains. The DTrace script tracing the
exact read return values is not shown due to appendix space constraint as read() behaviour can already be inferred
from this graph.

A.2

Syscall time quantisation

Time quantisation is more difficult to show due to space constraints. As such, only quantisations for the smallest
buffer size and for the pipe IPC max data transfer are shown to emphasises the different behaviour of No-Opt and
Always-Opt as caused by No-Opt only emptying its kernel buffer when its full while Always-Opt causes a data
transfer for each write. Fig.5 and fig.6 compare No-Opt to Always-Opt for the smallest buffersize b = 25 B while
fig.7 and fig.8 do the same for b = 216 B. They clearly show initial clustering for No-Opt time into a group of very
fast write() calls with slow write() calls happening when the kernel pipe IPC buffer is full. For always-opt little to
no clustering takes place. The behaviour homogenises once the max pipe IPC data transfer is reached.

write_qtime
value ------------- Distribution ------------- count
1024 |
0
2048 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ 517636
4096 |
4683
8192 |
1458
16384 |
231
32768 |
1
65536 |
1
131072 |
1
262144 |
0
524288 |
0
1048576 |
0
2097152 |
0
4194304 |
0
8388608 |
0
16777216 |
277
33554432 |
0

write_qtime
value ------------- Distribution ------------- count
8192 |
0
16384 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ 511018
32768 |@
13257
65536 |
3
131072 |
0
262144 |
9
524288 |
0
read_qtime
value ------------- Distribution ------------- count
2048 |
0
4096 |@@@@@@@@@@@@@@
182866
8192 |
137
16384 |@@@@@@@@@@@@@@@@@@@@@@@@@
332314
32768 |@
8961
65536 |
2
131072 |
0
262144 |
7
524288 |
0
1048576 |
0
2097152 |
0
4194304 |
0
8388608 |
0
16777216 |
0
33554432 |
0
67108864 |
0
134217728 |
0
268435456 |
0
536870912 |
0
1073741824 |
0
2147483648 |
0
4294967296 |
0
8589934592 |
0
17179869184 |
0
34359738368 |
0
68719476736 |
1
137438953472 |
0

read_qtime
value ------------- Distribution ------------- count
1024 |
0
2048 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ 517482
4096 |
4990
8192 |
1553
16384 |
249
32768 |
0
65536 |
0
131072 |
0
262144 |
0
524288 |
0
1048576 |
0
2097152 |
0
4194304 |
0
8388608 |
0
16777216 |
13
33554432 |
0
67108864 |
0
134217728 |
0
268435456 |
0
536870912 |
0
1073741824 |
0
2147483648 |
0
4294967296 |
0
8589934592 |
0
17179869184 |
0
34359738368 |
0
68719476736 |
0
137438953472 |
1
274877906944 |
0

Figure 6: Always-Opt read and write pow2quantisation for a buffer size of 25 B

Figure 5: No-Opt read and write pow2-quantisation
for a buffer size of 25 B

A.3

Write and read sleep and wake behaviour

Sleep and wake behaviour are presented similarly to the time quantisations with direct DTrace output. Fig.9 and
fig.10 compare No-Opt to Always-Opt for the smallest buffersize b = 25 B while fig.11 and fig.12 do the same for
b = 216 B. The sender and receiver are identified by the pid and tid, shown after the write and read counts above
right before the syscall entry/return cnt. For No-Opt, the sender begins by having to go to sleep only when the
kernel pipe IPC buffer is full, when the max pipe IPC transfer is reached it must go to sleep for every transfer.
Under Always-Opt the sender always goes to sleep as it does not have a kernel pipe IPC buffer. The results for the
sender and receiver going on and off-cpu are similar—and also reflect context switches—and not shown to save
space.

A.4

Chebyshev’s inequality

For most probability distributions Chebyshev’s inequality states that at most 1/k2 of the values will be more than k
standard deviations away from the mean.

10

write_qtime
value ------------- Distribution ------------- count
32768 |
0
65536 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ 254
131072 |
0
262144 |
2
524288 |
0

write_qtime
value ------------- Distribution ------------- count
32768 |
0
65536 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ 255
131072 |
0
262144 |
0
524288 |
1
1048576 |
0

read_qtime
value ------------- Distribution ------------- count
16384 |
0
32768 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ 255
65536 |
0
131072 |
0
262144 |
0
524288 |
0
1048576 |
0
2097152 |
0
4194304 |
0
8388608 |
0
16777216 |
0
33554432 |
0
67108864 |
0
134217728 |
0
268435456 |
0
536870912 |
0
1073741824 |
0
2147483648 |
0
4294967296 |
0
8589934592 |
0
17179869184 |
0
34359738368 |
0
68719476736 |
0
137438953472 |
1
274877906944 |
0

read_qtime
value ------------- Distribution ------------- count
16384 |
0
32768 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ 255
65536 |
0
131072 |
0
262144 |
0
524288 |
0
1048576 |
0
2097152 |
0
4194304 |
0
8388608 |
0
16777216 |
0
33554432 |
0
67108864 |
0
134217728 |
0
268435456 |
0
536870912 |
0
1073741824 |
0
2147483648 |
0
4294967296 |
0
8589934592 |
0
17179869184 |
0
34359738368 |
0
68719476736 |
0
137438953472 |
1
274877906944 |
0

Figure 7: No-Opt read and write pow2-quantisation
for a buffer size of 216 B

CPU
ID
1
2
read_entry_cnt_
524287
read_retun_cnt524288
write_entry_cnt524288
write_return_cnt524288

Figure 8: Always-Opt read and write pow2quantisation for a buffer size of 216 B

FUNCTION:NAME
:END

2675

100144

_sleep_cnt

2676

100142

_sleep_cnt

2676

100142

_wake_cnt

2675

100144

_wake_cnt

2675

100144

2675

100144

2676

100142

2676

100142

CPU
ID
2
2
read_entry_cnt_
524287
read_retun_cnt524288
write_entry_cnt524288
write_return_cnt524288
2614
231952
2615
247844
2615
524289
2614
546402

14
278
6956
7144
2676
100142
2274150342759
2675
100144
55138573376132

_sleep_ttime

2676
326933631
2675
7718165366

100142

_sleep_avg_time

100144

_sleep_avg_time

2676
24292186
2675
27521704

100142

_sleep_min_time

100144

_sleep_min_time

2676
100142
69560644299
2675
100144
69931644411

_sleep_max_time

_sleep_ttime

Figure 9: No-Opt sender and receiver thread sleep
and wake behavior for a buffersize of 25 B.

FUNCTION:NAME
:END

2733

100116

_wake_cnt

2733

100116

_sleep_cnt

2732

100226

_wake_cnt

2733

100116

2733

100116

2732

100226

2732

100226

2614

100092

_sleep_cnt

100091

_wake_cnt

100091

_sleep_cnt

100092

_wake_cnt

2615
100091
292788096157
2614
100092
2009154442424072

_sleep_ttime

2615
1181340
2614
3677062753

100091

_sleep_avg_time

100092

_sleep_avg_time

2615
46149
2614
48277

100091

_sleep_min_time

100092

_sleep_min_time

2615
100091
276275431257
2614
100092
276275524757

_sleep_max_time

100092

2614

100092

2615

100091

2615

100091

_sleep_ttime

Figure 10: Always-Opt sender and receiver thread
sleep and wake behavior for a buffersize of 25 B.

_sleep_max_time

CPU
ID
2
2
write_entry_cnt1
write_return_cnt1
read_entry_cnt_
255
read_retun_cnt256

FUNCTION:NAME
:END

_sleep_max_time

CPU
ID
3
2
write_entry_cnt1
write_return_cnt1
read_entry_cnt_
255
read_retun_cnt256

6

FUNCTION:NAME
:END
2672

2672

100142

_wake_cnt

2672

100142

_sleep_cnt

2671

100151

_wake_cnt

100142

2672

100142

2671

100151

2671

100151

4

256

257

332
2733
100116
160950750705
2732
100226
53448422782661

333
_sleep_ttime

2672
100142
66395139726
2671
100151
22122653186157

_sleep_ttime

Figure 11: No-Opt sender and receiver thread sleep
and wake behavior for a buffersize of 216 B.
2733
100116
26825125117
2732
100226
160989225248

_sleep_avg_time

2733
100116
277518
2732
100226
160949424855

_sleep_min_time

2733
100116
160949281836
2732
100226
161029447503

_sleep_max_time

_sleep_ttime
_sleep_ttime

Figure 12: Always-opt sender and receiver thread
sleep and wake behavior for a buffersize of 216 B.

_sleep_avg_time

_sleep_min_time

_sleep_max_time

11

2672
100142
16598784931
2671
100151
66434393952

_sleep_avg_time

2672
100142
290593
2671
100151
66394597855

_sleep_min_time

2672
100142
66394261818
2671
100151
66474384559

_sleep_max_time

_sleep_avg_time

_sleep_min_time

_sleep_max_time

Investigating the local-global accuracy
trade-off in Federated Learning

Alexandru-Andrei Iacob
Homerton College

A dissertation submitted to the University of Cambridge
in partial fulfilment of the requirements for the degree of
Master of Philosophy in Advanced Computer Science

University of Cambridge
Computer Laboratory
William Gates Building
15 JJ Thomson Avenue
Cambridge CB3 0FD
United Kingdom
Email: aai30@cam.ac.uk
May 9, 2022

Declaration
I Alexandru-Andrei Iacob of Homerton College, being a candidate for the M.Phil
in Advanced Computer Science, hereby declare that this report and the work
described in it are my own work, unaided except as may be specified below,
and that the report does not contain material that has already been used to any
substantial extent for a comparable purpose.

Total word count: Add Here

Signed:
Date:

This dissertation is copyright ©2010 Alexandru-Andrei Iacob.
All trademarks used in this dissertation are hereby acknowledged.

add
wordcount

Abstract (1 page)
Federated Learning is a form of distributed Machine Learning which leverages local data storage and training on edge-devices. It attempts to reduce communication
costs by alternating the local training steps with a global aggregation phase which
combines model parameters without ever directly sharing private data. While
local-only training presents distinct advantages with regard to communication efficiency and client privacy over other distributed training paradigms, it introduces
significant difficulties regarding data and system heterogeneity. Most relevant to
this work, clients with highly unusual data distributions may receive a worse model
following the global training process than they could have trained on their own.
This may be exacerbated by recent techniques which attempt to restrict how far a
local model could diverge from the global one in order to improve the federated
process convergence. Two primary directions for addressing the trade-off between
local and global accuracy have been explored in the academic literature. The first
attempts to create a “fairer” global model, thus constraining how much the accuracy
of the global model can vary on the local datasets of the clients. The second relies
on local adaptation techniques to construct what is effectively a customized local
model for each client alongside the global one. This work brings three contributions to the field of Federated Learning. First, it provides an experimental analysis
of how the distance between the global and local models affects level of fairness
or local adaptation necessary to provide a given client with better results than they
could have obtained individually. Second, it provides the first direct comparison
between Fair Federated Learning methods and local adaptation methods in terms
of their ability to. Third, it proposes a new sub-category of Federated Learning
which alternates normal training and aggregation steps with local adaptation ones.
The experimental results show

add
results
show

Contents
1

Introduction (2 page)

1

2

Background and related work (10 page)
4
2.1 Federated Learning . . . . . . . . . . . . . . . . . . . . . . . . . 4
2.1.1 Foundational challenges . . . . . . . . . . . . . . . . . . 5
2.1.2 Federated learning objective . . . . . . . . . . . . . . . . 6
2.1.3 FedAvg . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
2.1.4 The local-global accuracy trade-off . . . . . . . . . . . . 7
2.1.5 Flower . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
2.2 Related work . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
2.2.1 Limiting local model divergence . . . . . . . . . . . . . . 8
2.2.2 Fair Federated Learning . . . . . . . . . . . . . . . . . . 8
2.2.3 Personalization techniques . . . . . . . . . . . . . . . . . 10

3

Methods (10 page)
3.1 Hypotheses . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Experimental Setup . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.1 Proximal Term Tuning . . . . . . . . . . . . . . . . . . .
3.2.2 Fairness Tuning . . . . . . . . . . . . . . . . . . . . . . .
3.2.3 Targeted Local Adaptation . . . . . . . . . . . . . . . . .

14
14
14
15
15
16

4

Results (10 page)

17

5

Discussion (10 page)

18

6

Summary and Conclusions (3-4)

19

i

Add
wordcount

List of Figures

ii

List of Tables

iii

List of Algorithms
1
2

Federated Averaging [23] . . . . . . . . . . . . . . . . . . . . . .
Q-FedAvg [19] . . . . . . . . . . . . . . . . . . . . . . . . . . .

iv

7
10

Chapter 1
Introduction (2 page)
As the amount of data produced and gathered globally has grown rapidly, Machine
Learning (ML) methods capable of making practical use of it have become central
to the functioning of large sections of the global economy. Deep Learning (DL)
methods specifically have become the de-facto standard solution to core technical challenges faced by multi-billion-dollar industries, such as Natural Language
Processing [4, 32] in translation or writing assistance or Image Processing [1, 26]
in computer vision. Despite their success, such methods may require prohibitive
amounts of computation or high-quality training data.
The increasingly large number of internet-connected consumer devices represents
a pool of both computation power and training data for ML tasks. Unlike the
computational units used in classical Distributed ML [25], such devices may
not be wholly dedicated to the training task. As such, they may have privacy
concerns with regard to sharing their training data, computational constraints on
how much they can contribute to the training process at a given time, or data
transfer limitations. Furthermore, heterogeneity in device characteristics and the
local data they have gathered over time represent inherent challenges of the setting.
Importantly, this heterogeneity means that the ideal scenario for each device would
be an entirely custom model.
In order to tackle the peculiar challenges of the setting, McMahan et al. [23]

1

introduced Federated Learning (FL). This distributed ML paradigm shifted the
focus towards communication-efficiency and privacy preservation, in accordance
with the principles of focused collection and data minimization outlined in White
House [30]. The algorithm they introduced, Federated Averaging (FedAvg), has
been central to the development of a wide array of direct descendants [13, 18, 19]
and the field as a whole. FedAvg organizes training into rounds, at the beginning
of each round the server sends a global model to all clients which then proceed
train it locally before sending it back for aggregation to create a new global model.
The aggregation step consists off constructing a weighted average of the model
parameters from all clients according to the share of the global training data
that they hold. This simple aggregation mechanism proved empirically effective,
however, it’s limited focus to global model convergence irrespective of the local
training process of each client has been a significant challenge for subsequent
research.
The main issue of concern for this work is what will be referred to as the “localglobal accuracy trade-off”. This topic can be broadly defined as the tendency
of the final trained global model to perform worse on the local data of highly
heterogeneous clients despite good performance on the global distribution [19]. In
some cases, it may be possible that the global model is worse than one they could
have trained entirely locally in spite of the higher training time and data availability
[33]. According to Yu et al. [33], such clients are severely disincentivized from
participating in the training process. While the effect is well-documented when
using FedAvg, no research assessing the impact of newer aggregation algorithms
which further emphasizes global model convergence—such as FedProx [18], has
been found.
The existing body of work on the mitigation of this trade-off has focused on two
primary means of improving performance on heterogeneous clients. Li et al. [19]
propose a Fair Federated Learning (FFL) algorithm which tunes the federated
objective function to focus on clients with large losses in an attempt to smooth-out
the accuracy distribution of the final global model across the client data partitions.
Alternatively, personalization (fine-tuning) methods have been proposed by Yu
et al. [33] and Mansour et al. [22] as a means of quickly constructing effective
2

add
extra

local models for heterogeneous clients after training the global one using a standard
FL algorithm. To date, there has not been an attempt to reconcile the two methods.
Furthermore, little attention has been paid to the practical computational and
engineering cost of either FFL or any of the relevant personalization algorithms.
This work makes three primary contributions to the field of Federated Learning
1. It extends the work of Yu et al. [33] by exploring the impact of personalization
techniques on the FedProx [18] algorithm rather than FedAvg. FedProx
purposefully limits how far a client model can diverge from the global
one during one training round thus affecting highly heterogeneous clients
disproportionately. Experimental results show that the local-global accuracy
trade-off has a higher impact on FedProx than FedAvg and the effect scales
based on the degree of the limitation that model divergence is subject to.

edit

2. Second, it combines q-FedAvg[19] with personalization techniques to assess
if fine-tuning is still beneficial in the context of a fairer accuracy distribution.
This takes into account the computational cost of local adaptation as well
as the disproportionate impact it has upon an ML model lifecycle. Experimental results show that models trained via q-FedAvg are in need of local
adaptation less frequently. Additionally, when they do apply local adaptation it requires fewer rounds on average for the adapted model to exceed the
performance of a purely local one.

edit

3. Third, it proposes a new form of Federated Learning which interleaves
rounds of local training, global aggregation and selective local adaptation,
while keeping compatibility with pre-existing aggregation strategies.

edit

3

Chapter 2
Background and related work (10
page)
Given the recent emergence of the field, a great deal of the published literature is
concerned with the optimization of the fundamental Federated Learning process
with the explicit goal of constructing a well-performing global model. Although
several secondary research directions have been identified, the literature concerning them is largely exploratory in nature. As such, this chapter seeks to address
the fundamentals of FL as a field broadly in the first section while taking a narrow
and detailed view of research relevant to the local-global accuracy trade-off in the
second.

2.1

Federated Learning

Previous sections have referenced the common cross-device client-server FL architecture, however, several alterations have been proposed in the literature. Kairouz
et al. [13, sec 1] distinguishes between two versions of client-server FL. In crosssilo FL, the clients are organizations providing their siloed data. In cross-device
FL, the clients are mobile or IoT devices. They have in common a large federated
network with heterogeneous clients that cannot directly share data, although the
cross-silo condition may be seen as somewhat closer to standard distributed ML
4

given the higher degree of possible coordination and control over the training process. While the findings of this work will likely be relevant to both, future sections
will refer to cross-device FL unless stated otherwise.

2.1.1

Foundational challenges

As previously mentioned, standard FL may can be conceptualized as an attempt
to utilize latent data and computational resources on edge-devices while taking
their non-committal nature into account. The data-transfer ability of clients has
been established as the primary training performance bottleneck of this setting
since the initial work of McMahan et al. [23]. As such, the design space of
centralized client-server FL algorithms has been historically constrained by the
need for communication-efficiency through the maximization of the on-device
computation and minimization of data sharing. Data minimization also plays
a role in the privacy-preserving aspects of FL—which are beyond the scope of
this work. According to the surveys of Kairouz et al. [13] and Li et al. [20], this
paradigmatic shift towards local computation and data storage lead to the following
major challenges being shared across FL systems.
Statistical (data) heterogeneity Data generation and accrual naturally vary
across devices in terms of both quantity and characteristics. Factors such as
sensor capabilities, geographic location, time, or user behaviour may influence
the precise deviations seen by a client [13, sec.3.1]. This heterogeneity results in
data which cannot be assumed, as in traditional ML, to be Independent and Identically Distributed (IID)—as first noted by McMahan et al. [23]. Non-IID data has
been shown to negatively impact both practical accuracy [11, 34] and theoretical
convergence bounds [21]. A variety of contextually beneficial techniques have
been used to restrict the impact of data heterogeneity by either targeting the global
model [11, 13, 18, 19, 21, 34] or creating a personalized one for the final clients
[2, 5, 12, 15, 22, 33].
System (hardware) heterogeneity Devices within the federated network may
differ from one-another in terms of characteristics such as computational ability,

5

Look
at
zhang’s
survey

storage, network speed and reliability and data-gathering hardware. They may also
differ from themselves at a different point in time as their battery power, network
connection, or operational mode vary. Differences in data-generating hardware,
such as sensors, are linked to data heterogeneity. However, the other aspects of
system heterogeneity together with device unreliability create barriers to achieving
fault and straggler-tolerant algorithm capable of accommodating different client
training capabilities.

2.1.2

Federated learning objective

Together, the previously mentioned challenges require that client devices, their
data, and the models they train be seen as distinctly relevant entities from the global
model. Despite this fact, the research to date has tended to predominantly focus on
a Federated Learning objective concerned only with global model performance.
The standard loss function of FL is formulated by Li et al. [20] as seen in Eq. (2.1)
min 𝑓 (𝑤) =

𝑚
∑︁

𝑝 𝑘 𝐹𝑘 (𝑤)

(2.1)

𝑤
𝑘=1

where 𝑓 is the federated global loss function, m is the total number of devices,
w is the model at the beginning of a round, and 𝐹𝑘 is the local loss function of
client 𝑘 weighted by the associated 𝑝 𝑘 . For a total number of training examples 𝑛,
𝑝 𝑘 is typically defined as either the proportion of total training examples held by
the client 𝑛𝑛𝑘 or as the inverse of the total number of clients 𝑚1 . This formulation
of 𝑓 does not optimize for performance on the individual data partitions and may
result in skewed models for clients with a disproportionately large fraction of the
global data pool. Thus, tackling the local-global accuracy trade-off necessitates
changing the FL objective function either explicitly in Fair Federated Learning
(Section 2.2.2) or implicitly through personalization (Section 2.2.3)

2.1.3

FedAvg

The fundamental structure of Federated Averaging, seen in Alg (Algorithm 2), has
been reused to varying extents in a majority of published FL algorithms, including
6

add
citation
and
relevancy
to
current
work

those used in this work—FedProx [18] and q-FedAvg [19]. Since the publication
of McMahan et al. [23], the convergence of the algorithms is known to be highly
dependent on the degree of statistical heterogeneity, number of stragglers, and the
number aggregation rounds relative to local training steps. Specifically, a higher
level of heterogeneity or number of stragglers require increasing the frequency
of aggregation steps or decreasing local training steps to avoid global model
divergence. Since the global data distribution cannot be known prior to training,
the number of necessary aggregation rounds is unpredictable. This is inherited by
q-FedAvg and directly addressed by FedProx.
Algorithm 1 Federated Averaging, adapted from McMahan et al. [23]. Each client
is assumed to handle their training parameters.
Input: 𝑀, 𝐾, 𝑇
1: 𝑤 0 ← init()
2: for each round 𝑡 ← 1, . . . 𝑇 do
3:
𝑛, 𝑂 𝑡 ← 0, ∅
4:
𝑆𝑡 ← K selected clients out of M
5:
for for each client 𝑘 ∈ 𝑆𝑡 do
𝑡
6:
𝑤 𝑡+1
𝑘 ← train(k, 𝑤 )
7:
if 𝑤 𝑡+1
𝑘 ∉ ∅ then
8:
𝑂𝑡 ← 𝑂𝑡 ∪ 𝑘
9:
𝑛 ← 𝑛 + 𝑙𝑒𝑛(𝑘.𝑑𝑎𝑡𝑎)
Í
10:
𝑤 𝑡+1 ← 𝑧∈𝑂 𝑡 𝑙𝑒𝑛(𝑧.𝑑𝑎𝑡𝑎) × 𝑤 𝑡+1
𝑧 /𝑛

2.1.4

The local-global accuracy trade-off

7

Complete

2.1.5

Flower

2.2

Related work

2.2.1

Limiting local model divergence

In order to tackle both statistical and systems heterogeneity, Li et al. [18] introduced
FedProx as a successor to FedAvg capable of tolerating partial work from clients
while smoothing the training process. It achieved this by modifying the local client
training process rather than the aggregation algorithm. The objective function of
a local client 𝐹𝑘 from Eq. (2.1) is combined with a “proximal term” (Eq. (2.2))
min ℎ 𝑘 (𝑤, 𝑤 𝑔 ) = 𝐹𝑘 (𝑤) + 𝜇2 ∥𝑤 𝑔 − 𝑤∥ 2

(2.2)

𝑤

which is meant to limit the distance of its model from the global one in accordance
to the hyperparameter 𝜇.
Discussion The experimental analysis conducted by Li et al. [18] prove that
higher weighing of the proximal term allow FedProx to better handle a certain
degree of statistical heterogeneity or percentage of stragglers. Of interest to this
examination is the interaction between the proximal term and the local-global
accuracy trade-off. Since highly heterogeneous clients would diverge more from
the global model during training, larger weighing of the proximal term should
impact their contribution disproportionately. This potential effect was beyond the
scope of the early FL work conducted by Li et al. [18].

2.2.2

Fair Federated Learning

The canonical loss function of FL presented in 2.1 trains the sole global model
without regards to the distribution of client loss values. Although no global model
can fit the exact distribution of each client, this standard formulation solely emphasizes performance on the average case with regard to the global data distribution.
As such, rather than incurring the training cost of constructing an additional local
model per client, Li et al. [19] propose a form of FL, Fair Federated Learning
8

(FFL), which imposes a different distribution of model performance.
The authors construct the objective function for q-FFL, a specific version of FFL,
as seen in Eq. (2.3)
𝑚
∑︁
𝑝𝑘 𝑞
(2.3)
min 𝑓 (𝑤) =
𝑞+1 𝐹𝑘 (𝑤)
𝑤

𝑘=1

where the new parameter 𝑞 controls the degree of desired fairness. A value of
𝑞 = 0 corresponds to standard FL, while larger values impose an increasingly fairer
distribution. As 𝑞 grows lim𝑞→∞ 𝑞, the objective function approaches optimizing
solely for the client with the largest loss.
Discussion The exact formulation of Eq. (2.3) was proposed by Li et al. [19] in
order to allow for tuning the degree of fairness through a single parameter. The
authors drew inspiration from fair resource allocation in wireless networks [17].
Unlike other potential definitions amounting to a linear or geometric re-weighing of
𝑝 𝑘 , such as those based on generalized Gini Social-evaluation Functions introduced
by Weymark [29], the exponential function of q-FFL has wide implications for
the entire training process. First, Li et al. [19] show that choosing a 𝑞 value is
highly domain specific with optimal q-values ranging from 𝑞 = 0.001 to 𝑞 = 5
across evaluated tasks. Second, the exponential scaling of the loss function heavily
impacts the convergence rate of the global model.
Q-FedAvg
Li et al. [19] show that their adaptation of the FedAvg algorithm to FFL, q-FedAvg
(Algorithm 2), is capable of reducing the variance in global model performance
across clients in a wide variety of task. By carefully tuning the value of 𝑞, the
authors have shown that this is feasible without incurring a significant decrease in
the test-performance of the global model or the convergence speed of the training
process.
To fit the convergence rate of the new 𝑞-based exponential loss function, q-FedAvg
adjusts the step-size of the client training process in relation to 𝑞. Rather than
directly tuning the step size for each client, the authors choose to derive it based on
an estimation the Lipschitz constant—to which the optimal step-size is inversely
9

Algorithm 2 Q-FedAvg, adapted from Li et al. [19].
Input: 𝑀, 𝐾, 𝑇
1: 𝑤 0 ← init()
2: for each round 𝑡 ← 1, . . . 𝑇 do
3:
𝑛, 𝑂 𝑡 ← 0, ∅
4:
𝑆𝑡 ← K selected clients out of M
5:
for for each client 𝑘 ∈ 𝑆𝑡 do
𝑡
6:
𝑤 𝑡+1
𝑘 ← train(k, 𝑤 )
7:
if 𝑤 𝑡+1
𝑘 ∉ ∅ then
8:
Δ𝑤 𝑡𝑘 = 𝐿 (𝑤 𝑡 − 𝑤 𝑡+1
𝑘 )
𝑞
9:
Δ𝑡𝑘 = 𝐹𝑘 (𝑤 𝑡 )Δ𝑤 𝑡𝑘
𝑞−1
𝑞
10:
ℎ𝑡𝑘 = 𝑞𝐹𝑘 (𝑤 𝑡 )∥𝑤 𝑡𝑘 ∥ 2 + 𝐿𝐹𝑘 (𝑤 𝑡 )
11:
𝑂𝑡 ← 𝑂𝑡 ∪ 𝑘
Í
Í
𝑡+1
12:
𝑤 ← 𝑤 𝑡 − 𝑧∈𝑂 𝑡 Δ𝑡𝑘 / 𝑧∈𝑂 𝑡 ℎ𝑡𝑘

related—of the functions gradient for 𝑞 = 0.
Discussion The estimation procedure of the Lipschitz constant consists of tuning a step-size for 𝑞 = 0 and then taking the inverse of the optimum. Despite its
empirical success, this method creates difficulties in assessing the impact of modifying q-FedAvg in manners which affect the convergence rate of the algorithm.
To date, no attempts to extend q-FFL beyond q-FedAvg have been made and no
investigation into its interaction with personalization techniques has been found.

2.2.3

Personalization techniques

On the other end of the spectrum from FFL, personalized local models can be
used to handle client heterogeneity and the local-global accuracy trade-off instead
of tuning the global model. The existing literature on model personalization is
extensive[13, 33], as surveyed by Kulkarni et al. [15], when compared to limited
number of publications on fairness. However, the primary concern of this paper
is in extending the experimental evaluation conducted by Yu et al. [33] which
covered a majority of preponderant techniques.
10

add
citations
add
citations

The experimental analysis of Yu et al. [33] established that not only does the global
model perform worse on highly heterogeneous clients, as previous investigations
had already noted [13, 19], it may produce worse results than training a model
locally. The relevance of this result becomes clear when taking into account the
significantly higher amount of data and computation used during the FL training
process.
Yu et al. [33] apply three distinct personalization methods which operate entirely
locally and do not require server involvement beyond providing a global model.
Fine-tuning (FT) When a client receives a global model after the FL process, it
can apply Fine-tuning (see Paulik et al. [24], Wang et al. [27] and Mansour et al.
[22, Section D.2]) to retrain the model parameters on its own local data. To avoid
potential Catastrophic forgetting [6, 8, 14], Yu et al. [33] also opt to use Freezebase
(FB) as an additional variant of FT which retrains only the top layer.
As noted by Mansour et al. [22, Section 5], the performance of FT in general has
only been demonstrated empirically, the technique lacks any theoretical bounds
on its potential for Catastrophic forgetting. Furthermore, the last layer of a Neural
Network performance has been shown to contribute disproportionately to performance in the sparsity literature [3, 7, 9], thus FB may also be susceptible to
forgetting.
Knowledge Distillation (KD) As an alternative to FT, Knowledge Distillation
(see Hinton et al. [10]) uses the global model as a teacher for a student client
model. While KD technically allows for the two to differ in structure, Yu et al.
[33] opt to maintain the same architecture across both and to initialize the student
with the teachers parameters—making it possible to re-introduce the client model
into FL later. For the pure logit outputs of the global model 𝐺 (𝑥) and client model
𝐶 (𝑥), the client minimizes Eq. (2.4)
𝑙 (𝐶, 𝑥) = 𝛼𝐾 2 𝐿 (𝐶, 𝑥) + (1 − 𝛼)𝐾 𝐿 (𝜎(𝐺 (𝑥) / 𝐾), 𝜎(𝐶 (𝑥) / 𝐾))

(2.4)

where 𝐿 is the client loss function, 𝐾𝑙 is the Kullback-Leibler [16] divergence, 𝜎
is the activation function for the final output, 𝛼 is the weighing of the clients loss
11

add
more

and 𝐾 is the temperature.
Equation (2.4) states the optimization objective as a mixture of minimizing the
loss on the local client data and the 𝐾 𝐿-dstance between the temperature-adjusted
outputs of 𝐺 and 𝐶. It is worth noting the practical similarity of this objective
to that of FedProx [18] from Eq. (2.2) as they both intend to maintain a level of
similarity between the global and local models.
Multi-task Learning (MTL) The task of the global model is to perform well
on the distributions of all clients while the local model must perform on the
distribution of a single client. Similarly to the other techniques, the global model
must be used to create a client model optimized for the local task. Framing this as
a Multi-task Learning (MTL) problem in Eq. (2.5)
𝑙 (𝐶, 𝑥) = 𝐿(𝐶, 𝑥) +

∑︁

2
𝜆
2 𝐹 [𝑖] (𝐶 [𝑖] − 𝐺 [𝑖])

(2.5)

𝑖

where 𝜆 determines the weighing between the two tasks, F is the Fisher information
matrix and 𝑖 indexes model parameters. The loss L optimizes for the client model
while the second term represents the task of improving performance over all
participants—i.e., using the pre-trained global model to improve performance on
the local task. Multiplying the squared distance of parameters by the 𝑖-th entry
of 𝐹 serves the role of mitigating Catastrophic forgetting via the Elastic Weight
Consolidation technique introduced by Kirkpatrick et al. [14]. The 𝐹 [𝑖] term acts
as a surrogate for the second derivative near minimums and serves the purpose of
maintaining weights which are particularly important to the global task loss close
to their initial values.
Discussion The findings of Yu et al. [33] established the strong version of the
local-global accuracy trade-off and serve as foundation for the present investigation.
Their experimental results established the benefits of personalization techniques
as relevant for two categories of clients. Clients with generally inaccurate models
obtain the largest accuracy boost both from FL generally and local adaptation
particularly. Those with local models more accurate than the global one gain some
benefit from participating in FL by receiving an adapted model. This paper is
12

interested in clients falling within both categories.
Yu et al. [33] undertook a relatively narrow research scope with regard to the investigated family of aggregation algorithms. The authors experimented using FedAvg
(Algorithm 2) with two variations in the form of differential privacy [28] and
robust aggregation [31]—both of which have a practical effect of reducing training
effectiveness. Furthermore, the paper makes no attempt to explore potential effects
of re-starting the FL process following personalization.
The literature review presented in this chapter points to several conflicting directions within the field of Federated Learning, caused primarily by divergent
methods of handling client heterogeneity Section 2.1.1.

13

Read
all
the
new
personalization
references

Chapter 3
Methods (10 page)
3.1

Hypotheses

1. Allowing a higher degree of divergence from the global model during training
reduces the need for local adaptation.
2. Using a fairer global model reduces the need for local adaptation.
3. Targeted local adaptation has a non-negligible cost in terms of both the
number of clients adapted and total training.
4. Using a fair aggregation algorithm or clustering are both more efficient
overall than targeted local adaptation.

3.2

Experimental Setup

The specific set of experiments is designed as to isolate the impact of statistical
heterogeneity on the global and client model accuracies. As such, they are divided
according to the specific goal.
All experiments will share the following characteristics.

14

3.2.1

Proximal Term Tuning

The FedAvg algorithm investigated by Yu et al. [33] is unpredictable in terms of
how far the local client model diverges from the global one received at the start
of the round. Since this divergence is potentially very large, the entire training
process may fail to converge if sufficiently heterogeneous clients are present.
The implications of this upon the accuracy of the global model on local client data
is unclear. The expectation expressed in H.1 is that the heterogeneous clients will
have large changes in the global model and thus impact the overall training process
more resulting in less of a need for local adaptation. However, multiple client
models can diverge in highly contradictory directions thus resulting in a global
model that does not perform particularly well on any one of them.
To tackle this issue, the first set of experiments attempts to answer H.11 by extending the work of Yu et al. [33]. This is achieved by incorporating the proximal term
from FedProx [18]. Values of 𝜇 ∈ {0, 0.5, 1.0} will be tested, 𝜇 = 0 corresponds
to standard FedAvg.
Importantly, the proximal term of FedProx [18] can be incorporated into the local
objective function of a client regardless of the specific aggregation algorithm. As
such, it can be used in conjunction with q-FedAvg[19].

3.2.2

Fairness Tuning

A modified version of q-FedAvg[19] containing the proximal term from FedProx
[18] is used for this set of experiments. The overall goal is to obtain a baseline
for how much accuracy can and needs to be recovered by using local adaptation
techniques after the usage of a fair aggregation algorithm.
The major drawback of q-FedAvg is the need to tune the fairness parameter 𝑞.
Given that Li et al. [19] do not experiment with or provide q-values for the specific
datasets used in this work, new q-values must be chosen for the experimental
design. The procedure for doing so will consist of a hyperparameter search over
potential q-values 𝑞 ∈ [0, 20]. Based on final accuracy and accuracy variance,
alongside 𝑞 = 0 two other q-values will be selected representing a moderate or
15

high degree of fairness.
Following the q-value choice for all datasets, the general set of experiments will
be ran with local adaptation techniques afterwards to again establish a baseline
in terms of the potential benefits of local adaptation when using Fair Federated
Learning.

3.2.3

Targeted Local Adaptation

16

Chapter 4
Results (10 page)

17

Chapter 5
Discussion (10 page)

18

Chapter 6
Summary and Conclusions (3-4)

19

Bibliography
[1] Md. Zahangir Alom, Tarek M. Taha, Chris Yakopcic, Stefan Westberg, Paheding Sidike, Mst Shamima Nasrin, Brian C. Van Essen, Abdul A. S. Awwal,
and Vĳayan K. Asari. The history began from alexnet: A comprehensive
survey on deep learning approaches. ArXiv, abs/1803.01164, 2018.
[2] Manoj Ghuhan Arivazhagan, Vinay Aggarwal, Aaditya Kumar Singh, and
Sunav Choudhary. Federated learning with personalization layers. CoRR,
abs/1912.00818, 2019. URL http://arxiv.org/abs/1912.00818.
[3] Guillaume Bellec, David Kappel, Wolfgang Maass, and Robert A. Legenstein. Deep rewiring: Training very sparse deep networks. ArXiv,
abs/1711.05136, 2018.
[4] Ronan Collobert, Jason Weston, Léon Bottou, Michael Karlen, Koray
Kavukcuoglu, and Pavel P. Kuksa. Natural language processing (almost)
from scratch. CoRR, abs/1103.0398, 2011. URL http://arxiv.org/
abs/1103.0398.
[5] Yuyang Deng, Mohammad Mahdi Kamani, and Mehrdad Mahdavi. Adaptive
personalized federated learning. CoRR, abs/2003.13461, 2020. URL https:
//arxiv.org/abs/2003.13461.
[6] Robert M. French. Catastrophic forgetting in connectionist networks.
Trends in Cognitive Sciences, 3(4):128–135, 1999. ISSN 1364-6613.
doi: https://doi.org/10.1016/S1364-6613(99)01294-2. URL https://www.
sciencedirect.com/science/article/pii/S1364661399012942.
[7] Trevor Gale, Erich Elsen, and Sara Hooker. The state of sparsity in deep
neural networks. CoRR, abs/1902.09574, 2019. URL http://arxiv.org/
abs/1902.09574.
[8] Ian J. Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, and Yoshua
Bengio. An empirical investigation of catastrophic forgetting in gradientbased neural networks, 2013. URL https://arxiv.org/abs/1312.6211.
20

[9] Song Han, Jeff Pool, John Tran, and William J. Dally. Learning both weights
and connections for efficient neural networks. In Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume
1, NIPS’15, page 1135–1143, Cambridge, MA, USA, 2015. MIT Press.
[10] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a
neural network, 2015. URL https://arxiv.org/abs/1503.02531.
[11] Kevin Hsieh, Amar Phanishayee, Onur Mutlu, and Phillip Gibbons. The
non-IID data quagmire of decentralized machine learning. In Hal Daumé
III and Aarti Singh, editors, Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine
Learning Research, pages 4387–4398. PMLR, 13–18 Jul 2020. URL
https://proceedings.mlr.press/v119/hsieh20a.html.
[12] Yihan Jiang, Jakub Konečný, Keith Rush, and Sreeram Kannan. Improving
federated learning personalization via model agnostic meta learning. CoRR,
abs/1909.12488, 2019. URL http://arxiv.org/abs/1909.12488.
[13] Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi
Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham
Cormode, Rachel Cummings, et al. Advances and open problems in federated
learning. arXiv preprint arXiv:1912.04977, 2019.
[14] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho,
Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic forgetting in
neural networks. Proceedings of the national academy of sciences, 114(13):
3521–3526, 2017.
[15] Viraj Kulkarni, Milind Kulkarni, and Aniruddha Pant. Survey of personalization techniques for federated learning. In 2020 Fourth World Conference
on Smart Trends in Systems, Security and Sustainability (WorldS4), pages
794–797, 2020. doi: 10.1109/WorldS450073.2020.9210355.
[16] S. Kullback and R. A. Leibler. On Information and Sufficiency. The Annals of Mathematical Statistics, 22(1):79 – 86, 1951. doi: 10.1214/aoms/
1177729694. URL https://doi.org/10.1214/aoms/1177729694.
[17] Tian Lan, David Kao, Mung Chiang, and Ashutosh Sabharwal. An axiomatic
theory of fairness in network resource allocation. In 2010 Proceedings IEEE
INFOCOM, pages 1–9, 2010. doi: 10.1109/INFCOM.2010.5461911.
[18] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar,

21

and Virginia Smith. Federated optimization in heterogeneous networks. arXiv
preprint arXiv:1812.06127, 2018.
[19] Tian Li, Maziar Sanjabi, Ahmad Beirami, and Virginia Smith. Fair resource
allocation in federated learning. arXiv preprint arXiv:1905.10497, 2019.
[20] Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges, methods, and future directions. IEEE Signal
Processing Magazine, 37(3):50–60, 2020.
[21] Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua
Zhang. On the convergence of fedavg on non-iid data. arXiv preprint
arXiv:1907.02189, 2019.
[22] Y. Mansour, Mehryar Mohri, Jae Ro, and Ananda Theertha Suresh. Three
approaches for personalization with applications to federated learning. ArXiv,
abs/2002.10619, 2020.
[23] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
Blaise Aguera y Arcas. Communication-efficient learning of deep networks
from decentralized data. In Artificial intelligence and statistics, pages 1273–
1282. PMLR, 2017.
[24] Matthias Paulik, Matt Seigel, Henry Mason, Dominic Telaar, Joris Kluivers, Rogier van Dalen, Chi Wai Lau, Luke Carlson, Filip Granqvist, Chris
Vandevelde, Sudeep Agarwal, Julien Freudiger, Andrew Byde, Abhishek
Bhowmick, Gaurav Kapoor, Si Beaumont, Áine Cahill, Dominic Hughes,
Omid Javidbakht, Fei Dong, Rehan Rishi, and Stanley Hung. Federated
evaluation and tuning for on-device personalization: System design & applications, 2022. URL https://arxiv.org/pdf/2102.08503.pdf.
[25] Joost Verbraeken, Matthĳs Wolting, Jonathan Katzy, Jeroen Kloppenburg,
Tim Verbelen, and Jan S. Rellermeyer. A survey on distributed machine
learning. ACM Comput. Surv., 53(2), mar 2020. ISSN 0360-0300. doi:
10.1145/3377454. URL https://doi.org/10.1145/3377454.
[26] Athanasios Voulodimos, Nikolaos Doulamis, Anastasios Doulamis, Eftychios Protopapadakis, and Diego Andina. Deep learning for computer vision: A brief review. Intell. Neuroscience, 2018, jan 2018. ISSN 1687-5265.
doi: 10.1155/2018/7068349. URL https://doi.org/10.1155/2018/
7068349.
[27] Kangkang Wang, Rajiv Mathews, Chloé Kiddon, Hubert Eichner, Françoise
Beaufays, and Daniel Ramage. Federated evaluation of on-device person-

22

alization. CoRR, abs/1910.10252, 2019. URL http://arxiv.org/abs/
1910.10252.
[28] Kang Wei, Jun Li, Ming Ding, Chuan Ma, Howard H. Yang, Farhad Farokhi,
Shi Jin, Tony Q. S. Quek, and H. Vincent Poor. Federated learning with
differential privacy: Algorithms and performance analysis. IEEE Transactions on Information Forensics and Security, 15:3454–3469, 2020. doi:
10.1109/TIFS.2020.2988575.
[29] John A Weymark. Generalized gini inequality indices. Mathematical Social
Sciences, 1(4):409–430, 1981.
[30] White House. Consumer data privacy in a networked world: A framework for
protecting privacy and promoting innovation in the global digital economy.
Journal of Privacy and Confidentiality, 4(2), Mar. 2013. doi: 10.29012/
jpc.v4i2.623. URL https://journalprivacyconfidentiality.org/
index.php/jpc/article/view/623.
[31] Dong Yin, Yudong Chen, Ramchandran Kannan, and Peter Bartlett.
Byzantine-robust distributed learning: Towards optimal statistical rates. In
International Conference on Machine Learning, pages 5650–5659. PMLR,
2018.
[32] Tom Young, Devamanyu Hazarika, Soujanya Poria, and Erik Cambria. Recent trends in deep learning based natural language processing [review article]. IEEE Computational Intelligence Magazine, 13(3):55–75, 2018. doi:
10.1109/MCI.2018.2840738.
[33] Tao Yu, Eugene Bagdasaryan, and Vitaly Shmatikov. Salvaging federated
learning by local adaptation. arXiv preprint arXiv:2002.04758, 2020.
[34] Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas
Chandra. Federated learning with non-iid data, 2018.

23

1–26

Three Approaches for Personalization with Applications to Federated
Learning

Yishay Mansour

MANSOUR @ GOOGLE . COM

Google Research and Tel Aviv University

Mehryar Mohri

MOHRI @ GOOGLE . COM

arXiv:2002.10619v2 [cs.LG] 19 Jul 2020

Google Research and Courant Institute of Mathematical Sciences, New York

Jae Ro

JAERO @ GOOGLE . COM

Google Research, New York

Ananda Theertha Suresh

THEERTHA @ GOOGLE . COM

Google Research, New York

Abstract
The standard objective in machine learning is to train a single model for all users. However, in many learning
scenarios, such as cloud computing and federated learning, it is possible to learn a personalized model per user.
In this work, we present a systematic learning-theoretic study of personalization. We propose and analyze
three approaches: user clustering, data interpolation, and model interpolation. For all three approaches, we
provide learning-theoretic guarantees and efficient algorithms for which we also demonstrate the performance
empirically. All of our algorithms are model-agnostic and work for any hypothesis class.

1. Introduction
A popular application of language models is virtual keyboard applications, where the goal is to predict the
next word, given the previous words (Hard et al., 2018). For example, given “I live in the state of”, ideally, it
should guess the state the user intended to type. However, suppose we train a single model on all the user
data and deploy it, then the model would predict the same state for all users and would not be a good model
for most. Similarly, in many practical applications, the distribution of data across clients is highly non-i.i.d.
and training a single global model for all clients may not be optimal.
Thus, we study the problem of learning personalized models, where the goal is to train a model for each
client, based on the client’s own dataset and the datasets of other clients. Such an approach would be useful
in applications with the natural infrastructure to deploy a personalized model for each client, which is the
case with large-scale learning scenarios such as federated learning (FL) (McMahan et al., 2017).
Before we proceed further, we highlight one of our use cases in FL. In FL, typically a centralized global
model is trained based on data from a large number of clients, which may be mobile phones, other mobile
devices, or sensors (Konečnỳ et al., 2016b,a; McMahan et al., 2017; Yang et al., 2019) using a variant of

© Y. Mansour, M. Mohri, J. Ro & A.T. Suresh.

stochastic gradient descent called FedAvg. This global model benefits from having access to client data and
can often perform better on several learning problems, including next word prediction (Hard et al., 2018;
Yang et al., 2018) and predictive models in health (Brisimi et al., 2018). We refer to Appendix A.1 for more
details on FL.
Personalization of machine learning models has been studied extensively for specific applications such as
speech recognition (Yu and Li, 2017). However, many algorithms are speech specific or not suitable for FL
due to distributed constraints. Personalization is also related to Hierarchical Bayesian models (Gelman, 2006;
Allenby et al., 2005). However, they are not directly applicable for FL. Personalization in the context of FL
has been studied by several works via multi-task learning (Smith et al., 2017), meta-learning (Jiang et al.,
2019; Khodak et al., 2019), use of local parameters (Arivazhagan et al., 2019; Liang et al., 2020), mixture of
experts (Peterson et al., 2019), finetuning and variants (Wang et al., 2019; Yu et al., 2020) among others. We
refer readers to Appendix A.2 for an overview of works on personalization in FL.
We provide a learning-theoretic framework, generalization guarantees, and computationally efficient algorithms for personalization. Since FL is one of the main frameworks where personalized models can be used,
we propose efficient algorithms that take into account computation and communication bottlenecks.

2. Preliminaries
Before describing the mathematical details of personalization, we highlight two related models. The first one
is the global model trained on data from all the clients. This can be trained using either standard empirical
risk minimization (Vapnik, 1992) or other methods such as agnostic risk minimization (Mohri et al., 2019).
The second baseline model is the purely local model trained only on the client’s data.
The global model is trained on large amounts of data and generalizes well on unseen test data; however it does
not perform well for clients whose data distributions are very different from the global train data distribution.
On the other hand, the train data distributions of local models match the ones at inference time, but they do
not generalize well due to the scarcity of data.
Personalized models can be viewed as intermediate models between pure-local and global models. Thus, the
hope is that they incorporate the generalization properties of the global model and the distribution matching
property of the local model. Before we proceed further, we first introduce the notation used in the rest of the
paper.
2.1. Notation
We start with some general notation and definitions used throughout the paper. Let X denote the input space
and Y the output space. We will primarily discuss a multi-class classification problem where Y is a finite set
of classes, but much of our results can be extended straightforwardly to regression and other problems. The
hypotheses we consider are of the form h∶ X → ∆Y , where ∆Y stands for the simplex over Y. Thus, h(x) is
a probability distribution over the classes that can be assigned to x ∈ X. We will denote by H a family of
such hypotheses h. We also denote by ` a loss function defined over ∆Y × Y and taking non-negative values.
The loss of h ∈ H for a labeled sample (x, y) ∈ X × Y is given by `(h(x), y). Without loss of generality, we
assume that the loss ` is bounded by one. We will denote by LD (h) the expected loss of a hypothesis h with
respect to a distribution D over X × Y:
2

LD (h) =

[`(h(x), y)],

E

(x,y)∼D

and by hD its minimizer: hD = argminh∈H LD (h). Let RD,m (H) denote the Rademacher complexity of
class H over the distribution D with m samples.
Let p be the number of clients. The distribution of samples of client k is denoted by Dk . Clients do not know
the true distribution, but instead, have access to mk samples drawn i.i.d. from the distribution Dk . We will
̂ k the corresponding empirical distribution of samples and by m = ∑p mk the total number of
denote by D
k=1
samples.
2.2. Local model
We first ask when it is beneficial for a client to participate in global model training. Consider a canonical user
with distribution D1 . Suppose we train a purely local model based on the client’s data and obtain a model
hD
̂ 1 . By standard learning-theoretic tools (Mohri et al., 2018), the performance of this model can be bounded
as follows: with probability at least 1 − δ, the minimizer of empirical risk LD
̂ 1 (h) satisfies
√
⎛ d + log 1/δ ⎞
LD1 (hD
,
(1)
√
̂ 1 ) − LD1 (hD1 ) = O (RD1 ,m1 (H)) = O
m1
⎠
⎝
where RD1 ,m1 (H) is the Rademacher complexity and d is the pseudo-dimension of the hypothesis class
H (Mohri et al., 2018). Note that pseudo-dimension coincides with VC dimension for 0 − 1 loss. From (1), it
is clear that local models perform well when the number of samples m1 is large. However, this is often not
the case. In many realistic settings, such as virtual keyboard models, the average number of samples per user
is in the order of hundreds, whereas the pseudo-dimension of the hypothesis class is in millions (Hard et al.,
2018). In such cases, the above bound becomes vacuous.
2.3. Uniform global model
The global model is trained by minimizing the empirical risk on the concatenation of all the samples. For
λ ∈ ∆p , the weighted average distribution Dλ is given by ∑k λk Dk . The global model is trained on the
concatenated samples from all the users and hence is equivalent to minimize the loss on the distribution
̂ k , where λ′ = mk /m. Since the global model is trained on data from all the clients, it may not
Û = ∑k λ′k D
k
match the actual underlying client distribution and thus may perform worse.
The divergence between distributions is often measured by a Bregman divergence such as KL-divergence or
unnormalized relative entropy. However, such divergences do not consider the underlying machine learning
task at hand for example learning the best hypotheses out of H. To obtain better bounds, we use the notion
of label-discrepancy between distributions (Mansour et al., 2009b; Mohri and Medina, 2012). For two
distributions over features and labels, D1 and D2 , and a class of hypotheses H, label-discrepancy(Mohri and
Medina, 2012) is given by
discH (D1 , D2 ) = max ∣LD1 (h) − LD2 (h)∣.
h∈H

If the loss of all the hypotheses in the class is the same under both D1 and D2 , then the discrepancy is zero
and models trained on D1 generalize well on D2 and vice versa.

3

With the above definitions, it can be shown that the uniform global model generalizes as follows: with
probability at least 1 − δ, the minimizer of empirical risk on the uniform distribution satisfies
√
⎛ d + log 1/δ ⎞
√
+ discH (D1 , U). (2)
LD1 (hÛ ) − LD1 (hD1 ) = O (RU,m (H)) + discH (D1 , U) = O
m
⎠
⎝
Since the global model is trained on the concatenation of all users’ data, it generalizes well. However, due to
the distribution mismatch, the model may not perform well for a specific user. If U = ∑k λ′k Dk , the difference
between local and global models depends on the discrepancy between D1 and U, m1 the number of samples
from the domain D1 , and the total number of samples m. While in most practical applications m1 is small
and hence a global model usually performs better, this is not guaranteed. We provide a simple example
illustrating such a case in Appendix B.1.
Since the uniform global model assigns weight mk /m to client k, clients with larger numbers of samples
receive higher importance. This can adversely affect clients with small amounts of data. Furthermore, by (2),
the model may not generalize well for clients whose distribution is different than the uniform distribution.
Thus, (1) and (2) give some guidelines under which it is beneficial for clients to participate in global model
training.
Instead of using uniform weighting of samples, one can use agnostic risk proposed by Mohri et al. (2019),
which is more risk averse. We refer to Appendix B.2 for details about the agnostic risk minimization.

3. Our contributions
We ask if personalization can be achieved by an intermediate model between the local and global models.
Furthermore, for ease of applicability and to satisfy the communication constraints in FL, we focus on
scalable algorithms with low communication bottleneck. This gives rise to three natural algorithms, which
are orthogonal and can be used separately or together.
• Train a model for subsets of users: we can cluster users into groups and train a model for each group.
We refer to this as user clustering, or more refinely hypothesis-based clustering.
• Train a model on interpolated data: we can combine the local and global data and train a model on
their combination. We refer to this as data interpolation.
• Combine local and global models: we can train a local and a global model and use their combination.
We refer to this as model interpolation.
We provide generalization bounds and communication-efficient algorithms for all of the above methods.
We show that the above three methods has small communication bottleneck and enjoys qualitative privacy
benefits similar to training a global model. Of the three proposed approaches, data interpolation has non-trivial
communication cost and data security. We show that data interpolation can be implemented with small
communication overhead in Section 5. We also show discuss data security aspect and methods to improve it
in Appendix D.3.
Of the remaining methods, model interpolation has the same communication cost and security as that of
training a single model. Clustering has the same data security as that of training single models, but the
communication cost is q times that of training a single model, where q is the number of clusters. In the rest of
the paper, we study each of the above methods.
4

4. User clustering
Instead of training a single global model, a natural approach is to cluster clients into groups and train a
model for each group. This is an intermediate model between a purely local and global model and provides a
trade-off between generalization and distribution mismatch. If we have a clustering of users, then we can
naturally find a model for each user using standard optimization techniques. In this section, we ask how to
define clusters. Clustering is a classical problem with a broad literature and known algorithms (Jain, 2010).
We argue that, since the subsequent application of our clustering is known, incorporating it into the clustering
algorithm will be beneficial. We refer readers to Appendix C.1 for more details on comparison to baseline
works.
4.1. Hypothesis-based clustering
Consider the scenario where we are interested in finding clusters of images for a facial recognition task.
Suppose we are interested in finding clusters of users for each gender and find a good model for each cluster. If
we naively use the Bregman divergence clustering, it may focus on clustering based on the image background
e.g., outdoor or indoors to find clusters instead of gender.
To overcome this, we propose to incorporate the task at hand to obtain better clusters. We refer to this
approach as hypothesis-based clustering and show that it admits better generalization bounds than the
Bregman divergence approach. We partition users into q clusters and find the best hypothesis for each cluster.
In particular, we use the following optimization:
p

min ∑ λk ⋅ min LDk (hi ),

h1 ,...,hq k=1

i∈[q]

(3)

where λk is the importance of client k. The above loss function trains q best hypotheses and naturally divides
X × Y into q partitions, where each partition is associated with a particular hypothesis hk . In practice, we
̂ k . We replace LD (hi ) by L ̂ (hi ) in optimization. To
only have access to the empirical distributions D
k
Dk
simplify the analysis, we use the fraction of samples from each user mk /m as λk . An alternative approach is
to use λk = 1/p for all users, which assigns equal weight to all clients. The analysis is similar and we omit it
to be concise.
4.2. Generalization bounds
We now analyze the generalization properties of this technique. We bound the maximum difference between
true cluster based loss and empirical cluster based loss for all hypotheses. We note that such a generalization
bound holds for any clustering algorithm (see Appendix C.2).
Let C1 , C2 . . . , Cq be the clusters and let mCi be the number of samples from cluster i. Let Ci and ̂
Ci be the
empirical and true distributions of cluster Ci . With these definitions, we now bound the generalization error
of this technique.
Theorem 1 (Appendix C.3) With probability at least 1 − δ,
¿
Á p log 2q
p
q
mCi
mk
Á
À
δ
max ∣ ∑
⋅ (min LDk (hi ) − min LD
(h
))∣
≤
2
+
max
RCi ,mCi (H).
∑
̂k
i
C1 ,...,Cq i=1 m
h1 ,...,hq k=1 m
m
i∈[q]
i∈[q]
5

The above result implies the following corollary, which is easier to interpret.
Corollary 2 (Appendix C.4) Let d be the pseudo-dimension of H. Then with probability at least 1 − δ, the
following holds:
¿
Á 4p log 2q √ dq
p
mk
em
Á
À
δ
max ∣ ∑
⋅ (min LDk (hi ) − min LD
+
log
.
̂ k (hi ))∣ ≤
h1 ,...,hq k=1 m
m
m
d
i∈[q]
i∈[q]
The above learning bound can be understood as follows. For good generalization, the average number of
samples per user m/p should be larger than the logarithm of the number of clusters, and the average number
of samples per cluster m/q should be larger than the pseudo-dimension of the overall model. Somewhat
surprisingly, these results do not depend on the minimum number of samples per clients and instead depend
only on the average statistics.
To make a comparison between the local performance (1) and the global model performance (2), observe that
combining (8) and Corollary 2 together with the definition of discrepancy yields
¿
Á p log 2q √ dqe
p
p
m
mk
mk
Á
À
δ
̂
(h))
≤
2
(
h
)
−
min
L
⋅
(L
+
log
+
disc(Dk , Cf (k) ),
∑
∑
Dk
Dk
f (k)
h∈H
m
m
m
d
k=1 m
k=1
where f ∶ [p] → [q] is the mapping from users to clusters. Thus, the generalization bound is in between that
of the local and global model. For q = 1, it yields the global model, and for q = p, it yields the local model.
As we increase q, the generalization decreases and the discrepancy term gets smaller. Allowing a general q
lets us choose the best clustering scheme and provides a smooth trade-off between the generalization and the
distribution matching. In practice, we choose small values of q > 1. We further note that we are not restricted
to using the same value of q for all clients. We can find clusters for several values of q and use the best one
for each client separately using a hold-out set of samples.
4.3. Algorithm : H YP C LUSTER
We provide an expectation-maximization (EM)-type algorithm for finding clusters and hypotheses. A naive
EM modification may require heavy computation and communication resources. To overcome this, we
propose a stochastic EM algorithm in H YP C LUSTER. In the algorithm, we denote clusters via a mapping
f ∶ [p] → [q], where f (k) denotes the cluster of client k. Similar to k-means, H YP C LUSTER is not guaranteed
to converge to the true optimum, but, as stated in the beginning of the previous section, the generalization
guarantee of Theorem 1 still holds here.

5. Data interpolation
From the point of view of client k, there is a small amount of data with distribution Dk and a large amount
of data from the global or clustered distribution C. How are we to use auxiliary data from C to improve
the model accuracy on Dk ? This relates the problem of personalization to domain adaptation. In domain
adaptation, there is a single source distribution, which is the global data or the cluster data, and a single target
distribution, which is the local client data. As in domain adaptation with target labels (Blitzer et al., 2008),

6

Algorithm H YP C LUSTER
Initialize: Randomly sample P clients, train a model on them, and initialize h0i for all i ∈ [q] using
them randomly. For t = 1 to T do the following:
1. Randomly sample P clients.
2. Recompute f t for clients in P by assigning each client to the cluster that has lowest loss:
t−1
f t (k) = argmin LD
̂ k (hi ).

(4)

i

3. Run few steps of SGD for ht−1
with data from clients P ∩ (f t )−1 (i) to minimize
i
∑

k∶P ∩(f t )−1 (i)

mk LD
̂ k (hi ),

and obtain hti .
Compute f T +1 by using hT1 , hT2 , . . . , hTq via (4) and output it.
Figure 1: Pseudocode for H YP C LUSTER algorithm.
we have at our disposal a large amount of labeled data from the source (global data) and a small amount of
labeled data from the target (personal data). We propose to minimize the loss on the concatenated data,
λ ⋅ Dk + (1 − λ) ⋅ C,

(5)

where λ is a hyper-parameter and can be obtained by either cross validation or by using the generalization
bounds of Blitzer et al. (2008). C can either be the uniform distribution U or one of the distributions obtained
via clustering.
Personalization is different from most domain adaptation works as they assume they only have access to
unlabeled target data (Mansour et al., 2009a; Ganin et al., 2016; Zhao et al., 2018a), whereas in personalization
we have access to labeled target data. Secondly, we have one target domain per client, which makes our
problem computationally expensive, which we discuss next. Given the known learning-theoretic bounds,
a natural question is if we can efficiently estimate the best hypothesis for a given λ. However, note that
naive approaches suffer from the following drawbacks. If we optimize for each client separately, the time
complexity of learning per client is O(m) and the overall time complexity is O(m ⋅ p).
In addition to the computation time, the algorithm also admits a high communication cost in FL. This is
because, to train the model with a λ-weighted mixture requires the client to admit access to the entire dataset
̂
C, which incurs communication cost O(m). One empirically popular approach to overcome this is the
fine-tuning approach, where the central model is fine-tuned on the local data (Wang et al., 2019). However, to
the best of our knowledge, there are no theoretical guarantees and the algorithm may be prone to catastrophic
forgetting (Goodfellow et al., 2013). In fine-tuning, the models are typically trained first on the global data
and then on the client’s local data. Hence, the order in which samples are seen are not random. Furthermore,
we only care about the models’ performance on the local data. Hence, one cannot directly use known
online-to-batch conversion results from online learning to obtain theoretical guarantees.
We propose DAPPER, a theoretically motivated and efficient algorithm to overcome the above issues. The
algorithm first trains a central model on the overall empirical distribution ̂
C. Then for each client, it subsamples
̂
C to create a smaller dataset of size Ĉ′ of size r ⋅ mk , where r is a constant. It then minimizes the loss on
7

weighted combination of two datasets i.e., λLD
̂ k (h) + (1 − λ)LĈ′ (h) for several values of λ. Finally, it
chooses the best λ using cross-validation. The algorithm is efficient both in terms of its communication
complexity which is r ⋅ mk and its computation time, which is at most (r + 1) ⋅ mk . Hence, the overall
communication and computation time is O(r ⋅ m). Due to space constraints, we relegate the pseudo-code of
the algorithm to Appendix D.2.
We analyze DAPPER when the loss function is strongly convex in the hypothesis parameters h and show that
the model minimizes the intended loss to the desired accuracy. To the best of our knowledge, this is the first
fine-tuning algorithm with provable guarantees.
To prove convergence guarantees, we need to ask what the desired convergence guarantee is. Usually,
models are required to converge to the generalization guarantee and we use the same criterion. To this
end, we first state a known generalization theorem. Let ĥλ = argmin λLD
̂ k (h) + (1 − λ)L̂
C (h) and hλ =
argmin λLDk (h) + (1 − λ)LC (h).
Lemma 3 ( (Blitzer et al., 2008)) If the pseudo-dimension of the H is d 1 , then with probability at least
1 − δ,
√
√
⎛ λ2 (1 − λ)2
1⎞
λLDk (ĥλ ) + (1 − λ)LC (ĥλ ) − λLDk (hλ ) + (1 − λ)LC (hλ ) = O
+
⋅ d log
.
mC
δ⎠
⎝ mk
√
(1−λ)2
λ2
+
Since the generalization bound scales as m
mC , the same accuracy in convergence is desired. Let
k
√
(1−λ)2
λ2
λ = m
+
mC , denote the desired convergence guarantee. For strongly convex functions, we show that
k
one can achieve this desired accuracy using DAPPER, furthermore the amount of additional data is a constant
multiple of mk , independent of λ and m.
Theorem 4 (Appendix D.1) Assume that the loss function is µ-strongly convex and assume that the gradi2

ents are G-smooth. Let H admit diameter at most R. Let r ≥ G2 ( 4G
µ + 2R) , a constant independent of λ.
2Gλ
Let the learning rate η = G√1rmk min ( µ(1−λ)
, R). Then after r ⋅ mk steps of SGD, the output hA satisfies,

E[λLD
̂ k (hA ) + (1 − λ)L̂
̂ k (ĥ
λ ) + (1 − λ)L̂
λ )] + λ .
C (hA )] ≤ E[λLD
C (ĥ
The above bound shows the convergence result for a given λ. One can find the best λ either by cross
validation or by minimizing the overall generalization bound of Blitzer et al. (2008). While the above
algorithm reduces the amount of data transfer and is computationally efficient, it may be vulnerable to
privacy issues in applications such as FL. We propose several alternatives to overcome these privacy issues in
Appendix D.3.

6. Model interpolation
The above approaches assume that the final inference model belongs to class H. In practice, this may not be
the case. One can learn a central model hc from a class Hc , and learn a local model hl from Hl , and use their
interpolated model
λ ⋅ hl + (1 − λ) ⋅ hc .
1. Blitzer et al. (2008) states the result for 0 − 1 loss, but it can extended to other loss functions.

8

More formally, let hc be the central or cluster model and let h̄l = (hl,1 , hl,2 , . . . , hl,p ), where hl,k is the local
model for client k. Let λk be the interpolated weight for client k and let λ̄ = λ1 , λ2 , . . . , λp . If one has
access to the true distributions, then learning the best interpolated models can be formulated as the following
optimization,
p
mk
min ∑
LDk ((1 − λk )hc + λk hl,k ).
hc ,h̄l ,λ̄ k=1 m
Since, the learner does not have access to the true distributions, we replace LDk ((1 − λk )hc + λk hl,k ) with
LD
̂ k ((1 − λk )hc + λk hl,k ) in the above optimization. We now show a generalization bound for the above
optimization.
Theorem 5 (Appendix E.1) Let the loss ` is L Lipschitz, Hc be the hypotheses class for the central model,
and H` be the hypotheses class for the local models. Let h∗c , λ̄∗ , h̄∗l be the optimal values and ̂
h∗c , ̂
λ∗k , ̂
h∗l be
the optimal values for the empirical estimates. Then, with probability at least 1 − δ,
p
mk
mk
h∗l,k ) − ∑
LDk ((1 − ̂
λ∗k )̂
h∗c + ̂
λ∗k̂
LDk ((1 − λ∗k )h∗c + λ∗k h∗l,k )
m
m
k=1
k=1
¿
Á log 1
p
mk
Á
À
δ
≤ 2L (RU,m (Hc ) + ∑
RDk ,mk (Hl )) + 2
.
m
m
k=1
p

∑

(6)

Standard bounds on Rademacher complexity by the pseudo-dimension yields the following corollary.
Corollary 6 Assume that ` is L Lipschitz. Let h∗c , λ̄∗ , h̄∗l be the optimal values and ̂
h∗c , ̂
λ∗k , ̂
h∗l be the optimal
values for the empirical estimates. Then with probability at least 1 − δ, the LHS of (6) is bounded by
¿
√
√
1
⎛ dc
em
dl p
em ⎞ Á
Á
À log δ
2L
log
+
log
,
+2
dc
m
dl ⎠
m
⎝ m
where dc is the pseudo-dimension of Hc and dl is the pseudo-dimension of Hl .
Hence for models to generalize well, it is desirable to have m ≫ dc and the average number of samples to be
much greater than dl , i.e., m/p ≫ dl . Similar to Corollary 2, this bound only depends on the average number
of samples and not the minimum number of samples.
A common approach for model interpolation in practice is to first train the central model hc and then train the
local model hl separately and find the best interpolation coefficients, i.e.,
p

mk
̂
hc = argmin ∑
LD
̂ k (hc )
hc
k=1 m

and

̂
hl,k = argmin LD
̂ k (hl,k ).
hl,k

We show that this approach might not be optimal in some instances and also propose a joint optimization for
minimizing local and global models. Due to space constraints, we refer reader to Appendix E.2 for details.
We refer to model interpolation algorithms by M APPER.
Table 2: Test accuracy of seen clients for the EMNIST dataset.
initial model +F INETUNE +DAPPER +M APPER
F EDAVG
84.3%
90.0%
90.1%
90.0%
AGNOSTIC
84.6%
89.9%
90.0%
89.9%
H YP C LUSTER (q = 2)
89.1%
90.2%
90.3%
90.1%
9

Table 1: Test loss of H YP C LUSTER as a function of number of clusters q for the synthetic dataset.
q
1
2
3
4
5
test loss 3.4 3.1 2.9 2.7 2.7

Table 3: Test accuracy of unseen clients for the EMNIST dataset.
initial model +F INETUNE +DAPPER +M APPER
F EDAVG
84.1%
90.3%
90.3%
90.2%
AGNOSTIC
84.5%
90.1%
90.2%
90.1%
H YP C LUSTER (q = 2)
88.8%
90.1%
90.1%
89.9%

7. Experiments
7.1. Synthetic dataset
We first demonstrate the proposed algorithms on a synthetic dataset for density estimation. Let X = ∅,
Y = [d], and d = 50. Let ` be cross entropy loss and the number of users p = 100. We create client
distributions as a mixture of a uniform component, a cluster component, and an individual component.
The details of the distributions are in Appendix F.1. We evaluate the
algorithms as we vary the number of samples per user. The results
are in Figure 2. H YP C LUSTER performs the best when the number of Figure 2: Test loss of algorithms as a
function of number of samsamples per user mk is very small. If mk is large, M APPER performs
ples per user for the synthe best followed closely by F INETUNE and DAPPER. However, the
thetic dataset.
difference between F INETUNE and DAPPER is statistically insignificant. In order to understand the effect of clustering, we evaluate
various clustering algorithms as a function of q when mk = 100, and
the results are in Table 1. Since the clients are naturally divided into
four clusters, as we increase q, the test loss steadily decreases till the
number of clusters reaches 4 and then remains constant.
7.2. EMNIST dataset
We evaluate the proposed algorithms on the federated EMNIST-62
dataset (Caldas et al., 2018) provided by TensorFlow Federated (TFF).
The dataset consists of 3400 users’ examples that are each one of 62
classes. We select 2500 users to train the global models (referred to as seen) and leave the remaining 900 as
unseen clients reserved for evaluation only. We shuffle the clients first before splitting as the original client
ordering results in disjoint model performance. The reported metrics are uniformly averaged across clients
similar to previous works (Jiang et al., 2019). For model architecture, we use a two-layer convolutional neural
net. We refer to Appendix F.2 for more details on the architecture and training procedure.
The test results for seen and unseen clients are in Table 2 and Table 3, respectively. We trained models with
F EDAVG, AGNOSTIC (Mohri et al., 2019), and H YP C LUSTER and combined them with F INETUNE, DAPPER,
and M APPER. We observe that H YP C LUSTER with two clusters performs significantly better compared to
10

F EDAVG and AGNOSTIC models and improves accuracy by at least 4.3%. Thus clustering is significantly
better than training a single global model.
The remaining algorithms DAPPER and M APPER improve the accuracy by another 1% compared to H YP C LUSTER, but the EMNIST dataset is small and standard deviation in our experiments was in the order of
0.1% and hence their improvement over F INETUNE is not statistically significant. However, these algorithms
have provable generalization guarantees and thus would be more risk averse.

8. Conclusion
We presented a systematic learning-theoretic study of personalization in learning and proposed and analyzed
three algorithms: user clustering, data interpolation, and model interpolation. For all three approaches, we
provided learning theoretic guarantees and efficient algorithms. Finally, we empirically demonstrated the
usefulness of the proposed approaches on synthetic and EMNIST datasets.

9. Acknowledgements
Authors thank Rajiv Mathews, Brendan Mcmahan, Ke Wu, and Shanshan Wu for helpful comments and
discussions.

References
Alekh Agarwal, John Langford, and Chen-Yu Wei.
arXiv:2003.12880, 2020.

Federated residual learning.

arXiv preprint

Naman Agarwal, Ananda Theertha Suresh, Felix X. Yu, Sanjiv Kumar, and Brendan McMahan. cpSGD:
Communication-efficient and differentially-private distributed SGD. In Proceedings of NeurIPS, pages
7575–7586, 2018.
Greg M Allenby, Peter E Rossi, and Robert E McCulloch. Hierarchical bayes models: A practitioners guide.
ssrn scholarly paper id 655541. Social Science Research Network, Rochester, NY, 2005.
Manoj Ghuhan Arivazhagan, Vinay Aggarwal, Aaditya Kumar Singh, and Sunav Choudhary. Federated
learning with personalization layers. arXiv preprint arXiv:1912.00818, 2019.
Sean Augenstein, H. Brendan McMahan, Daniel Ramage, Swaroop Ramaswamy, Peter Kairouz, Mingqing
Chen, Rajiv Mathews, et al. Generative models for effective ml on private, decentralized datasets. arXiv
preprint arXiv:1911.06679, 2019.
Arindam Banerjee, Srujana Merugu, Inderjit S Dhillon, and Joydeep Ghosh. Clustering with Bregman
divergences. Journal of machine learning research, 6(Oct):1705–1749, 2005.
John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman. Learning bounds for
domain adaptation. In Advances in neural information processing systems, pages 129–136, 2008.

11

Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H. Brendan McMahan, Sarvar Patel,
Daniel Ramage, Aaron Segal, and Karn Seth. Practical secure aggregation for privacy-preserving machine
learning. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications
Security, pages 1175–1191. ACM, 2017.
Theodora S. Brisimi, Ruidi Chen, Theofanie Mela, Alex Olshevsky, Ioannis Ch. Paschalidis, and Wei Shi.
Federated learning of predictive models from federated electronic health records. International journal of
medical informatics, 112:59–67, 2018.
Duc Bui, Kshitiz Malik, Jack Goetz, Honglei Liu, Seungwhan Moon, Anuj Kumar, and Kang G Shin.
Federated user representation learning. arXiv preprint arXiv:1909.12535, 2019.
Sebastian Caldas, Peter Wu, Tian Li, Jakub Konečnỳ, H Brendan McMahan, Virginia Smith, and Ameet
Talwalkar. Leaf: A benchmark for federated settings. arXiv preprint arXiv:1812.01097, 2018.
Fei Chen, Mi Luo, Zhenhua Dong, Zhenguo Li, and Xiuqiang He. Federated meta-learning with fast
convergence and efficient communication. arXiv preprint arXiv:1802.07876, 2018.
Mingqing Chen, Rajiv Mathews, Tom Ouyang, and Françoise Beaufays. Federated learning of out-ofvocabulary words. arXiv preprint arXiv:1903.10635, 2019a.
Mingqing Chen, Ananda Theertha Suresh, Rajiv Mathews, Adeline Wong, Françoise Beaufays, Cyril
Allauzen, and Michael Riley. Federated learning of N-gram language models. In Proceedings of the 23rd
Conference on Computational Natural Language Learning (CoNLL), 2019b.
Luca Corinzia and Joachim M Buhmann. Variational federated multi-task learning. arXiv preprint
arXiv:1906.06268, 2019.
Yuyang Deng, Mohammad Mahdi Kamani, and Mehrdad Mahdavi. Adaptive personalized federated learning.
arXiv preprint arXiv:2003.13461, 2020.
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. Personalized federated learning: A meta-learning
approach. arXiv preprint arXiv:2002.07948, 2020.
Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep
networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages
1126–1135. JMLR. org, 2017.
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, François Laviolette,
Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks. The Journal of
Machine Learning Research, 17(1):2096–2030, 2016.
Andrew Gelman. Multilevel (hierarchical) modeling: what it can and cannot do. Technometrics, 48(3):
432–435, 2006.
Ian J Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, and Yoshua Bengio. An empirical investigation
of catastrophic forgetting in gradient-based neural networks. arXiv preprint arXiv:1312.6211, 2013.
Patrick J Grother. Nist special database 19 handprinted forms and characters database. National Institute of
Standards and Technology, 1995.

12

Filip Hanzely and Peter Richtárik. Federated learning of a mixture of global and local models. arXiv preprint
arXiv:2002.05516, 2020.
Andrew Hard, Kanishka Rao, Rajiv Mathews, Françoise Beaufays, Sean Augenstein, Hubert Eichner,
Chloé Kiddon, and Daniel Ramage. Federated learning for mobile keyboard prediction. arXiv preprint
arXiv:1811.03604, 2018.
Anil K Jain. Data clustering: 50 years beyond k-means. Pattern recognition letters, 31(8):651–666, 2010.
Yihan Jiang, Jakub Konečnỳ, Keith Rush, and Sreeram Kannan. Improving federated learning personalization
via model agnostic meta learning. arXiv preprint arXiv:1909.12488, 2019.
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji,
Keith Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances and open
problems in federated learning. arXiv preprint arXiv:1912.04977, 2019.
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank J Reddi, Sebastian U Stich, and
Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for on-device federated learning.
arXiv preprint arXiv:1910.06378, 2019.
Mikhail Khodak, Maria-Florina F Balcan, and Ameet S Talwalkar. Adaptive gradient-based meta-learning
methods. In Advances in Neural Information Processing Systems, pages 5915–5926, 2019.
Jakub Konečnỳ, H Brendan McMahan, Daniel Ramage, and Peter Richtárik. Federated optimization:
Distributed machine learning for on-device intelligence. arXiv preprint arXiv:1610.02527, 2016a.
Jakub Konečnỳ, H Brendan McMahan, Felix X Yu, Peter Richtárik, Ananda Theertha Suresh, and Dave Bacon.
Federated learning: Strategies for improving communication efficiency. arXiv preprint arXiv:1610.05492,
2016b.
Viraj Kulkarni, Milind Kulkarni, and Aniruddha Pant. Survey of personalization techniques for federated
learning. arXiv preprint arXiv:2003.08673, 2020.
Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges, methods,
and future directions. arXiv preprint arXiv:1908.07873, 2019.
Paul Pu Liang, Terrance Liu, Liu Ziyin, Ruslan Salakhutdinov, and Louis-Philippe Morency. Think locally,
act globally: Federated learning with local and global representations. arXiv preprint arXiv:2001.01523,
2020.
Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Domain adaptation with multiple sources. In
NIPS, pages 1041–1048, 2009a.
Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Domain adaptation: Learning bounds and
algorithms. arXiv preprint arXiv:0902.3430, 2009b.
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Agüera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In Proceedings of AISTATS, pages 1273–1282, 2017.

13

Mehryar Mohri and Andres Munoz Medina. New analysis and algorithm for learning with drifting distributions. In International Conference on Algorithmic Learning Theory, pages 124–138. Springer, 2012.
Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of machine learning. MIT press,
2018.
Mehryar Mohri, Gary Sivek, and Ananda Theertha Suresh. Agnostic federated learning. In International
Conference on Machine Learning, pages 4615–4625, 2019.
Daniel Peterson, Pallika Kanani, and Virendra J Marathe. Private federated learning with domain adaptation.
arXiv preprint arXiv:1912.06733, 2019.
Swaroop Ramaswamy, Rajiv Mathews, Kanishka Rao, and Françoise Beaufays. Federated learning for emoji
prediction in a mobile keyboard. arXiv preprint arXiv:1906.04329, 2019.
Sumudu Samarakoon, Mehdi Bennis, Walid Saad, and Merouane Debbah. Federated learning for ultra-reliable
low-latency v2v communications. In 2018 IEEE Global Communications Conference (GLOBECOM),
pages 1–7. IEEE, 2018.
Felix Sattler, Klaus-Robert Müller, and Wojciech Samek. Clustered federated learning: Model-agnostic
distributed multi-task optimization under privacy constraints. arXiv preprint arXiv:1910.01991, 2019.
Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet S Talwalkar. Federated multi-task learning. In
Advances in Neural Information Processing Systems, pages 4424–4434, 2017.
Sebastian U. Stich. Local SGD converges fast and communicates little. arXiv preprint arXiv:1805.09767,
2018.
Ananda Theertha Suresh, Felix X Yu, Sanjiv Kumar, and H Brendan McMahan. Distributed mean estimation
with limited communication. In Proceedings of the 34th International Conference on Machine LearningVolume 70, pages 3329–3337. JMLR. org, 2017.
Vladimir Vapnik. Principles of risk minimization for learning theory. In Advances in neural information
processing systems, pages 831–838, 1992.
Kangkang Wang, Rajiv Mathews, Chloé Kiddon, Hubert Eichner, Françoise Beaufays, and Daniel Ramage.
Federated evaluation of on-device personalization. arXiv preprint arXiv:1910.10252, 2019.
Blake E Woodworth, Jialei Wang, Adam Smith, H. Brendan McMahan, and Nati Srebro. Graph oracle
models, lower bounds, and gaps for parallel stochastic optimization. In Advances in neural information
processing systems, pages 8496–8506, 2018.
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. Federated machine learning: Concept and
applications. ACM Transactions on Intelligent Systems and Technology (TIST), 10(2):1–19, 2019.
Timothy Yang, Galen Andrew, Hubert Eichner, Haicheng Sun, Wei Li, Nicholas Kong, Daniel Ramage, and
Françoise Beaufays. Applied federated learning: Improving Google keyboard query suggestions. arXiv
preprint arXiv:1812.02903, 2018.
Dong Yu and Jinyu Li. Recent progresses in deep learning based acoustic models. IEEE/CAA Journal of
Automatica Sinica, 4(3):396–409, 2017.
14

Tao Yu, Eugene Bagdasaryan, and Vitaly Shmatikov. Salvaging federated learning by local adaptation. arXiv
preprint arXiv:2002.04758, 2020.
Valentina Zantedeschi, Aurélien Bellet, and Marc Tommasi. Fully decentralized joint learning of personalized
models and collaboration graphs. 2019.
Han Zhao, Shanghang Zhang, Guanhang Wu, José MF Moura, Joao P Costeira, and Geoffrey J Gordon.
Adversarial multiple source domain adaptation. In Advances in neural information processing systems,
pages 8559–8570, 2018a.
Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra. Federated learning
with non-iid data. arXiv preprint arXiv:1806.00582, 2018b.

15

Appendix A. Related works
A.1. Federated learning
FL was introduced by McMahan et al. (2017) as an efficient method for training models in a distributed way.
They proposed a new communication-efficient optimization algorithm called FedAvg. They also showed
that the training procedure provides additional privacy benefits. The introduction of FL has given rise
to several interesting research problems, including the design of more efficient communication strategies
(Konečnỳ et al., 2016b,a; Suresh et al., 2017; Stich, 2018; Karimireddy et al., 2019), the study of lower
bounds for parallel stochastic optimization with a dependency graph (Woodworth et al., 2018), devising
efficient distributed optimization methods benefiting from differential privacy guarantees (Agarwal et al.,
2018), stochastic optimization solutions for the agnostic formulation (Mohri et al., 2019), and incorporating
cryptographic techniques (Bonawitz et al., 2017), meta-learning (Chen et al., 2018), see (Li et al., 2019;
Kairouz et al., 2019) for an in-depth survey of recent work in FL.
Federated learning often results in improved performance, as reported in several learning problems, including
next word prediction (Hard et al., 2018; Yang et al., 2018), vocabulary estimation (Chen et al., 2019a), emoji
prediction (Ramaswamy et al., 2019), decoder models (Chen et al., 2019b), low latency vehicle-to-vehicle
communication (Samarakoon et al., 2018), and predictive models in health (Brisimi et al., 2018).
A.2. Personalization in federated learning
There are several recent works that focus on multi-task and meta-learning in the context of federated learning.
Smith et al. (2017) studied the problem of federated multi-task learning and proposed MOCHA, an algorithm
that jointly learns parameters and a similarity matrix between user tasks. MOCHA tackles various aspects
of distributed multitask learning including communication constraints, stragglers, and fault tolerance. They
focus on the convex setting and their application to non-convex deep learning models where strong duality is
no longer guaranteed is unclear.
Jiang et al. (2019) drew interesting connections between FedAvg and first-order model agnostic meta-learning
(MAML) (Finn et al., 2017) and showed that FedAvg is in fact already a meta-learning algorithm. Fallah et al.
(2020) also proposed to use the MAML objective in a global model training to obtain a better personalizable
global model. Khodak et al. (2019) proposed ARUBA that improves upon gradient-based meta-learning
approaches. A variational approach for multi-task learning was proposed by Corinzia and Buhmann (2019).
Recently, Hanzely and Richtárik (2020) proposed to learn a model per user by adding an `2 penalty on model
parameters to ensure they are similar.
Another line of work uses a set of local parameters, which are trained per-client, and a set of global parameters,
which are trained using FL. For example, Bui et al. (2019) proposed to use user-representations by having a
set of client-specific local parameters, which are trained per-client and a set of global parameters, which are
trained using FL. Arivazhagan et al. (2019); Liang et al. (2020) proposed to store some layers of the model
locally, while training the rest of the model with federated learning.
Peterson et al. (2019) proposed to use techniques from a mixture of experts literature and their approach
is similar to our approach of model interpolation, but they learn an interpolation weight based on features.
Furthermore, there are no theoretical guarantees for their approach. A theoretical analysis of interpolation
models without variable mixing weights was recently presented in Agarwal et al. (2020). Concurrent to this
16

work, Deng et al. (2020) proposed to use an interpolation of a local and global model. Their approach is
similar to model interpolation in our paper.
Wang et al. (2019) showed that federated models can be fine-tuned based on local data. They proposed
methods to find the best hyper-parameters for fine-tuning and showed that it improves the next word prediction
of language models in virtual keyboard applications. Yu et al. (2020) proposed several variants of the finetuning approach, including training only a few layers of the networks, adding a local penalty term in the form
of model distillation, or elastic weight averaging to the fine-tuning objective to improve local adaptation.
Zhao et al. (2018b) showed that one can improve the accuracy of FedAvg, by sharing a small amount of public
data to reduce the non-i.i.d. nature of the client data. Sattler et al. (2019) proposed to use cosine-similarity
between gradient updates for clustering in federated learning. However, their approach requires all clients to
participate in each round and hence is computationally infeasible. Personalization in other settings such as
peer-to-peer networks have been studied by Zantedeschi et al. (2019). We refer the readers to (Kulkarni et al.,
2020) for a survey of algorithms for personalization in FL.

Appendix B. Global models
B.1. Example for the suboptimality of global models
We provide the following simple example, which shows that global models can be a constant worse compared
to the local model.
Example 1 Let X = R and Y = {0, 1}. Suppose there are two clients with distributions D1 and D2 defined
as follows. ∀x, D1 (x) = D2 (x) and D1 (1∣x) = 1 if x > 0 and zero otherwise. Similarly, D2 (1∣x) = 1 only if
x < 0 and zero otherwise. Let H be the class of threshold classifiers indexed by a threshold t ∈ R and sign
s ∈ {−1, 1} such that ht,s ∈ H is given by ht,s (x) = 1(x−t)s>0 . Further, suppose we are interested in zero-one
loss and the number of samples from both domains is very large and equal.
The optimal classifier for D1 is h0,1 and the optimal classifier for D2 is h0,−1 , and they achieve zero error in
their respective clients. Since the number of samples is the same from both clients, U is the uniform mixture of
the two domains, U = 0.5D1 + 0.5D2 . Note that for all h ∈ H, LU (h) = 0.5 and hence the global objective
cannot differentiate between any of the hypotheses in H. Thus, with high probability, any globally trained
model incurs a constant loss on both clients.
B.2. Agnostic global model
Instead of assigning weights proportional to the number of samples as in the uniform global model, we can
weight them according to any λ ∈ ∆p . For example, instead of uniform sample weights, we can weight clients
uniformly corresponding to λk = p1 , for all k. Let D̄λ denote the λ-weighted empirical distribution and let
hD̄λ be the minimizer of loss over D̄λ . Instead of the uniform global model described in the previous section,
we can use the agnostic loss, where we minimize the maximum loss over a set of distributions. Let Λ ⊆ ∆p .
Agnostic loss is given by
max LD̄λ (h).
λ∈Λ

17

Let hD̄Λ be the minimizer. Let s(Λ, m) = maxλ∈Λ s(λ, m). Let Λ be an -cover of ∆p . Let m denote the
empirical distribution of samples (m1 /m, m2 /m, . . . , mp /m). The skewness between the distributions λ
λ2

and m is defined as s(λ, m) = ∑pk=1 mkk , where mk = mk /m. With these definitions, the generalization
guarantee of (Mohri et al., 2019, Theorem 2) for client one can be expressed as follows:
√
∣Λ ∣
⎞
⎛√
d + log δ
√
+ ⎟ + discH (D1 , Dλ∗ ),
LD1 (hD
̂ Λ ) ≤ LD1 (hD1 ) + Õ ⎜ s(Λ ∣∣m) ⋅

m
⎠
⎝
where λ∗ = argmaxλ LD̄λ (hD
̂ Λ ) is the mixture weight where the trained model hD
̂ Λ has the highest loss.


Hence, this approach would personalize well for hard distributions and can be considered as a step towards
ensuring that models work for all distributions. In this work, we show that training a different model for each
client would significantly improve the model performance.

Appendix C. Supplementary material for clustering
C.1. Baselines
If we have meta-features about the data samples and clients, such as location or type of device, we can use
them to find clusters. This can be achieved by algorithms such as k-means or variants. This approach depends
on the knowledge of the meta-features and their relationship to the set of hypotheses under consideration.
While it may be reasonable in many circumstances, it may not be always feasible. If there are no meta-features,
a natural approach is to cluster using a Bregman divergence defined over the distributions Dk (Banerjee et al.,
2005). However, it is likely that we would overfit as the generalization of the density estimation depends on
the covering number of the class of distributions D1 , D2 , . . . , Dp , which in general can be much larger than
that of the class of hypotheses H. To overcome this, we propose an approach based on hypotheses under
consideration which we discuss next.
C.2. Generalization of clustering algorithms
Recall that we solve for

p

mk
⋅ min L ̂ (hi ).
h1 ,...,hq k=1 m i∈[q] Dk
min ∑

(7)

Lemma 7 Let h∗1 , h∗2 , . . . , h∗q be the q models obtained by solving (3) and ̂
h∗1 , ̂
h∗2 , . . . , ̂
h∗q be the q models
obtained by solving (7). Then,
p

p
mk
mk
⋅ (min LDk (̂
h∗i ) − min LDk (h∗i )) ≤ 2 max ∣ ∑
⋅ (min LDk (hi ) − min LD
̂ k (hi ))∣ .
h1 ,...,hq k=1 m
i∈[q]
i∈[q]
i∈[q]
i∈[q]
k=1 m

∑

18

(8)

Proof
p
mk
mk
∗
̂
⋅
min
L
(
h
)
−
⋅ min LDk (h∗i )
∑
∑
Dk
i
m
m
i∈[q]
i∈[q]
k=1
k=1
p

p

p
p
mk
mk
mk
̂∗
̂∗
⋅ min LDk (̂
h∗i ) + ∑
⋅ min LD
⋅ min LD
̂ k (hi ) − ∑
̂ k (hi )
m
m
m
i∈[q]
i∈[q]
i∈[q]
k=1
k=1
k=1

=∑

p
p
mk
mk
mk
∗
∗
⋅ min LD
⋅ min LDk (h∗i ) − ∑
⋅ min LD
̂ k (hi ) − ∑
̂ k (hi )
k=1 m i∈[q]
k=1 m i∈[q]
k=1 m i∈[q]
p

+∑

p

p
mk
mk
⋅ min LDk (hi ) − ∑
⋅ min LD
̂ k (hi )∣ ,
h1 ,...,hq k=1 m i∈[q]
k=1 m i∈[q]

≤ 2 max ∣ ∑

p
mk
∗
̂∗
where the inequality follows by observing that ∑pk=1 mmk ⋅ mini∈[q] LD
̂ k (hi ) ≤ ∑k=1 m ⋅ mini∈[q] LD
̂ k (hi ),
by the definition of ̂
h∗ .
i

C.3. Proof of Theorem 1
For any set of real numbers a1 , a2 , . . . , aq and b1 , b2 , . . . , bq , observe that
min ai − min bi = min bi + (ai − bi ) − min bi ≤ min bi + max(ai − bi ) − min bi = max(ai − bi ).
i

i

i

i

i

i

i

We first prove the theorem for one side. Let f ∶ [p] → [q] be a mapping from clients to clusters. Applying the
above result yields,
p

p

max ( ∑ mk ⋅ min LDk (hk ) − ∑ mk ⋅ min LD
̂ k (hk ))

h1 ,...,hq

i∈[q]

k=1

k=1

i∈[q]

p

≤ max ( ∑ mk ⋅ max(LDk (hk ) − LD
̂ k (hk )))
h1 ,...,hq

k∈[p]

k=1
p

= max ( ∑ mk ⋅ max(LDk (hf (k) ) − LD
̂ k (hf (k) )))
h1 ,...,hq

f (k)

k=1

p

= max max ( ∑ mk ⋅ (LDk (hf (k) ) − LD
̂ k (hf (k) )))
h1 ,...,hq

f

k=1
p

= max max ( ∑ mk ⋅ (LDk (hf (k) ) − LD
̂ k (hf (k) ))) .
f

h1 ,...,hq

k=1

Since changing one sample changes the above function by at most 1, for a given f , by the McDiarmid’s
inequality, with probability at least 1 − δ, the following holds:
p

max ( ∑ mk ⋅ (LDk (hf (k) ) − LD
̂ k (hf (k) )))

h1 ,...,hq

k=1

√

p

≤ E [ max ( ∑ mk ⋅ (LDk (hf (k) ) − LD
̂ k (hf (k) )))] + 2
h1 ,...,hq

k=1

19

1
m log .
δ

The number of possible functions f is q p . Hence, by the union bound, for all f , with probability at least 1 − δ,
the following holds:
p

max ( ∑ mk ⋅ (LDk (hf (k) ) − LD
̂ k (hf (k) )))

h1 ,...,hq

k=1

√
q
≤ E [ max ( ∑ mk ⋅ (LDk (hf (k) ) − LD
mp log .
̂ k (hf (k) )))] + 2
h1 ,...,hq k=1
δ
p

For a given clustering f , by the sub-additivity of max,
p

max ( ∑ mk ⋅ (LDk (hf (k) ) − LD
̂ k (hf (k) )))

h1 ,...,hq

k=1

⎞
⎛ p
∑ ∑ mk ⋅ (LDk (hf (k) ) − LD
̂ k (hf (k) ))
h1 ,...,hq ⎝k=1
⎠
k∶f (k)=i

= max

⎞
⎛
∑ mk ⋅ (LDk (hf (k) ) − LD
̂ k (hf (k) ))
⎠
i=1 h1 ,...,hq ⎝k∶f (k)=i
q

≤ ∑ max

⎞
⎛
∑ mk ⋅ (LDk (hi ) − LD
̂ k (hi ))
⎠
i=1 h1 ,...,hq ⎝k∶f (k)=i
q

= ∑ max
q

= ∑ max
i=1 hi

⎛
⎞
∑ mk ⋅ (LDk (hi ) − LD
̂ k (hi ))
⎝k∶f (k)=i
⎠

q

= ∑ max (mCi ⋅ (LCi (hi ) − L̂Ci (hi ))) ,
i=1 hi

where Ci is the cluster of clients such that f (k) = i and mCi is the number of samples in that cluster, and Ci
is its distribution. Thus,
p

q

E [ max ( ∑ mk ⋅ (LDk (hf (k) ) − LD
̂ k (hf (k) )))] ≤ E [∑ max (mCi ⋅ (LCi (hi ) − L̂
Ci (hi )))]
h1 ,...,hq

i=1 hi

k=1

q

≤ ∑ RCi ,mCi (H)mCi ,
i=1

where the last inequality follows from standard learning-theoretic guarantees and the definition of Rademacher
complexity (Mohri et al., 2018). The proof follows by combining the above equations, normalizing by m,
and the union bound.
C.4. Proof of Corollary 2
We show that for any clustering,
q

mCi
RCi ,mCi (H) ≤
∑
i=1 m

20

√

dp
em
log
.
m
d

The proof then follows from Theorem 1. To prove the above observation, observe that
√
√
q
q
q
mCi
mCi
mCi
emCi
dp
dp
em
RCi ,mCi (H) ≤ ∑
≤∑
log
log
∑
m
m
m
d
m
m
d
Ci
Ci
i=1
i=1
i=1
√
√
q
1 q
em
dq
em
≤ ∑ ∑ dpmCi log
≤
log
,
d
m
d
i=1 m i=1
where the last inequality follows from Jensen’s inequality.

Appendix D. Supplementary material for data interpolation
D.1. Proof of Theorem 4
Let g(h) = λLD
̂ k (h) + (1 − λ)L̂
C (h). Suppose we are interested in running T steps of SGD on g, where
̂ k with probability λ and ̂
at each step we independently sample D
C with probability 1 − λ and choose a
random sample from the selected empirical distribution to compute the gradient. This can be simulated by
first sampling T elements from ̂
C, denoted by ̂
C′ and using ̂
C′ instead of ̂
C during optimization. Hence to
prove the theorem, suffices to show that T = rmk steps of SGD on g using the above mentioned sampling
procedure yields the desired bound.
We now ask how large should T be to obtain error of λ . By standard stochastic gradient descent guarantees,
the output hA satisfies
∥hc − ĥλ )∥2 ηG2 T
+
.
E[g(hA )] ≤ E[g(ĥλ )] +
2η
2
Since the loss is strongly convex and hc is optimal for L̂C (hc ),
L̂C (ĥλ ) − L̂C (hc ) ≥

µ
∥hc − ĥλ )∥2 .
2

Furthermore, since ĥλ is optimal for a λ-mixture,
λLD
̂ k (ĥ
̂ k (hc ) + (1 − λ)L̂
λ ) + (1 − λ)L̂
λ ) ≤ λLD
C (ĥ
C (hc ).
Hence,
µ
∥hc − ĥλ )∥2 ≤ L̂C (ĥλ ) − L̂C (hc )
2
λ
≤
(L ̂ (hc ) − LD
̂ k (ĥ
λ ))
1 − λ Dk
Gλ
≤
∥hc − ĥλ )∥.
1−λ
Therefore,
∥hc − ĥλ )∥ ≤ min (

21

2Gλ
, R)
µ(1 − λ)

Algorithm DAPPER(hc )
For each client k do the following:
1. Randomly sample r ⋅ mk data points from ̂
C. Let this dataset be Ĉ′ .
2. Let Λ be a cover of [0, 1]. For each λ ∈ Λ, the client starts with hc and minimizes
λLD
̂ k (h) + (1 − λ)LĈ′ (h)

(9)

̂ k with probability
using stochastic gradient descent for r ⋅ mk steps, where at each step, it selects D
′
̂
λ and C with probability 1−λ and samples an element from the corresponding dataset to compute
the stochastic gradient. Let hλ be the resulting model and HΛ = {hλ ∶ λ ∈ Λ}.
3. Output
argmin LD
̂ k (h).
h∈HΛ

Figure 3: Pseudocode for the DAPPER algorithm.
Combining the above equations, we get
2

E[g(hA )] ≤ E[g(ĥλ )] +

1
2Gλ
ηG2 T
min (
, R) +
.
2η
µ(1 − λ)
2

Substituting the learning rate and setting T = rmk yields
G
2Gλ
E[g(hA )] ≤ E[g(ĥλ )] + √
min (
, R) .
rmk
µ(1 − λ)
2

2G
Hence if r ≥ G2 maxλ min ( µ(1−λ)
,R
λ ) , the above bound is at most

min (

√ 2

λ
mk ≤ λ . Note that for any λ,

2G
R
2G
R
4G
, )≤
1λ<1/2 + 1λ≥1/2 ≤
+ 2R,
µ(1 − λ) λ
µ(1 − λ)
λ
µ

hence the theorem.
D.2. Dapper pseudo-code
We provide pseudo-code for the DAPPER algorithm in Figure 3.
D.3. Practical considerations
While the above algorithm reduces the amount of data transfer and is computationally efficient, it may be
vulnerable to privacy issues in applications such as FL. To overcome that, we propose several alternatives:
1. Sufficient statistics: in many scenarios, instead of the actual data, we only need some sufficient statistics.
For example in regression with `22 loss, we only need the covariance matrix of the dataset from ̂
C.

22

2. Generative models: for problems such as density estimation and language modelling, we can use the
centralized model to generate synthetic samples from hc and use that as an approximation to Ĉ′ . For
other applications, one can train a GAN and send the GAN to the clients and the clients can sample
from the GAN to create the dataset Ĉ′ (Augenstein et al., 2019).
3. Proxy public data: if it is not feasible to send the actual user data, one could send proxy public data
instead. While this may not be theoretically optimal, it will still avoid overfitting to the local data.

Appendix E. Supplementary material for model interpolation
E.1. Proof of Theorem 5
Observe that
p
mk
mk
h∗l,k ) − ∑
LDk ((1 − ̂
λ∗k )̂
h∗c + λ∗k̂
LDk ((1 − λ∗k )h∗c + λ∗k h∗l,k )
k=1 m
k=1 m
p

∑

p

mk
(LDk ((1 − λk )hc + λk hl,k ) − LD
̂ k ((1 − λk )hc + λk hl,k ))) .
k=1 m

≤ 2 max ( ∑
hc ,λ̄,h̄l

Changing one sample changes the above function by at most 1/m. Thus by McDiarmid’s inequality, with
probability at least 1 − δ,
p

mk
(LDk ((1 − λk )hc + λk hl,k ) − LD
̂ k ((1 − λk )hc + λk hl,k )))
k=1 m

max ( ∑

hc ,λ̄,h̄l

¿
Á log 1
mk
Á
À
δ
((1
−
λ
)h
+
λ
h
)))]
+
2
(LDk ((1 − λk )hc + λk hl,k ) − LD
.
≤ E [ max ( ∑
̂k
k c
k l,k
m
hc ,λ̄,h̄l k=1 m
p

Let H̄l be the Cartesian product of hypothesis classes where the k th hypothesis class is the hypothesis applied
to k th client. Let H = λ̄Hc + (1 − λ̄)H̄l . Hence, by Talagrand’s construction lemma and the properties of
Rademacher complexity,
p

mk
(LDk ((1 − λk )hc + λk hl,k ) − LD
̂ k ((1 − λk )hc + λk hl,k )))]
k=1 m

E [ max ( ∑
hc ,λ̄,h̄l

≤ RU+D̄,m̄ (`(H))
≤ LRU+D̄,m̄ (H)
≤ LRU,m (Hc ) + LRDk ,mk (H̄l )
p

mk
RDk ,mk (Hl )) ,
k=1 m

≤ L (RU,m (Hc ) + ∑

where the last inequality follows from the sub-additivity of Rademacher complexity.
E.2. M APPER algorithms
We first show that this method of independently finding the local models is sub-optimal with an example.
23

Algorithm M APPER
Randomly initialize h0c and for t = 1 to T , randomly select a client k and do the following.
1. Let Λ be a cover of [0, 1]. For each λ ∈ Λ, let

t−1
hl,k (λ) = argmin LD
̂ k (λhl,k + (1 − λ)hc ).

(10)

hl,k

2. Find the best local model:
t−1
λ∗ = argmin LD
̂ k (λhl,k (λ) + (1 − λ)hc ).

(11)

λ∈Λ

3. Minimize the global model.
∗
∗
∗ t−1
htc = ht−1
̂ k (λ hl,k (λ ) + (1 − λ )hc ).
c − η∇LD

(12)

Let hTc be the final global model. For each client k rerun 1(a) and 1(b) to obtain the local model hl,k
and the interpolation weight λk .
Figure 4: Pseudocode for the M APPER algorithm.
Example 2 Consider the following discrete distribution estimation problem. Let Hc be the set of distributions
over d values and let Hl be the set of distributions with support size 1. For even k, let Dk (1) = Deven (1) = 1.0
and for odd k, let Dk (y) = Dodd (y) = 1/d for all 1 ≤ y ≤ d. Let the number of clients p be very large and the
number of samples per client a constant, say ten. Suppose we consider the log-loss.
The intuition behind this example is that since we have only one example per domain, we can only derive
good estimates for the local model for even k and we need to estimate the global model jointly from the odd
clients. With this approach, the optimal solution is as follows. For even k, hl,k = Dk and λk = 1.0. For odd k,
λk = 0.0 and the optimal hc is given by, hc = Dodd . If we learn the models separately, observe that, for each
client ̂
hl,k be the empirical estimate and ̂
hc would be 0.5 ⋅ Deven + 0.5 ⋅ Dodd . Thus, for any λ̄, the algorithm
would incur at least a constant loss more than optimal for any λk for odd clients.
Since training models independently is sub-optimal in certain cases, we propose a joint-optimization algorithm.
First observe that the optimization can be rewritten as
p

mk
min LD
̂ k ((1 − λk )hc + λk hl,k ).
hc k=1 m h̄l λ̄

min ∑

Notice that for a fixed λ the function is convex in both h` and hc . But with the minimization over λ, the
function is no longer convex. We propose algorithm M APPER for minimizing the interpolation models. At
each round, the algorithm randomly selects a client. It then finds the best local model and interpolation weight
for that client using the current value of the global model. It then updates the global model using the local
model and the interpolation weight found in the previous step.

24

Layer
Conv2d
Conv2d
MaxPool2d
Dropout
Flatten
Dense
Dropout
Dense

Output Shape
(26, 26, 32)
(24, 24, 64)
(12, 12, 64)
(12, 12, 64)
9216
128
128
62

Table 4: EMNIST convolutional model.
# Parameters
Activation
Hyperparameters
320
ReLU
out chan=32;filter shape=(3, 3)
18496
ReLU
out chan=64;filter shape=(3, 3)
0
window shape=(2, 2);strides=(2, 2)
0
keep rate=0.75
0
1179776
ReLU
0
keep rate=0.5
7998
LogSoftmax

Appendix F. Supplementary material for experiments
F.1. Synthetic dataset
Let U be a uniform distribution over Y. Let Pk be a point mass distribution with Pk (k) = 1.0 and for all
y ≠ k, Pk (y) = 0. For a client k, let Dk be a mixture given by
Dk = 0.5 ⋅ Pk%4 + 0.25 ⋅ U + 0.25 ⋅ Pk%(d−4) ,
where a%b, is a modulo b. Roughly, U is the uniform component and is same for all the clients, Pk%4 is the
cluster component and same for clients with same clusters, and Pk%(d−4) is the individual component per
client.
F.2. EMNIST dataset
For the EMNIST experiments, we follow previous work for model architecture (Jiang et al., 2019). The full
model architecture layer by layer is provided in Table 4. We train the model for 1000 communication rounds
with 20 clients per round and use server side momentum, though one can use different optimizers (Jiang et al.,
2019). Evaluating the combined effect of our approach and adaptive optimizers remains an interesting open
direction. Additionally, we apply logit smoothing with weight = 0.9 to the loss function to mitigate against
exploding gradients experienced often in training federated models.
For all algorithms, the following hyperparameters are the same: client batch size=20, num clients per
round=20, num rounds=1000, server learning rate=1.0, server momentum=0.9. For the remaining hyperparameters, we perform a sweep over parameters and use the eval dataset to choose the best. The best
hyperparameters after sweeping are as follows.
• F EDAVG: client num epochs=1, client step size=0.05.
• AGNOSTIC: client num epochs=1, client step size=0.05, domain learning rate=0.05. NIST documentation shows that the EMNIST dataset comes from two writer sources: C ENSUS and H IGH
S CHOOL (Grother, 1995). We use these two distinct sources as domains.
• H YP C LUSTER: client num epochs=1, client step size=0.03, num clusters=2. We determined that 2 was
the optimal number of clusters since for larger numbers of clusters, all clients essentially mapped to
just 2 of them.
25

• F INETUNE: client num epochs=5, client step size=0.01. We use the best baseline model as the
pre-trained starting global model and finetune for each client.
• DAPPER: client num epochs=1, client step size=0.04. Similar to F INETUNE, we use the best baseline
model as the pre-trained starting global model. For each client, we finetune the global model using a
mixture of global and client data. Given mk client examples, we sample 5 ⋅ mk global examples.
• M APPER: client num epochs=1, client step size=0.03 . We use the same global hyperparameters as the
starting global model with the above local hyperparameters. As stated previously, we use the same
architecture for both local and global models and at each optimization step, we initialize the local
model using the global parameters.
Over the course of running experiments, we observed a peculiar behavior regarding the original client ordering
provided in the EMNIST dataset. If the seen and unseen split is performed on the original ordering of clients,
the model performance between seen and unseen clients is very different. In particular, unseen is almost 10%
absolute worse than seen. Looking through the NIST documentation, we found that the data was sourced from
two distinct sources: C ENSUS and H IGH S CHOOL (Grother, 1995). The original client ordering is derived
from the data partition they are sourced from and H IGH S CHOOL clients were all in one split, resulting in the
difference in model performance. Thus, we determined that shuffling the clients before splitting was better.

26

Communication-Efficient Learning of Deep Networks
from Decentralized Data

H. Brendan McMahan

Eider Moore
Daniel Ramage
Seth Hampson
Google, Inc., 651 N 34th St., Seattle, WA 98103 USA

Abstract
Modern mobile devices have access to a wealth
of data suitable for learning models, which in turn
can greatly improve the user experience on the
device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos.
However, this rich data is often privacy sensitive,
large in quantity, or both, which may preclude
logging to the data center and training there using
conventional approaches. We advocate an alternative that leaves the training data distributed on
the mobile devices, and learns a shared model by
aggregating locally-computed updates. We term
this decentralized approach Federated Learning.
We present a practical method for the federated
learning of deep networks based on iterative
model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments
demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a
defining characteristic of this setting. Communication costs are the principal constraint, and
we show a reduction in required communication
rounds by 10–100× as compared to synchronized
stochastic gradient descent.

1

Introduction

Increasingly, phones and tablets are the primary computing
devices for many people [30, 2]. The powerful sensors on
these devices (including cameras, microphones, and GPS),
combined with the fact they are frequently carried, means
they have access to an unprecedented amount of data, much
of it private in nature. Models learned on such data hold the
Proceedings of the 20th International Conference on Artificial Intelligence and Statistics (AISTATS) 2017, Fort Lauderdale, Florida,
USA. JMLR: W&CP volume 54. Copyright 2017 by the author(s).

Blaise Agüera y Arcas

promise of greatly improving usability by powering more
intelligent applications, but the sensitive nature of the data
means there are risks and responsibilities to storing it in a
centralized location.
We investigate a learning technique that allows users to
collectively reap the benefits of shared models trained from
this rich data, without the need to centrally store it. We term
our approach Federated Learning, since the learning task is
solved by a loose federation of participating devices (which
we refer to as clients) which are coordinated by a central
server. Each client has a local training dataset which is
never uploaded to the server. Instead, each client computes
an update to the current global model maintained by the
server, and only this update is communicated. This is a
direct application of the principle of focused collection or
data minimization proposed by the 2012 White House report
on privacy of consumer data [39]. Since these updates are
specific to improving the current model, there is no reason
to store them once they have been applied.
A principal advantage of this approach is the decoupling of
model training from the need for direct access to the raw
training data. Clearly, some trust of the server coordinating the training is still required. However, for applications
where the training objective can be specified on the basis
of data available on each client, federated learning can significantly reduce privacy and security risks by limiting the
attack surface to only the device, rather than the device and
the cloud.
Our primary contributions are 1) the identification of the
problem of training on decentralized data from mobile devices as an important research direction; 2) the selection of
a straightforward and practical algorithm that can be applied
to this setting; and 3) an extensive empirical evaluation of
the proposed approach. More concretely, we introduce the
FederatedAveraging algorithm, which combines local stochastic gradient descent (SGD) on each client with
a server that performs model averaging. We perform extensive experiments on this algorithm, demonstrating it is
robust to unbalanced and non-IID data distributions, and
can reduce the rounds of communication needed to train a
deep network on decentralized data by orders of magnitude.

Communication-Efficient Learning of Deep Networks from Decentralized Data

Federated Learning Ideal problems for federated learning have the following properties: 1) Training on real-world
data from mobile devices provides a distinct advantage over
training on proxy data that is generally available in the data
center. 2) This data is privacy sensitive or large in size (compared to the size of the model), so it is preferable not to log
it to the data center purely for the purpose of model training
(in service of the focused collection principle). 3) For supervised tasks, labels on the data can be inferred naturally from
user interaction.

mation than the raw training data (by the data processing
inequality), and will generally contain much less. Further,
the source of the updates is not needed by the aggregation
algorithm, so updates can be transmitted without identifying
meta-data over a mix network such as Tor [7] or via a trusted
third party. We briefly discuss the possibility of combining
federated learning with secure multiparty computation and
differential privacy at the end of the paper.

Many models that power intelligent behavior on mobile
devices fit the above criteria. As two examples, we consider image classification, for example predicting which
photos are most likely to be viewed multiple times in the
future, or shared; and language models, which can be used
to improve voice recognition and text entry on touch-screen
keyboards by improving decoding, next-word-prediction,
and even predicting whole replies [10]. The potential training data for both these tasks (all the photos a user takes and
everything they type on their mobile keyboard, including
passwords, URLs, messages, etc.) can be privacy sensitive.
The distributions from which these examples are drawn are
also likely to differ substantially from easily available proxy
datasets: the use of language in chat and text messages is
generally much different than standard language corpora,
e.g., Wikipedia and other web documents; the photos people
take on their phone are likely quite different than typical
Flickr photos. And finally, the labels for these problems are
directly available: entered text is self-labeled for learning
a language model, and photo labels can be defined by natural user interaction with their photo app (which photos are
deleted, shared, or viewed).

Federated Optimization We refer to the optimization
problem implicit in federated learning as federated optimization, drawing a connection (and contrast) to distributed optimization. Federated optimization has several key properties
that differentiate it from a typical distributed optimization
problem:

Both of these tasks are well-suited to learning a neural network. For image classification feed-forward deep networks,
and in particular convolutional networks, are well-known
to provide state-of-the-art results [26, 25]. For language
modeling tasks recurrent neural networks, and in particular
LSTMs, have achieved state-of-the-art results [20, 5, 22].
Privacy Federated learning has distinct privacy advantages compared to data center training on persisted data.
Holding even an “anonymized” dataset can still put user
privacy at risk via joins with other data [37]. In contrast,
the information transmitted for federated learning is the
minimal update necessary to improve a particular model
(naturally, the strength of the privacy benefit depends on the
content of the updates).1 The updates themselves can (and
should) be ephemeral. They will never contain more infor1

For example, if the update is the total gradient of the loss on
all of the local data, and the features are a sparse bag-of-words,
then the non-zero gradients reveal exactly which words the user
has entered on the device. In contrast, the sum of many gradients
for a dense model such as a CNN offers a harder target for attackers
seeking information about individual training instances (though
attacks are still possible).

• Non-IID The training data on a given client is typically
based on the usage of the mobile device by a particular
user, and hence any particular user’s local dataset will
not be representative of the population distribution.
• Unbalanced Similarly, some users will make much
heavier use of the service or app than others, leading
to varying amounts of local training data.
• Massively distributed We expect the number of
clients participating in an optimization to be much
larger than the average number of examples per client.
• Limited communication Mobile devices are frequently offline or on slow or expensive connections.
In this work, our emphasis is on the non-IID and unbalanced
properties of the optimization, as well as the critical nature
of the communication constraints. A deployed federated
optimization system must also address a myriad of practical
issues: client datasets that change as data is added and
deleted; client availability that correlates with the local data
distribution in complex ways (e.g., phones from speakers
of American English will likely be plugged in at different
times than speakers of British English); and clients that
never respond or send corrupted updates.
These issues are beyond the scope of the current work;
instead, we use a controlled environment that is suitable
for experiments, but still addresses the key issues of client
availability and unbalanced and non-IID data. We assume
a synchronous update scheme that proceeds in rounds of
communication. There is a fixed set of K clients, each
with a fixed local dataset. At the beginning of each round,
a random fraction C of clients is selected, and the server
sends the current global algorithm state to each of these
clients (e.g., the current model parameters). We only select
a fraction of clients for efficiency, as our experiments show
diminishing returns for adding more clients beyond a certain
point. Each selected client then performs local computation
based on the global state and its local dataset, and sends an
update to the server. The server then applies these updates
to its global state, and the process repeats.

H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, Blaise Agüera y Arcas

While we focus on non-convex neural network objectives,
the algorithm we consider is applicable to any finite-sum
objective of the form
min f (w)

w∈Rd

where

def 1

f (w) =

n
X

n i=1

fi (w).

(1)

For a machine learning problem, we typically take fi (w) =
`(xi , yi ; w), that is, the loss of the prediction on example
(xi , yi ) made with model parameters w. We assume there
are K clients over which the data is partitioned, with Pk the
set of indexes of data points on client k, with nk = |Pk |.
Thus, we can re-write the objective (1) as
f (w) =

K
X
nk
k=1

n

Fk (w) where Fk (w) =

1 X
fi (w).
nk
i∈Pk

If the partition Pk was formed by distributing the training
examples over the clients uniformly at random, then we
would have EPk [Fk (w)] = f (w), where the expectation is
over the set of examples assigned to a fixed client k. This is
the IID assumption typically made by distributed optimization algorithms; we refer to the case where this does not
hold (that is, Fk could be an arbitrarily bad approximation
to f ) as the non-IID setting.
In data center optimization, communication costs are relatively small, and computational costs dominate, with much
of the recent emphasis being on using GPUs to lower these
costs. In contrast, in federated optimization communication
costs dominate — we will typically be limited by an upload
bandwidth of 1 MB/s or less. Further, clients will typically
only volunteer to participate in the optimization when they
are charged, plugged-in, and on an unmetered wi-fi connection. Further, we expect each client will only participate in a
small number of update rounds per day. On the other hand,
since any single on-device dataset is small compared to the
total dataset size, and modern smartphones have relatively
fast processors (including GPUs), computation becomes
essentially free compared to communication costs for many
model types. Thus, our goal is to use additional computation
in order to decrease the number of rounds of communication needed to train a model. There are two primary ways
we can add computation: 1) increased parallelism, where
we use more clients working independently between each
communication round; and, 2) increased computation on
each client, where rather than performing a simple computation like a gradient calculation, each client performs a more
complex calculation between each communication round.
We investigate both of these approaches, but the speedups
we achieve are due primarily to adding more computation
on each client, once a minimum level of parallelism over
clients is used.
Related Work Distributed training by iteratively averaging locally trained models has been studied by McDonald et al. [28] for the perceptron and Povey et al. [31] for

speech recognition DNNs. Zhang et al. [42] studies an asynchronous approach with “soft” averaging. These works only
consider the cluster / data center setting (at most 16 workers,
wall-clock time based on fast networks), and do not consider
datasets that are unbalanced and non-IID, properties that
are essential to the federated learning setting. We adapt
this style of algorithm to the federated setting and perform
the appropriate empirical evaluation, which asks different
questions than those relevant in the data center setting, and
requires different methodology.
Using similar motivation to ours, Neverova et al. [29] also
discusses the advantages of keeping sensitive user data on
device. The work of Shokri and Shmatikov [35] is related in
several ways: they focus on training deep networks, emphasize the importance of privacy, and address communication
costs by only sharing a subset of the parameters during each
round of communication; however, they also do not consider
unbalanced and non-IID data, and the empirical evaluation
is limited.
In the convex setting, the problem of distributed optimization and estimation has received significant attention
[4, 15, 33], and some algorithms do focus specifically on
communication efficiency [45, 34, 40, 27, 43]. In addition
to assuming convexity, this existing work generally requires
that the number of clients is much smaller than the number
of examples per client, that the data is distributed across
the clients in IID fashion, and that each node has an identical number of data points — all of these assumptions
are violated in the federated optimization setting. Asynchronous distributed forms of SGD have also been applied
to training neural networks, e.g., Dean et al. [12], but these
approaches require a prohibitive number of updates in the
federated setting. Distributed consensus algorithms (e.g.,
[41]) relax the IID assumption, but are still not a good fit for
communication-constrained optimization over very many
clients.
One endpoint of the (parameterized) algorithm family we
consider is simple one-shot averaging, where each client
solves for the model that minimizes (possibly regularized)
loss on their local data, and these models are averaged to
produce the final global model. This approach has been
studied extensively in the convex case with IID data, and it
is known that in the worst-case, the global model produced is
no better than training a model on a single client [44, 3, 46].

2

The FederatedAveraging Algorithm

The recent multitude of successful applications of deep
learning have almost exclusively relied on variants of
stochastic gradient descent (SGD) for optimization; in fact,
many advances can be understood as adapting the structure of the model (and hence the loss function) to be more
amenable to optimization by simple gradient-based methods [16]. Thus, it is natural that we build algorithms for

Communication-Efficient Learning of Deep Networks from Decentralized Data

In the federated setting, there is little cost in wall-clock time
to involving more clients, and so for our baseline we use
large-batch synchronous SGD; experiments by Chen et al.
[8] show this approach is state-of-the-art in the data center
setting, where it outperforms asynchronous approaches. To
apply this approach in the federated setting, we select a Cfraction of clients on each round, and compute the gradient
of the loss over all the data held by these clients. Thus, C
controls the global batch size, with C = 1 corresponding
to full-batch (non-stochastic) gradient descent.2 We refer to
this baseline algorithm as FederatedSGD (or FedSGD).
A typical implementation of FedSGD with C = 1 and
a fixed learning rate η has each client k compute gk =
OFk (wt ), the average gradient on its local data at the current
model wt , and the central server aggregates
PKthese gradients
and applies the update wt+1 ← wt − η k=1 nnk gk , since
PK nk
k=1 n gk = Of (wt ). An equivalent update is given by
PK
k
k
∀k, wt+1
← wt − ηgk and then wt+1 ← k=1 nnk wt+1
.
That is, each client locally takes one step of gradient descent on the current model using its local data, and the
server then takes a weighted average of the resulting models.
Once the algorithm is written this way, we can add more
computation to each client by iterating the local update
wk ← wk − ηOFk (wk ) multiple times before the averaging step. We term this approach FederatedAveraging
(or FedAvg). The amount of computation is controlled
by three key parameters: C, the fraction of clients that
perform computation on each round; E, then number of
training passes each client makes over its local dataset on
each round; and B, the local minibatch size used for the
client updates. We write B = ∞ to indicate that the full
local dataset is treated as a single minibatch. Thus, at one
endpoint of this algorithm family, we can take B = ∞ and
E = 1 which corresponds exactly to FedSGD. For a client
with nk local examples, the number of local updates per
round is given by uk = E nBk ; Complete pseudo-code is
given in Algorithm 1.

Independent initialization
1.2
1.1
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.20.0 0.2 0.4 0.6 0.8 1.0 1.2
mixing weight θ

loss

SGD can be applied naively to the federated optimization
problem, where a single batch gradient calculation (say on
a randomly selected client) is done per round of communication. This approach is computationally efficient, but
requires very large numbers of rounds of training to produce
good models (e.g., even using an advanced approach like
batch normalization, Ioffe and Szegedy [21] trained MNIST
for 50000 steps on minibatches of size 60). We consider
this baseline in our CIFAR-10 experiments.

loss

federated optimization by starting from SGD.

Common initialization
0.54
0.52
0.50
0.48
0.46
0.44
0.42
0.40
0.20.0 0.2 0.4 0.6 0.8 1.0 1.2
mixing weight θ

Figure 1: The loss on the full MNIST training set for models
generated by averaging the parameters of two models w
and w0 using θw + (1 − θ)w0 for 50 evenly spaced values
θ ∈ [−0.2, 1.2].The models w and w0 were trained using
SGD on different small datasets. For the left plot, w and w0
were initialized using different random seeds; for the right
plot, a shared seed was used. Note the different y-axis scales.
The horizontal line gives the best loss achieved by w or w0
(which were quite close, corresponding to the vertical lines
at θ = 0 and θ = 1). With shared initialization, averaging
the models produces a significant reduction in the loss on
the total training set (much better than the loss of either
parent model).

Following the approach of Goodfellow et al. [17], we see
exactly this bad behavior when we average two MNIST
digit-recognition models3 trained from different initial conditions (Figure 1, left). For this figure, the parent models w
and w0 were each trained on non-overlapping IID samples
of 600 examples from the MNIST training set. Training
was via SGD with a fixed learning rate of 0.1 for 240 updates on minibatches of size 50 (or E = 20 passes over
the mini-datasets of size 600). This is approximately the
amount of training where the models begin to overfit their
local datasets.

For general non-convex objectives, averaging models in
parameter space could produce an arbitrarily bad model.

Recent work indicates that in practice, the loss surfaces of
sufficiently over-parameterized NNs are surprisingly wellbehaved and in particular less prone to bad local minima
than previously thought [11, 17, 9]. And indeed, when we
start two models from the same random initialization and
then again train each independently on a different subset of
the data (as described above), we find that naive parameter
averaging works surprisingly well (Figure 1, right): the average of these two models, 12 w + 12 w0 , achieves significantly
lower loss on the full MNIST training set than the best
model achieved by training on either of the small datasets
independently. While Figure 1 starts from a random initialization, note a shared starting model wt is used for each
round of FedAvg, and so the same intuition applies.

2
While the batch selection mechanism is different than selecting a batch by choosing individual examples uniformly at
random, the batch gradients g computed by FedSGD still satisfy
E[g] = Of (w).

3
We use the “2NN” multi-layer perceptron described in Section 3.

H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, Blaise Agüera y Arcas

Algorithm 1 FederatedAveraging. The K clients are
indexed by k; B is the local minibatch size, E is the number
of local epochs, and η is the learning rate.
Server executes:
initialize w0
for each round t = 1, 2, . . . do
m ← max(C · K, 1)
St ← (random set of m clients)
for each client k ∈ St in parallel do
k
wt+1
← ClientUpdate(k, wt )
PK
k
wt+1 ← k=1 nnk wt+1
ClientUpdate(k, w): // Run on client k
B ← (split Pk into batches of size B)
for each local epoch i from 1 to E do
for batch b ∈ B do
w ← w − ηO`(w; b)
return w to server

3

Table 1: Effect of the client fraction C on the MNIST 2NN
with E = 1 and CNN with E = 5. Note C = 0.0 corresponds to one client per round; since we use 100 clients for
the MNIST data, the rows correspond to 1, 10 20, 50, and
100 clients. Each table entry gives the number of rounds
of communication necessary to achieve a test-set accuracy
of 97% for the 2NN and 99% for the CNN, along with the
speedup relative to the C = 0 baseline. Five runs with
the large batch size did not reach the target accuracy in the
allowed time.
2NN
C

IID
B=∞

0.0 1455
0.1 1474 (1.0×)
0.2 1658 (0.9×)
0.5
— (—)
1.0
— (—)
CNN, E = 5
0.0 387
0.1 339 (1.1×)
0.2 337 (1.1×)
0.5 164 (2.4×)
1.0 246 (1.6×)

N ON -IID
B = 10

B=∞

B = 10

316
87 (3.6×)
77 (4.1×)
75 (4.2×)
70 (4.5×)

4278
1796 (2.4×)
1528 (2.8×)
— (—)
— (—)

3275
664 (4.9×)
619 (5.3×)
443 (7.4×)
380 (8.6×)

50
18 (2.8×)
18 (2.8×)
18 (2.8×)
16 (3.1×)

1181
1100 (1.1×)
978 (1.2×)
1067 (1.1×)
— (—)

956
206 (4.6×)
200 (4.8×)
261 (3.7×)
97 (9.9×)

Experimental Results

We are motivated by both image classification and language
modeling tasks where good models can greatly enhance the
usability of mobile devices. For each of these tasks we first
picked a proxy dataset of modest enough size that we could
thoroughly investigate the hyperparameters of the FedAvg
algorithm. While each individual training run is relatively
small, we trained over 2000 individual models for these
experiments. We then present results on the benchmark
CIFAR-10 image classification task. Finally, to demonstrate
the effectiveness of FedAvg on a real-world problem with
a natural partitioning of the data over clients, we evaluate
on a large language modeling task.
Our initial study includes three model families on two
datasets. The first two are for the MNIST digit recognition
task [26]: 1) A simple multilayer-perceptron with 2-hidden
layers with 200 units each using ReLu activations (199,210
total parameters), which we refer to as the MNIST 2NN.
2) A CNN with two 5x5 convolution layers (the first with
32 channels, the second with 64, each followed with 2x2
max pooling), a fully connected layer with 512 units and
ReLu activation, and a final softmax output layer (1,663,370
total parameters). To study federated optimization, we also
need to specify how the data is distributed over the clients.
We study two ways of partitioning the MNIST data over
clients: IID, where the data is shuffled, and then partitioned
into 100 clients each receiving 600 examples, and Non-IID,
where we first sort the data by digit label, divide it into 200
shards of size 300, and assign each of 100 clients 2 shards.
This is a pathological non-IID partition of the data, as most
clients will only have examples of two digits. Thus, this lets
us explore the degree to which our algorithms will break on
highly non-IID data. Both of these partitions are balanced,

however.4
For language modeling, we built a dataset from The Complete Works of William Shakespeare [32]. We construct a
client dataset for each speaking role in each play with at
least two lines. This produced a dataset with 1146 clients.
For each client, we split the data into a set of training lines
(the first 80% of lines for the role), and test lines (the last
20%, rounded up to at least one line). The resulting dataset
has 3,564,579 characters in the training set, and 870,014
characters5 in the test set. This data is substantially unbalanced, with many roles having only a few lines, and a few
with a large number of lines. Further, observe the test set is
not a random sample of lines, but is temporally separated
by the chronology of each play. Using an identical train/test
split, we also form a balanced and IID version of the dataset,
also with 1146 clients.
On this data we train a stacked character-level LSTM language model, which after reading each character in a line,
predicts the next character [22]. The model takes a series of
characters as input and embeds each of these into a learned
8 dimensional space. The embedded characters are then
processed through 2 LSTM layers, each with 256 nodes.
Finally the output of the second LSTM layer is sent to a
softmax output layer with one node per character. The full
model has 866,578 parameters, and we trained using an
unroll length of 80 characters.
4
We performed additional experiments on unbalanced versions
of these datasets, and found them to in fact be slightly easier for
FedAvg.
5
We always use character to refer to a one byte string, and use
role to refer to a part in the play.

Communication-Efficient Learning of Deep Networks from Decentralized Data

Table 2: Number of communication rounds to reach a target
accuracy for FedAvg, versus FedSGD (first row, E = 1
and B = ∞). The u column gives u = En/(KB), the
expected number of updates per round.
MNIST CNN, 99% ACCURACY
E
B
u
IID
N ON -IID
1
∞
1
626
483
5
∞
5
179 (3.5×)
1000 (0.5×)
1
50
12
65 (9.6×)
600 (0.8×)
20
∞
20
234 (2.7×)
672 (0.7×)
1
10
60
34 (18.4×)
350 (1.4×)
5
50
60
29 (21.6×)
334 (1.4×)
20
50
240
32 (19.6×)
426 (1.1×)
5
10
300
20 (31.3×)
229 (2.1×)
20
10
1200
18 (34.8×)
173 (2.8×)
S HAKESPEARE LSTM, 54% ACCURACY
LSTM
E
B
u
IID
N ON -IID
F E D SGD
1
∞
1.0
2488
3906
FE DAV G
1
50
1.5
1635 (1.5×)
549 (7.1×)
FE DAV G
5
∞
5.0
613 (4.1×)
597 (6.5×)
FE DAV G
1
10
7.4
460 (5.4×)
164 (23.8×)
FE DAV G
5
50
7.4
401 (6.2×)
152 (25.7×)
FE DAV G
5
10
37.1
192 (13.0×)
41 (95.3×)

CNN
F E D SGD
FE DAV G
FE DAV G
FE DAV G
FE DAV G
FE DAV G
FE DAV G
FE DAV G
FE DAV G

SGD is sensitive to the tuning of the learning-rate parameter
η. The results reported here are based on training over
a sufficiently wide grid of learning rates (typically 11-13
1
values for η on a multiplicative grid of resolution 10 3 or
1
10 6 ). We checked to ensure the best learning rates were in
the middle of our grids, and that there was not a significant
difference between the best learning rates. Unless otherwise
noted, we plot metrics for the best performing rate selected
individually for each x-axis value. We find that the optimal
learning rates do not vary too much as a function of the
other parameters.
Increasing parallelism We first experiment with the
client fraction C, which controls the amount of multi-client
parallelism. Table 1 shows the impact of varying C for both
MNIST models. We report the number of communication
rounds necessary to achieve a target test-set accuracy. To
compute this, we construct a learning curve for each combination of parameter settings, optimizing η as described
above and then making each curve monotonically improving
by taking the best value of test-set accuracy achieved over
all prior rounds. We then calculate the number of rounds
where the curve crosses the target accuracy, using linear
interpolation between the discrete points forming the curve.
This is perhaps best understood by reference to Figure 2,
where the gray lines show the targets.
With B = ∞ (for MNIST processing all 600 client examples as a single batch per round), there is only a small
advantage in increasing the client fraction. Using the smaller
batch size B = 10 shows a significant improvement in using
C ≥ 0.1, especially in the non-IID case. Based on these
results, for most of the remainder of our experiments we
fix C = 0.1, which strikes a good balance between computational efficiency and convergence rate. Comparing the
number of rounds for the B = ∞ and B = 10 columns in

Figure 2: Test set accuracy vs. communication rounds
for the MNIST CNN (IID and then pathological non-IID)
and Shakespeare LSTM (IID and then by Play&Role) with
C = 0.1 and optimized η. The gray lines show the target
accuracies used in Table 2. Plots for the 2NN are given as
Figure 7 in Appendix A.

Table 1 shows a dramatic speedup, which we investigate
next.
Increasing computation per client In this section, we
fix C = 0.1, and add more computation per client on each
round, either decreasing B, increasing E, or both. Figure 2
demonstrates that adding more local SGD updates per round
can produce a dramatic decrease in communication costs,
and Table 2 quantifies these speedups. The expected number
of updates per client per round is u = (E[nk ]/B)E =
nE/(KB), where the expectation is over the draw of a
random client k. We order the rows in each section of
Table 2 by this statistic. We see that increasing u by varying
both E and B is effective. As long as B is large enough
to take full advantage of available parallelism on the client
hardware, there is essentially no cost in computation time
for lowering it, and so in practice this should be the first
parameter tuned.
For the IID partition of the MNIST data, using more computation per client decreases the number of rounds to reach the
target accuracy by 35× for the CNN and 46× for the 2NN
(see Table 4 in Appendix A for details for the 2NN). The
speedups for the pathologically partitioned non-IID data are
smaller, but still substantial (2.8 – 3.7×). It is impressive

H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, Blaise Agüera y Arcas
CIFAR-10

1.0

Test Accuracy

0.8
0.6
0.4

FedAvg, η=0.05
FedAvg, η=0.15
FedAvg, η=0.25
FedSGD, η=0.45
FedSGD, η=0.6
FedSGD, η=0.7

0.2
0

Figure 3: The effect of training for many local epochs (large
E) between averaging steps, fixing B = 10 and C = 0.1 for
the Shakespeare LSTM with a fixed learning rate η = 1.47.

that averaging provides any advantage (vs. actually diverging) when we naively average the parameters of models
trained on entirely different pairs of digits. Thus, we view
this as strong evidence for the robustness of this approach.
The unbalanced and non-IID distribution of the Shakespeare
(by role in the play) is much more representative of the kind
of data distribution we expect for real-world applications.
Encouragingly, for this problem learning on the non-IID and
unbalanced data is actually much easier (a 95× speedup vs
13× for the balanced IID data); we conjecture this is largely
due to the fact some roles have relatively large local datasets,
which makes increased local training particularly valuable.
For all three model classes, FedAvg converges to a higher
level of test-set accuracy than the baseline FedSGD models. This trend continues even if the lines are extended
beyond the plotted ranges. For example, for the CNN the
B = ∞, E = 1 FedSGD model eventually reaches 99.22%
accuracy after 1200 rounds (and had not improved further
after 6000 rounds), while the B = 10, E = 20 FedAvg
model reaches an accuracy of 99.44% after 300 rounds. We
conjecture that in addition to lowering communication costs,
model averaging produces a regularization benefit similar
to that achieved by dropout [36].
We are primarily concerned with generalization performance, but FedAvg is effective at optimizing the training
loss as well, even beyond the point where test-set accuracy
plateaus. We observed similar behavior for all three model
classes, and present plots for the MNIST CNN in Figure 6
in Appendix A.
Can we over-optimize on the client datasets? The current model parameters only influence the optimization performed in each ClientUpdate via initialization. Thus,
as E → ∞, at least for a convex problem eventually the
initial conditions should be irrelevant, and the global minimum would be reached regardless of initialization. Even
for a non-convex problem, one might conjecture the algo-

500

1000
1500
2000
Communication Rounds

2500

3000

Figure 4: Test accuracy versus communication for the CIFAR10 experiments. FedSGD uses a learning-rate decay
of 0.9934 per round; FedAvg uses B = 50, learning-rate
decay of 0.99 per round, and E = 5.

rithm would converge to the same local minimum as long as
the initialization was in the same basin. That is, we would
expect that while one round of averaging might produce a
reasonable model, additional rounds of communication (and
averaging) would not produce further improvements.
Figure 3 shows the impact of large E during initial training
on the Shakespeare LSTM problem. Indeed, for very large
numbers of local epochs, FedAvg can plateau or diverge.6
This result suggests that for some models, especially in the
later stages of convergence, it may be useful to decay the
amount of local computation per round (moving to smaller
E or larger B) in the same way decaying learning rates
can be useful. Figure 8 in Appendix A gives the analogous experiment for the MNIST CNN. Interestingly, for this
model we see no significant degradation in the convergence
rate for large values of E. However, we see slightly better
performance for E = 1 versus E = 5 for the large-scale
language modeling task described below (see Figure 10 in
Appendix A).
CIFAR experiments We also ran experiments on the
CIFAR-10 dataset [24] to further validate FedAvg. The
dataset consists of 10 classes of 32x32 images with three
RGB channels. There are 50,000 training examples and
10,000 testing examples, which we partitioned into 100
clients each containing 500 training and 100 testing examples; since there isn’t a natural user partitioning of this data,
we considered the balanced and IID setting. The model
architecture was taken from the TensorFlow tutorial [38],
which consists of two convolutional layers followed by two
fully connected layers and then a linear transformation layer
to produce logits, for a total of about 106 parameters. Note
6

Note that due to this behavior and because for large E not all
experiments for all learning rates were run for the full number of
rounds, we report results for a fixed learning rate (which perhaps
surprisingly was near-optimal across the range of E parameters)
and without forcing the lines to be monotonic.

Communication-Efficient Learning of Deep Networks from Decentralized Data

ACC .
SGD
F E D SGD
FE DAV G

80%
18000
(—)
3750 (4.8×)
280 (64.3×)

82%
31000
(—)
6600 (4.7×)
630 (49.2×)

85%
99000
(—)
N/A
(—)
2000 (49.5×)

that state-of-the-art approaches have achieved a test accuracy of 96.5% [19] for CIFAR; nevertheless, the standard
model we use is sufficient for our needs, as our goal is to
evaluate our optimization method, not achieve the best possible accuracy on this task. The images are preprocessed as
part of the training input pipeline, which consists of cropping the images to 24x24, randomly flipping left-right and
adjusting the contrast, brightness and whitening.
For these experiments, we considered an additional baseline, standard SGD training on the full training set (no user
partitioning), using minibatches of size 100. We achieved
an 86% test accuracy after 197,500 minibatch updates
(each minibatch update requires a communication round
in the federated setting). FedAvg achieves a similar test
accuracy of 85% after only 2,000 communication rounds.
For all algorithms, we tuned a learning-rate decay parameter in addition to the initial learning rate. Table 3 gives
the number of communication rounds for baseline SGD,
FedSGD, and FedAvg to reach three different accuracy
targets, and Figure 4 gives learning-rate curves for FedAvg
versus FedSGD.
By running experiments with minibatches of size B = 50
for both SGD and FedAvg, we can also look at accuracy as
a function of the number of such minibatch gradient calculations. We expect SGD to do better here, because a sequential
step is taken after each minibatch computation. However,
as Figure 9 in the appendix shows, for modest values of C
and E, FedAvg makes a similar amount of progress per
minibatch computation. Further, we see that both standard
SGD and FedAvg with only one client per round (C = 0),
demonstrate significant oscillations in accuracy, whereas
averaging over more clients smooths this out.
Large-scale LSTM experiments We ran experiments on
a large-scale next-word prediction task task to demonstrate
the effectiveness of our approach on a real-world problem.
Our training dataset consists 10 million public posts from a
large social network. We grouped the posts by author, for
a total of over 500,000 clients. This dataset is a realistic
proxy for the type of text entry data that would be present
on a user’s mobile device. We limited each client dataset
to at most 5000 words, and report accuracy (the fraction
of the data where the highest predicted probability was on
the correct next word, out of 10000 possibilities) on a test
set of 1e5 posts from different (non-training) authors. Our

Next Word Prediction LSTM, Non-IID Data
0.14
Test Accuracy @ 1

Table 3: Number of rounds and speedup relative to baseline
SGD to reach a target test-set accuracy on CIFAR10. SGD
used a minibatch size of 100. FedSGD and FedAvg used
C = 0.1, with FedAvg using E = 5 and B = 50.

0.12
0.10
0.08
0.06
FedSGD
´=6.0
´=9.0
´=18.0
´=22.0

0.04
0.02
0.00
0

200

FedAvg (E=1)
´=3.0
´=6.0
´=9.0
´=18.0

400
600
Communication Rounds

800

1000

Figure 5: Monotonic learning curves for the large-scale
language model word LSTM.

model is a 256 node LSTM on a vocabulary of 10,000 words.
The input and output embeddings for each word were of
dimension 192, and co-trained with the model; there are
4,950,544 parameters in all. We used an unroll of 10 words.
These experiments required significant computational resources and so we did not explore hyper-parameters as thoroughly: all runs trained on 200 clients per round; FedAvg
used B = 8 and E = 1. We explored a variety of learning rates for FedAvg and the baseline FedSGD. Figure 5
shows monotonic learning curves for the best learning rates.
FedSGD with η = 18.0 required 820 rounds to reach 10.5%
accuracy, while FedAvg with η = 9.0 reached an accuracy
of 10.5% in only 35 communication rounds (23× fewer then
FedSGD). We observed lower variance in test accuracy for
FedAvg, see Figure 10 in Appendix A. This figure also
include results for E = 5, which performed slightly worse
than E = 1.

4

Conclusions and Future Work

Our experiments show that federated learning can be made
practical, as FedAvg trains high-quality models using relatively few rounds of communication, as demonstrated by
results on a variety of model architectures: a multi-layer
perceptron, two different convolutional NNs, a two-layer
character LSTM, and a large-scale word-level LSTM.
While federated learning offers many practical privacy benefits, providing stronger guarantees via differential privacy [14, 13, 1], secure multi-party computation [18], or
their combination is an interesting direction for future work.
Note that both classes of techniques apply most naturally to
synchronous algorithms like FedAvg.7
7
Subsequent to this work, Bonawitz et al. [6] introduced an
efficient secure aggregation protocol for federated learning, and
Konečný et al. [23] presented algorithms for further decreasing
communication costs.

H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, Blaise Agüera y Arcas

References
[1] Martin Abadi, Andy Chu, Ian Goodfellow, Brendan
McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang.
Deep learning with differential privacy. In 23rd ACM
Conference on Computer and Communications Security (ACM CCS), 2016.
Anderson.
Technology
de[2] Monica
vice ownership:
2015.
http://www.
pewinternet.org/2015/10/29/
technology-device-ownership-2015/,
2015.
[3] Yossi Arjevani and Ohad Shamir. Communication
complexity of distributed convex learning and optimization. In Advances in Neural Information Processing Systems 28. 2015.
[4] Maria-Florina Balcan, Avrim Blum, Shai Fine, and
Yishay Mansour. Distributed learning, communication complexity and privacy. arXiv preprint
arXiv:1204.3514, 2012.
[5] Yoshua Bengio, Réjean Ducharme, Pascal Vincent,
and Christian Janvin. A neural probabilistic language
model. J. Mach. Learn. Res., 2003.
[6] Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H. Brendan McMahan, Sarvar Patel,
Daniel Ramage, Aaron Segal, and Karn Seth. Practical
secure aggregation for federated learning on user-held
data. In NIPS Workshop on Private Multi-Party Machine Learning, 2016.
[7] David L. Chaum. Untraceable electronic mail, return
addresses, and digital pseudonyms. Commun. ACM,
24(2), 1981.
[8] Jianmin Chen, Rajat Monga, Samy Bengio, and Rafal
Jozefowicz. Revisiting distributed synchronous sgd.
In ICLR Workshop Track, 2016.
[9] Anna Choromanska, Mikael Henaff, Michaël Mathieu,
Gérard Ben Arous, and Yann LeCun. The loss surfaces
of multilayer networks. In AISTATS, 2015.
[10] Greg
Corrado.
Computer,
respond
to
this
email.
http://
googleresearch.blogspot.com/2015/
11/computer-respond-to-this-email.
html, November 2015.
[11] Yann N. Dauphin, Razvan Pascanu, Çaglar Gülçehre,
KyungHyun Cho, Surya Ganguli, and Yoshua Bengio.
Identifying and attacking the saddle point problem in
high-dimensional non-convex optimization. In NIPS,
2014.
[12] Jeffrey Dean, Greg S. Corrado, Rajat Monga, Kai
Chen, Matthieu Devin, Quoc V. Le, Mark Z. Mao,
Marc’Aurelio Ranzato, Andrew Senior, Paul Tucker,
Ke Yang, and Andrew Y. Ng. Large scale distributed
deep networks. In NIPS, 2012.

[13] John Duchi, Michael I. Jordan, and Martin J. Wainwright. Privacy aware learning. Journal of the Association for Computing Machinery, 2014.
[14] Cynthia Dwork and Aaron Roth. The Algorithmic
Foundations of Differential Privacy. Foundations and
Trends in Theoretical Computer Science. Now Publishers, 2014.
[15] Olivier Fercoq, Zheng Qu, Peter Richtárik, and Martin
Takác. Fast distributed coordinate descent for nonstrongly convex losses. In Machine Learning for
Signal Processing (MLSP), 2014 IEEE International
Workshop on, 2014.
[16] Ian Goodfellow, Yoshua Bengio, and Aaron Courville.
Deep learning. Book in preparation for MIT Press,
2016.
[17] Ian J. Goodfellow, Oriol Vinyals, and Andrew M. Saxe.
Qualitatively characterizing neural network optimization problems. In ICLR, 2015.
[18] Slawomir Goryczka, Li Xiong, and Vaidy Sunderam.
Secure multiparty aggregation with differential privacy: A comparative study. In Proceedings of the
Joint EDBT/ICDT 2013 Workshops, 2013.
[19] Benjamin Graham. Fractional max-pooling. CoRR,
abs/1412.6071, 2014. URL http://arxiv.org/
abs/1412.6071.
[20] Sepp Hochreiter and Jürgen Schmidhuber. Long shortterm memory. Neural Computation, 9(8), November
1997.
[21] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing
internal covariate shift. In ICML, 2015.
[22] Yoon Kim, Yacine Jernite, David Sontag, and Alexander M. Rush. Character-aware neural language models.
CoRR, abs/1508.06615, 2015.
[23] Jakub Konečný, H. Brendan McMahan, Felix X. Yu,
Peter Richtarik, Ananda Theertha Suresh, and Dave
Bacon. Federated learning: Strategies for improving
communication efficiency. In NIPS Workshop on Private Multi-Party Machine Learning, 2016.
[24] Alex Krizhevsky. Learning multiple layers of features
from tiny images. Technical report, 2009.
[25] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional
neural networks. In NIPS. 2012.
[26] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner.
Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 1998.
[27] Chenxin Ma, Virginia Smith, Martin Jaggi, Michael I
Jordan, Peter Richtárik, and Martin Takáč. Adding vs.
averaging in distributed primal-dual optimization. In
ICML, 2015.

Communication-Efficient Learning of Deep Networks from Decentralized Data

[28] Ryan McDonald, Keith Hall, and Gideon Mann. Distributed training strategies for the structured perceptron. In NAACL HLT, 2010.

[43] Yuchen Zhang and Lin Xiao. Communication-efficient
distributed optimization of self-concordant empirical
loss. arXiv preprint arXiv:1501.00263, 2015.

[29] Natalia Neverova, Christian Wolf, Griffin Lacey, Lex
Fridman, Deepak Chandra, Brandon Barbello, and
Graham W. Taylor. Learning human identity from
motion patterns. IEEE Access, 4:1810–1820, 2016.

[44] Yuchen Zhang, Martin J Wainwright, and John C
Duchi. Communication-efficient algorithms for statistical optimization. In NIPS, 2012.

[30] Jacob Poushter. Smartphone ownership and internet
usage continues to climb in emerging economies. Pew
Research Center Report, 2016.
[31] Daniel Povey, Xiaohui Zhang, and Sanjeev Khudanpur.
Parallel training of deep neural networks with natural
gradient and parameter averaging. In ICLR Workshop
Track, 2015.
[32] William Shakespeare. The Complete Works of
William Shakespeare. Publically available at https:
//www.gutenberg.org/ebooks/100.
[33] Ohad Shamir and Nathan Srebro. Distributed stochastic optimization and learning. In Communication, Control, and Computing (Allerton), 2014.
[34] Ohad Shamir, Nathan Srebro, and Tong Zhang. Communication efficient distributed optimization using
an approximate newton-type method. arXiv preprint
arXiv:1312.7853, 2013.
[35] Reza Shokri and Vitaly Shmatikov. Privacy-preserving
deep learning. In Proceedings of the 22Nd ACM
SIGSAC Conference on Computer and Communications Security, CCS ’15, 2015.
[36] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: A
simple way to prevent neural networks from overfitting.
15, 2014.
[37] Latanya Sweeney. Simple demographics often identify
people uniquely. 2000.
[38] TensorFlow team. Tensorflow convolutional neural networks tutorial, 2016. http://www.tensorflow.
org/tutorials/deep_cnn.
[39] White House Report. Consumer data privacy in a networked world: A framework for protecting privacy and
promoting innovation in the global digital economy.
Journal of Privacy and Confidentiality, 2013.
[40] Tianbao Yang. Trading computation for communication: Distributed stochastic dual coordinate ascent. In
Advances in Neural Information Processing Systems,
2013.
[41] Ruiliang Zhang and James Kwok. Asynchronous distributed admm for consensus optimization. In ICML.
JMLR Workshop and Conference Proceedings, 2014.
[42] Sixin Zhang, Anna E Choromanska, and Yann LeCun.
Deep learning with elastic averaging sgd. In NIPS.
2015.

[45] Yuchen Zhang, John Duchi, Michael I Jordan, and Martin J Wainwright. Information-theoretic lower bounds
for distributed statistical estimation with communication constraints. In Advances in Neural Information
Processing Systems, 2013.
[46] Martin Zinkevich, Markus Weimer, Lihong Li, and
Alex J. Smola. Parallelized stochastic gradient descent.
In NIPS. 2010.

Compression Frameworks & Bayesian Deep
Learning

Milad Alizadeh
Linacre College
University of Oxford

DPhil Transfer Report
Michaelmas 2018

Contents
1 Research Proposal

1

1.1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1

1.2

Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1

1.3

Research Questions and Objectives . . . . . . . . . . . . . . . . . . . . . . . . . .

2

1.4

Research Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2

1.4.1

Extreme Quantisation of DNNs . . . . . . . . . . . . . . . . . . . . . . . .

2

1.4.2

Acceleration Frameworks for DNNs . . . . . . . . . . . . . . . . . . . . . .

4

1.4.3

Adaptive Single-Shot Compression . . . . . . . . . . . . . . . . . . . . . .

5

1.4.4

Lost and Gained Capabilities of Compressed DNNs . . . . . . . . . . . . .

5

2 Literature Review

6

2.1

Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6

2.2

Binary Neural Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

7

2.3

Classical Network Pruning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

8

2.4

Bayesian Network Pruning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

10

2.5

Single-Shot Pruning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

12

2.6

The Lottery Ticket Hypothesis . . . . . . . . . . . . . . . . . . . . . . . . . . . .

13

2.7

Model Distillation

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

14

2.8

Efficient Architectures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

15

2.9

Bag-of-Tricks Compression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

16

2.10 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

17

Bibliography

17

A Conference Paper: ICLR 2019

22

B Conference Poster: MobiSys 2018

34

C Collaboration: IJCAI 2018

37

D Collaboration: IPSN 2019

47

i

Chapter 1

Research Proposal
1.1

Introduction

This DPhil thesis will focus on the intersection of theoretical methods from Bayesian statistics
and applied techniques and architectures used in practice and aims to formalise and improve
model compression of Deep Neural Networks (DNNs). The goal is to better understand current
compression techniques used in practice, formalise their consequences, and to design more efficient
algorithms that could help deploy DNNs to mobile resource-constrained devices. The project is
going to look at how Bayesian methods can enable better compression schemes and inversely,
how Bayesian models themselves can be accelerated to run on resource-constrained devices.
This report is organised as follows: The remainder of Chapter 1 outlines the research outline
and plans for completed and future projects. Chapter 2 provides a literature review of the key
methods in model compression of DNNs and highlights some of the limitations and opportunists
in the field.

1.2

Motivation

Deep Neural Networks are the state of the art models in many tasks across various domains such
as computer vision, speech recognition, and natural language processing. However, these models
are often deployed using remote cloud infrastructures. There is great interest in expanding usage
of DNNs from running remotely in the cloud to performing local on-device inference on resourceconstrained devices [Sze et al., 2017, Lane and Warden, 2018]. Examples of such devices are
mobile phones, wearables, IoT devices, and robots. This is motivated by the privacy implications
of sharing data and models with remote machines, and the appetite to apply DNNs in new
environments and scenarios where cloud-inference is not viable. However, requirements of such
devices are very demanding: there are stringent compute, storage, memory and bandwidth
limitations; many applications need to work in real-time; many devices require long battery life
for all-day or always-on use, and there is a thermal ceiling to consider when designing thin and
light devices.
1

On the other hand, the quest for more accurate DNNs has resulted in deeper, more computeintensive models. This is particularly the case for CNNs. For instance, while the convolutional
layers of AlexNet [Krizhevsky et al., 2012] make up only 4% of the model parameters, they are
accountable for 91% of the computations at inference time [Louizos et al., 2017a]. Compression
and efficient implementation of DNNs are therefore more important than ever. There has been a
spate of recent work proposing training and post-training schemes that aim to compress models
without significant loss in their performance. Primary examples of these techniques are: pruning,
weight sharing, low-rank approximation, knowledge distillation and perhaps most importantly
quantisation to lower precisions [Han et al., 2015a, Ullrich et al., 2017, Hinton et al., 2015].
Another critical yet overlooked challenge in using DNNs on-device is the robustness and reliability
of sensory inference results. Obtaining uncertainty estimates in such systems, e.g., autonomous
cars, is crucial. However, effective and efficient usage of Bayesian DNNs remains an open research
question.

1.3

Research Questions and Objectives

The work in this DPhil intends to address some of the challenges covered in the previous section
and answer the following questions:
• “What are the limitations, theoretical foundations, and best approaches of quantising DNNs
to the extreme?”

• “What are the system architectures, hardware architectures, and algorithms that would
allow Bayesian deep models to be deployed on constrained devices?”

• “How can DNNs be trained, particularly using Bayesian techniques, to facilitate obtaining
on-demand compressed versions?”

• “What properties and information are lost or gained when large models are compressed
into smaller versions?”

1.4

Research Outline

1.4.1

Extreme Quantisation of DNNs

It has been shown that even when quantisation is pushed to the extreme, it is still possible to
train DNNs with state-of-the-art results. One example of such methods is training Binary Neural
Networks (BNNs) using Straight-Through-Estimator (STE) for backpropagation. However, the
training process of this technique is not well-founded. This is due to the discrepancy between
the evaluated function in the forward path, and the weight updates in the back-propagation.
In other words, the weights updates computed with STE do not correspond to gradients of the
forward path.
2

While there have been attempts to provide theoretical justifications for STE in the literature,
their scope has been limited. The first part of this project aims to empirically study the performance of various techniques used in BNNs in order to identify the key parts that enable to
them work. The goal in the second part of the project is to formalise and provide theoretical
justifications for optimisation of BNNs based on the findings from the empirical study.

Completed Project
Efficient convergence and accuracy of binary models often rely on careful fine-tuning and various ad-hoc techniques. This project empirically identified and studied the effectiveness of the
techniques commonly used in the literature on the accuracy and convergence performance of
binary models. It showed that training binary models are harder and slower than the equivalent
non-binary model and while the limit of STE’s capability can be achieved easily, finding the best
set of weights requires longer training. It also provided a series of recommendations and best
practices for the efficient training of binary models.
The contributions of the project can be summarised as the following:
• It identifies the essential techniques required for successful optimisation of binary models
and shows that end-to-end training of binary networks crucially relies on the optimiser
taking advantage of second-moment gradient estimates. Other optimisers can easily get
stuck in local minima and can fail to converge.
• It shows that most of the commonly used tricks in training binary models, such as gradient

and weight clipping, are only required during the final stages of the training to achieve
the best performance. Further, it demonstrates that these tricks lead to much slower
convergence in the early stages of optimisation.

• It proposes new procedures for training, making optimisation notably faster by delaying

these tricks, or by training a full-precision model first and fine-tune it into a binary model.

This work is currently under review in the International Conference on Learning Representations
(ICLRL) 2019 and is included in Appendix A. The early results from this projected was presented
as a poster at the ACM International Conference on Mobile Systems (MobiSys) 2018 and is
included in Appendix B.

Future Project
The analysis done in the first part of the project helps in disambiguating what is necessary from
what is unnecessary training of binary neural networks, and paves the way for future development
of solid theoretical foundations for studying optimisation of quantised models. The second part
of this project looks more carefully at the STE and attempts to find proxy loss functions where
STE can be seen as the solution in expectation.
3

1.4.2

Acceleration Frameworks for DNNs

Purpose-built hardware accelerators for DNNs are on the verge of going mainstream, and will
soon be available in various commodity mobile and embedded devices. This variety of hardware
has the potential to perform inference on deep models vastly more efficiently than conventional
processors (such as CPUs). But their wide-spread availability will provoke a number of basic
questions in system design, processor selection and usage as well as deep model tuning for which
we are not yet ready to answer.

Completed Project
This project is a collaboration with Nokia Bell Labs in Cambridge and Stony Brook University in
New York and aims to provide early answers through in-depth study of currently one of the only
commercially-available open neural network accelerators, the Intel Movidius Neural Compute
Stick. This study performs a first-of-its-kind systematic measurement study of the latency and
energy of this accelerator under a variety of deep convolutional networks, and considers its performance in comparison to processor alternatives for constrained devices; specifically, the DSP,
GPU and multi-core CPU available in Qualcomm Snapdragon 820; a platform that is representative of typical mobile and embedded hardware. The project offers a preview of the future in
which resource-constrained devices perform on-device deep learning using a rich heterogeneous
processor mix that includes hardware accelerators.
This work was lead by Nokia Bell Labs and Stony Brookand and it is currently under review
at the International Conference on Information Processing in Sensor Networks (IPSN) 2019 and
included in Appendix D.

Future Project
The next steps of the project will explore new architectures that work better on commodity
accelerator frameworks, but more importantly will propose system architectures for future accelerator with a focus on Bayesian models. Bayesian methods can provide uncertainty estimates
for model predictions. However, performing exact Bayesian inference is in general intractable.
Bayesian methods often need approximations to make the inference tractable. Among various
approximation techniques, variational approximation, or variational inference, tends to be faster
and easier to implement. Besides, the variational inference method offers better scalability with
large models, especially for large-scale neural networks in deep learning applications.
Using Bayesian models on resource-constrained devices will have fundamentally different requirements. This project will look at system design space, computation blocks, memory and cache
architectures, and closed-form approximations that could enable efficient variational inference
on Bayesian networks. The project will look at ways to replace the resource-hungry sampling by
layer-wise distribution approximations amenable to closed-form representations.
4

1.4.3

Adaptive Single-Shot Compression

Future Project
This project will borrow ideas from few-shot learning and meta-learning but rather than applying them to unseen new data points, it aims to train models that can be adopted for various
compression levels. The goal is to train multi-objective networks that can achieve their standard
best results or target a specific compression via a single or few gradient-steps. Moreover, the
project attempts to design methods that can use a single mini-batch from the dataset to prune
or determine quantisation-levels for the models before training begins.

1.4.4

Lost and Gained Capabilities of Compressed DNNs

Future Project
It is well known that compressed model can achieve better generalisation bounds. This project
looks at some of the other properties that are gained or lost when DNNs are compressed. For
instance, it will look at Dropout as a Bayesian approximation in DNNs and attempts to answer
whether these approximations begin to fail when models are compressed.
Another space to explore will be to see the effect of compression on the interpretability of DNNs.
The goal is to find models that are not just high-performing but also make explainable predictions
and are robust against adversaries. This project attempts to see if these properties are easier to
obtain in compressed models.

5

Chapter 2

Literature Review
2.1

Overview

There has been a spate of work in recent years that aim to tackle the problem of compression and
efficiency of Deep Neural Networks (DNNs) from various viewpoints and with different objectives.
This chapter provides a survey and discussion of the most prominent methods proposed in this
area.
The main body of work in deriving more efficient deep neural networks can be roughly organised
into the following main categories:
• Simplified Representations These methods attempt to derive a simpler, smaller repres-

entation of the original model. This goal is typically achieved by identifying and pruning
away unimportant weights, neurons and convolutions filters, representing parameters with
lower-precision and distilling and transferring the learned knowledge of the original model
into the smaller model.

• Efficient Architectures The methods in this group propose DNN architectures that are
designed from the ground up to be more efficient when deployed. These architectures
typically aim to have a smaller number of parameters or operations.
• Bag of Tricks These methods exploit a combination of various ad-hoc techniques to
compress neural networks. For example, they borrow methods from linear algebra, such

as Singular Value Decomposition (SVD), Huffman coding from information theory, weight
sharing, etc.
• Hardware Acceleration This category consists of architectures and available consumer
products that use custom-designed hardware and silicon to train and run DNNs more
efficiently and with a fraction of energy compared to GPUs and cloud deployments.
In addition to categories above compression techniques can be categorised as training-time methods or post-processing methods. In the following sections of this chapter, we review some of the
most important works from these categories followed by a critical discussion of the overall state
of model compression literature.
6

2.2

Binary Neural Networks

Representing weights and activations of a neural network by quantising them to lower-preicisons
is an obvious solution to derive simpler models. Early quantised models were derived by quantisating full-precision weights of pre-trained models as a post-processing step [Gong et al., 2014].
This approach is widely used in real deployments and enjoys advantages such as the flexibility to
apply different levels of quantisation based on the target model size, and not requiring knowledge
of model internals. However, it suffers from a significant loss of accuracy. Hubara et al. [2017]
showed that in order to maintain model performance, quantisation must be incorporated as part
of the training process. This is done by either performing additional training steps to fine-tune a
quantised model or by directly learning quantised parameters. This is essential for BNNs where
binarising weights of pre-trained models result in significant loss in accuracy.
One appealing quantisation scheme is to push quantisation level to the extreme by representing
each weight with a single bit. This approach leads to the emergence of Binary Neural Networks
(BNNs). The first successful binarisation-aware training method was proposed in BinaryConnect
by Courbariaux et al. [2015]. In their work, the binary weights are not learned directly; instead,
full-precision weights are maintained and learned during the training as proxies for the binary
weights. These proxies are only required during training. During the forward path, binary
weights are computed by applying sign function to their corresponding full-precision proxies.
Since the sign function is not differentiable BinaryConnect employs Straight-Through-Estimator
(STE) [Bengio et al., 2013] for back-propagating gradient estimates to full-precision proxies.
The STE estimator simply passes the gradients along as if the non-differentiable operator was
not present. In practice, BinaryConnect applied two additional restrictions on vanilla STE: (1)
Gradient clipping stops gradient flow if the weight’s magnitude is larger than 1. This effectively
means gradients are computed with respect to hard tanh function. (2) Weight clipping is applied
to weights after gradients have been applied to keep them within a range. To formalise this
consider wr to be a full-precision proxy for binary weight wb . During the forward path (and at
the end of the training):

wb = sign(wr )
STE with gradient clipping provides an estimate for gradient of this operation:
∂wb
= 1|r|≤1
∂wr

(2.1)

∂C
In a back-propagation context we assume the gradient of the cost C at the output ( ∂w
) is
b

available where in computing it the same STE estimator above has been used wherever required.
∂C
Eq 2.1 enables us to estimate the gradient of the cost at the input ( ∂w
) and update the proxies:
r

∂C
∂C
=
1
∂wr
∂wb |r|≤1
7

The estimator passes gradients backwards unchanged when proxies are within the {-1,1} range
and cancels the gradient flow when the proxy weight has got too positive or too negative. Figure 2.1 depicts how this works for a convolutional kernel in a CNN.

2

1

0

-1

-2
-2

-1

0

1

2

1

2

2

1

0

-1

-2
-2

-1

0

(b)
(a)

Figure 2.1: A convolutional kernel in a Binary Neural Network is binary (left) but its values are
derived from a full-precision proxy learned using using the STE estimator (right). At the end of
the training the proxy kernel is used for one last time to compute final binary values.
There has been several extensions to BinaryConnect’s core idea of using STE estimator in binary
models. BinaryConnect showed slightly better results when STE was used in stochastic binary
neurons. Courbariaux et al. [2016] and Rastegari et al. [2016] expanded BNNs by using the
sign function as the non-linearity to achieve binary activations in addition to binary parameters.
With this approach full-precision MAC operations in convolution layers can be replaced with
cheap XNOR and POPCOUNT binary operations. This results in 58× [Rastegari et al., 2016]
improvement in compute-time in addition to the inherit 32× saving in model size that comes from
replacing 32-bit floating point parameters with binary ones. XNOR-Net and BWN [Rastegari
et al., 2016] managed to scale up BNNs to achieve competitive results on the much bigger
ImageNet [Deng et al., 2009] dataset by learning additional full-precision scale factors per-layer.
DoReFa-Net [Zhou et al., 2016] used STE in the backpropagation path to quantise gradients and
achieve faster training. TernaryNet [Zhu et al., 2016] quantised parameters to one and a half bits
and represented weights using {-1,0,+1}. Having zero allows efficient hardware implementations
when kernels are sparse. Lin et al. [2017] achieved state-of-the-art performance by learning a
combination of very few binary kernels in each layer.

2.3

Classical Network Pruning

The main motivation for pursuing pruning in DNNs comes from observations that deep models
are often hevaily over-parameterised, and that pruned models can yield better generalisation
bounds [Reed, 1993, Arora et al., 2018]. Therefore, pruning has a long history in the literature
on neural networks. Most of the classical methods in network pruning can be placed into two
categories [Reed, 1993]:
• Saliency Criterion These methods aim to identify and prune a subset of weights from a

pretrained network based on some kind of saliency criterion to measure weights importance.
8

• Loss Penalty

These methods attempt to directly induce sparsity during training by

enforcing extra penalties in the loss function.

The simplest approach from the first category is to use magnitude of the weights to estimate
their saliency. Methods that use this criterion assume that small weights are less important
than large weights [Wan et al., 2009, Hagiwara, 1994]. Magnitude-based pruning techniques are
computationally efficient and scale well to large datasets and models but they are also known
to unnecessarily remove important parts of the network [Sietsma and Dow, 1988]. Optimal
Brain Damage [LeCun et al., 1990] and Optimal Brain Surgeon [Hassibi and Stork, 1993] are
two classic papers from the 1990s that expand magnitude-based pruning by using a second-order
Taylor approximation of the sensitivity of the loss function to determine unimportant weights.
In Optimal Brain Damage, the saliency for each parameter is computed using a diagonal Hessian
approximation. The low-saliency weights are pruned from the network and the resulting network
is then re-trained. To formalise, given a network with weights w, a small change on the weight
vector, denoted by δw, causes a change on the loss function L:

δL = L(w + δw) − L(w)

(2.2)

This change can be approximated by applying the Taylor expansion:

δL ≈ δw

∂L 1 T
+ δw Hδw
∂w 2

(2.3)

∂L
where H is the Hessian matrix. For a sufficiently trained network, the ∂w
≈ 0 and therefore

the change on L is mostly caused by the second order term. The authors further ignore the
non-diagonal elements of H, i.e. hi,i , and estimate the saliency using:
K

δL ≈

1X
hi,i δwi2
2

(2.4)

i=1

Optimal Brain Surgeon improves this approach by allowing for general error measures, and
proposes a more efficient implementation using dominant eigenspace decomposition that requires
less computational and storage. The criteria in both these methods is heavily dependent on the
scale of the weights and is designed to be incorporated within the training process. Therefore
these methods require many iterations of pruning and retraining steps.
The methods from the second category work by adding sparsity-inducing penalty terms to the
loss function. This allows the back-propagation to directly penalise the magnitude of the weights
during training. Traditionally the penalty has taken the form of L2 regularisation which is
equivalent to the weight-decay [Denker et al., 1987]. Later work [Williams, 1995] proposed using
L1 regularisation, which is known to induce sparsity [Tibshirani, 1996, Ng, 2004]. This solution
alleviates the need for sophisticated approximations of the Hessian to estimate a parameter’s
contribution to the loss. Finally, in a recent paper proposed using the simple L0 norm (i.e. the
raw number of parameters) during training to encourage weights to become exactly zero Louizos
9

et al. [2017b]. However, since L0 norm of the weights is not differentiable it cannot be embedded
directly into the loss function as a regularization term. The authors proposed a combination
of variational inference, reparametreisation rick [Kingma and Welling, 2013] and a relaxation of
the Concrete distribution [Maddison et al., 2016] to infer stochastic binary gates that determine
which weights should be set to zero.

2.4

Bayesian Network Pruning

Bayesian methods apply Occam’s razor principle and search for the simplest model that can
explain the data. As a result Bayesian perspective is inherently aligned with the objective
of compressing models. This connection is made explicit in the Minimum Description Length
Principle (MDL) principle [Rissanen, 1986, Grünwald, 2007] which is known to be related to
Bayesian inference. This section covers some of the early works that aimed to keep neural
networks simple and their relation to the Bayesian interpretation of neural networks. It also
covers a more recent line of work on Bayesian and variational deep learning and how it has been
used to compress models.
One of the earliest works on Bayesian Neural Networks was by Hinton and Van Camp [1993]
in the 90s where the problem of overfitting in Neural Networks was framed in terms of MDL
framework [Rissanen, 1986, Grünwald, 2007]. The MDL principle has strong links to model
compression and can be summarised with the following statement: “The best model is the one
that compresses the data best. There are two costs, one for transmitting a model and one for
reporting the data misfit.”. The model cost can be represented by the number of bits it takes to
describe the weights while the data-misfit is represented by the number of bits it takes to describe
the discrepancy between the correct output and the output of the model on each training data
point.
Hinton and Van Camp applied this framework to neural networks and argued that in order to
avoid overfitting, it is important to ensure that there is less information in the weights than there
is in the output vectors of the training dataset. Therefore during learning, weights must be kept
simple by penalizing the amount of information they contain. The amount of information in a
weight can be controlled by adding a source of Gaussian noise. During learning, the amount of
noise can be adapted to optimise the trade-off between the expected squared error of the network
and the amount of information in the weights. The paper proposed an efficient approach for
computing the derivatives of the expected squared error and the amount of information in the
noisy weights in a network. The authors also showed how the idea of minimising the amount of
information required to communicate the weights leads to a number of interesting schemes for
encoding the weights.
The methods used in this paper effectively leads to a Bayesian interpretation of neural networks.
Interestingly, the word ‘Bayesian’ is not mentioned even once in the paper. A more explicit line
of work in Bayesian learning is the application of Variational Inference (VI) methods to dropout
regularisation. Dropout [Hinton et al., 2012] is one of the most popular and empirically effective
10

techniques for reducing overfitting in neural networks. The key idea behind this technique is to
stochastically remove neurons (along with all their connections) from the model during training.
Hinton et al. argue that this approach can prevent units from learning to collaborate too much.
During training, dropout effectively samples from an exponential number of different sparse
networks. At test time, using the un-thinned model approximate averaging over predictions of
all thinned models.
In the original dropout scheme (also known as the binary dropout), the decision to drop or keep a
unit is determined by sampling from a Bernoulli distribution. The parameter p of the distribution
is a fixed hyper-parameter (often 0.5) and shared among all units. However, it was shown in a
later work [Srivastava et al., 2014] that a continuous distribution with the same relative mean and
variance, such as a Gaussian, works as well or even better compared to the binary dropout. This
was expanded by Wang and Manning [2013] who proposed Gaussian Dropout, where instead of
sampling to drop weights, the activations are directly drawn from their (approximate or exact)
marginal distributions.
Using continuous distribution for dropout began to reveal the relationship between dropout
and Bayesian inference. Multiplying the inputs by a Gaussian noise is equivalent to putting
Gaussian noise on the weights and can be used to obtain a posterior over the model’s weights.
This connection was made more clear by Kingma et al. [2015] who presented a re-interpretation
of the Gaussian dropout as a variational inference method, and proposed a generalisation that
they called "Variational dropout". In doing so, they provided a form of Bayesian justification for
dropout by deriving its implicit prior distribution and variational objective. This formulation
also allowed them to propose several useful extensions to dropout, such as a principled way of
making the typically fixed dropout rates p to be learned directly from the training data. By
maximising the variational lower bound (ELBO) with respect to a they managed to learn a
separate dropout rate per layer, per neuron, or even per separate weight.
Interestingly, the variational inference can also be reinterpreted from an MDL point of view by
decomposing ELBO into two terms as per Equation 2.5. When training using VI the emphasise
is not on the KL divergence term, and it is often seen as a regularisation term. However, if
we look at the objective from the viewpoint of compression, the KL term can be viewed as the
primary objective while the data misfit is the part that regularises the compression objective.


log p(D) ≥ Eq(w)
|


p(D, w)
log
q(w)
{z
}

ELBO L(φ)

(2.5)

= Eq(w) [log p(D|w)] − KL (q(w)kp(w))
|
{z
}
|
{z
}
transmitting data misfit

transmitting the model

Learning dropout rates directly during training and its interpretation in terms of MDL objective
can be directly linked to pruning. By carefully choosing the prior distribution and setting hyperparameters correctly one could push these learned dropout rates to go higher. This approach
11

then allows us to prune connections whose learned rates are too high safely. However Kingma
et al. [2015] were not very successful in achieving that goal. The authors found that very large
values of a correspond to local optima from which it is difficult to escape due to large-variance
gradients. In order to avoid such local optima they had to constraint α ≤ 1 during training,

i.e., maximise the posterior variance at the square of the posterior mean, which corresponds to

a dropout rate of 0.5. While Variational Dropout learns individual alphas but gradients are too
noisy, and rates cannot be too large. The initial version of variational dropout could not push
the rates too high because the estimator had high variance.
Molchanov et al. [2017] solved this limitation in their “Sparse Variational Dropout” scheme.
Their work builds on top of variational Gaussian Dropout but employs a reparametrisation to
replace the multiplicative noise with additive to reduce the variance of the estimator. This
reparametrisation greatly reduces the variance of the gradient estimator and therefore allows
dropout rates to become unbounded. Additionally, they provide a new approximation of the
KL-divergence term in Variational Dropout objective which is tight on the full domain. As a
result of these improvements they observed that if they allow variational dropout to proceed
with dropping irrelevant weights automatically, it it leads to extremely sparse solutions both
in fully-connected and convolutional layers. This is the key work that allowed dropout to be
adopted to result in pruned models. This approach reduced the number of model parameters
up to 280 times on LeNet architectures, and up to 68 times on VGG-like models with almost
negligible loss in accuracy.
Finally, another recent work that builds on top of variational dropout methods is “Bayesian
Compression” by Louizos et al. [2017a]. In this work the authors introduce two novelties: firstly
they employ hierarchical priors (Normal-Jeffreys and Horseshoe) which in turn allows them to
drop entire neurons (instead of individual weights) or convolutional kernels altogether. Secondly,
they use the uncertainty estimates in the posterior to determine the optimal fixed-point precision
required to encode the weights. This means if the model is unsure about a parameter, i.e. the
posterior has high variance, then there is little sense is representing this parameter with very
high precision. This work is interesting because it covers both sides of Bayesian inference for the
purpose of model compression: (1) use prior to induce sparsity (2) sse the posterior to decide
quantisation levels.

2.5

Single-Shot Pruning

In a recent work (under review in ICLR 2019), Lee et al. [2018] proposed SNIP, a single-step
pruning scheme using one mini-batch of the dataset. Unlike most pruning schemes, SNIP attempts to directly measure the importance of connections, as opposed to weights. Removing
dependency on the weights enables pruning to happen at the initialisation point, where the values of the weights are not known yet. After pruning the obtained sparse network is trained in
the standard way.
Classical saliency criterion-based methods often attempt to estimate the sensitivity of the loss
12

function with respect to the weighs of the connections. The main idea in SNIP is that if the
weight of the connection could be separated from whether the connection is present or not, then
perhaps the importance of each connection could be directly determined by measuring its effect
on the loss function.
In order to derive this new saliency criterion, the paper introduces auxiliary indicator variables.
These can be seen as a binary mask representing the presence or absence of each connection.
Ideally, we would like to evaluate the influence of each connection by toggling each bit in the
auxiliary vector from 1 to 0 and look at the change in loss while keeping all other connections
intact. However, this approach is not computationally feasible. SNIP proposes estimating this
metric by setting all indicator variables to 1 and then computing the gradient of the auxiliary
mask values using one stochastic mini-batch of data. This gradient should not be confused with
the gradient with respect to the weights, where the change in loss is measured with respect to an
additive change in weight. Instead, using the auxiliary indicator variables, the gradient measures
the change in the loss function due to multiplicative perturbation of weights.
The pruning method in SNIP has several attractive properties:
• It is simple, requires only a single training step, and eliminates the need for both pretraining as well as the complex pruning schedule.

• It does not require computing or estimating the Hessian of the loss function. Instead it
uses the auto-differentiation functionality already available in all deep learning software
frameworks to compute the importance score.
• Typically, applying a particular pruning schemes to another type of architecture requires a
great deal of modifications. The method proposed by Lee et al. [2018] is interesting because
it can be applied to a wider range of architectures. The authors claim to be the first
to demonstrate extreme sparsification on residual, convolutional, and recurrent networks
without modifying the pruning algorithm or requiring additional hyper-parameters.
In terms of performance, this approach achieves very completive results compared to some of the
more more sophisticated approaches covered earlier in this section. It is also interesting to look
at this line of work together in light of the Lottery ticket hypothesis covered earlier in Section 2.6
which suggested what SNIP does is not very difficult.

2.6

The Lottery Ticket Hypothesis

In previous sections, it was shown how various compression techniques are able to reduce the
number of parameter in a neural network significantly with marginal compromise in terms accuracy. If a network can be so compressed, then the function it has learned can be represented
by a much smaller network than the original one. Why, then, do we train large models in the
first place when we can get similar performance from much smaller models? Many experiments
show that large networks are easier to train than small ones [Han et al., 2015b, Bengio et al.,
2006, Hinton et al., 2015, Zhang et al., 2016]. Why is it is difficult to train small models from
13

scratch?
Finding answers to these questions and understanding the differences between small and large
models are crucial for designing more efficient models in the future. A recent work that attempts
to answer these questions is the “Lottery Ticket” hypothesis by Frankle and Carbin [2018]. It
states that any large network that has been successfully trained contains sub-networks that are
initialised in a way that, when trained on their own in isolation, can match the accuracy of the
original network in at most the same number of training steps.
These sub-networks, called “winning tickets” by the authors, have won the initialisation lottery, i.e. they have initial weights that make training particularly effective. When re-initialised
randomly, the discovered winning tickets can no longer match the performance of the original
network. This suggests that the the original initialisation is of great importance.
The paper argues that large networks are easier to train because, when randomly initialised, they
contain more combinations of sub-networks from which training can recover a winning ticket.
The authors present a series of experiments that support their lottery ticket hypothesis and also
demonstrate how pruning techniques uncover the winning tickets predicted by the lottery ticket
hypothesis. They show that they can consistently find winning tickets that are less than 20%
of the size of various fully-connected, convolutional, and residual architectures for MNIST and
CIFAR10 datasets.

2.7

Model Distillation

A different line of work in model compression, pioneered by Hinton et al. [2015], attempts to
derive smaller models by distilling the knowledge of a large and transferring it into a much
smaller model.
The optimisation procedure when training a normal model aims to maximise the average logprobability of the correct class. However, a side-effect of this learning process is that the trained
model also assigns probabilities to all of the incorrect classes through a softmax layer. Even
when these probabilities are very small, some of them are much larger than others. Hinton et al.
[2015] argue a large amount of information the model has learned during training is stored in
the soft outputs of the last softmax layer.
Hinton et al. [2015] offered a general solution to use this information called “knowledge distillation”. The main idea behind this approach is to use those soft outputs as a ground truth dataset
for training a smaller model so that the small model can mimic the large one. The authors
also show that it often helps to combine this soft-target dataset with the real one-hot training
dataset where the loss function is a linear combination of the two. They also showed that the
temperature hyperparameter in the softmax function plays a crucial role in the performance of
distillation technique.
14

2.8

Efficient Architectures

The majority of the research in machine learning community has been focused on pushing the
envelope in terms of model performance and accuracy. Requirements and implications of deploying these models are often second-class objectives. However, there have been architectures
designed from the ground up with efficiency in mind. In this section, we cover two of the main
examples of these models.
SqueezeNet Iandola et al. [2016] proposed a compressed architecture for CNNs called SqueezeNet.
This architecture aimed to achieve AlexNet-level accuracy on ImageNet dataset [Krizhevsky
et al., 2012] with significantly fewer parameters. The core design decisions made in this architecture were: (1) Replacing 3x3 filters with 1x1 filters. (2) Decreasing the number of input channels
to the 3x3 filters. (3) Delaying downsampling the pipeline so that convolution layers have large
activation maps.
These decisions resulted in a model that had 50x fewer parameters but still maintained the accuracy level of AlexNet. Moreover, by borrowing compression techniques from DeepCompression
[Han et al., 2015a], SqueezeNet was able to compress model size to less than 0.5MB (510x smaller
compared to AlexNet). The authors also introduced the notion of “Fire Modules” which consists
of: a squeeze layer comprising of only 1x1 filters, feeding into an expansion layer that has a mix
of 1x1 and 3x3 filters.
MobileNet(s)
Another family of efficient convolutional neural networks is MobileNets. These architectures
are small, fast, accurate and come in two versions: MobileNet v1 [Howard et al., 2017] and v2
[Sandler et al., 2018]. The main idea behind the original MobileNet is to split convolutional
operation, which is known to computationally expensive, into two sub-routines: a depthwise
convolution layer that filters the input, followed by a 1x1 convolution layer (also known as
pointwise convolution) that combines the filtered values of the first sub-operator. Together, the
depthwise and pointwise convolutions form what authors call a “depthwise separable convolution”
layer which performs an approximation of vanilla convolution operation. This approximation
leads to 9x less computation in each convolutional layer while maintaining the same accuracy
levels. Figure 2.2 depicts different convolution layers in MobileNet.
Sandler et al. [2018] slightly modified their architecture in Mobile v2. In the first version of
MobileNet the number of pointwise convolution filters was doubled or at least kept the same.
In the second version, the authors chose the opposite path and made the number of channels
smaller. They called these “projection layers” where high dimensional data is projected into a
tensor with much lower number of dimensions. This results in further reduction of the size and
the number of Multiply-Accumulate (MAC) operations.
15

M

…

D
D

N

(a) Standard Convolution Filters
1

…

D
D
M

(b) Depthwise Convolution Filters

…

M

1
1

N

(c) Pointwise 1x1 Convolution Filters

Figure 2.2: Convolution Operators in MobileNet Architectures

2.9

Bag-of-Tricks Compression

This section highlights two works that propose frameworks for compressing models via a combination of different approaches rather than an individual algorithm.
A good example of the works in this area is the DeepCompression framework proposed by [Han
et al., 2015a]. This architecture consists of a three-stage pipeline: first, a pre-trained model is
pruned by learning the importance of connections. This reduces weights by 10x when making
use of Compressed Sparse Row (CSR) format. Next, the weights are clustered together using
quantisation to enforce weight sharing. After the first two steps network is trained to fine-tune
the quantized (to 8 bits or less) centroids of the clusters and the remaining connections. Finally,
Huffman coding is applied to compress the model even further. In the case of AlexNet, this
framework reduces storage requirements by 35x, from 240MB to 6.9MB without affecting model
accuracy. The authors further designed a hardware accelerator called EIE [Han et al., 2016] that
operates directly on the compressed model, achieving substantial speedups and energy savings.
This framework was successfully used in SqueezeNet resulting in an architecture offering AlexNet
performance with a 500x smaller model size.
CNNpack is another framework proposed by Wang et al. [2016]. In this framework, the processing
happens in the frequency domain where convolutional filters are treated as images, and their
representations in the frequency domain are decomposed into common parts shared among similar
filters, and individual unique parts. A large portion of the low-energy frequency components
in both parts are then discarded to produce highly-compressed models without significantly
16

compromising accuracy.

2.10

Discussion

While not comprehensvive, the previous sections cover some of the key approaches in neural
networks compression. This section finishes the literature review by highlighting some of the
gaps and limitation of current compression methods:
Small Datasets In the compression literature, pruning methods are often tested on small
datasets such as MNIST and CIFAR-10 [LeCun, 1998, Krizhevsky and Hinton, 2009]. However,
most of the state-of-the-art models are evaluated on larger datasets such as ImageNet. This
is particularly problematic in case of MNIST where data points have black backgrounds, and
the pixels are encoded such that black is mapped to zero. This could impact saliency methods
that rely on computing the gradient of the loss function with respect to parameters. An easy
way to perform further analysis when testing on MNIST is to invert MNIST (make the images
black-on-white, not white-on-black) and see if the proposed method still works. Fashion MNIST
[Xiao et al., 2017] is another dataset suffering from the same problem.
Non-Adaptive The majority of compression techniques require additional hyperparameters,
heuristic design choices, long iterative fine-tuning steps or end-to-end training. Less attention
has been paid to augmenting the standard training procedure with compression objective such
that compression can be applied as a quick, simple, single-step with arbitrary compression rates.
Vision-centeric Most of the compression methods have been designed and tested to work with
vision-centric datasets and network architectures. While this makes sense given how deep vision
models become, a robust compression method should be generic enough to work on other types
of neural networks such as recurrent and residual networks.
Non-Bayesian As DNNs slowly find their ways into smaller mobile and IoT devices, ensuring
robustness and reliability of sensory inference will become essential. Uncertainty estimates from
Bayesian models can be crucial for such applications. However, while Bayesian techniques have
been used to train compressed models, Bayesian models themselves have not been subject to
compression much.

17

Bibliography
Sanjeev Arora, Rong Ge, Behnam Neyshabur, and Yi Zhang. Stronger generalization bounds for
deep nets via a compression approach. arXiv preprint arXiv:1802.05296, 2018.
Yoshua Bengio, Nicolas L Roux, Pascal Vincent, Olivier Delalleau, and Patrice Marcotte. Convex
neural networks. In Advances in neural information processing systems, pages 123–130, 2006.
Yoshua Bengio, Nicholas Léonard, and Aaron Courville. Estimating or propagating gradients
through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432, 2013.
Matthieu Courbariaux, Yoshua Bengio, and Jean-Pierre David. Binaryconnect: Training deep
neural networks with binary weights during propagations. In Advances in neural information
processing systems, pages 3123–3131, 2015.
Matthieu Courbariaux, Itay Hubara, Daniel Soudry, Ran El-Yaniv, and Yoshua Bengio. Binarized
neural networks: Training neural networks with weights and activations constrained to+ 1 or-1.
arXiv preprint arXiv:1602.02830, 2016.
Jia Deng, Wei Dong, Richard Socher, Li jia Li, Kai Li, and Li Fei-fei. Imagenet: A large-scale
hierarchical image database. In CVPR, 2009.
John Denker, Daniel Schwartz, Ben Wittner, Sara Solla, Richard Howard, Lawrence Jackel,
and John Hopfield. Large automatic learning, rule extraction, and generalization. Complex
systems, 1(5):877–922, 1987.
Jonathan Frankle and Michael Carbin. The lottery ticket hypothesis: Training pruned neural
networks. arXiv preprint arXiv:1803.03635, 2018.
Yunchao Gong, Liu Liu, Ming Yang, and Lubomir Bourdev. Compressing deep convolutional
networks using vector quantization. arXiv preprint arXiv:1412.6115, 2014.
Peter D Grünwald. The minimum description length principle. MIT press, 2007.
Masafumi Hagiwara. A simple and effective method for removal of hidden units and weights.
Neurocomputing, 6(2):207–218, 1994.
Song Han, Huizi Mao, and William J Dally.

Deep compression:

Compressing deep

neural networks with pruning, trained quantization and huffman coding.

arXiv preprint

arXiv:1510.00149, 2015a.
Song Han, Jeff Pool, John Tran, and William Dally. Learning both weights and connections
18

for efficient neural network. In Advances in neural information processing systems, pages
1135–1143, 2015b.
Song Han, Xingyu Liu, Huizi Mao, Jing Pu, Ardavan Pedram, Mark A Horowitz, and William J
Dally. Eie: efficient inference engine on compressed deep neural network. In Computer Architecture (ISCA), 2016 ACM/IEEE 43rd Annual International Symposium on, pages 243–254.
IEEE, 2016.
Babak Hassibi and David G Stork. Second order derivatives for network pruning: Optimal brain
surgeon. In Advances in neural information processing systems, pages 164–171, 1993.
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network.
arXiv preprint arXiv:1503.02531, 2015.
Geoffrey E Hinton and Drew Van Camp. Keeping the neural networks simple by minimizing the
description length of the weights. In Proceedings of the sixth annual conference on Computational learning theory, pages 5–13. ACM, 1993.
Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and Ruslan R
Salakhutdinov. Improving neural networks by preventing co-adaptation of feature detectors.
arXiv preprint arXiv:1207.0580, 2012.
Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861, 2017.
Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, and Yoshua Bengio. Quantized neural networks: Training neural networks with low precision weights and activations.
The Journal of Machine Learning Research, 18(1):6869–6898, 2017.
Forrest N Iandola, Song Han, Matthew W Moskewicz, Khalid Ashraf, William J Dally, and Kurt
Keutzer. Squeezenet: Alexnet-level accuracy with 50x fewer parameters and< 0.5 mb model
size. arXiv preprint arXiv:1602.07360, 2016.
Diederik P Kingma and Max Welling.

Auto-encoding variational bayes.

arXiv preprint

arXiv:1312.6114, 2013.
Diederik P Kingma, Tim Salimans, and Max Welling. Variational dropout and the local reparameterization trick. In Advances in Neural Information Processing Systems, pages 2575–2583,
2015.
Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images.
Technical report, Citeseer, 2009.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep
convolutional neural networks. In Advances in neural information processing systems, pages
1097–1105, 2012.
N. D. Lane and P. Warden. The deep (learning) transformation of mobile and embedded computing. Computer, 51(5):12–16, May 2018.
19

Yann LeCun. The mnist database of handwritten digits. http://yann. lecun. com/exdb/mnist/,
1998.
Yann LeCun, John S Denker, and Sara A Solla. Optimal brain damage. In Advances in neural
information processing systems, pages 598–605, 1990.
Namhoon Lee, Thalaiyasingam Ajanthan, and Philip HS Torr. Snip: Single-shot network pruning
based on connection sensitivity. arXiv preprint arXiv:1810.02340, 2018.
Xiaofan Lin, Cong Zhao, and Wei Pan. Towards accurate binary convolutional neural network.
In Advances in Neural Information Processing Systems, pages 345–353, 2017.
Christos Louizos, Karen Ullrich, and Max Welling. Bayesian compression for deep learning. In
I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett,
editors, Advances in Neural Information Processing Systems 30, pages 3288–3298. Curran
Associates, Inc., 2017a.
Christos Louizos, Max Welling, and Diederik P Kingma. Learning sparse neural networks through
l_0 regularization. arXiv preprint arXiv:1712.01312, 2017b.
Chris J Maddison, Andriy Mnih, and Yee Whye Teh. The concrete distribution: A continuous
relaxation of discrete random variables. arXiv preprint arXiv:1611.00712, 2016.
Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov. Variational dropout sparsifies deep
neural networks. arXiv preprint arXiv:1701.05369, 2017.
Andrew Y Ng. Feature selection, l 1 vs. l 2 regularization, and rotational invariance. In Proceedings of the twenty-first international conference on Machine learning, page 78. ACM, 2004.
Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, and Ali Farhadi. Xnor-net: Imagenet
classification using binary convolutional neural networks. In European Conference on Computer
Vision, pages 525–542. Springer, 2016.
Russell Reed. Pruning algorithms-a survey. IEEE transactions on Neural Networks, 4(5):740–747,
1993.
Jorma Rissanen. Stochastic complexity and modeling. The annals of statistics, pages 1080–1100,
1986.
Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen.
Mobilenetv2: Inverted residuals and linear bottlenecks. In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition, pages 4510–4520, 2018.
Jocelyn Sietsma and Robert JF Dow. Neural net pruning-why and how. In IEEE international
conference on neural networks, volume 1, pages 325–333. IEEE San Diego, 1988.
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.
Dropout: a simple way to prevent neural networks from overfitting. The Journal of Machine
Learning Research, 15(1):1929–1958, 2014.
20

Vivienne Sze, Yu-Hsin Chen, Tien-Ju Yang, and Joel S Emer. Efficient processing of deep neural
networks: A tutorial and survey. Proceedings of the IEEE, 105(12):2295–2329, 2017.
Robert Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society. Series B (Methodological), pages 267–288, 1996.
Karen Ullrich, Edward Meeds, and Max Welling. Soft weight-sharing for neural network compression. arXiv preprint arXiv:1702.04008, 2017.
Weishui Wan, Shingo Mabu, Kaoru Shimada, Kotaro Hirasawa, and Jinglu Hu. Enhancing the
generalization ability of neural networks through controlling the hidden layers. Applied Soft
Computing, 9(1):404–414, 2009.
Sida Wang and Christopher Manning. Fast dropout training. In international conference on
machine learning, pages 118–126, 2013.
Yunhe Wang, Chang Xu, Shan You, Dacheng Tao, and Chao Xu. Cnnpack: packing convolutional
neural networks in the frequency domain. In Proceedings of the 30th International Conference
on Neural Information Processing Systems, pages 253–261. Curran Associates Inc., 2016.
Peter M Williams. Bayesian regularization and pruning using a laplace prior. Neural computation,
7(1):117–143, 1995.
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017.
Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding
deep learning requires rethinking generalization. arXiv preprint arXiv:1611.03530, 2016.
Shuchang Zhou, Yuxin Wu, Zekun Ni, Xinyu Zhou, He Wen, and Yuheng Zou. Dorefa-net: Training low bitwidth convolutional neural networks with low bitwidth gradients. arXiv preprint
arXiv:1606.06160, 2016.
Chenzhuo Zhu, Song Han, Huizi Mao, and William J. Dally. Trained ternary quantization.
CoRR, abs/1612.01064, 2016.

21

Appendix A

Conference Paper: ICLR 2019
The following is the submission to the International Conference on Learning Representations
(ICLRL) 2019. The paper is titled “A Systematic Study of Binary Neural Networks’ Optimisation” and provides an empirical study of the effectiveness of the various ad-hoc techniques
commonly used in training Binary Neural Networks using.

22

Under review as a conference paper at ICLR 2019

A S YSTEMATIC S TUDY OF
B INARY N EURAL N ETWORKS ’ O PTIMISATION
Anonymous authors
Paper under double-blind review

A BSTRACT
Neural networks with deterministic binary weights using the Straight-ThroughEstimator (STE) have been shown to achieve state-of-the-art results, but their
training process is not well-founded. This is due to the discrepancy between
the evaluated function in the forward path, and the weight updates in the backpropagation, updates which do not correspond to gradients of the forward path.
Efficient convergence and accuracy of binary models often rely on careful finetuning and various ad-hoc techniques. In this work, we empirically identify and
study the effectiveness of the various ad-hoc techniques commonly used in the literature, providing best-practices for efficient training of binary models. We show
that adapting learning rates using second moment methods is crucial for the successful use of the STE, and that other optimisers can easily get stuck in local
minima. We also find that many of the commonly employed tricks are only effective towards the end of the training, with these methods making early stages
of the training considerably slower. Our analysis disambiguates necessary from
unnecessary ad-hoc techniques for the training of binary neural networks, paving
the way for future development of solid theoretical foundations for these. Our
newly-found insights further lead to new procedures which make training of existing binary neural networks notably faster.

1

I NTRODUCTION

There is great interest in expanding usage of Deep Neural Networks (DNNs) from running remotely
in the cloud to performing local on-device inference on resource-constrained devices (Sze et al.,
2017; Lane & Warden, 2018). Examples of such devices are mobile phones, wearables, IoT devices
and robots. This is motivated by privacy implications of sharing data and models with remote machines, and the appetite to apply DNNs in new environments and scenarios where cloud-inference is
not viable. However, requirements of such devices are very demanding: there are stringent compute,
storage, memory and bandwidth limitations; many applications need to work in real-time; many devices require long battery life for all-day or always-on use; and there is a thermal ceiling to consider
when designing thin and light devices. On the other hand, the quest for more accurate DNNs have
resulted in deeper, more compute-intensive models. This is particularly the case for CNNs. For
instance, while the convolutional layers of AlexNet (Krizhevsky et al., 2012) make up only 4% of
the model parameters, they are accountable for 91% of the computations at inference time (Louizos
et al., 2017).
Compression and efficient implementation of DNNs are therefore more important than ever. There
has been a spate of recent work proposing training and post-training schemes that aim to compress
models without significant loss in their performance. Main examples of these techniques are: pruning, weight sharing, low-rank approximation, knowledge distillation and perhaps most importantly
quantisation to lower precisions (Han et al., 2017; Ullrich et al., 2017; Hinton et al., 2015). Quantisation is widely used in commercial deployments and its trade-offs and performance improvements for
CNNs is well-studied in the lirerature (Krishnamoorthi, 2018). One appealing training-time quantisation scheme (Courbariaux et al., 2015) pushed it to the extreme, by representing each weight
with a single bit, while maintaining respectable model accuracy. This paved the way for emergence
Binary Neural Networks (BNNs). Courbariaux et al. (2016) and Rastegari et al. (2016) expanded
BNNs by using the sign function as the non-linearity to achieve binary activations in addition to
binary parameters. With this approach full-precision MAC operations in convolution layers can be
1

Under review as a conference paper at ICLR 2019

replaced with cheap XNOR and POPCOUNT binary operations. This results in 58× (Rastegari
et al., 2016) improvement in compute-time in addition to the inherit 32× saving in model size that
comes from replacing 32-bit floating point parameters with binary ones.
However, as we will describe in Section 2, the common optimisation process used in BNNs is still
not fully understood. Moreover, state-of-the-art binary models employ various modifications to
conventional training settings in order to squeeze the best performance from the models. Some examples of these modifications are: applying constraints to weights and gradients, changing typical
order of operations in a convolutional block, scaling learning rates based on Xavier (Glorot & Bengio, 2010) initialisation values, learning additional parameters for affine transformations of kernels,
changing momentum hyper-parameters in Batch Normalisation (Ioffe & Szegedy, 2015) and the
choice of optimiser, loss function, learning rate and number of training epochs. In the absence of
rigorous mathematical understanding as of yet, it is imperative to empirically study the sensitivity of
the optimisation process and the performance of BNNs to these settings and tweaks. Such empirical
understanding of the tools will greatly aid any development of solid mathematical foundations for
the field. To that end, the main contributions of this work are as follows:
• We identify the essential techniques required for successful optimisation of binary models and show that end-to-end training of binary networks crucially relies on the optimiser
taking advantage of second moment gradient estimates.
• We show that most of the commonly used tricks in training binary models, such as gradient
and weight clipping, are only required during the final stages of the training to achieve the
best performance. Further, we demonstrate that these tricks lead to much slower convergence in the early stages of optimisation.
• We propose new procedures for training, making optimisation notably faster by delaying
these tricks, or by training a full-precision model first and fine-tune it into a binary model.
• We provide our reference implementations and training-evaluation source code online 1 .

2

BACKGROUND

Early quantised models were derived by quantisating full-precision weights of pre-trained models
(Gong et al., 2014). This approach is widely used in real deployments and enjoys advantages such as
flexibility to apply different levels of quantisation based on the target model size, and not requiring
knowledge of model internals. However, it suffers from significant loss of accuracy. Hubara et al.
(2017) showed that in order to maintain model performance, quantisation must be incorporated as
part of the training process. This is done by either performing additional training steps to fine-tune
a quantised model or by directly learning quantised parameters. This is essential for BNNs where
binarising weights of pre-trained models result in significant loss in accuracy.
The first successful binarisation-aware training method was proposed in BinaryConnect by Courbariaux et al. (2015). In their work, the binary weights are not learned directly; instead, full-precision
weights are maintained and learned during the training as proxies for the binary weights. These
proxies are only required during training. During the forward path, binary weights are computed
by applying sign function to their corresponding full-precision proxies. Since the sign function is
not differentiable BinaryConnect employs Straight-Through-Estimator (STE) (Bengio et al., 2013)
for back-propagating gradient estimates to full-precision proxies. The STE estimator simply passes
the gradients along as if the non-differentiable operator was not present. In practice, BinaryConnect
applied two additional restrictions on vanilla STE: (1) Gradient clipping stops gradient flow if the
weight’s magnitude is larger than 1. This effectively means gradients are computed with respect
to hard tanh function. (2) Weight clipping is applied to weights after gradients have been applied
to keep them within a range. To formalise this consider wr to be a full-precision proxy for binary
weight wb . During the forward path (and at the end of the training):
wb = sign(wr )
STE with gradient clipping provides an estimate for gradient of this operation:
1

Anonymous GitHub repository

2

Under review as a conference paper at ICLR 2019

∂wb
= 1|r|≤1
∂wr

(1)

∂C
) is available
In a back-propagation context we assume the gradient of the cost C at the output ( ∂w
b
where in computing it the same STE estimator above has been used wherever required. Eq 1 enables
∂C
us to estimate the gradient of the cost at the input ( ∂w
) and update the proxies:
r

∂C
∂C
=
1|r|≤1
∂wr
∂wb
The estimator passes gradients backwards unchanged when proxies are within the {-1,1} range and
cancels the gradient flow when the proxy weight has got too positive or too negative. Figure 1
depicts how this works for a convolutional kernel in a CNN.

2

1

0

-1

-2
-2

-1

0

1

2

1

2

2

1

0

-1

-2
-2

-1

0

(b)
(a)

Figure 1: A convolutional kernel in a Binary Neural Network is binary (left) but its values are derived
from a full-precision proxy learned using using the STE estimator (right). At the end of the training
the proxy kernel is used for one last time to compute final binary values.
There has been several extensions to BinaryConnect’s core idea of using STE estimator in binary
models. BinaryConnect showed slightly better results when STE was used in stochastic binary neurons. BinaryNet (Courbariaux et al., 2016) used binary activations in addition to binary parameters
(as described in Section 1) and made the convolution operation more efficient by using a custom
GPU kernel. XNOR-Net and BWN (Rastegari et al., 2016) managed to scale up BNNs to achieve
competitive results on the much bigger ImageNet (Deng et al., 2009) dataset by learning additional
full-precision scale factors per-layer. DoReFa-Net (Zhou et al., 2016) used STE in the backpropagation path to quantise gradients and achieve faster training. TernaryNet (Zhu et al., 2016) quantised
parameters to one and a half bits and represented weights using {-1,0,+1}. Having zero allows efficient hardware implementations when kernels are sparse. Lin et al. (2017) achieved state-of-the-art
performance by learning a combination of very few binary kernels in each layer.

3

A S YSTEMATIC S TUDY OF E XISTING M ETHODOLOGIES IN BNN S

There have been several non-empirical attempts to formalise STE and BNNs. Anderson & Berg
(2018) took a high-dimensional geometric point-of-view to justify existence of binary solutions irrespective of the optimisation process. Li et al. (2017) provided accuracy guarantees for training
binary models under convexity assumptions. However, STE still has not been shown to find the solution of any particular loss function. In the meantime, binary models are achieving acceptable levels
of accuracy in practice. Table 1 lists some of the recent binary architectures and their commonlyused training setup.
In this section, we provide an empirical analysis of the main approaches used in these models and
help the researchers and practitioners navigate this space. We explore two classes of architectures
in our study of binary networks: A CNN inspired by VGG-10 (Simonyan & Zisserman, 2015) on
CIFAR-10 (Krizhevsky & Hinton, 2009) dataset and an MLP with three hidden layers with 2048
3

Under review as a conference paper at ICLR 2019

Table 1: Recent binary architectures and their training setup. The Reorder column refers to reordering of blocks in a convolutional layer to make sure pooling layer’s input is full-precision. The 1st
Layer column indicates whether the first layer of the network is binary or kept at full precision.
Network

Optimiser

STE

Clipping

Reorder

1st Layer

Activation

BinaryConnect
BinaryNet
XNOR-Net
BWN
DoReFa-Net
ABC-Net
HBN
Bulat et al. (2017)
Cai et al. (2017)
Xiang et al. (2017)

Adam
AdaMax
Adam
Momentum
Adam
Momentum
Adam
RMSprop
Momentum
AdaMax

Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes

Weights & Gradients
Weights & Gradients
Gradients
Gradients
Gradients
Gradients
Gradients
Gradients
Gradients
Gradients

Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
-

Binary
FP
FP
FP
Binary
FP
FP
FP
FP

32-bits
1-bit
1-bit
32-bits
≥1-bit
≥1-bit
≥1-bit
1-bit
≥2-bits
1-bit

units and rectified linear units (ReLUs) for MNIST (LeCun, 1998) dataset. We make use of gradient
and weight clipping and squared hinge loss unless stated otherwise. We use the last 10% of the
training set for validation and report the best accuracy on the test set associated with the highest
validation accuracy achieved during training. The results shown are the average of five runs. We
have not used early stopping or finite time budget in any of the experiments.
The remainder of this section is organised as follows: We first show that the choice of optimiser
matters considerably. We then show the impact of clipping gradients and weights followed by batch
normalisation hyper-parameters on convergence speed and accuracy of BNNs. We finish by testing
the effectiveness of some of the other commonly used tweaks used in training binary models.
3.1

I MPACT OF O PTIMISER

The majority of recent binary models use an adaptive optimiser in their implementations: BinaryConnect uses ADAM (Kingma & Ba, 2015) for CIFAR-10 and vanilla SGD for MNIST (although
in their released source code they used ADAM for both datasets), DoReFa-Net and XNOR-Net use
ADAM in their experiments and ABC-Net (Lin et al., 2017) uses SGD with momentum. In this
section, we show that this is not accidental and investigate how the optimiser type and its associated
hyper-parameters affects the viability of the STE estimator.
For experiments in this section, we looked at optimisers from four classes in order of increasing
complexity: (1) history-free optimisers such as mini-batch SGD that do not take previous jumps
or gradients into account, (2) momentum optimisers that maintain and use a running average of
previous jumps such as Momentum and Nesterov (Sutskever et al., 2013), (3) Adaptive optimisers
that adjust learning rate for each parameter separately such as AdaGrad (Duchi et al., 2011) and
AdaDelta (Zeiler, 2012), and finally, (4) optimisers that combine elements from categories above
such as ADAM which combines momentum with adaptive learning rate.
Table 2 summarises the best accuracies we achieved using different optimisers. We ran experiments
for more epochs than typically required for the datasets (up to 500 epochs depending on the experiment). In each experiment the relevant hyper-parameters were tuned for best results. We observed
great variance in convergence speed and model performance as a result of optimiser choice that goes
beyond differences seen when training non-binary models. Our first observation is that vanilla SGD
generally fails in optimising binary models using STE. We note that reducing SGD’s stochasticity
(by increasing batch size) improves performance initially. However, it still fails to obtain the best
possible accuracy. SGD momentum and Nesterov optimisers perform better than SGD when they are
carefully fine-tuned. However, they perform significantly slower compared to optimsing non-binary
models and have to be used for many more epochs than normally used for CIFAR-10 and MNIST
datasets. Similar to SGD, increasing momentum rate improves training speed significantly but results in worse final model accuracy. In Appendix A we include results for the equivalent non-binary
models that show the effect of batch size and momentum are far less substantial.
A possible hypothesis is that early stages of training binary models require more averaging for the
optimiser to proceed in presence of binarisaton operation. On the other hand, in the late stages of the
4

Under review as a conference paper at ICLR 2019

training we rely on noisier sources to increase exploration power of the optimiser. This is reinforced
by our observation that binary models are often trained long after the training or validation accuracy
stop showing improvements. Reducing the learning rate in these epochs does not improve things
either. Yet, the best validations are often found in these epochs. In other words, using early stopping
for training binary models would terminate the training early on and would result in suboptimal
accuracies.
Finally, adaptive optimisers, and specifically ADAM, consistently perform faster and able to achieve
better accuracy levels. We experimented with different hyper-parameters in ADAM optimiser (see
Figure 2c) and found the decay rate for the second moment estimate to play a significant role.
Table 2: Achievable test errors using different optimisers for binary MLP model trained on MNIST
and binary CNN model train on CIFAR-10. The hyper-parameters of each optimiser were fine-tuned
for best results.
MNIST
CIFAR-10

SGD

Momentum

Nesterov

AdaGrad

AdaDelta

RMSProp

ADAM

4.48%
17.98%

1.87%
12.41%

1.86%
12.42%

1.28%
10.87%

1.22%
10.34 %

1.21%
10.33%

1.19%
10.30%

Binary CNN

102

101

101

10 1
10 2
10 3

0

Batch-size=50
Batch-size=100
Batch-size=150
Batch-size=200
100
200
300
Epochs

Binary CNN

102
Training Error

Training Error

102
100

Binary MLP

103

100
10 1
10 2

400

10 3 0

500

Batch-size=50
Batch-size=100
Batch-size=150
Batch-size=200
100
200
300
Epochs

(a) SGD for Binary CNN and MLP

100
10 1
10 2
10 3 0

Momentum=0.7
Momentum=0.8
Momentum=0.9
Momentum=0.99
50
100

150
Epochs

200

250

100
10 1
10 2
10 3 0

300

500

Momentum=0.7
Momentum=0.8
Momentum=0.9
Momentum=0.99

101

101

400

Binary MLP

102
Training Error

Training Error

103

50

100

150
Epochs

200

250

300

(b) Momentum SGD for Binary CNN and MLP

Binary CNN (beta1=0.9)
beta2=0.8
beta2=0.9
beta2=0.999

Training Cost

101
100

102
101
Training Cost

102

10 1
10 2
10 3

100

Binary CNN (beta2=0.999)
beta1=0.0
beta1=0.8
beta1=0.9

10 1
10 2

0

50

100
150
Epochs

200

10 3 0

250

50

100
150
Epochs

200

250

(c) ADAM for Binary CNN

Figure 2: Convergence speeds of two binary models trained with different optimisers. We found
ADAM to be consistently faster in training BNNs compared to other optimisers. Figure (c) shows
effect of various momentum rates for ADAM’s first and second moment estimates on convergence
of BNNs.

5

Under review as a conference paper at ICLR 2019

3.2

I MPACT OF G RADIENT AND W EIGHT C LIPPING

The STE variant used in BinaryConnect, XNOR-Net, and most other binary models, is different
from vanilla STE introduced by Bengio et al. (2013). In these models the STE stops gradient flow to
proxies when the full-precision weights have grown beyond ±1. Additionally, BinaryConnect clips
weights after gradient updates have been applied to keep weights within range. Our experiments
(summarised in Table 3) show that this technique does indeed result in slight improvements in the
accuracy of binary models. We observed 0.07% and 0.54% improvement for MNIST and CIFAR10 datasets respectively. Clipping weights does generally help when it is combined with gradient
clipping but is less effective on its own. In our experiments placing these additional constraints had
negligible effects on speed of SGD or Momentum based optimisers. However, ADAM is sensitive
to these constraints. We will revisit clipping in Section 4 where we study them again in terms of
optimising convergence speed.
Table 3: Impact of gradient and/or weight clipping on the final test accuracy of BNNs.

3.3

Clipping

None (Vanilla STE)

Weights

Gradients

Both

MNIST
CIFAR-10

1.28%
10.79%

1.22%
10.73%

1.17%
10.53%

1.18%
10.38%

I MPACT OF BATCH N ORMALISATION

Batch normalisation (BN) uses mini-batch statistics during training but at inference-time the model
is classifying a single data point. Therefore, each BN layer maintains a running average of minibatch statistics to use during inference. The default momentum rate for this running average is
usually large, e.g. 0.99. We noted that some binary models use smaller values for this hyperparameter. Binary models are typically trained for more epochs than their non-binary counterpart
and training is continued even when there is not a meaningful improvement in loss or accuracy. This
is consistent with our earlier hypothesis in 3.1. Reducing the momentum rate in BN can help to
cancel the effect of long training. The effect is small but consistent. Table 4 shows how different
values of BN momentum results in different test accuracies. Krishnamoorthi (2018) also observed
that Batch normalisation should be handled differently when training quantised models in order to
achieve better performance.
Table 4: Impact of momentum rate in Batch Normalisation’s moving average on the final test accuracy of BNNs.

3.4

Momentum

0.8

0.85

0.9

0.99

MNIST
CIFAR-10

1.21%
10.31%

1.19%
10.35%

1.22%
10.53%

1.23%
10.61%

I MPACT OF P OOLING AND L EARNING R ATE

Reordering Pooling Block. As can be seen in Table 1 all binary models change the placement of
pooling operation within a convolutional layer. This change makes sense intuitively. For instance,
applying MaxPooling to a binary vector results in a vector with almost all ones. We have seen two
variants of block reordering and in both cases (see Figure 3) pooling is done immediately after the
convolution operator where the vector is not binary. In our experiments, not making this change
resulted in significant accuracy loss.
Learning Rate Scaling using Xavier. In BinaryConnect Courbariaux et al. (2015) propose scaling
learning rates of each convolutional or fully connected layer by the inverse of Xavier initialisation’s
variance value. The same value is also used as the range in weight clipping after gradient update.
They report noticeable accuracy improvements using these techniques. This modification is interesting because it suggests STE estimator requires an additional dimension. Applying this change
effectively makes the slope of the line between −1 and +1 (see Figure 1b) directly proportional to
square root of (Fan-In + Fan-Out) of each layer. In our experiments, this approach helped when used
6

(b)

(a)

Pooling

Conv

Activation

BatchNorm

Conv

Pooling

Activation

BatchNorm

Pooling

Conv

Pooling

Activation

Conv

BatchNorm

Under review as a conference paper at ICLR 2019

(c)

Figure 3: Changing the order of pooling operation within a convolutional block is necessary when
training binary models.
70

88
86
84

Full Precission
Binary
Binary (from full precision)

82
80 0

100

200
300
Epochs

(a) VGG-10

400

500

Validation Accuracy (%)

95
Validation Accuracy (%)

Validation Accuracy (%)

90

90
85
80

Full Precission
Binary
Binary (from full precision)

75
70 0

100

200
300
Epochs

(b) ResNet-18

400

500

60
50
40
30

Full Precission
Binary
Binary (from full precision)

20
10

0

10

20

30

40
Epochs

50

60

70

80

(c) AlexNet-like on ImageNet

Figure 4: A binary model (red) is initialised from a full precision model (blue) and reaches top
accuracy in a fraction of the epochs that would require to train a binary model (green) end-to-end.
with SGD but we did not see any impact when used with other optimisers. We were able to replicate
accuracy levels reported by BinaryConnect without using this technique.

4

T RAINING BNN S FASTER : E MPIRICAL I NSIGHTS PUT INTO P RACTICE

We continue in this section by applying a number of our empirical observations towards optimising
BNNs in a faster and more efficient manner. We believe this demonstrates some of the practical
implications of our results described earlier that are still to be explored.
In this case-study we consider the well-known observation that training a binary model is often
notably slower than its non-binary counter-part, the reasons for which are not well understood. One
reason typically cited is that binarisation hinders the use of large learning rates – relative to those
adopted in full precision networks. Our experiments show that counter to the conventional wisdom
the STE on its own does not affect the training speed of BNNs considerably. The slowdown is mainly
caused by the commonly applied gradient and weight clipping, as they keep parameters within the
{-1,1} range at all times during training. Figure 5 shows how disabling one or both of these clipping
schemes affects the training curve of a binary CNN. It can be seen that not clipping weights when
learning rates are large can completely halt the optimisation (red curve in Figure 5). On the other
hand, using vanilla STE brings the training speed back on par with the non-binary model. This is
particularly true for ADAM.
However, this faster convergence comes at the price of a loss in accuracy (see Section 3.2). While
weight and gradient clipping help achieve better accuracy, our hypothesis is that they are only required in the later stages of training where the noise added by clipping weights and gradients increases the exploration of the optimiser. We tested this hypothesis by training a binary model in two
stages: (1) using vanilla STE in the first stage with higher learning rates and (2) turning clippings
back on when the accuracy stops improving by reducing learning rate.
With vanilla STE the gradients are simply passed along to the full-precision proxies and the model
is optimised as if the binarisation operations were not present. This, combined with results above,
prompts the question whether it is even necessary to apply binarisation from the very beginning of
the training. While it might be conceptually attractive to train binary models end-to-end, we are
still learning full-precision structures during training. One can define and train an equivalent nonbinary model where the binarisation operations are removed. This is useful because in many cases
this model is already available. This pre-trained model can then be used to initialise the values of
full-precision proxies in the binary model. The model can then be trained using STE and gradient
7

Under review as a conference paper at ICLR 2019

102
Training Error

101
100
10 1
10 2 0

Clipping weights
Clipping gradients
No clipping
Clipping gradients and weights
25
50
75 100 125
Epochs

150

175

200

Figure 5: Impact of gradient and weight clipping on convergence speed of binary VGG-10 with
large learning rates (0.1).
clipping. Our experiments (see Figure 4) show that this works equally well in terms of accuracy but
converges considerably faster for ResNet-18 (He et al., 2016) and VGG-10 architectures than if we
had trained these binary models end-to-end. Mishra & Marr (2018) reported similar results.
There is a significant loss in accuracy when this model is binarised for the first time. This can be
seen in the starting point of the Binary (from full precision) curves in Figure 4. This shows once
again why we cannot simply binarise a pre-trained non-binary model and expect it to work well.
However, we noted that the number of training steps required to recover the accuracy is very small.
This result is encouraging because it turns the problem of learning binary models into a fine-tuning
stage that can be applied to available pre-trained models.
It is important to note that while we can quickly get to the point where training and validation accuracies stagnate, there is a small gap between the achieved accuracy and the best possible one. This
gap can only be filled by continuing training for many epochs. This difference is often consistent
with the gap we observe between (a) the best test accuracy when training for many epochs and (b)
the first epoch where validations accuracy stops improving. This reinforces our earlier hypothesis
in Section 3.1 that suggests the last mile of model performance has little dependence on the STE’s
capability and mostly relies on stochastic exploration of the parameter space.
Table 5: Training binary models using pre-trained full-precision models for CIFAR-10 (ResNet-18
and VGG-10) and ImageNet (AlexNet-like) datasets.

5

Binarisation

Best Validation Accuracy

Test Accuracy

Binary ResNet-18

end-to-end
from full-precision

94.40% (in epoch 457)
93.60% (in epoch 17)

91.16%
91.18%

Binary VGG-10

end-to-end
from full-precision

89.76% (in epoch 391)
90.16% (in epoch 24)

89.18%
89.32%

Binary AlexNet-like

end-to-end
from full-precision

51.98% (in epoch 88)
51.85% (in epoch 30)

—
—

C ONCLUSION AND B EST-P RACTICES

In this work we study the landscape of binary neural networks and evaluate the impact of various
techniques on the accuracy and convergence performance of binary models. We show that training
binary models is harder and slower than the equivalent non-binary model. Our empirical study
suggests that while the limit of STE’s capability can be achieved easily, finding the best set of
weights requires longer training. For efficient training of Binary models we recommend: (1) using
ADAM for optimising the objective, (2) not using early stopping, (3) splitting the training into two
stages, (4) removing gradient and weight clipping in the first stage and (5) reducing the averaging
rate in Batch Normalisation layers in the second stage.
8

Under review as a conference paper at ICLR 2019

R EFERENCES
Alexander G. Anderson and Cory P. Berg. The high-dimensional geometry of binary neural networks. In International Conference on Learning Representations, 2018.
Yoshua Bengio, Nicholas Léonard, and Aaron Courville. Estimating or propagating gradients
through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432, 2013.
Adrian Bulat et al. Binarized convolutional landmark localizers for human pose estimation and face
alignment with limited resources. In International Conference on Computer Vision, 2017.
Zhaowei Cai, Xiaodong He, Jian Sun, and Nuno Vasconcelos. Deep learning with low precision by
half-wave gaussian quantization. In CVPR, 2017.
Matthieu Courbariaux, Yoshua Bengio, and Jean-Pierre David. Binaryconnect: Training deep neural
networks with binary weights during propagations. In Advances in neural information processing
systems, pp. 3123–3131, 2015.
Matthieu Courbariaux, Itay Hubara, Daniel Soudry, Ran El-Yaniv, and Yoshua Bengio. Binarized
neural networks: Training neural networks with weights and activations constrained to+ 1 or-1.
arXiv preprint arXiv:1602.02830, 2016.
Jia Deng, Wei Dong, Richard Socher, Li jia Li, Kai Li, and Li Fei-fei. Imagenet: A large-scale
hierarchical image database. In CVPR, 2009.
John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and
stochastic optimization. Journal of Machine Learning Research, 12(Jul):2121–2159, 2011.
Xavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural
networks. In Proceedings of the thirteenth international conference on artificial intelligence and
statistics, pp. 249–256, 2010.
Yunchao Gong, Liu Liu, Ming Yang, and Lubomir Bourdev. Compressing deep convolutional networks using vector quantization. arXiv preprint arXiv:1412.6115, 2014.
Song Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks
with pruning, trained quantization and huffman coding. In International Conference on Learning
Representations, 2017.
K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In 2016 IEEE
Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770–778, June 2016.
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. arXiv
preprint arXiv:1503.02531, 2015.
Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, and Yoshua Bengio. Quantized
neural networks: Training neural networks with low precision weights and activations. The Journal of Machine Learning Research, 18(1):6869–6898, 2017.
Sergey Ioffe and Christian Szegedy. Batch normalization: accelerating deep network training by
reducing internal covariate shift. In Proceedings of the 32nd International Conference on International Conference on Machine Learning-Volume 37, pp. 448–456. JMLR. org, 2015.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International
Conference on Learning Representations, 2015.
Raghuraman Krishnamoorthi. Quantizing deep convolutional networks for efficient inference: A
whitepaper. arXiv preprint arXiv:1806.08342, 2018.
Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. Technical report, Citeseer, 2009.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pp. 1097–1105,
2012.
9

Under review as a conference paper at ICLR 2019

N. D. Lane and P. Warden. The deep (learning) transformation of mobile and embedded computing.
Computer, 51(5):12–16, May 2018.
Yann LeCun. The ”MNIST” database of handwritten digits. http://yann. lecun. com/exdb/mnist/,
1998.
Hao Li, Soham De, Zheng Xu, Christoph Studer, Hanan Samet, and Tom Goldstein. Training
quantized nets: A deeper understanding. In Advances in Neural Information Processing Systems,
pp. 5811–5821, 2017.
Xiaofan Lin, Cong Zhao, and Wei Pan. Towards accurate binary convolutional neural network. In
Advances in Neural Information Processing Systems, pp. 345–353, 2017.
Christos Louizos, Karen Ullrich, and Max Welling. Bayesian compression for deep learning. In
I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett
(eds.), Advances in Neural Information Processing Systems 30, pp. 3288–3298. Curran Associates, Inc., 2017.
Asit Mishra and Debbie Marr. Apprentice: Using knowledge distillation techniques to improve lowprecision network accuracy. In International Conference on Learning Representations, 2018.
Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, and Ali Farhadi. Xnor-net: Imagenet
classification using binary convolutional neural networks. In European Conference on Computer
Vision, pp. 525–542. Springer, 2016.
K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. In International Conference on Learning Representations, 2015.
Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton. On the importance of initialization and momentum in deep learning. In International conference on machine learning, pp.
1139–1147, 2013.
Vivienne Sze, Yu-Hsin Chen, Tien-Ju Yang, and Joel S Emer. Efficient processing of deep neural
networks: A tutorial and survey. Proceedings of the IEEE, 105(12):2295–2329, 2017.
Karen Ullrich, Edward Meeds, and Max Welling. Soft weight-sharing for neural network compression. In International Conference on Learning Representations, 2017.
Xu Xiang, Yanmin Qian, and Kai Yu. Binary deep neural networks for speech recognition. In Proc.
Interspeech 2017, pp. 533–537, 2017.
Matthew D Zeiler. Adadelta: an adaptive learning rate method. arXiv preprint arXiv:1212.5701,
2012.
Shuchang Zhou, Yuxin Wu, Zekun Ni, Xinyu Zhou, He Wen, and Yuheng Zou. DoReFaNet: Training low bitwidth convolutional neural networks with low bitwidth gradients. CoRR,
abs/1606.06160, 2016.
Chenzhuo Zhu, Song Han, Huizi Mao, and William J. Dally. Trained ternary quantization. CoRR,
abs/1612.01064, 2016.

10

Under review as a conference paper at ICLR 2019

I MPACT OF O PTIMISERS IN N ON -B INARY M ODELS
Full-precision CNN

103
Training Error

102
101
100

Batch-size=50
Batch-size=100
Batch-size=150
Batch-size=200

102

10 1
10 2
10 3

Full-precision MLP

103

Batch-size=50
Batch-size=100
Batch-size=150
Batch-size=200

Training Error

A

101
100
10 1
10 2

0

100

200
300
Epochs

400

10 3 0

500

100

(a) SGD for Non-Binary CNN and MLP

Full-precision CNN

102

Momentum=0.7
Momentum=0.8
Momentum=0.9
Momentum=0.99

101
100
10 1
10 2
10 3 0

50

100

150
Epochs

200

250

500

Momentum=0.7
Momentum=0.8
Momentum=0.9
Momentum=0.99

100
10 1
10 2
10 3 0

300

400

Full-precision MLP

101
Training Error

Training Error

102

200
300
Epochs

50

100

150
Epochs

200

250

300

(b) Momentum SGD for Non-Binary CNN and MLP

102

Full-precision CNN (beta1=0.9)

102
101
Training Cost

Training Cost

101
100
10 1
10 2
10 3 0

Full-precision CNN (beta2=0.999)

beta2=0.8
beta2=0.9
beta2=0.999
50

100
150
Epochs

100
10 1
10 2

200

10 3 0

250

beta1=0.0
beta1=0.8
beta1=0.9
50

100
150
Epochs

200

(c) ADAM for Non-Binary CNN

Convergence speeds of two full-precision models trained with different optimisers.

11

250

Appendix B

Conference Poster: MobiSys 2018
The following are the accepted abstract and poster presented at the ACM International Conference on Mobile Systems (MobiSys) 2018. This work includes some of the early studies that later
led to submission to ICLR 2019 conference A.

34

Poster: Using Pre-trained Full-Precision Models to Speed Up
Training Binary Networks For Mobile Devices
Milad Alizadeh† , Nicholas D. Lane†∗
† University of Oxford, ∗ Nokia Bell Labs

ABSTRACT

While this does not circumvent the need for training stage it has
benefits for mobile scenarios:
• Customizing models for different devices and network environments would be valuable at the edge (e.g. cloud-let levels)
in reaction to devices coming into range but doing so is not
practical without speeding up training.
• Many pre-trained full-precision models are already available for use and can be adopted for mobile applications by
replacing training with a quick fine-tuning process.

Binary Neural Networks (BNNs) are well-suited for deploying Deep
Neural Networks (DNNs) to small embedded devices but state-ofthe-art BNNs need to be trained from scratch for a long time. We
show how weights from a pre-trained full-precision model can be
used to speed-up training of binary networks. We show that for
CIFAR-10, accuracies within 1% of the full-precision model can be
achieved in just 5 epochs.

CCS CONCEPTS

3

• Computing methodologies → Neural networks; • Theory
of computation → Network optimization;

1

INTRODUCTION

In recent years DNNs have achieved great success on many tasks
across various domains such as computer vision, speech recognition and machine translation [1, 5, 6]. However, less attention
has been paid to practical requirements and trade-offs of deploying these models to real-time embedded platforms where there
are stringent requirements in terms of available compute power,
memory footprint and energy consumption.
Binary networks are suitable candidates for such platforms as binaries are cheap to store and operations involving binary operands
are cheap to compute. Initial attempts [4] to derive quantized networks by post-processing a full-precision model suffered from significant loss of accuracy. But it has been recently shown [2, 3, 7]
that much better performance can be achieved by training binary
networks end-to-end instead of post-processing a trained network.
The best results are achieved when binary parameters are learned
indirectly through full-precision proxies. Binary parameters are derived from these proxies during the forward and backwards paths to
respectively compute model predictions and gradients. During the
training, the computed gradients are backpropagated and applied
to the full-precision proxies.

2

EVALUATION

Figure 1 shows the validation accuracies on CIFAR-10 dataset for
three scenarios with architectures identical to [2]. The experiments
are done using TensrFlow. Training a BNN from scratch is slower
than the equivalent full-precision model but using the full-precision
values for initialisation boosts the accuracy and achives good performance in few epochs.
90

Validation Accuracy (%)

80
70
60
50
40
30

Binary model with full-precision initialization
Regular Binary Model
Full-Precision Model
0

5

10

15
20
Epoch (Batch Size=50)

25

30

35

Figure 1: Validation Accuracy on CIFAR-10

REFERENCES

[1] Bahdanau, D., Cho, K., and Bengio, Y. Neural machine translation by jointly
learning to align and translate. arXiv preprint arXiv:1409.0473 (2014).
[2] Courbariaux, M., Bengio, Y., and David, J.-P. Binaryconnect: Training deep
neural networks with binary weights during propagations. In Advances in neural
information processing systems (2015), pp. 3123–3131.
[3] Courbariaux, M., Hubara, I., Soudry, D., El-Yaniv, R., and Bengio, Y. Binarized
neural networks: Training deep neural networks with weights and activations
constrained to+ 1 or-1. arXiv preprint arXiv:1602.02830 (2016).
[4] Han, S., Mao, H., and Dally, W. J. Deep compression: Compressing deep neural
networks with pruning, trained quantization and huffman coding. arXiv preprint
arXiv:1510.00149 (2015).
[5] Hinton, G., et al. Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. IEEE Signal Processing Magazine
29, 6 (2012), 82–97.
[6] Krizhevsky, A., Sutskever, I., and Hinton, G. E. Imagenet classification with
deep convolutional neural networks. In Advances in neural information processing
systems (2012), pp. 1097–1105.
[7] Rastegari, M., Ordonez, V., Redmon, J., and Farhadi, A. Xnor-net: Imagenet
classification using binary convolutional neural networks. In European Conference
on Computer Vision (2016), Springer, pp. 525–542.

PRE-TRAINING FOR BNNS

We show that using full-precision weights from a trained model
as initialisation values of full-precision proxies in the equivalent
binary network can significantly speed up the training process.
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
MobiSys ’18, June 10–15, 2018, Munich, Germany
© 2018 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-5720-3/18/06.
https://doi.org/10.1145/3210240.3210821

528

Using Pre-Trained Full-Precision Models to
Speed Up Training of Binary Neural Networks
Milad Alizadeh, Nicholas Lane, Yarin Gal
Department of Computer Science, University of Oxford
{milad.alizadeh, nicholas.lane, yarin.gal} @ cs.ox.ac.uk

TL;DR

Distilling Knowledge from Full-Precision Model

• Binary Neural Networks (BNNs) are great candidates for
mobile applications but best-performing BNNs need to be
trained end-to-end. This process is noisy and slow.
• The corresponding full-precision network can be used at
initialisation or during training to significantly speed-up and
guide the training of the binary network.
• For CIFAR-10, our approach reaches 87% accuracy in just 5
epochs compared to 80% accuracy in 30 epochs when initialised
with XAVIER.

• When the associated full-precision
model is available one can apply
knowledge distillation techniques
where the full-precision network is
the teacher and the binary
network is the student.

Full-precision kernels

• Full-precision proxies in the student
network can be primed with
values from the teacher network at
the beginning of the training.
• Outputs from the teacher model
can also be used as an additional
dataset with soft-labels.

Background

Primed binary kernels

• Early attempts to derive quantised networks by post-processing a
full-precision model suffered from significant loss of accuracy.
• Much better accuracies were achieved by training quantised/binary
networks end-to-end.
• The best results are achieved when binary parameters are learned
indirectly through full-precision proxies. Binary parameters are
derived from these proxies during the forward and backwards
paths to respectively compute model predictions and gradients.
• During the training, the gradients are backpropagated and
applied to the full-precision proxies.
• Because the sign( ) functions is non-differentiable it is replaced
with a relaxed continuous version for the backwards path. This is
known as Straight-Through-Estimator (STE). This estimator is
biased, noisy and slow.

Results
Two scenarios:
1. MLP model on MNIST (3 hidden layers of 1024 ReLU units)
2. CIFAR-10 using CNN (4 convolutional layers, 2 max-pooling)
For each scenario trained 3 models:
1. Binary model
2. Associated full-precision model
3. Binary model primed by full-precision model from the last step
For CIFAR-10, our approach reaches 87% accuracy in 5 epochs
compared to 80% accuracy in the 30 epochs when initialised with
XAVIER.
CNN - CIFAR-10

Binarised
Parameter

Full-Precision
Parameter

Applications in Mobile
• Real-time embedded system have stringent requirements in terms
of compute power, memory footprint and energy consumption.

MLP - MNIST

• Binaries are cheap to store. When binary parameters are
combined with binary activation as non-linearity, MAC ops in
CNNs are reduced to XOR and POPCNT instructions.
• Quantising models for different devices and network environments
(e.g. cloud-let levels) when devices coming into range is desirable
but not practical without speeding up training.
• Many pre-trained full-precision models are already available for use
and can be adopted for mobile applications by replacing training
with a quick fine-tuning process.
[1] Courbariaux, M., Bengio, Y., and David, J.-P. Binaryconnect: Training deep neural networks with binary weights during propagations. In Advances in neural information processing systems (2015).
[2] Courbariaux, M., Hubara, I., Soudry, D., El-Yaniv, R., and Bengio, Y. Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1(2016).
[3] Rastegari, M., Ordonez, V., Redmon, J., and Farhadi, A. Xnor-net: Imagenet classification using binary convolutional neural networks. In European Conference on Computer Vision (2016).

Appendix C

Collaboration: IJCAI 2018
The following paper was accepted in the International Joint Conferences on Artificial Intelligence (IJCAI) 2018 and is a collaboration with Nokia Bell Labs in Cambridge, UK and Cornell
University, US.

37

Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18)

Deterministic Binary Filters for Convolutional Neural Networks
Vincent W.-S. Tseng‡ , Sourav Bhattachara† , Javier Fernández-Marqués∗ ,
Milad Alizadeh∗ , Catherine Tong∗ and Nicholas D. Lane†∗
‡
Cornell University
†
Nokia Bell Labs
∗
University of Oxford
Abstract
We propose Deterministic Binary Filters, an approach to Convolutional Neural Networks that
learns weighting coefficients of predefined orthogonal binary basis instead of the conventional approach of learning directly the convolutional filters. This approach results in architectures offering significantly fewer parameters (4× to 16×) and
smaller model sizes (up to 32× due to the use of binary rather than floating point precision). We show
our deterministic filter design can be integrated into
well-known network architectures (such as ResNet
and SqueezeNet) with as little as 2% loss of accuracy under datasets like CIFAR-10. Under ImageNet, they are used in an architectures 3× smaller
compared to sub-megabyte binary networks while
reaching comparable accuracy levels.

1

Introduction

Since the success of AlexNet [Krizhevsky et al., 2012], convolutional neural networks (CNN) have become the preferred option for computer vision related tasks. While traditionally the research community has been fixated on goals
such as model generalization and accuracy in detriment of
model size. Recently, multiple approaches attempt to reduce
model’s on-device memory footprint while still maintaining
high levels of accuracy. Such approaches could be subdivided
into two main categories: new network compression techniques and novel layer architectural designs. Multiple network compression techniques [Wang et al., 2016; Han et al.,
2015; Frosst and Hinton, 2017] have been proposed as posttraining stages. In addition, several approaches, [Courbariaux
and Bengio, 2016; Rastegari et al., 2016], proved the suitability of aggressive data quantisation techniques as a way to
reduce the memory and compute requirements during inference by replacing 32-bit parameters with 8-bit and/or binary
values. Examples of novel layer design are [He et al., 2015;
Howard et al., 2017] aiming all of them to offer alternative
approaches to the traditional convolutional layers, being their
advantages more noticeable when operating with very highdimensional feature maps in deeper layers of the network.
In this work, we present Deterministic Binary Filters
(DBF), an approach to Convolutional Neural Networks that

2739

learns weighting coefficients of predefined orthogonal binary
bases instead of the conventional approach of learning directly the convolutional filters. We generate the filters as a
linear combination of orthogonal binary codes that can be
generated very efficiently on real time. We achieve this by using a popular orthogonal binary code generator that has been
extensively studied for over two decades in the wireless community and widely used in mobile cellular systems. Our work
lies in the intersection between the previously mentinoned
categories: compression techniques and novel architectural
designs.
Our approach results in 4× to 16× reduction in the number of convolutional layer parameters to be learned, and more
than 32× savings in model size due to the use of binary
weights instead of floating point parameters. Unlike most
of the network compression techniques, our method allows
learning compressed models directly. We demonstrate our
deterministic filter design can be integrated into well-known
network architectures (such as ResNet [He et al., 2015] and
SqueezeNet [Iandola et al., 2016]) with as little as 2% loss
of accuracy under CIFAR-10. With fewer parameters such
models are less prone to over-fitting and can be potentially
trained with significantly less compute operations and memory needs. DBFs can also offer improved efficiency for inference on microprocessors and embedded devices. Experiments show the suitability of DBFs and their usage in networks with model size up to 3× smaller compared to already optimized binary networks while offering comparable
accuracy levels for datasets like ImageNet, which has 1000
classes.
We believe DBFs are a first step in the development of efficient architectures relying less on large amounts of trainable
parameters and more on deterministic data structures. Models with such characteristics would be more suitable for applications on resource constrained embedded devices requiring
high accuracy rates but minimal compute complexity. In this
work we offer the following contributions:
• A new module that performs convolution filters using a
weighted combination of orthogonal binary bases that
offers significantly reductions on the amount of learnable parameters required for the network.
• We find that such a module is able to offer nearly equal
accuracy levels under common network architectures

Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18)

and datasets, making it a viable model choice, and providing insights into filter design moving forward.
• The ability to trade-off model size for low-complexity
compute, this is a unique characteristic important for
low-memory platforms.
• The number of parameters needed to be updated during
training can be greatly reduced since we only need to
update the weights and not the entire filter, leading to a
faster training and inferences stages.

2

Related Work

Our study of DBFs for CNNs touch upon the following areas
of deep neural network research.
Novel Filter Design. The design of filters within convolutional networks is critical to the effectiveness of such networks in discriminative tasks, and have significant downstream implications for efficiency (e.g., requirements for
memory and compute). Earlier work [Jarrett et al., 2009]
showed random kernels with no learning achieving decent
performance in Caltech-101. Similarly, other works [Saxe
et al., 2011; Pinto et al., 2009] make use of random filters
to show that in addition to the convolutional filters, the network architecture plays a fundamental role in the learning
process. Moreover, [Saxe et al., 2011] argued that some performance of certain state-of-the-art methods can be attributed
to the their architecture alone. All of these demonstrate the
ability for filters despite not being learned from data during
training. More closely to our filter design is the LBCNN (Local Binary CNN) module [Juefei-Xu et al., 2017] that use
pre-defined sparse local binary filters that also do not need to
be updated during training. However, a critical difference in
our design is our ability to generate DBFs on the fly through
efficient algorithms that enable significantly smaller model
sizes as light-weight compute operations replaces in-memory
overhead (critical for embedded and mobile scenarios with
low memory footprints). LBCNN modules also cannot directly replace conventional filters in existing architectures as
requires a two stage approximation of convolution. This may
not be applicable to all architectural designs. In comparison,
our DBFs can be trivially applied to common architectures.
Binary Networks.
Adoption of network architecture designs that include binary filters and weights are also a promising direction. Under this approach parameters are represented
with only one bit, reducing the model size by 32×. Although such methods offer small model size and inference
efficiency they do not necessarily reduce the amount of parameters as offered by our deterministic binary filters. Expectation BackPropagation (EBP) [Soudry et al., 2014] proposes a variational Bayes method for training deterministic
Multilayer Neural Networks, using binary weights and activations. This and a similar approach [Esser et al., 2015]
give great speed and energy efficiency improvements. However, the improvement is still limited as binarised parameters
were only used for inference. Many other proposed binary

2740

networks suffer from the problem of not having enough representational power for complex computer vision tasks, e.g.
BNN [Courbariaux and Bengio, 2016], DeepIoT [Yao et al.,
2017], eBNN [McDanel et al., 2017] are unable to support
the complex ImageNet dataset seen in our results.
Network Architecture Optimization. Many attempts towards optimizing network architectures for more efficient
training, inference and parameter exist. One direction in
quantization involves taking a pre-trained model and normalizing its weights to a certain range. This is done in [Vanhoucke et al., 2011] which uses an 8 bits quantization to store
activations and weights. Other works such as [Han et al.,
2015] and [Wang et al., 2016] are a conglomerate of multiple
clustering, quantisation and word encoding techniques that
have been proven to work well in large architectures such as
AlexNet and ResNet. In addition to compressing weights in
neural networks, researchers have also been exploring more
light-weight architectures: SqueezeNet uses 1 × 1 filters in
combination with 3 × 3 filters, reducing the model to 50×
smaller than AlexNet while maintaining the same accuracy
levels; bottleneck layers, introduced in ResNet, that aims to
reduce the number operations and parameters of convolutional layers by reducing the number of channels of the input
tensor using 1×1 filters; or MobileNets [Howard et al., 2017]
that make use of depthwise convolutional layers and result in
lightweight networks suitable for embedded vision applications. SparseSep [Bhattacharya and Lane, 2016b] adds sparsification to both convolutional and dense layers resulting in
highly compact model representations.
Deep Learning for embedded platforms.
Energy efficiency and low computational complexity are two major requirements that algorithms must fulfil when deploying them
in memory and compute restricted platforms [Lane et al.,
2015] and they become a major concern when considering
the commercialization of such applications. Embedded deep
learning applications, often instantiated as wearables, exist
for a diverse range applications including vision [Mathur et
al., 2017; Suleiman et al., 2017], audio [Fernandez-Marques
et al., 2018; Georgiev et al., 2017] and activity recognition [Tahavori et al., 2017; Bhattacharya and Lane, 2016a].
We refer the interested reader to [Lane et al., 2017] and [Sze
et al., 2017] for a deeper evaluation of the challenges associated with this area of research.

3

Deterministic Binary Filters

In this section, we introduce a novel approach of performing
convolution operations and present an efficient algorithm for
training the parameters. Specifically, we design a convolution layer, where all filter kernels are generated using a linear superposition of a predefined bases set of binary orthogonal vectors. Fewer number of tunable parameters generates a
model with a smaller memory footprint, which is particularly
suitable for deployment on resource-constrained wearable or
IoT devices. The properties of the binary codes used to generate the filters also makes it possible to implement convolu-

C8,8=(1,-1,-1,1,-1,1,1,-1)
L=1

L=2

L=4

L=8

Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18)
Binary basis vectors
2.9

-5.2

0.0

C4,1=(1,1,1,1)

-1.0

C2,1=(1,1)
C4,2=(1,1,-1,-1)
Convolutional
Kernel

4.4

5.8

-2.3

-8.3

C1,1=(1)
C4,3=(1,-1,1,-1)

-1.1

1.1

-1.1

8.1

-10.1

C2,2=(1,-1)

-0.2

12.9

C4,4=(1,-1,-1,1)
L=1

-1.9

L=2

L=4

C8,1=(1,1,1,1,1,1,1,1)
C8,2=(1,1,1,1,-1,-1,-1,-1)
C8,3=(1,1,-1,-1,1,1,-1,-1)
C8,3=(1,1,-1,-1,-1,-1,1,1)
C8,5=(1,-1,1,-1,1,-1,1,-1)
C8,6=(1,-1,1,-1,-1,1,-1,1)
C8,7=(1,-1,-1,1,1,-1,-1,1)
C8,8=(1,-1,-1,1,-1,1,1,-1)
L=8

Figure 2: Code Tree for OVSF Code Generation
Figure 1: Overview of representing a convolution kernel using a
set of binary mutually orthogonal basis vectors. The convolutional
kernel (on the left) can be represent accurately using linear superposition of all the binary vectors (patches) presented on the right. The
coefficient or strength of a binary vector used in the reconstruction
is given on top of the patches.

tions without explicitly having the filters allocated in RAM,
therefore allowing efficient runtime on embedded devices.
In this work we employ orthogonal variable spreading factor (OVSF) codes to generate filters for the convolution layer.
The presented technique can also be applied to the fully connected layer parameters, however, we only focus on convolution layers in this work. In the following three sub-sections
we present the main intuition behind representing convolution
kernels with OVSF codes, present technique to efficiently use
the codes to generate kernels and lastly describe the featuremaps generation process.

3.1

OVSF Codes: Overview

A point x ∈ RN can be represented by the span of a set of N
mutually orthogonal set of vectors or bases {Bi }N
i=1 (Bi ∈
RN ), where ∀i, j, and i 6= j, Bi ⊥ Bj . In other words, any
point in RN can be presented as a linear combination of the
basis vectors as:
N
X
x=
α i · Bi ,
(1)
i=1

th

where, αi is the coefficient or strength for the i basis vector.
Without a loss of generality, we can apply the same linear superposition strategy when generating the hypermatrix
or tensor that would become our convolutional filter. To
gain computational or representational benefits, we can enforce certain properties on the bases set. For instance, in
this work we only consider binary basis vectors, i.e., Bi ∈
{−1, +1}N , ∀i. For illustration, in Figure 1 we present a scenario when a random filter of dimension 4 × 4 is represented
accurately by a set of 16 binary and mutually orthogonal basis vectors. The coefficients for individual binary vectors are
presented on the top of each patches. Note that, for illustration purpose we only consider 2D filters, whereas in practice
the filters used in convolution layers are 3D.

2741

To achieve this filter representation, we require a techniques for efficiently generating the basis vector set. Specifically, given the dimensionality of a filter, the bases generation
technique should output all the orthogonal binary vectors for
the convolution parameter space. This bases generator should
have the following properties: (i) capable of generating all
the bases for any space regardless of its dimensionality, (ii)
employs a deterministic procedure, i.e., for a given dimension, the basis vectors set remains invariant, (iii) being efficient such that it can be used in real-time applications on
embedded devices.
OVSF Codes
For the purpose of generating convolutional kernels, while
meeting the above mentioned conditions, we use the algorithm presented in [Adachi et al., 1998]. The OVSF codes
have been extensively studied in the wireless community [Andreev et al., 2003; Rintakoski et al., 2004; Kim et al., 2009;
Purohit et al., 2013] and widely used in W-CDMA based 3G1
mobile cellular systems to provide multi-user network access.
Their simplicity and efficiency on-silicon implementation
makes them suitable for real-time implementation on powerconstrained devices. OVSF codes are binary {−1, +1}, orthogonal to each other and of length L = 2l , l ∈ N. Figure 2
shows OVSF bases at different l values generated as a recursive process in a binary tree [Adachi et al., 1997].

3.2

Filter Generation Process

Unlike in standard CNNs, our architecture does not learn convolutional filters directly. Instead, it learns the coefficient for
the basis vectors needed to generate the convolutional filters.
Note that the dimension of the OVSF code is the same as the
N filters, which is W ×H ×C, where W and H are the width
and height of the filters2 , and C is the number of channels.
For any given code length L, there are L different OVSF
codes (as observable in Figure 2). Therefore, to generate a
filter of dimensions dim = W × H × C, our generator could
output at most dim different codes that would form a basis of Rdim . Intuitively, by combining all OVSF codes of
1
3GPP TS 25.213, v 3.0.0, Spreading and modulation (FDD),
Oct. 1999
2
In this work we only consider square filters with dimension of
the form 2l .

..

OVSF Bases
Generation

.

-1.3

0.9

0.2
-0.4
-1.3
0.7
3
bi1=, b̃
[b̃2i1,, b̃b̃i23, ,b̃...
bikk ==[1,[1,
−1,
2, 1,2,
... 1,
− 1]
bi = [b̃
b̃b̃NiN]] b
−1,
... -0.8
− 11]
i , ...
-.03
0.3 22.1 3

-1.1

i

i

i

i

.
.. -1 1 -1 -1

i

+

fi =

b = [b , b , b , ...b ] b = [1, 0, 1, 1, ...0] b = [1, 1, 0, 1, ...1]
b = [0, 1, 1, 0, ...1]

Reshape

-0.4
1.7

-1.3

1
2
3
N
N
k
bi =1.2 [b̃1.7-0.5i , -1.3
b̃-0.5i , -1.2
b̃-2.8i , ...
3.2 b̃ ] wi = [w , w , w , ...w
i
i
i
i ] bi = [1, −1, 2, 1, ... − 2]
i
1.2

-1 -1
1 -1
1 -1
1 -1
1 -1-1 11-1-111 -1
-1 1 2
1
1
2
3
N
2 −1,
N1 -1 ik
-1
13−1,
-1 -1
-1...−1]
i
i =iN ][b̃
, ...b
bik1=
[1,
1,
b2 = [1, 0, 0, 1, ...1]
i
i bi i = [bi1 , bii2 , bi3b
-1
,
b̃
,
b̃
,
...
b̃
i
i i = [1, −1, 2, 1, ... − 1]
i
i 1 i 1 -1 i 1 ] b
N
biN = [0, 1, 1, 0, ...1]
..
1 1 -1 1
bi = [bi1 , bi2 , bi3i, ...biN ] bik = [1, −1, −1, 1, ...−1] bi2 = [1, 0, 0, 1, ...1]-1 -1 1 1 .
-1 -1 1 1
N

bi = [0, 1, 1, 0, ...1]

0.2
1.2

-1.3
-1.3
2.1
-0.4
-1.3
-0.5
-2.8
1.5

0.9

-0.5
-0.5
-2.8
-0.4
2.1
-0.4
-1.3
0.9

1.7

..

-0.5

2.1

-0.4

-1.3

.

0.0

αi = [αi1 ,αi2 ,αi3 ...αiN ]

Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18)

would first generate OVSF codes of length 4 × 4 × 1 × 1; then
keep 9 out
of the 16 dimensions; and proceed with the reshape
w = [wi1 , wi2 , wi3 , ...wiN ] bik = [1, −1, 2, 1, ... − 2]
.
..
andi combination
stages as shown in Figure 3. This approach
fi =
results
in
pseudo-OVSF
codes that are no longer orthogonal
.. .
1 12, b 23, b 3 , ...b
N N1] b k1= [1,2−1, 3
2...−1]
N [1, b1,i2k0,
[1,[1,
0, 0,−1,
1, ...1]2, 1, ... − 1]
bi =b[b
bii ii ...b
=i [1,
0, 1, 1, −1,
...0].. 1,
bb̃
...1]
i =i ,[b
i i[b̃
i ii ]=b
b
bi ==1,
i =]
to each other. We call these codes square-pseudo OVSF, spi , b̃i , b̃i , ....
i
N b N = [0, 1, 1, 0, ...1]
bi =i [0, 1, 1, 0, ...1]
OVSF for brevity. In Section 4, we empirically show that the
αi = [αi1 ,αi2 ,αi3 ...αiN ]
Reshape
generated filters perform well even though the codes used are
no longer mutually orthogonal.

OVSF Bases
Generation

..

.

23 3
bi1=, b̃
[b̃2i1,, b̃
, b̃i , ...
bik ==[1,[1,
−1,
2, 1,2,
... 1,
− 1]
bi = [b̃
b̃b̃iNiN]] b
−1,
... − 1]
i
i
i b̃i i , ...
k

+

bi = [b̃i1 , b̃i2 , b̃i3 , ...b̃iN ]

Figure 3: From OVSF codes to DBFs. Each code bki is first reshaped to match the final filter dimensions, becoming b̃ki . Then, the
reshaped codes in b̃i are combined using the weights αi .
OVSF codes

Weights

a given dimension dim we
could perfectly represent any fil{0.5, -0.7}
Convolutional
#$
!"
# "
ter of that dimension.
On the other
hand, using fewer OVSF
1 1
1 1
Filter
,
1 1
-1 -1
"
!
codes
would
result
in
a
coarser
representation
of the target fil-0.2 -0.2
Reshape
+
1.2 1.2
ter. Mathematically, the quality of a filter generated by combination of OVSF codes could be measured as:

basisOVSF = {[1, 1, 1, 1], [1, 1, -1, -1]}

2

bρ·lc
2
Ek = kfk0 − fk k2 =

X
i=0

αki Bki − fk

< ,

(2)

2

Algorithm 1 Training with DBFs
Input: A minibatch of inputs labels and labels(X, Y ), a dictionary of orthogonal binary bases {B1 , B2 , ..., Bk } for each convolution filter and learning rate η.
Output: Updated coefficients {α1t+1 , α2t+1 , ..., αkt+1 } for each of
the binary filters.
for l = 1 to L do
1. Forward Propagation:
{B1 , B2 , . . . , Bk } ← OVSF(n, k)
f t ← α1t B1 + α2t B2 + . . . + αkt Bk
Compute X ∗ f t
. ∗ is the convolution operation.
2. Backward Propagation:
for i=1 to k, do
t
P
∂L
∂L ∂fj
= n
j=1 ∂f t ∂αt
∂αt
i

where ρ ∈ [0, 1] is the ratio of codes to use in order to approximate filter fk , l is the total number of OVSF codes of
length l = W HC, Bki is the ith OVSF code and αji ∈ R its
associated weight.  is the difference between the the approximated DBF, fk0 , and the real filter, fk . Intuitively,  → 0 as
we increase the ratio of binary codes used. When ρ 6= 1, the
product p · l is rounded to the nearest integer value.
Filter Generation Stages
During training, the set of weights {α}N
i=1 that pre-multiply
each of the OVSF codes are learnt via backpropagation [LeCun et al., 1989]. At inference time, the generated filter fk0
can be treated as any other standard floating-valued convolutional filter. The filter generation process using OVSF bases
and the learned weights is didactically illustrated in Figure 3.
This process involves: generation of bρ · lc OVSF codes of
length l = W × H × C; reshape each code in order to match
the shape of the filter; and combine them using the learnt
weights {α}N
i=1 .
The Importance of Ratios
One of the main focus of our evaluation is the study of how
ρ impacts on the performance of our models. This parameter,
that can be independently set for each convolutional layer in
the network, is directly proportional to the number of learnable parameters N in a given layer. As an example, when
ρ = 0.5, the filter would be generated using half of the OVSF
codes and, therefore, our network would only require to learn
half to the weights.
OVSF Limitations
By design, OVSF codes must be of length L = 2l , l ∈ N.
This means that commonly used filter dimensions such as 3 ×
3 or 5 × 5 are not a possibility. We overcome this limitation
by only using a portion of the elements in each OVSF code.
For example, in order to construct a 3 × 3 × 1 × 1 filter, we

2742

j

i

3. Coefficient Update:
for i=1 to k
∂L
αit+1 ← αit − η ∂α
t
i

3.3

Model Training and Optimization

In the following we describe the main steps involved in the
training of the proposed architecture. We use stochastic gradient descent (SDG) to update all the tunable parameters in
the architecture and an overview of the training process is
presented in Algorithm 1. During the forward pass, we first
generate individual filters, and then follow the conventional
CNN inferencing to compute the loss. However, during the
backward pass, we only update the coefficients {α}N
i=1 , but
not the binary basis vectors. The loss propagates to each of
the layers from the output layer, and the gradient of each coefficient with respect to the the total loss is calculated using
chain rule, i.e.:
n
X
∂L
∂L ∂fj
=
∂αi
∂f
j ∂αi
j=1

(3)

where L is the loss, fj is the convolution filter. During the
forward propagation in the next iteration, the filters is generated using the updated coefficients.
Convolution kernel generation using OVSF codes as binary
basis vectors can be easily integrated to existing architectures,
such as fully CNNs, ResNet or any architecture employing
convolutions. Therefore, existing architectures can be trained
faster, as we have smaller number of free parameters to update, and can have better inference time.

Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18)

3.4

4.1

Inference

The convolution operations within a layer, using the set of
OVSF codes, can be summarized as:


bρ·lc
X
O
i
i
Fk = 
α k · Bk  ∗ F I ,
(4)
i=1

where, F I is the input feature-map and FkO is the output
feature-map for filter k, Bki and αki are the binary vector and
corresponding coefficient while representing the k th filter. Interestingly, we can use the linearity of the convolution operation and compute the same output feature-map as follows:
bρ·lc

FkO =

X
i=1


αki · Bki ∗ F I ,

(5)

These two formulations allow two distinct architecture deployment methods that are suitable in two different application scenarios. In the first case, we generate a static version of
the model, employing Equation 4, and in the latter case, for
resource constrained devices, we instantiate a dynamic version of the architecture where the OVSF codes are generated
on the fly and then used during convolution convolutions as
in Equation 5. In the following we describe the two cases.
Explicit Filter Generation. In scenarios with sufficient ondevice memory to store the model in memory, the DBFs could
be generated, and therefore allocated in memory, as part of a
initialization stage during model deployment and set-up. After this, the inference stage would be identical to that of any
other CNN architecture.
On-the-fly convolutions. Due to the nature of the filter generation process by combining OVSF codes using weighting
coefficients learned during training we could bypass the generation and allocation of the filters during model deployment.
These filters would no longer need to be explicitly generated.
Instead, since our model has the weighting coefficient and we
can generate OVSF codes very efficiently, we can subdivide
the operations of a convolutional layer into smaller operations
that are less memory taxing. Effectively, this strategy trades
memory for computations.

4

Evaluation

In this section we validate the usage of DBFs in convolutional
networks for the task of image classification. Here we:
• Compare the performance of two popular CNNs architectures when using filters generated from OVSF codes
against standard fully-learnable filters.
• Make use of DBFs a as model size reduction strategy.

• Validate the usage of sp-OVSF codes that would permit
the usage of filter with arbitrary dimensionality.

2743

Datasets

We conducted our experiments on three popular datasets, ImageNet, CIFAR-10 and MNIST. ImageNet is a large-scale image classification dataset, which contains 1000 categories and
a total of 1.33 million color images. These images vary in dimension and resolution and are generally resized and cropped
to 224×224 images. The dataset is divided into training and
validation data, with 1.28 million images and 50,000 images,
respectively. The CIFAR-10 dataset contains 60,000 32×32
color images in 10 classes, with 6,000 images per class. There
are 50,000 training images and 10,000 test images, with equal
number of images per class in both training set and test set.
The MNIST dataset consists of 28×28 grayscale images of
handwritten digits, with 60,000 training images and 10,000
test images.

4.2

Experimental Setup

Filters generated using OVSF codes can be used in any CNN
for both training and inference. In order to validate the representation capabilities of these filters, we substitute the standard convolutional layers of two popular CNN architectures,
ResNet and SqueezeNet, and train them on CIFAR-10 for 250
epochs. We used batch size of 128, initial learning rate of 0.1
with decay factor of 0.1 at epochs {90, 150, 190, 220}. We
applied standard dat augmentation: random image cropping,
random mirroing and image normalization. We evaluate our
architecture on two configuration of ResNet with 18 and 34
layers. The architectures evaluated in this section were originally designed for ImageNet, here, they have been adapted
to the dimensionality of the CIFAR-10 dataset. This adaptation consist on reducing the filter dimensions and stride of the
input convolutional layer.
Quality of OVSF filters. Given that OVSF codes are limited to be of length 2l , l ∈ N, we have modified the spatial
dimensions (width and height) of all the 3×3 and 7×7 the
convolutional filters in ResNet and SqueezeNet, and replace
them with 4×4 and 8×8 filters, respectively. In Table 1 (right)
we compare the accuracy levels reached for each architecture
when learning filters directly and when using the proposed
OVSF filter generation stage.
sp-OVSF: Overcoming 2l limitation. Despite not being
the focus of this work, we evaluated the suitability of OVSF
codes to generate filters whose dimensions are not a 2l , e.g.
those with spatial dimensions 3 × 3 or 5 × 5. To achieve this,
each time we require an OVSF code of l0 , we first generate the
shortest OVSF code of dimensionality 2l > l0 , and then clip
it. The resulting set of sp-OVSF codes are no longer orthogonal to each other, limiting the performance of the generated
filters. In Table 1 (left) we should that these codes can still be
use to generate convolutional filters.
The impact of ratios. The nature of the filter generation
process using OVSF codes permits, by means of a hyperparameter, choose how many bases use to generate each convolutional filter. This hyperparamter is represented in Eq. 2

+
Conv
Output

+
Output

Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18)

Input

Conv ReLu

Conv ReLu

Filter
Generator

Conv

+

Architecture
ResNet-18
ResNet-18DBF
ResNet-34
ResNet-34DBF
SqueezeNet
SqueezeNetDBF

Output

Weights

OVSF codes
generator

Architecture
ResNet-18
ResNet-18sp-OVSF
ResNet-34
ResNet-34sp-OVSF
SqueezeNet
SqueezeNetsp-OVSF

Acc. (%)
90.68
89.12
92.53
91.30
91.22
90.25

Table 1: Evaluation on CIFAR-10 when filters are (left) either of
dimensionality 2l and (right) when maintaining the original filter
dimensions. DBFs are generated with ρ = 1. In each table, every
pair of architectures (e.g. ResNet-18 and ResNet-18DBF ) uses the
same filter dimensions accross layers and the same model size.

Figure 4: A three layers DBF Module.

as ρ. Lower ρ values results in fewer trainable parameters
and a more efficient inference stage at the cost of generating
coarser filters and a potential drop in accuracy. We evaluated
the effect of using coarser filters on ResNet-18, ResNet-34
and SqueezeNet. These results are shown in Table 2. Reducing ρ effectively reduces the number of weights, α in
Eq.2, needed to generate the filter and therefore resulting in
a smaller model, as shown in Table 3. An architecture with
DBF and ρ = 1 has the same model size as it would have
with standard filters.
A new CNN architecture. We designed a new CNN architecture using DBFs. We will refer to it as DBFNet. Macroarchitecturally, it borrows from SqueezeNet in the sense that after an initial convolution and max-pooling layer, the remaining of the pipeline is comprised of a three cascades of convolutional modules separated by max-pooling layers. We call
these blocks DBF Modules and consist of three stacked OVSF
convolutional layers with a bypass connection. Our network
is comprised of eight DBF Moudles arranged similarly to
SqueezeNet’s FireModules. Figure 4 shows a generic DBF
Module in isolation with explicit filter generation. When part
of a network, a single OVSF code generator is enough to generate the convolutional filters of the entire network. This architecture is evaluated on MNIST, CIFAR-10 and ImageNet
at different ρ values. The results are shown in Table 4. On
ImageNet we used learning rate of 0.1 and decay factor of
0.1 every 30 epochs for a total of 100 epochs using bach size
64. For CIFAR-10 and MNIST datasets we used batch size
of 128, the same initial learning rate and decay factor but decaying it at epochs {40, 70, 90}. No pre-processing or data
augmentation was applied.

4.3

Acc. (%)
91.15
91.02
92.46
92.32
91.16
91.33

Results

We have proven that, despite the simplicity of the filter generation process using binary OVSF codes, CNNs can perform
as well as if filters were learnt directly, like most CNNs do.
As we described in Eq.2, the proposed DBFs are as good as
any other standard convolutional filter. This is shown in Table 1 (left). We have validated this on two popular deep convolutional architectures, ResNet and SqueezeNet.
Using Coarser DBFs
Networks using DBFs in their convolutional layers can adjust
their memory footprint by tuning ρ. This parameter can be set
independently for each convolutional layer and is used to determine the number of OVSF codes a generator should output

2744

in order to generate a given convolutional filter. We demonstrate that even a 4× reduction in the number of parameters
of popular architectures such as ResNet and SqueezeNet can
result in only 2% accuracy loss. In our experiments we found
that reducing ρ for deeper convolutional layer has a lesser impact on accuracy than in the first layers of the network. Concretely, ρ was set to 6.25% for the last two layers in ResNet34DBF in the set up where, on average, ρ = 0.25. On the other
hand, shallower layers kept ρ = 1.
Architecture
ResNet-18DBF
ResNet-34DBF
SqueezeNetDBF

100%
91.02
92.32
91.33

75%
90.46
92.92
91.28

50%
89.34
91.43
91.17

35%
89.11
91.31
89.89

25%
88.02
89.88
89.22

Table 2: Evaluation of different architectures using DBFs generated
with different average ρ values (%) on CIFAR-10.

Architecture
ResNet-18DBF
ResNet-34DBF
SqueezeNetDBF

100%
1.37
3.39
4.41

75%
1.02
2.54
3.31

50%
0.69
1.70
2.21

35%
0.48
1.19
1.54

25%
0.34
0.85
1.10

Table 3: Model size (MB) of architectures using DBFs with different
average ρ values (%). Accuracy values are shown in Table 2.

To our advantage, ρ and the number of learnable parameters are tightly correlated for any architecture using DBFs.
This is evidenced in Table 3. Convolutional filters of deeper
layers tend to be considerably larger than those in shallower
layers, as is the case in ResNet and SqueezeNet. Consequently, these filters represent a seizable portion of the total model size. By means of the parameter ρ their impact in
model size can be lessened and, as previously exemplified for
the case of ResNet-34DBF , it is possible to achieve 16× memory impact reduction of certain layers while maintaining good
accuracy results.
Finally, we show that the benefits of using an architecture
with OVSF-based filters are also applicable when the image
classification task is considerable more challenging, as is the
case with in the ImageNet dataset. Table 4 shows the performance of DBFNet on various image classification dataset at
different ρ values.

Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18)

Dataset
MNIST
CIFAR-10
ImageNet
Size (MB)

100%
99.6
89.7
55.1/78.5
10.32

70%
99.6
88.3
53.3/77.3
7.25

50%
99.6
88.0
50.4/74.8
5.16

25%
99.5
85.5
40.5/65.7
2.58

Table 4: Accuracy (%) of our DBFNet in three popular image
datasets at different ρ values (expressed as %). For ImageNet, accuracy values are shown as Top-1/Top-5.

5

Benefits of Deterministic Binary Filters

In the following section we present the main benefits of using
the binary basis vectors for the construction of convolution
filters and its effect during inference and training time.

5.1

Fewer Parameters

Results from Section 4 show that networks using DBFs offer
significant parameter savings. Table 2 shows that 4× reduction in the number of total learnable parameters is possible.
By means of parameter ρ we can adjust the memory impact
of each layer individually, resulting in 16× memory savings
in the deeper layers of the networks while maintaining their
dimensionality. We believe these results can be improved by
forcing the set of coefficients that pre-multiply each OVSF
bases to be sparse in a layer by layer.
We demonstrated the feasibility of DBFs to reduce the
model size of already small architectures, in the order of 1-4
MB in size. Our technique brings model size to levels achievable by binary networks. In Table 5 we compare ResNet18 using DBFs to two popular binary networks. BinaryConnect’s results use deterministic binarization. Our technique is
capable of providing similar levels of accuracy while reducing the model size to sub-MB levels. Similarly, we compare
in Table 6 BinaryConnect and BWN [Rastegari et al., 2016]
against our DBFNet when evaluated on ImageNet. DBFNet
performs better than BinaryConnect while being 3× smaller.
Architecture
BinaryConnect
BNN
ResNet-18DBF (ρ = 0.35)

Accuracy (%)
90.1
89.85
89.11

Size (MB)
0.73
0.73
0.48

Table 5: Comparison in terms of accuracy and model size of binary
architectures and floating-valued architectures using DBF. Results
are shown for CIFAR-10.

Architecture
BinaryConnect
DBFNet (ρ = 0.125)
BWN
DBFNet (ρ = 0.7)

Top-1 (%)
35.4
36.5
56.8
53.3

Top-5 (%)
61.0
61.9
79.4
77.3

Size (MB)
7.8
2.2
7.8
7.3

convolutional layers. This does not impose a big memory
footprint as bases are binary and they can be densely packed
into bytes and occupy 8× less space.
When these bases are expanded and combined to form the
full-precision kernel we do not need to store any of the intermediate values and the run-time memory required is the
same as any normal convolutional layer. However, since convolution operation is distributive and associative with scalar
multiplication one can change the order of operations and do
convolution of input with binary bases first and then scale
and combine the results. While this approach normally does
not make sense given the significant cost of convolution operation, it can be efficient in architectures with binary inputs
where the convolution operation is reduced to XORing and
bit counting [Rastegari et al., 2016].

5.3

Training Efficiency

The main benefits of using Deterministic Binary Filters come
from their ability to reduce memory and computation footprints without a significant drop in the recognition accuracy.
From the previous section we see that across different datasets
the proposed architecture can achieve high accuracy while
only considering a fraction of the OVSF codes. This allows
for a significant reduction int the number of tunable convolution parameters, in our case only the coefficients, and generates a very compact model size, which is ideal for embedded
deployment. As we need a smaller number of parameters to
tune, the model becomes less prone to overfitting than the corresponding static version of the architecture. An architecture
with DBFs runs faster backward pass, thereby reducing the
overall training procedure significantly.

6

Conclusion

We have presented Deterministic Binary Filters, an new approach to constructing modules within CNNs that only requires learning of weighting coefficients with respect to a
predefined orthogonal binary basis. Significant savings result in comparison to conventional convolutional filters that
are learned entirely from data. With fewer parameters such
models are less prone to over-fitting and can be potentially
trained with significantly less compute operations and memory needs. DBFs provides important new insights in the
design of low-complexity models that maintain high accuracy level for discriminative image tasks with implications
for training and inference efficiency.

Acknowledgements
This work was supported in part by the UK’s Engineering and
Physical Sciences Research Council (EPSRC) with grants
EP/M50659X/1, EP/N509711/1 and EP/R512333/1.

Table 6: Comparison in terms of accuracy and model size of binary
architectures and DBFNet. Results are shown for ImageNet.

References

5.2

[Adachi et al., 1997] F. Adachi, M. Sawahashi, and
K. Okawa. Tree-structured generation of orthogonal
spreading codes with different lengths for forward link of
ds-cdma mobile radio. Electronics Letters, 33(1):27–28,
Jan 1997.

Inference Efficiency

During inference, the overhead of using binary bases is
marginal. Bases can be generated once and used across all

2745

Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18)

[Adachi et al., 1998] Fumiyuki Adachi, Mamoru Sawahashi,
and Hirohito Suda. Wideband ds-cdma for next-generation
mobile communications systems. IEEE communications
Magazine, 36(9):56–69, 1998.
[Andreev et al., 2003] Boris D. Andreev, Edward L. Titlebaum, and Eby G. Friedman. Orthogonal code generator
for 3g wireless transceivers. In Proceedings of the 13th
ACM Great Lakes Symposium on VLSI, GLSVLSI ’03,
pages 229–232, New York, NY, USA, 2003. ACM.
[Bhattacharya and Lane, 2016a] S. Bhattacharya and N. D.
Lane. From smart to deep: Robust activity recognition on
smartwatches using deep learning. In 2016 IEEE International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops), pages 1–6, March
2016.
[Bhattacharya and Lane, 2016b] Sourav Bhattacharya and
Nicholas D. Lane. Sparsification and separation of deep
learning layers for constrained resource inference on wearables. In Proceedings of the 14th ACM Conference on Embedded Network Sensor Systems CD-ROM, SenSys ’16,
pages 176–189, New York, NY, USA, 2016. ACM.
[Courbariaux and Bengio, 2016] Matthieu Courbariaux and
Yoshua Bengio. Binarynet: Training deep neural networks with weights and activations constrained to +1 or
-1. CoRR, abs/1602.02830, 2016.
[Esser et al., 2015] Steve K Esser, Rathinakumar Appuswamy, Paul Merolla, John V. Arthur, and Dharmendra S Modha.
Backpropagation for energy-efficient
neuromorphic computing. In Advances in Neural Information Processing Systems 28, pages 1117–1125. Curran
Associates, Inc., 2015.
[Fernandez-Marques et al., 2018] Javier
FernandezMarques, Vincent T.-S. Tseng, Sourav Bhattacharya,
and Nicholas D. Lane. On-the-fly deterministic binary
filters for memory efficient keyword spotting applications
on embedded devices. In Proceedings of the 2nd International Workshop on Deep Learning for Mobile Systems
and Applications, EMDL ’18. ACM, 2018.
[Frosst and Hinton, 2017] Nicholas Frosst and Geoffrey E.
Hinton. Distilling a neural network into a soft decision
tree. CoRR, abs/1711.09784, 2017.
[Georgiev et al., 2017] Petko Georgiev, Nicholas D. Lane,
Cecilia Mascolo, and David Chu. Accelerating mobile audio sensing algorithms through on-chip gpu offloading. In
Proceedings of the 15th Annual International Conference
on Mobile Systems, Applications, and Services, MobiSys
’17, pages 306–318, New York, NY, USA, 2017. ACM.
[Han et al., 2015] Song Han, Huizi Mao, and William J.
Dally. Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding. CoRR, abs/1510.00149, 2015.
[He et al., 2015] Kaiming He, Xiangyu Zhang, Shaoqing
Ren, and Jian Sun. Deep residual learning for image recognition. CoRR, abs/1512.03385, 2015.

2746

[Howard et al., 2017] Andrew G. Howard, Menglong Zhu,
Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias
Weyand, Marco Andreetto, and Hartwig Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications. CoRR, abs/1704.04861, 2017.
[Iandola et al., 2016] Forrest N. Iandola, Matthew W.
Moskewicz, Khalid Ashraf, Song Han, William J. Dally,
and Kurt Keutzer. Squeezenet: Alexnet-level accuracy
with 50x fewer parameters and <1mb model size. CoRR,
abs/1602.07360, 2016.
[Jarrett et al., 2009] Kevin Jarrett, Koray Kavukcuoglu,
Marc’Aurelio Ranzato, and Yann LeCun. What is the best
multi-stage architecture for object recognition? In IEEE
12th International Conference on Computer Vision, ICCV
2009, 2009.
[Juefei-Xu et al., 2017] Felix Juefei-Xu, Vishnu Naresh
Boddeti, and Marios Savvides. Local binary convolutional
neural networks. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on, volume 1, 2017.
[Kim et al., 2009] S. Kim, M. Kim, C. Shin, J. Lee, and
Y. Kim. Efficient implementation of ovsf code generator for umts systems. In 2009 IEEE Pacific Rim Conference on Communications, Computers and Signal Processing, pages 483–486, Aug 2009.
[Krizhevsky et al., 2012] Alex Krizhevsky, Ilya Sutskever,
and Geoffrey E Hinton. Imagenet classification with deep
convolutional neural networks. In Advances in Neural Information Processing Systems 25, pages 1097–1105. Curran Associates, Inc., 2012.
[Lane et al., 2015] Nicholas D. Lane, Sourav Bhattacharya,
Petko Georgiev, Claudio Forlivesi, and Fahim Kawsar. An
early resource characterization of deep learning on wearables, smartphones and internet-of-things devices. In Proceedings of the 2015 International Workshop on Internet
of Things Towards Applications, IoT-App ’15, pages 7–12,
New York, NY, USA, 2015. ACM.
[Lane et al., 2017] N. D. Lane, S. Bhattacharya, A. Mathur,
P. Georgiev, C. Forlivesi, and F. Kawsar. Squeezing deep
learning into mobile and embedded devices. IEEE Pervasive Computing, 16(3):82–88, 2017.
[LeCun et al., 1989] Y. LeCun, B. Boser, J. S. Denker,
D. Henderson, R. E. Howard, W. Hubbard, and L. D.
Jackel. Backpropagation applied to handwritten zip code
recognition. Neural Comput., 1(4):541–551, December
1989.
[Mathur et al., 2017] Akhil Mathur, Nicholas D. Lane,
Sourav Bhattacharya, Aidan Boran, Claudio Forlivesi, and
Fahim Kawsar. Deepeye: Resource efficient local execution of multiple deep vision models using wearable commodity hardware. In Proceedings of the 15th Annual International Conference on Mobile Systems, Applications,
and Services, MobiSys ’17, pages 68–81, New York, NY,
USA, 2017. ACM.
[McDanel et al., 2017] Bradley McDanel, Surat Teerapittayanon, and H. T. Kung. Embedded binarized neural net-

Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18)

works. In Proceedings of the 2017 International Conference on Embedded Wireless Systems and Networks, EWSN
2017, Uppsala, Sweden, February 20-22, 2017, pages
168–173, 2017.
[Pinto et al., 2009] Nicolas Pinto, David Doukhan, James J.
DiCarlo, and David D. Cox. A high-throughput screening approach to discovering good forms of biologically
inspired visual representation. PLOS Computational Biology, 5:1–12, 11 2009.
[Purohit et al., 2013] G. Purohit, V. K. Chaubey, K. S. Raju,
and P. V. Reddy. Fpga based implementation and testing of
ovsf code. In 2013 International Conference on Advanced
Electronic Systems (ICAES), pages 88–92, Sept 2013.
[Rastegari et al., 2016] Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, and Ali Farhadi. Xnor-net: Imagenet classification using binary convolutional neural networks. CoRR, abs/1603.05279, 2016.
[Rintakoski et al., 2004] T. Rintakoski, M. Kuulusa, and
J. Nurmi. Hardware unit for ovsf/walsh/hadamard code
generation [3g mobile communication applications]. In
2004 International Symposium on System-on-Chip, 2004.
Proceedings., pages 143–145, Nov 2004.
[Saxe et al., 2011] Andrew Saxe, Pang W. Koh, Zhenghao
Chen, Maneesh Bhand, Bipin Suresh, and Andrew Y. Ng.
On random weights and unsupervised feature learning. In
Proceedings of the 28th International Conference on Machine Learning (ICML-11). ACM, 2011.
[Soudry et al., 2014] Daniel Soudry, Itay Hubara, and Ron
Meir. Expectation backpropagation: Parameter-free training of multilayer neural networks with continuous or discrete weights. In Advances in Neural Information Processing Systems 27, pages 963–971. Curran Associates, Inc.,
2014.
[Suleiman et al., 2017] A. Suleiman, Y. H. Chen, J. Emer,
and V. Sze. Towards closing the energy gap between hog
and cnn features for embedded vision. In 2017 IEEE International Symposium on Circuits and Systems (ISCAS),
pages 1–4, May 2017.
[Sze et al., 2017] Vivienne Sze, Yu-Hsin Chen, Tien-Ju
Yang, and Joel S. Emer. Efficient processing of deep neural
networks: A tutorial and survey. CoRR, abs/1703.09039,
2017.
[Tahavori et al., 2017] Fatemeh Tahavori, Emma Stack,
Veena Agarwal, Malcolm Burnett, Ann Ashburn,
Seyed Amir Hoseinitabatabaei, and William Harwin.
Physical activity recognition of elderly people and people
with parkinson’s (pwp) during standard mobility tests
using wearable sensors. In Smart Cities Conference
(ISC2), 2017 International, pages 1–4. IEEE, 2017.
[Vanhoucke et al., 2011] Vincent Vanhoucke, Andrew Senior, and Mark Z. Mao. Improving the speed of neural
networks on cpus. In Deep Learning and Unsupervised
Feature Learning Workshop, NIPS 2011, 2011.
[Wang et al., 2016] Yunhe Wang, Chang Xu, Shan You,
Dacheng Tao, and Chao Xu. Cnnpack: Packing convolutional neural networks in the frequency domain. In D. D.

2747

Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett, editors, Advances in Neural Information Processing
Systems 29, pages 253–261. Curran Associates, Inc., 2016.
[Yao et al., 2017] Shuochao Yao, Yiran Zhao, Aston Zhang,
Lu Su, and Tarek F. Abdelzaher. Compressing deep neural
network structures for sensing systems with a compressorcritic framework. CoRR, abs/1706.01215, 2017.

Appendix D

Collaboration: IPSN 2019
The following paper is collaborations with Nokia Bell Labs in Cambridge, UK and Stony Brook
University in New York, US and is currently under review at the International Conference on
Information Processing in Sensor Networks (IPSN) 2019.

47

An Empirical Study of Convolutional Neural Network Design
for a Commodity Deep Learning Hardware Accelerator
Anonymous Author(s)
ABSTRACT
Purpose-built hardware accelerators for deep neural networks are
on the verge of going mainstream, and will soon be available in
various commodity mobile and embedded devices. This variety of
hardware has the potential to perform inference on deep models
vastly more efficiently than conventional processors (like CPUs).
But their wide-spread availability will provoke a number of basic
questions in system design, processor selection and usage as well
as deep model tuning for which we are not yet ready to answer.
In this work, we begin to provide early answers through in-depth
study of currently one of the only commercially-available open neural network accelerators, the Intel Movidius Neural Compute Stick.
We perform a first-of-its-kind systematic measurement study of
the latency and energy of this accelerator under a variety of deep
convolutional networks, and consider its performance in comparison to processor alternatives for constrained devices; specifically,
the DSP, GPU and multi-core CPU available in Qualcomm Snapdragon 820 – a platform that is representative of typical mobile
and embedded hardware. In this way, our study offers a preview
of the future in which resource constrained devices perform ondevice deep learning using a rich heterogeneous processor mix that
includes hardware accelerators.

1

INTRODUCTION

The past four years has seen sizable strides made in the inferencetime efficiency of deep learning, and at a cost of few percentage points in accuracy the execution of the best learning algorithms for various tasks (e.g., speech, vision, language) are increasingly becoming feasible for phone, wearable and embedded platforms [21, 23, 29, 33, 38, 48]. This capability provides a range of
benefits for network edge devices, not only are they able to use the
state-of-the-art models for processing data such as images, audio,
and text (instead of weaker, but less complex models) – they are also
able to do so when network connectivity is poor (and the cloud is
unavailable) and provide a processing option to users where sensitive data (spoken words, image of faces) leaves their personal device.
Such benefits have pushed industry towards adoption of on-device
deep learning, for instance in Android devices and the iPhone it
is used to detect if a user is in a car, walking or running [1] or
when they say special hot-key words (e.g., “Hey Siri”) [2]. Though
it should be noted, due to limited resources many types of deep
models and thus possible applications remain out of reach.
Research advances within efficient inference for deep learning
has tended to into two major directions, one software-centric and
the other related to processor hardware. Examples of softwarebased innovation include improvements within the learning algorithms themselves, such as more efficient model architectures, or in
software system solutions that improve performance through a better understanding of the workload [15, 17, 47, 48]. Efficiency gains
in the order of 10× or more using such methods are routine, though

usually gains are accompanied with a certain loss in accuracy. On
the hardware side, processor designs that are purpose-built for the
execution of neural architectures have proliferated [10, 14, 20, 39].
It is common for such accelerators to offer substantial performance
gains over mainstream more general-purpose processors like GPUs,
CPUs and DSPs (again performance gains of 10× and more are the
norm). Though this is often achieved by making strong assumptions
as to the neural architecture composition to be executed; this in
turn makes offering such performance broadly across a variety of
architectures (especially very large and deep models) problematic.
Driven by these intersecting trends, looking forward perhaps the
most important question for on-device deep learning will be to understand the role to be filled by purpose-built hardware accelerators.
Will accelerators make all neural network models "cheap" to run?
Are the resource bottlenecks in deep learning inference observed
on mainstream CPUs today going to disappear tomorrow as accelerators become more accessible? Core questions of this type have
been inaccessible until only recently due to the lack of shipping
accelerator hardware. In comparison to the hundreds of proposed
accelerator designs and approaches, there had been almost no open
accessible accelerator processors suitable for comparing again other
processor architecture types or mature enough to run a wide range
of deep models. This has now changed with offerings being made
from companies that include Nvidia [46], Huawei [27] and Intel [4].
In this paper, we will begin to address these open questions by
presenting, to the best of our knowledge, the first performance
characterization of how convolutional neural architectures perform
under one of the only commercially available hardware accelerators
purpose-built to execute deep models efficiently: the Intel Movidius
Neural Compute Stick [4] (NCS) – especially, within the increasingly common context of accelerators like the NCS being available
on systems that also have other heterogeneous processor hardware
(GPUs, DSPs, CPUs) present. The NCS itself delivers exceptional
deep model inference performance at a low energy rate through
12 proprietary 128-bit SIMD processors referred to as Vision Processing Units (VPUs). In comparison, a mainstream CPU such as
the ARM Cortex-A57 contains just 128-bit SIMD vector units (two,
coarsely similar to VPUs). On a per watt power basis, the NCS has
been shown to outperform high performance embedded/mobile
GPUs like the Nvidia Jetson X2 [43]. Notably, the NCS has many
processor design similarities (such as, use of a data flow architecture
and hardware support of sparse data structures – see §2) to that
of both proposed and already released accelerators like Huawei’s
Kirin 970 [27] and others, making its study of general importance.
Our empirical study is partitioned into two core elements (corresponding to the results reported in §5 and §4 respectively).
(1) Accelerator Profiling and Hetero-Processor Comparison.
In the first, we perform detailed comparisons of neural network energy and latency performance under the NCS relative to the distinct
processor architecture alternatives (viz. multi-core CPUs, DSPs and

GPUs) present in the Qualcomm Snapdragon 820 [6] – a highly
popular mid-range mobile/embedded system-on-a-chip (SoC). To
facilitate these experiments we develop a proof-of-concept experimental smartphone platform and software that comprises a OnePlus
3 Android smartphone [5] (that uses the Snapdragon 820 SoC) and
NCS with the two communicating across a USB bridge. Such experiments, for instance, identify critical trade-offs that dictate which
processor is best for particular deep models and highlight execution
bottlenecks in the NCS and other processor architectures.

accelerator design. We systematically report the implications of
such neural architecture changes and the impact on accelerator
performance that results. We expect results of this type will open
new opportunities to design software-based efficiency methods
aligned with accelerator design principles.
• Hetero-Processor and Accelerator Platform. To enable the
above series of experiments, we devise an experimental platform
and software stack the allows for precise latency and energy
measurements of any CNN when executing on any of the native
processors present in the Qualcomm Snapdragon 820 (viz. DSP,
GPU, CPU) as well as the accelerator present in the NCS. We
envision the community at large will be interested in adopting
this platform for a wide variety of follow-up experiments, or even
in the development of end-to-end applications that require this
mixture of processors. This aspect of our work plugs a important
methodological hole for researchers, by allowing accelerators
and conventional processors to be easily mixed and measured in
support of a variety of neural architectures.

(2) Neural Design for Efficient Accelerator Execution. In our
second set of experiments, we how common variations in neural
network architecture impact performance goals like latency and
energy. We systematically explore deep model parameterization
(e.g., network depth, filter dimensions) that have arisen from aforementioned software-centric methods that seek to reduce and shape
resource usage. By performing these experiments on the NCS we
can identify which of these proliferating software techniques are
beneficial when applied under hardware acceleration. Comparisons
again performed against other processor architectures (e.g., DSP,
GPUs) allow the impact related to processor design of accelerators
with respect to more familiar processor types to made clear. Furthermore, such experiments offer insights into the specific design
of deep models best suited for accelerators like the NCS.

2

PROCESSORS FOR DEEP LEARNING

In this section, we describe how varieties of processor architectures
investigated in our study (viz. CPU, GPU, DSP and accelerators in
the form of the Intel Movidius Neural Compute Stick) can be used
for deep learning inference. But before we begin this discussion
we briefly connect processor design to the inferenece workload of
neural networks.

Significantly in all of these experiments, we consider exclusively
convolutional neural networks (CNNs) often used for computer
vision related tasks (like object and face recognition or more general
scene understanding). Such models and tasks are perhaps the most
popular use of mobile and embedded deep learning today – but
more importantly, results of the CNN varieties we test generalize
strongly to other deep models as they contain network architecture
components (e.g., feed-forward layers, skip connections) present in
other combinations of model and task; for example, compact fullyconnected networks used for on-device audio and speech tasks [44]
and neural architecture techniques from CNNs that are adopted in
language understanding and machine translation [12].
The scientific contributions of this work are as follows:

2.1

Processor design and Neural Networks

Deep models often have stringent storage and computational requirements and state-of-the-art models are moving towards even
bigger and more complex architectures. Convolutional layers –
which we focus on in this study – are the commonly-used building blocks in vision models, are very computationally expensive.
AlexNet [32] for instance, one of the first successful deep architectures for image classifications, has over 60 million parameters;
and while the convolutional layers of AlexNet account for only 4%
of the parameters, they are responsible for more than 90% of the
computations at inference time [36]. As a result, optimising and designing computation platforms that enable fast and energy-efficient
deployment of DNNs are critical for their wide adoption.
The fundamental component of both the convolutional and (fully
connected if present) layers are the multiply-and-accumulate (MAC)
operations, which can be easily parallelized. In order to achieve
high performance, highly-parallel compute paradigms are very
commonly used, including both temporal and spatial architectures.
The temporal architectures appear mostly in CPUs or GPUs, and
employ a variety of techniques to improve parallelism such as vectors (SIMD) or parallel threads (SIMT). Such temporal architecture
use a centralized control for a large number of ALUs. These ALUs
can only fetch data from the memory hierarchy and cannot communicate directly with each other. In contrast, spatial architectures
use dataflow processing, i.e., the ALUs form a processing chain so
that they can pass data from one to another directly. Sometimes
each ALU can have its own control logic and local memory, called

• CNN performance under a commodity accelerator. Detailed
experimental results highlight the performance of various popular CNNs under the NCS. These results highlight performance
bottlenecks and shed light as to which model varieties are best
suited to execution under accelerator hardware. We anticipate
such results will assist in the development of accelerator-friendly
CNNs as well inform future accelerator designs.
• Comparisons to hetero-processor alternatives. As mobile
and embedded hardware increasingly offers a variety of processor
types, we compare the performance under deep model workloads
of the NCS to the GPU, CPU and DSP from a representative
Qualcomm SoC. These are fundamental empirical comparisons
that inform which processor is best suited certain workloads and
performance goals. We believe such comparisons represent some
of the first of their kind.
• Relationship to neural architectural variants. Because accelerator hardware has been unavailable, the enormous variety
of software-based approaches that modify a model to improve its
system performance has ignored how these solutions relate to
2

a scratchpad or register file. We refer to the ALU with its own local memory as a processing engine (PE). Spatial architectures are
commonly used for DNNs in ASIC and FPGA-based designs.

2.2

CPU
ALU

ALU

ALU

ALU

Control

Processor Architecture Varieties

Cache

After briefly discussing the ties between processor architecture and
design with neural network workloads, we provide the background
processor design details necessary to appreciate the results of our
measurement study.

GPU

CPU: Central Processing Unit. Mobile CPUs such as ARM processors have Single Instruction Multiple Data (SIMD) capabilities
to parallelize compute intensive operations. Most deep learning
frameworks on mobile (e.g. TensorFlow Lite, SNPE, etc) use NEON
(ARM’s enhanced SIMD technique) features to speed up DNN model
inference. While mobile CPUs do have some parallelization power
for compute intensive applications, they are natively designed for
more general tasks and have complex control logic and lower compute density, which are mainly optimized for serial operations (i.e.,
fewer execution arithmetic units and higher clock speeds). On the
other hand, GPUs are originally designed to accelerate graphics
applications thus having stronger SIMD capabilities built for massively parallel workloads. Deep learning execution frameworks
using GPUs typically utilize many GPU shader cores (usually range
from tens to hundreds) SIMD architecture to parallelize the mathematical computations. Figure 1 shows the differences between
CPU and GPU SIMD architectures, GPUs are built to have high
compute density and high computations per memory access, which
are optimized for parallel operations.
There are multiple software libraries designed to provide optimised implementations of linear algebra operations for generalpurpose CPUs (e.g. OpenBLAS, Intel MKL) and GPUs (e.g. cuBLAS,
cuDNN). Hardware platforms have also started adding support for
NN workloads. Two examples are: Arm’s NN SDK that enables
efficient translation of models from existing frameworks such as
TensorFlow and Caffe to run efficiently on Arm Cortex CPUs and
Arm Mali GPUs. Qualcomm’s Snapdragon Neural Processing Engine (SNPE) framework offers similar feature for its mobile CPUs,
GPUs or DSPs. FPGAs are also suitable platforms that can exploit
properties of neural network to obtain parallel implementations.

Figure 1: CPU and GPU SIMD Architecture Comparison

Interfaces (SPI, USB, Ethernet, etc)

Low Power Memory Fabric
Optimised Configurable Vision HW Engines

RISC-RT Scheduler

12 Shave Processors
(128-bit vector VLIW)
POSIX RTOS

Figure 2: Myriad VPU Architecture

a hybrid architecture that combines ideas from RISC, DSP, GPU and
VLIW architectures: It supports RISC-style instruction predication,
has multiple parallels units and 8/16/32-bit SIMD support controlled
via VLIW instructions. It also supports stream processing and Texture Management Units (TMU) similar to GPUs and and provides
zero-overhead looping, modulo addressing and FFT units like DSPs.
When we dig into the SHAVE processors, we find each contains
wide and deep register files coupled with a variable-length long
instruction word (VLLIW) controlling multiple functional units including extensive SIMD capability for high parallelism and throughput at both a functional unit and processor level. The SHAVE processor is a hybrid stream processor architecture combining the best
features of GPUs, DSPs, and RISC with both 8-, 16-, and 32-bit integer and 16- and 32-bit floating-point arithmetic as well as unique
features such as hardware support for sparse data structures. The
architecture maximizes performance per watt while maintaining
ease of programmability, especially in terms of support for design
and porting of multicore software applications
Thus, sharing data flexibly between SHAVE processors and hardware accelerators via the multiported memory subsystem was a key
challenge in the design of the Myriad 2 VPU. In the 28-nm Myriad
2 VPU, 12 SHAVE processors, hardware accelerators, shared data,
and SHAVE instructions reside in a shared 2-Mbyte memory block
called Connection Matrix (CMX) memory, which can be configured

Accelerators: Intel Movidius Neural Compute Stick. Intel Movidius Neural Compute Stick (NCS) is one of the first commercially
available of such accelerators for mobile, wearable, and embedded systems. It is powered by a low-power, high-performance SoC
designed to handle a range of applications such as Deep Neural
Network-based classification, object tracking, indoor navigation
and 3D vision applications. At the heart of the NCS is the Myriad2
MA2450 Vision Processing Unit (VPU). Myriad2 provides up to
100 GFLOPs of performance at 600MHz within a nominal 1W of
power consumption. The Myriad2 features twelve 128-bit vector
processing cores called SHAVE (Streaming Hybrid Architecture
Vector Engine) which compute most of the neural network load
[11]. Figure 2 shows the architecture inside Myriad2.
Critically, emerging deep learning accelerators like the NCS and
others use dataflow architecture instead of the SIMD architecture
used on CPUs and GPUs. Figure 4 shows the comparison between
dataflow and SIMD processor. As you can see each SHAVE core has
3

3

Instruction
cache

We compare the performance of the only commercially available
hardware accelerator, NCS, with existing mobile processor architecture—
CPU, GPU, and DSP. In this section, we present the measurement
setup that is used in subsequent sections (§4 and §5) which report
results.

L2 cache / TCM

Instruction unit

Data unit
(load/store/
ALU)

Data unit
(load/store/
ALU)

STUDY METHODOLOGY

Execution unit
(64-bit vector)

Convolutional Network Workload

Execution unit
(64-bit vector)

We evaluate the performance of the four process architectures on
the most popular neural network workload, that of image recognition. To this end, we study a large number of popular image recognition models: AlexNet [32], SqueezeNet [30], InceptionV3 [41],
MobileNetV1 [26], ResNet50 [25], and MobileNetV2 [40]. All of
these models use Convolutional Neural Networks [35].
Table 1 summarizes the characteristics of the neural network
models. The fields corresponding to FLOPs (Floating-Point OPeration per second) and parameters show the computationally needs
of the model. The larger the number of FLOPs and the number of
parameters (in millions), the more compute the model requires.
The models represent a diverse range in terms of accuracy, computational requirements, and complexity. Some of the models are
designed specifically for mobile devices while others are designed
for server-class devices. AlexNet [32] was the watershed model
for the deep learning community. SqueezeNet [30] has comparable accuracy to AlexNet [32] but has significantly lower number
of parameters making them suitable for mobile deployment. InceptionV3 [41] was developed by Google and further pushed the
accuracy higher. MobileNetV1 [26] is a model that is specifically
designed for mobile devices, which improves on the efficiency of
SqueezeNet [30].
The more recent model, ResNet50 [25], is the state-of-the-art
model in terms of accuracy, but is computationally intensive (see
Table 1). MobileNetV2 [40] is an improved version of MobileNetV1
that leverages the residual blocks in ResNets [25] to improve accuracy but still maintaining a smaller number of parameters and
FLOPs

Data cache

Register file/thread

Figure 3: Hexagon DSP with SIMD extensions

to accommodate different instruction and data mixes depending on
the workload.
DSP: Digital Signal Processor. Mobile DSPs (e.g. Hexagon DSP)
use SIMD extentions, which enhance the original SIMD by introducing vector execution unit in addition to ALUs as shown in Figure
3. Another characteristic of DSPs is that they usually support integer based operations to further reduce computer clock cycles and
energy footprints.
Interestingly, VPU (found in the NCS) and DSPs are more similar
in terms of design considerations including hardware parallelization, energy efficiency. VPU are optimized for vision algorithms
and in contrast DSPs are optimized for multimedia streaming, encoding/decoding. But fundamentally the computer requirements
and hence logic design are closely related.
Compression and efficient implementation of DNNs are more
important than ever. There has been a torrent of recent work proposing training and post-training schemes that aim to compress models
while avoiding significant loss in their performance. Main examples of such techniques are: pruning, weight sharing, low-rank
approximation, knowledge distillation and perhaps most importantly quantisation to lower precisions [22].

SIMD CPUs/GPUs

Dataflow Accelerator

Memory

Memory

Register File

GPU: Graphics Processing Unit. The basic building block in
a GPU is a Streaming Multiprocessor or SM. Different GPU architectures have different numbers and configuration of SMs. For
example, each SM in NVIDIA’s V100 has 128 cores, 64k registers,
96KB of shared memory, 48KB L1 cache, and up to 2000 threads.
The important hardware feature is that the cores in a SM are Single
Instruction Multiple Threads (SIMT). This means groups of multiple
cores (e.g. 32) execute the same instructions simultaneously, but
with different data. This means all threads within an SM are do the
same thing at the same time. This is natural for many scientific
computing abd graphics processing.

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

Control

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

ALU

Figure 4: SIMD and Dataflow Architecture Comparison
4

Million Million Top1
FLOPs
Params Accuracy
AlexNet
8
1574.9
50.31
57.2%
SqueezeNet 10
1683.1
1.25
57.5%
InceptionV3 48
5744.4
25.57
78.0%
MobileNetV1 29
1146.0
4.23
70.9%
ResNet50
50
7022.3
25.56
75.2%
MobileNetV2 21
608.8
3.51
71.9%
Table 1: The six image classification neural network models considered in this study. The table shows the number of
layers, the number of floating point operations per second
(FLOPS), the number of parameters (in millions) and the accuracy of these models. MobileNetV1 and MobileNetV2 are
designed specifically for mobile devices and have a lower
number of parameters.
Name

USB stick internally has a Myraid 2 Vision Processing Unit (VPU),
accompanied with 1 GB RAM, 4GB storage. The smartphone is
running Android 8.0.0 and has a Qualcomm 820 CPU, Adreno 530
GPU and Hexagon 680 DSP. It also has a 6 GB RAM and 64 GB
storage. The NCS is connected to a PC as instructed by the SDK.

Layers

Software Runtime and Tools
We use the available TensorFlow [42] implementation for all models.
The software used to run the inference depends on the processor
architecture. Each of the software used is necessary to support
individual experiments and model/hardware needs. We perform the
necessary steps to ensure we can compare results across software.
The NCS inference is performed on the Movidius Neural Compute
Software Developer Kit (NCSDK) [7]. It includes software tools for
compiling and profiling TensorFlow models. On the CPU, we run the
inference on TensorFlow Lite (TFLite) [8]. TensorFlow’s lightweight
solution for mobile and embedded devices. It enables on-device
machine learning inference with low latency and a small binary.
Finally, for the DSP and GPU experiments, we use Snapdragon
Neural Processing Engine (SNPE).

4

PERFORMANCE STUDY OF THE CNN
EXECUTION ON MOBILE PROCESSORS

We start by investigating the latency and energy consumption of
running size neural network models (Table 1) over NCS, CPU, GPU,
and DSP.
The key takeaways are:
• Takeaway 1: The NCS accelerator has been specifically designed for neural models. However, while NCS improves
latency over CPU, the latency of NCS is more than that on
the GPU and DSP. Interestingly, the relative performance of
the models remain the same across the four processors.
• Takeaway 2: NCS does improve the energy consumption for
inferencing compared to CPU and GPU. However, te energy
consumption of DSP is lower than that of NCS. As before,
the relative energy consumption across the models remain
the same.
• Takeaway 3: Increasing the number of parallel (SHAVE) cores
in NCS improves the inference latency, but then reduces. The
per-model consumed energy first decreases as more SHAVE
cores are used, but then increases when using more than a
certain number of cores, which means the speedup gains are
not able to compensate for the increased energy consumption
of more cores operating simultaneously.

Figure 5: Experiment setup: The figure shows how the NCS
is connected to the phone. The entire unit is connected to
the Monsoon Power Monitor for power measurements.

Latency and Energy measurement
We compare the performance of different processors based on latency and energy, two critical metrics on mobile devices. Since we
run the same model on different processors, the accuracy remains
the same. The inference latency is the time between inputing the
image and finishing the classification. The energy consumption
is measured during the inference time. All reported numbers are
averaged over 10 runs.
We use Monsoon Power Monitor [3] to measure the power for
the smartphone. To measure the power of NCS, we use a on-the-go
cable to connect the NCS into the phone.

Overall, we find that NCS behaves more like a DSP but not
better than DSP for the studied CNN workloads. We also notice
that even conventional processors like DSPs can well suit CNN
workloads although being purposely designed for multimedia and
signal processing applications.

4.1

Latency and Energy Characterization

Figure 6 shows the inference latency of running the CNN models
on the NCS compared with the smartphone CPU/GPU/DSP. Both
GPU/DSP and the NCS demonstrates speedups over the CPU baseline in all cases. However, to our surprisingly interest, the NCS

Device Specification
We compare performance of CNN model performance on the Movidius NCS and an OnePlus 3 Android smartphone [5]. The NCS
5

450

350

1300
CPU
NCS
GPU
DSP

403.1

1200
Inference Energy (mW)

Inference Time (ms)

400

337.8

300
250
200

196.8
177.6

150
100
50

87.1
70.7
51.3

16.3

0

Alex
N

et

95.9
80.9

88.7
73.3

1132

1000
900
800

785

50.9
23.0
14.5

36.4

39.4
17.9
10.6

700
600

682

667

589

587
538

500

467

541

455

400

38.9
12.7
11.3

300

Re
Mob
Inc
Mo
ilene
zeNe eptionV3 bilenetV sNet50
tV2
1
t

Sque
e

741

729
703

431

526

424
416

418
397
364

Alex

Net

CNN Models

357

Sque

In
M
R
M
ezeN ceptionV obilenetV esNet50 obilenetV
et
3
1
2

CNN Models

Figure 6: Inference latency on NCS and the other three
smartphone processors for the six neural network models.
Note that SNPE does not support ResNet50 yet, so GPU/DSP
latency are not shown.

Figure 7: Energy consumption of studied 6 CNN workloads
on NCS and smartphone CPU/GPU and DSP processors
the DRAM and possible cache them in each SHAVE core’s local
SRAM memory. We also see that the slowdown is not due to any
model side factors or bottlenecks, thus being more likely the lack
of software SDK optimization.
Table 2 also shows convolution layers being much less efficient
for the NCS. Relative speedup for the NCS over CPU on the convolution layers vs. its speed on fully connected is extreme, which
indicates new architectures that are fully convolutional would be
great for the NCS.

armed with a commodity deep learning accelerator turns out to
be not better than conventional mobile GPU and DSP. Another
interesting point is that different CNN model architectures do not
affect the processor speedup performance (compared to CPU), i.e.
the case where one model runs faster and the other slower does
not exist in our study.
Figure 7 shows the network energy consumption of over the four
processors. DSP consumes the minimum energy across all models.
However NCS consumes lower energy compared to the GPU and
CPU. The fact that GPU and DSP are faster than CPU is understandable since they have much better parallelization capabilities
(i.e, many cores, simpler control logics, optimized compute cycles).
However, NCS has more energy footprints than DSP and longer
inference time for the studied models.
Based on the latency and energy study, the recent general notion [11, 13, 37] that specialized DNN hardware accelerator has
short latency and impressive power efficiency does not hold in our
case. Conventional mobile processors like GPU and DSP have highly
optimized both hardware and software stack(compiler toolchain,
extensively tested code quality). DSPs can be used as the accelerator
choice for DNNs, at least the design experience for DSPs can be
borrowed to new accelerator design.

4.2

1100

1232

CPU
NCS
GPU
DSP

Layer
NCS
GPU
DSP
CPU
conv1 3.961
1.563
1.707 8.904
pool1
0.319
0.044
0.086 0.548
conv2 9.824
4.136
1.578 21.854
pool2
0.201
0.03
0.039 0.256
conv3 4.036
2.245
0.704 9.043
conv4 6.549
4.602
1.505 17.244
conv5 6.754
3.284
1.024 11.692
pool5
0.068
0.011
0.027 0.042
fc6
20.018 22.959 4.142 7.091
fc7
15.046 11.316 2.222 5.646
fc8
3.71
1.02
0.824 2.907
output 0.201
0.12
0.16
0.041
total
70.69
51.33
14.02 85.27
Table 2: AlexNet inference time (ms) breakdown by layers

AlexNet Layer Latency Breakdown

To further study the reason, we also perform the layer latency for
the AlexNet model [32]. Table 2 shows AlexNet inference time
breakdown at each layer. We find that there is little difference in the
relative performance across layers. For example, in each layer, the
GPU latency is lower than NCS resulting in an overall reduction
in latency. The one exception of fc6 (the sixth layer which is fully
connected), where the NCS latency is slightly better than GPU. This
is due to the large feature map processing after the convolution
layers. The Phone GPU needs to allocate the memory (shared with
CPU) on demand while the NCS can prealloacte the memory on

4.3

Performnce of NCS with multiple cores

Figure 6 shows the AlexNet inference latency using different number of SHAVE cores on the NCS. The inference time plateaus as
the number of core increases, with most of the speed up occuring
between 4 and 6 cores. Figure 9 shows the corresponding energy
consumption numbers of running AlexNet using different number of SHAVE cores. It can be seen that using 6 to 8 cores gives
the best energy performance. This is because fewer cores result
6

depth. In terms of optimization, we study the effect of two common
model optimizations: low precision and pruning.
Our key takeaways in this are:
• Takeaway 1: CPU and NCS prefer "fat-wide" style networks
(i.e. larger filter size, more filters) while GPU and DSP prefer
a moderate style (i.e. both filter size and number of filters
are neither big nor small).
• Takeaway 2: DSP is not sensitive to filter size under changing
network depth. On the GPU, the performance is best under
moderate conditions of not too deep network and not too
big filter. still prefer moderate style network (i.e., neither too
deep nor too big filter).
• Takeaway 3: Increasing the network input size will slowdown the inference for all 4 processors. NCS slowdown is
between the GPU and DSP.
• Takeaway 4: Existing known hardware CNN optimization
techniques like low precision and pruning optimizations
does not provide benefits for either GPU or NCS.

350
AlexNet Inference Time (ms)

inference time
300

303

250
200
167

150

127

100

103

104
91

92
77

81

77

78

50
0

2

4

6

8

10

71

12

NCS SHAVE cores

Figure 8: AlexNet inference latency on NCS when using different number of SHAVE cores.

Model Name
stage 3
fw1
874C1 × 2 − 256C1
Filter size vs. Width
fw3 (baseline) 256C3 × 3
fw5
128C5 × 2 − 256C5
fd2
256C2 × 6
Filter size vs depth
fd3 (baseline)
256C3 × 3
fd5
256C5
wd6 (baseline) 256C3 × 3
wd8
160C3 × 5 − 256C3
wd11
128C3 × 8 − 256C3
Width vs Depth
wd13
108C3 × 10 − 256C3
wd18
96C3 × 15 − 256C3
wd25
80C3 × 22 − 256C3
wd38
64C3 × 35 − 256C3
Table 3: Various configurations in final stages of AlexNet
under constrained time complexity. The first stages of the
models are the same in all configurations, i.e. (64C7)-(MP3)(128C5)-(MP2). The notation (s, n) represents the filter size
and the number of filters. "/2" represents stride = 2 (default
1). "×m" means the same layer configuration is applied k
times (not sharing weights). The numbers in the pooling
layer represent the filter size and also the stride. All convolutional layers are with ReLU.

610
AlexNet Inference Energy (mW)

inference energy
600

601

590

589

580

582

580

574

570

573
568
564

563

560
550

552
546

548

540
0

2

4

6

8

10

12

NCS SHAVE cores

Figure 9: AlexNet inference energy on NCS when using different number of SHAVE cores

in longer latency increasing energy while a large number of cores
consume energy for computation. This SHAVE core behavior indicates always using all available cores may not be the optimal
choice, furthermore, different workloads may need to be tuned to
use different number of cores to achieve the best latency and energy
trade-offs.

5

5.1

EFFECT OF MODEL PARAMETERS AND
OPTIMIZATIONS

In this section we study the effect of using different models on
its latency and energy performance of the hardware accelerator.
We do this by warying the model parameters and apply existing
model optimizations to the six models. To study the effect of model
configurations, we vary three of the most common model hyperparameters in CNN models: filter size, network width, and network
7

Changing model parameters

Table 3 shows the parameters we vary across filters, network width,
and network depth. All the networks have a 224 × 224 × 3 input
image size. We group the network layers into three stages. Stage
1 has one convolutional layer having 64 7 × 7 filters with a stride
2, followed by a 3 × 3 max pooling layer with a stride 3. Stage 2
consists of a convolutional layer that has 128 5 × 5 filters, followed
by a 2 × 2 max pooling layer with a stride 2. In the third stage, for
the baseline model, it has three convolutional layers all have 256
3 × 3 filters, for other models, they are shown in table 3. After the
stage 3, there is a 3 × 3 max pooling layer with a stride 3, followed

160

140
CPU
NCS
GPU
DSP

150.2

Inference Time (ms)

140

130
Inference Time (ms)

150

130
119.7

120
110.9

110

105.3

100

98.6
91.5

90

110
100
90
80

81.3

80

70

74.4
70.2

70
62.7

66.6

64.5

60
8

d3

w

5

d2

w

100
96.2
93.2
91.5

90
82.2

80
70.4

70

8

5.1.2 Filter Size versus Network Depth. Similar to filter size
versus network width variations, convolutional layers with smaller
filters have more layers in the network which means deeper network. Figure 11 shows the inference time of varying the filter size
versus network depth. Interestingly, DSP is not sensitive to the
filter size and network width tradeoffs, this can attribute to the
fact that the inference is already fast enough and the computation
complexity stays the same across the variants. NCS along with CPU
performs best with large filter size, while the GPU performs best
with a filter size that is not too big or small.

CPU
NCS
GPU
DSP

110.9

d1

Figure 12: CNN network width vs network depth

120
114.6

w

model name (number means network depth)

Figure 10: CNN filter size vs network width

110

3
d1
w 1
d1

model name (number means stage 3 filter size)

d8

fw5

w

fw3

d6

fw1

w

w

60

Inference Time (ms)

120

CPU
NCS
GPU
DSP

66.7
64.5

5.1.3 Network Width versus Network Depth. To further
see the effects of network depth and width variations, we designed
a set of network architectures ranging from "wide-shadow" style
to "deep-thin" style as shown in Table 3.
Figure 12 shows that GPU and DSP are not sensitive to the
network width and depth alterations. This again is because the
inference is fast enough and the computation complexity stays the
same across the variants. For CPU, the performance on the wideshadow network is better since as the network becomes deeper and
thinner the inference latency becomes larger. More interestingly,
on NCS the performance is best under not too wide-shadow nor too
deep-thin networks conditions. The inference latency is lowest at
11 layers. Stacking more layers will cause slightly longer inference
time but not as aggressive as on the CPU. This is possibly because
NCS is not tuned for more general CNN models as the official SDK
only supports a limited number of published networks.

64.4 64.4

62.7

60
fd2

fd3

fd5

model name (number means stage 3 filter size)

Figure 11: CNN filter size vs network depth

by two 4096-d fully connected layers and a 1000-d fully connected
layer with softmax as the output.
To isolate the effect of each of these parameters we vary one
parameter keeping the rest of the network a constant. The evaluations are performed over AlexNet [32]. only using SqueezeNet for
network input size study, reason is commented out below.
5.1.1 Filter Size versus Network Width. Table 3 shows that
convolutional layers with smaller filters have more filters which
means wider network. Figure 10 shows the inference time of varying
the filter size versus network width. On both NCS and CPU, the
performance improves with larger filter sizes. However, on the GPU
and DSP, the performance is best when the filter size is not too big
or small. We guess this is due to the memory/cache limit of GPU
and DSP, both CPU and NCS have more available memory to use or
cache if more filter weights come in within a layer’s computation
time.

5.1.4 Network Input Size. Figure 13 shows the SqueezeNet
inference slowdown for increasing input size. As the input size to
the network becomes larger, NCS slowdown is between the GPU
and DSP. We guess this is due to the memory characteristics, GPU
shares the memory with CPU (which is fast when CPU offloads the
computation to GPU), NCS VPU has its own DRAM and SRAM for
caching. DSP, however, only has L2 cache (small size compared to
VPU SHAVE core SRAM) for model weight reusing.
8

893.9

100

GPU
NCS
DSP
CPU

800
700

90
80

600

Inference Time (ms)

SqueezeNet Inference Latency (ms)

900

575.3

500
408.3

400

356.3

300

285.6

203.6

200
100

85.9

29.1

0
224

336

448

50
40

20

50.9

48.4

60

121.9

119.4
77.7

CPU
NCS
GPU
DSP

30

176.4

105.8

95.9
50.9
23.0
14.5

186.3

70

560

10

672

0

Input Size

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

MobileNetV1 inference latency under different pruning ratios

Figure 13: SqueezeNet inference latency on NCS and smartphone processors when input size increases

Figure 16: MobileNetV1 inference latency w.r.t to pruning
ratio

Figure 14: SqueezeNet inference latency vs input size.

Inference Time (ms)

200

150

Note that AlexNet full precision is much lower than the half precision counterpart, and SqueezeNet full precision takes infinite time
to run, we found this is due to the NCSDK software problem.

196.8197.0

GPU_FP16
GPU_32
NCS_16
NCS_FP32

177.6177.7

5.2.2 Weights Pruning. The purpose of pruning is to avoid computations for zero-value parameters (model weights), which is especially effective for CNN accelerators as shown in [19, 20, 48].
The MobileNet architecture consists of one standard convolution
layer acting on the input image, a stack of depthwise separable convolutions, and finally averaging pooling and fully connected layers.
99% of the parameters in the MobileNetV1 are in the 1x1 pointwise
convolution layers (74.6%) and fully connected layers (24.3%). In
this study, we set the weight pruning threshold to 10−3 . We do
not prune the parameters in the one standard convolution layer
and in the depthwise convolution layers since there are very few
parameters in these layers (1.1% of the total number of parameters).
Figure 16 shows the inference latency of MobilenetV1 when
applied with different pruning ratio. Both GPU and NCS show no
significant changes in latency. No performance gains for GPU is
understandable since it’s mainly designed for graphics rendering
and general parallel computations. But for NCS, our hypothesis is
that, even though NCS has a CNN accelerator chip, the VPU itself
is not optimized for sparse CNN computations.

101.2

100

82.3 80.9
70.7
55.2

50

50.9

51.3

39.4 40.2
21.7 23.0

0

Alex
N

et

15.4 17.9

38.9 39.4

11.7 12.7

Re
Mob
Inc
Mo
ilene
zeNe eptionV3 bilenetV sNet50
tV2
1
t

Sque
e

CNN Models with FP16 weights

Figure 15: Latency comparison for CNNs with FP16 and FP32
precision weights

5.2

The effect of Optimizations

We applied two sets of optimizations, i.e., low precision and pruning
to the MobileNetV1 network. We could not study the effect of other
common optimizations including quantization [] because they are
not currently supported in NCS.

6

RELATED WORK

As there are very few measurement studies like the one we perform
in this paper, we survey results found in software-based architecture optimization research and accelerator design studies. These
represent the most salient forms of related work.

5.2.1 Low Precision Inference. Figure 12 shows that GPU and
NCS inference latency for low precision model weights. For GPU,
AlexNet and InceptionV3 perform slightly better using the full
precision weights while their mobile variants – SqueezeNet and
MobileNet(V1 and V2) slightly prefer half precision model weights.
For NCS, we found that although the internal VPU supports low
precision arithmetics such as INT8/FP16 operations, the software
stack is not fully optimized for the hardware. We also found the
NCSDK internally represents the model weights in half precision
format even though it supports full precision as input and output.

Software-based architecture optimization. Early models with
quantized parameters were derived by applying quantization operation to weights of pre-trained models [18]. This approach is
common but suffers from significant loss in accuracy. [28] showed
that in order to maintain model performance, quantization must
be an integral part of the training process. This can be achieved
9

by either performing additional fine-tuning steps after training is
finished or by directly learning quantized parameters.
The core idea is to use new coding or scaling techniques for
the float point real numbers reside in DNN weights. The extreme
form form of quantization, binarization, can constrain network
parameter to 1-bit representation [15] (+1 and -1) so that parameter
updates and calculating activations can be implemented through
X-nor [38] operations. For example, floating point multiplications
are supplanted with bitwise XNORs and left and right bit shifts.
Although DNN models normally require a vast number of parameters to guarantee their superior performance, significant redundancies have been reported in their parameterizations [16]. Therefore,
with a proper strategy, it is possible to compress these models without significantly losing their prediction accuracies. Among existing
methods, network pruning appears to be an outstanding one due
to its surprising ability of accuracy loss prevention.
There are various pruning approaches with respect to different
criteria, deep compression [22] applies pruning to reduce model
size and starts by learning the connectivity via normal network
training and prune the small-weight connections(all connections
with weights below a threshold are removed from the network) and
followed by retraining the network to learn the final weights for the
remaining sparse connections. [48] proposes a new fine-grained
pruning algorithm that specifically targets energy-efficiency. It
aggressively prune the layers with the highest energy consumption
with marginal impact on accuracy. Moreover, the pruning algorithm
considers the joint influence of weights on the final output feature
maps, thus enabling both a higher compression ratio and a larger
energy reduction.

on mobile phones’ GPU could achieve promising real time execution
of deep vision models.
AI benchmarks [31] studies eight computer vision workloads
for various mobile SoCs. [24] characterizes the CNN latency and
throughput for mobile vision tasks. Both of them don’t study the
CNN performance for commodity hardware accelerators. [9] discusses various deep learning workloads for training and inference
on server-level processors.

7

CONCLUSION

Motivated by the looming arrival of neural network accelerators in
embedded and mobile devices, we have conducted one of the first
systematic measurement studies that considers an early open commercially available neural network accelerator: the Intel Movidius
Neural Compute Stick. Because, only until very recently, accelerators have been available hardware simulations or limited supply
prototypes many of our empirical results are the first time. Along
with accelerators, heterogeneous compute options (such as, GPUs,
multi-core CPUs, DSP) are becoming commonplace in constrained
platforms – many of which have been shown to be viable processors
onto which to perform efficient deep learning inference. For this
reason, one core element of our investigation as been to compare
the efficiency of neural architectures under such processor design
alternatives. We perform these experiments using the collection of
processors available in the Qualcomm Snapdragon 820 – a platform
that is representative of typical mobile and embedded hardware.
Finally, due to the proliferation of software-based deep architecture
variations for low resource situations – virtually none of which
consider processor designs of accelerators; we systematically study
commonly manipulated architecture parameters to under the NCS.

Processor Hardware and System Optimization. As the compute cost of machine learning models continues to grow, and their
adaptation increases, more optimisations are required to deploy
them in practice. There is also an increase desire for ASIC accelerators specifically designed for NN workloads. Many of these optimisatuins are achieved using custom hardware acceleration blocks.
Most of these solutions are designed to speed up inferences, while
others aim to accelerate the training phase. Given popularity of
DNNs it’s not surprising that there has been a spate of publications,
prototypes, and commercial hardware accelerations. While less
flexible than other platform they can offer better energy-efficiency
and smaller silicon area footprint.
[20] proposed an energy efficient inference engine called EIE.
The engine performs inference on a model compressed using weight
pruning and weight sharing. The result is accelerated using sparse
matrix-vector multiplication with weight sharing, skipping zero activations from ReLUs, exploiting sparsity and going from DRAM to
SRAM. [45] presented a scalable hardware prototype on FPGA for
using with DNNs. The DLAU accelerator employs three pipelined
processing units to improve the throughput and utilizes tile techniques to explore locality for deep learning applications.
Mobile GPUs provide another optimization avenue. CNNDroid [34]
both showed a mobile GPU can be used to improve the CNN/DNN
execution time. In CNNDroid, they reported more than 10-fold
speedup for AlexNet model on CIFAR-10 dataset. DeepMon [29]
showed careful optimization like caching or sharing partial results

REFERENCES

[1] 2018. Google APIs for Android. https://developers.google.com/android/reference/
com/google/android/gms/location/DetectedActivity. (2018).
[2] 2018. Hey Siri: An On-device DNN-powered Voice Trigger for AppleâĂŹs Personal Assistant. https://machinelearning.apple.com/2017/10/01/hey-siri.html.
(2018).
[3] 2018. Monsoon Power Monitor. https://www.msoon.com/LabEquipment/
PowerMonitor/. (2018).
[4] 2018. Movidius Neural Compute Stick. https://developer.movidius.com/. (2018).
accessed 23-March-2018.
[5] 2018. OnePlus 3. https://www.oneplus.com/3. (2018).
[6] 2018. Qualcomm Snapdragon 820. https://www.qualcomm.com/products/
snapdragon/processors/820. (2018).
[7] 2018. Software Development Kit for the Neural Compute Stick. https://github.
com/movidius/ncsdk. (2018). accessed 21-April-2018.
[8] 2018. TensorFlow Lite. https://www.tensorflow.org/. (2018). accessed 8-April2017.
[9] Robert Adolf, Saketh Rama, Brandon Reagen, Gu-Yeon Wei, and David Brooks.
2016. Fathom: Reference workloads for modern deep learning methods. In
Workload Characterization (IISWC), 2016 IEEE International Symposium on. IEEE,
1–10.
[10] Jorge Albericio, Patrick Judd, Tayler Hetherington, Tor Aamodt, Natalie Enright
Jerger, and Andreas Moshovos. 2016. Cnvlutin: Ineffectual-neuron-free deep
neural network computing. In ACM SIGARCH Computer Architecture News, Vol. 44.
IEEE Press, 1–13.
[11] B. Barry, C. Brick, F. Connor, D. Donohoe, D. Moloney, R. Richmond, M. O’Riordan,
and V. Toma. 2015. Always-on Vision Processing Unit for Mobile Applications.
IEEE Micro 35, 2 (Mar 2015), 56–66. https://doi.org/10.1109/MM.2015.10
[12] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc Le. 2017. Massive exploration of neural machine translation architectures. arXiv preprint arXiv:1703.03906
(2017).
[13] Yu-Hsin Chen, Joel Emer, and Vivienne Sze. 2016. Eyeriss: A spatial architecture for energy-efficient dataflow for convolutional neural networks. In ACM
SIGARCH Computer Architecture News, Vol. 44. IEEE Press, 367–379.
10

[35] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. nature
521, 7553 (2015), 436.
[36] Christos Louizos, Karen Ullrich, and Max Welling. 2017. Bayesian compression for
deep learning. In Advances in Neural Information Processing Systems. 3288–3298.
[37] David Moloney, Brendan Barry, Richard Richmond, Fergal Connor, Cormac Brick,
and David Donohoe. 2014. Myriad 2: Eye of the computational vision storm. In
Hot Chips 26 Symposium (HCS), 2014 IEEE. IEEE, 1–18.
[38] Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, and Ali Farhadi. 2016.
Xnor-net: Imagenet classification using binary convolutional neural networks.
In European Conference on Computer Vision. Springer, 525–542.
[39] Brandon Reagen, Paul Whatmough, Robert Adolf, Saketh Rama, Hyunkwang Lee,
Sae Kyu Lee, José Miguel Hernández-Lobato, Gu-Yeon Wei, and David Brooks.
2016. Minerva: Enabling low-power, highly-accurate deep neural network accelerators. In ACM SIGARCH Computer Architecture News, Vol. 44. IEEE Press,
267–278.
[40] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and LiangChieh Chen. 2018. MobileNetV2: Inverted Residuals and Linear Bottlenecks. In
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.
4510–4520.
[41] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew
Wojna. 2016. Rethinking the inception architecture for computer vision. In
Proceedings of the IEEE conference on computer vision and pattern recognition.
2818–2826.
[42] TheTensorFlowAuthers. 2018. TensorFlow. https://www.tensorflow.org/. (2018).
accessed 8-May-2018.
[43] Nvidia TX2. 2018.
Nvidia TX2.
https://devblogs.nvidia.com/
jetson-tx2-delivers-twice-intelligence-edge/. (2018).
[44] Ehsan Variani, Xin Lei, Erik McDermott, Ignacio Lopez-Moreno, and Javier
Gonzalez-Dominguez. 2014. Deep neural networks for small footprint textdependent speaker verification.. In ICASSP, Vol. 14. Citeseer, 4052–4056.
[45] Chao Wang, Qi Yu, Lei Gong, Xi Li, Yuan Xie, and Xuehai Zhou. 2016. DLAU: A
scalable deep learning accelerator unit on FPGA. arXiv preprint arXiv:1605.06894
(2016).
[46] Nvidia Xiaver. 2018. Nvidia Xiaver. https://developer.nvidia.com/embedded/buy/
jetson-xavier-devkit. (2018).
[47] Jian Xue, Jinyu Li, and Yifan Gong. 2013. Restructuring of deep neural network
acoustic models with singular value decomposition.. In Interspeech. 2365–2369.
[48] Tien-Ju Yang, Yu-Hsin Chen, and Vivienne Sze. 2017. Designing EnergyEfficient Convolutional Neural Networks Using Energy-Aware Pruning. 2017
IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (Jul 2017).
https://doi.org/10.1109/cvpr.2017.643

[14] Yu-Hsin Chen, Tushar Krishna, Joel S Emer, and Vivienne Sze. 2017. Eyeriss:
An energy-efficient reconfigurable accelerator for deep convolutional neural
networks. IEEE Journal of Solid-State Circuits 52, 1 (2017), 127–138.
[15] Matthieu Courbariaux, Itay Hubara, Daniel Soudry, Ran El-Yaniv, and Yoshua
Bengio. 2016. Binarized neural networks: Training deep neural networks with
weights and activations constrained to+ 1 or-1. arXiv preprint arXiv:1602.02830
(2016).
[16] Misha Denil, Babak Shakibi, Laurent Dinh, Nando de Freitas, et al. 2013. Predicting
parameters in deep learning. In Advances in Neural Information Processing Systems.
2148–2156.
[17] Yunchao Gong, Liu Liu, Ming Yang, and Lubomir Bourdev. 2014. Compressing deep convolutional networks using vector quantization. arXiv preprint
arXiv:1412.6115 (2014).
[18] Yunchao Gong, Liu Liu, Ming Yang, and Lubomir Bourdev. 2014. Compressing deep convolutional networks using vector quantization. arXiv preprint
arXiv:1412.6115 (2014).
[19] Song Han, Junlong Kang, Huizi Mao, Yiming Hu, Xin Li, Yubin Li, Dongliang
Xie, Hong Luo, Song Yao, Yu Wang, Huazhong Yang, and William (Bill) J.
Dally. 2017. ESE: Efficient Speech Recognition Engine with Sparse LSTM
on FPGA. In Proceedings of the 2017 ACM/SIGDA International Symposium on
Field-Programmable Gate Arrays (FPGA ’17). ACM, New York, NY, USA, 75–84.
https://doi.org/10.1145/3020078.3021745
[20] Song Han, Xingyu Liu, Huizi Mao, Jing Pu, Ardavan Pedram, Mark A Horowitz,
and William J Dally. 2016. EIE: efficient inference engine on compressed deep
neural network. In Computer Architecture (ISCA), 2016 ACM/IEEE 43rd Annual
International Symposium on. IEEE, 243–254.
[21] S. Han, H. Mao, and W. J. Dally. 2015. Deep Compression: Compressing Deep
Neural Networks with Pruning, Trained Quantization and Huffman Coding.
ArXiv e-prints (Oct. 2015). arXiv:cs.CV/1510.00149
[22] Song Han, Huizi Mao, and William J Dally. 2015. Deep compression: Compressing
deep neural networks with pruning, trained quantization and huffman coding.
arXiv preprint arXiv:1510.00149 (2015).
[23] Seungyeop Han, Haichen Shen, Matthai Philipose, Sharad Agarwal, Alec Wolman,
and Arvind Krishnamurthy. 2016. Mcdnn: An approximation-based execution
framework for deep stream processing under resource constraints. In Proceedings
of the 14th Annual International Conference on Mobile Systems, Applications, and
Services. ACM, 123–136.
[24] Jussi Hanhirova, Teemu Kämäräinen, Sipi Seppälä, Matti Siekkinen, Vesa
Hirvisalo, and Antti Ylä-Jääski. 2018. Latency and Throughput Characterization
of Convolutional Neural Networks for Mobile Computer Vision. In Proceedings
of the 9th ACM Multimedia Systems Conference (MMSys ’18). ACM, New York,
NY, USA, 204–215. https://doi.org/10.1145/3204949.3204975
[25] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual
learning for image recognition. In Proceedings of the IEEE conference on computer
vision and pattern recognition. 770–778.
[26] Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun
Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. 2017. Mobilenets:
Efficient convolutional neural networks for mobile vision applications. arXiv
preprint arXiv:1704.04861 (2017).
[27] Huawei. 2018. Kirin 970. http://www.hisilicon.com/en/Media-Center/News/
Key-Information-About-the-Huawei-Kirin970. (2018).
[28] Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, and Yoshua
Bengio. 2017. Quantized Neural Networks: Training Neural Networks with Low
Precision Weights and Activations. Journal of Machine Learning Research 18
(2017), 187–1.
[29] Loc N Huynh, Youngki Lee, and Rajesh Krishna Balan. 2017. DeepMon: Mobile GPU-based Deep Learning Framework for Continuous Vision Applications.
In Proceedings of the 15th Annual International Conference on Mobile Systems,
Applications, and Services. ACM, 82–95.
[30] Forrest N Iandola, Song Han, Matthew W Moskewicz, Khalid Ashraf, William J
Dally, and Kurt Keutzer. 2016. Squeezenet: Alexnet-level accuracy with 50x fewer
parameters and< 0.5 mb model size. arXiv preprint arXiv:1602.07360 (2016).
[31] A. Ignatov, R. Timofte, W. Chou, K. Wang, M. Wu, T. Hartley, and L. Van Gool.
2018. AI Benchmark: Running Deep Neural Networks on Android Smartphones.
ArXiv e-prints (Oct. 2018). arXiv:cs.AI/1810.01109
[32] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. Imagenet classification with deep convolutional neural networks. In Advances in neural information
processing systems. 1097–1105.
[33] N. D. Lane, S. Bhattacharya, P. Georgiev, C. Forlivesi, L. Jiao, L. Qendro, and F.
Kawsar. 2016. DeepX: A Software Accelerator for Low-Power Deep Learning
Inference on Mobile Devices. In 2016 15th ACM/IEEE International Conference on
Information Processing in Sensor Networks (IPSN). 1–12. https://doi.org/10.1109/
IPSN.2016.7460664
[34] Seyyed Salar Latifi Oskouei, Hossein Golestani, Matin Hashemi, and Soheil Ghiasi.
2016. CNNdroid: GPU-Accelerated Execution of Trained Deep Convolutional
Neural Networks on Android. In Proceedings of the 2016 ACM on Multimedia
Conference (MM ’16). ACM, New York, NY, USA, 1201–1205. https://doi.org/10.
1145/2964284.2973801
11

Investigating the local-global accuracy
trade-off in Federated Learning

Alexandru-Andrei Iacob
Homerton College

A dissertation submitted to the University of Cambridge
in partial fulfilment of the requirements for the degree of
Master of Philosophy in Advanced Computer Science

University of Cambridge
Computer Laboratory
William Gates Building
15 JJ Thomson Avenue
Cambridge CB3 0FD
United Kingdom
Email: aai30@cam.ac.uk
May 10, 2022

Declaration
I Alexandru-Andrei Iacob of Homerton College, being a candidate for the M.Phil
in Advanced Computer Science, hereby declare that this report and the work
described in it are my own work, unaided except as may be specified below,
and that the report does not contain material that has already been used to any
substantial extent for a comparable purpose.

Total word count: Add Here

Signed:
Date:

This dissertation is copyright ©2010 Alexandru-Andrei Iacob.
All trademarks used in this dissertation are hereby acknowledged.

add
wordcount

Abstract (1 page)
Federated Learning is a form of distributed Machine Learning which leverages local data storage and training on edge-devices. It attempts to reduce communication
costs by alternating the local training steps with a global aggregation phase which
combines model parameters without ever directly sharing private data. While
local-only training presents distinct advantages with regard to communication efficiency and client privacy over other distributed training paradigms, it introduces
significant difficulties regarding data and system heterogeneity. Most relevant to
this work, clients with highly unusual data distributions may receive a worse model
following the global training process than they could have trained on their own.
This may be exacerbated by recent techniques which attempt to restrict how far a
local model could diverge from the global one in order to improve the federated
process convergence. Two primary directions for addressing the trade-off between
local and global accuracy have been explored in the academic literature. The first
attempts to create a “fairer” global model, thus constraining how much the accuracy
of the global model can vary on the local datasets of the clients. The second relies
on local adaptation techniques to construct what is effectively a customized local
model for each client alongside the global one. This work brings three contributions to the field of Federated Learning. First, it provides an experimental analysis
of how the distance between the global and local models affects level of fairness
or local adaptation necessary to provide a given client with better results than they
could have obtained individually. Second, it provides the first direct comparison
between Fair Federated Learning methods and local adaptation methods in terms
of their ability to. Third, it proposes a new sub-category of Federated Learning
which alternates normal training and aggregation steps with local adaptation ones.
The experimental results show

add
results
show

Contents
1

Introduction (2 page)

1

2

Background and related work (10 page)
4
2.1 Federated Learning . . . . . . . . . . . . . . . . . . . . . . . . . 4
2.1.1 Foundational challenges . . . . . . . . . . . . . . . . . . 5
2.1.2 Federated learning objective . . . . . . . . . . . . . . . . 6
2.1.3 FedAvg . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
2.1.4 The local-global accuracy trade-off . . . . . . . . . . . . 7
2.1.5 Flower . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
2.2 Related work . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
2.2.1 Limiting global model divergence . . . . . . . . . . . . . 8
2.2.2 Fair Federated Learning . . . . . . . . . . . . . . . . . . 8
2.2.3 Personalization techniques . . . . . . . . . . . . . . . . . 10

3

Methods (10 page)
3.1 Hypotheses . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Experimental Setup . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.1 Proximal Term Tuning . . . . . . . . . . . . . . . . . . .
3.2.2 Fairness Tuning . . . . . . . . . . . . . . . . . . . . . . .
3.2.3 Targeted Local Adaptation . . . . . . . . . . . . . . . . .

14
14
14
15
15
16

4

Results (10 page)

17

5

Discussion (10 page)

18

6

Summary and Conclusions (3-4)

19

i

Add
wordcount

List of Figures

ii

List of Tables

iii

List of Algorithms
1
2

Federated Averaging [23] . . . . . . . . . . . . . . . . . . . . . .
Q-FedAvg [19] . . . . . . . . . . . . . . . . . . . . . . . . . . .

iv

7
10

Chapter 1
Introduction (2 page)
As the amount of data produced and gathered globally has grown rapidly, Machine
Learning (ML) methods capable of making practical use of it have become central
to the functioning of large sections of the global economy. Deep Learning (DL)
methods specifically have become the de-facto standard solution to core technical challenges faced by multi-billion-dollar industries, such as Natural Language
Processing [4, 32] in translation or writing assistance or Image Processing [1, 26]
in computer vision. Despite their success, such methods may require prohibitive
amounts of computation or high-quality training data.
The increasingly large number of internet-connected consumer devices represents
a pool of both computation power and training data for ML tasks. Unlike the
computational units used in classical Distributed ML [25], such devices may
not be wholly dedicated to the training task. As such, they may have privacy
concerns with regard to sharing their training data, computational constraints on
how much they can contribute to the training process at a given time, or data
transfer limitations. Furthermore, heterogeneity in device characteristics and the
local data they have gathered over time represent inherent challenges of the setting.
Importantly, this heterogeneity means that the ideal scenario for each device would
be an entirely custom model.
In order to tackle the peculiar challenges of the setting, McMahan et al. [23]

1

introduced Federated Learning (FL). This distributed ML paradigm shifted the
focus towards communication-efficiency and privacy preservation, in accordance
with the principles of focused collection and data minimization outlined in White
House [30]. The algorithm they introduced, Federated Averaging (FedAvg), has
been central to the development of a wide array of direct descendants [13, 18, 19]
and the field as a whole. FedAvg organizes training into rounds, at the beginning
of each round the server sends a global model to all clients which then proceed
train it locally before sending it back for aggregation to create a new global model.
The aggregation step consists off constructing a weighted average of the model
parameters from all clients according to the share of the global training data
that they hold. This simple aggregation mechanism proved empirically effective,
however, it’s limited focus to global model convergence irrespective of the local
training process of each client has been a significant challenge for subsequent
research.
The main issue of concern for this work is what will be referred to as the “localglobal accuracy trade-off”. This topic can be broadly defined as the tendency
of the final trained global model to perform worse on the local data of highly
heterogeneous clients despite good performance on the global distribution [19]. In
some cases, it may be possible that the global model is worse than one they could
have trained entirely locally in spite of the higher training time and data availability
[33]. According to Yu et al. [33], such clients are severely disincentivized from
participating in the training process. While the effect is well-documented when
using FedAvg, no research assessing the impact of newer aggregation algorithms
which further emphasizes global model convergence—such as FedProx [18], has
been found.
The existing body of work on the mitigation of this trade-off has focused on two
primary means of improving performance on heterogeneous clients. Li et al. [19]
propose a Fair Federated Learning (FFL) algorithm which tunes the federated
objective function to focus on clients with large losses in an attempt to smooth-out
the accuracy distribution of the final global model across the client data partitions.
Alternatively, personalization (fine-tuning) methods have been proposed by Yu
et al. [33] and Mansour et al. [22] as a means of quickly constructing effective
2

add
extra

local models for heterogeneous clients after training the global one using a standard
FL algorithm. To date, there has not been an attempt to reconcile the two methods.
Furthermore, little attention has been paid to the practical computational and
engineering cost of either FFL or any of the relevant personalization algorithms.
This work makes three primary contributions to the field of Federated Learning
1. It extends the work of Yu et al. [33] by exploring the impact of personalization
techniques on the FedProx [18] algorithm rather than FedAvg. FedProx
purposefully limits how far a client model can diverge from the global
one during one training round thus affecting highly heterogeneous clients
disproportionately. Experimental results show that the local-global accuracy
trade-off has a higher impact on FedProx than FedAvg and the effect scales
based on the degree of the limitation that model divergence is subject to.

edit

2. Second, it combines q-FedAvg[19] with personalization techniques to assess
if fine-tuning is still beneficial in the context of a fairer accuracy distribution.
This takes into account the computational cost of local adaptation as well
as the disproportionate impact it has upon an ML model lifecycle. Experimental results show that models trained via q-FedAvg are in need of local
adaptation less frequently. Additionally, when they do apply local adaptation it requires fewer rounds on average for the adapted model to exceed the
performance of a purely local one.

edit

3. Third, it proposes a new form of Federated Learning which interleaves
rounds of local training, global aggregation and selective local adaptation,
while keeping compatibility with pre-existing aggregation strategies.

edit

3

Chapter 2
Background and related work (10
page)
Given the recent emergence of the field, a great deal of the published literature is
concerned with the optimization of the fundamental Federated Learning process
with the explicit goal of constructing a well-performing global model. Although
several secondary research directions have been identified, the literature concerning them is largely exploratory in nature. As such, this chapter seeks to address
the fundamentals of FL as a field broadly in the first section while taking a narrow
and detailed view of research relevant to the local-global accuracy trade-off in the
second.

2.1

Federated Learning

Previous sections have referenced the common cross-device client-server FL architecture, however, several alterations have been proposed in the literature. Kairouz
et al. [13, sec 1] distinguishes between two versions of client-server FL. In crosssilo FL, the clients are organizations providing their siloed data. In cross-device
FL, the clients are mobile or IoT devices. They have in common a large federated
network with heterogeneous clients that cannot directly share data, although the
cross-silo condition may be seen as somewhat closer to standard distributed ML
4

given the higher degree of possible coordination and control over the training process. While the findings of this work will likely be relevant to both, future sections
will refer to cross-device FL unless stated otherwise.

2.1.1

Foundational challenges

As previously mentioned, standard FL may can be conceptualized as an attempt
to utilize latent data and computational resources on edge-devices while taking
their non-committal nature into account. The data-transfer ability of clients has
been established as the primary training performance bottleneck of this setting
since the initial work of McMahan et al. [23]. As such, the design space of
centralized client-server FL algorithms has been historically constrained by the
need for communication-efficiency through the maximization of the on-device
computation and minimization of data sharing. Data minimization also plays
a role in the privacy-preserving aspects of FL—which are beyond the scope of
this work. According to the surveys of Kairouz et al. [13] and Li et al. [20], this
paradigmatic shift towards local computation and data storage lead to the following
major challenges being shared across FL systems.
Statistical (data) heterogeneity Data generation and accrual naturally vary
across devices in terms of both quantity and characteristics. Factors such as
sensor capabilities, geographic location, time, or user behaviour may influence
the precise deviations seen by a client [13, sec.3.1]. This heterogeneity results in
data which cannot be assumed, as in traditional ML, to be Independent and Identically Distributed (IID)—as first noted by McMahan et al. [23]. Non-IID data has
been shown to negatively impact both practical accuracy [11, 34] and theoretical
convergence bounds [21]. A variety of contextually beneficial techniques have
been used to restrict the impact of data heterogeneity by either targeting the global
model [11, 13, 18, 19, 21, 34] or creating a personalized one for the final clients
[2, 5, 12, 15, 22, 33].
System (hardware) heterogeneity Devices within the federated network may
differ from one-another in terms of characteristics such as computational ability,

5

Look
at
zhang’s
survey

storage, network speed and reliability and data-gathering hardware. They may also
differ from themselves at a different point in time as their battery power, network
connection, or operational mode vary. Differences in data-generating hardware,
such as sensors, are linked to data heterogeneity. However, the other aspects of
system heterogeneity together with device unreliability create barriers to achieving
fault and straggler-tolerant algorithm capable of accommodating different client
training capabilities.

2.1.2

Federated learning objective

Together, the previously mentioned challenges require that client devices, their
data, and the models they train be seen as distinctly relevant entities from the global
model. Despite this fact, the research to date has tended to predominantly focus on
a Federated Learning objective concerned only with global model performance.
The standard loss function of FL is formulated by Li et al. [20] as seen in Eq. (2.1)
min 𝑓 (𝑤) =

𝑚
∑︁

𝑝 𝑘 𝐹𝑘 (𝑤)

(2.1)

𝑤
𝑘=1

where 𝑓 is the federated global loss function, m is the total number of devices,
w is the model at the beginning of a round, and 𝐹𝑘 is the local loss function of
client 𝑘 weighted by the associated 𝑝 𝑘 . For a total number of training examples 𝑛,
𝑝 𝑘 is typically defined as either the proportion of total training examples held by
the client 𝑛𝑛𝑘 or as the inverse of the total number of clients 𝑚1 . This formulation
of 𝑓 does not optimize for performance on the individual data partitions and may
result in skewed models for clients with a disproportionately large fraction of the
global data pool. Thus, tackling the local-global accuracy trade-off necessitates
changing the FL objective function either explicitly in Fair Federated Learning
(Section 2.2.2) or implicitly through personalization (Section 2.2.3)

2.1.3

FedAvg

The fundamental structure of Federated Averaging, seen in Alg (Algorithm 2), has
been reused to varying extents in a majority of published FL algorithms, including
6

add
citation
and
relevancy
to
current
work

those used in this work—FedProx [18] and q-FedAvg [19]. Since the publication
of McMahan et al. [23], the convergence of the algorithms is known to be highly
dependent on the degree of statistical heterogeneity, number of stragglers, and the
number aggregation rounds relative to local training steps. Specifically, a higher
level of heterogeneity or number of stragglers require increasing the frequency
of aggregation steps or decreasing local training steps to avoid global model
divergence. Since the global data distribution cannot be known prior to training,
the number of necessary aggregation rounds is unpredictable. This is inherited by
q-FedAvg and directly addressed by FedProx.
Algorithm 1 Federated Averaging, adapted from McMahan et al. [23]. Each client
is assumed to handle their training parameters.
Input: 𝑀, 𝐾, 𝑇
1: 𝑤 0 ← init()
2: for each round 𝑡 ← 1, . . . 𝑇 do
3:
𝑛, 𝑂 𝑡 ← 0, ∅
4:
𝑆𝑡 ← K selected clients out of M
5:
for for each client 𝑘 ∈ 𝑆𝑡 do
𝑡
6:
𝑤 𝑡+1
𝑘 ← train(k, 𝑤 )
7:
if 𝑤 𝑡+1
𝑘 ∉ ∅ then
8:
𝑂𝑡 ← 𝑂𝑡 ∪ 𝑘
9:
𝑛 ← 𝑛 + 𝑙𝑒𝑛(𝑘.𝑑𝑎𝑡𝑎)
Í
10:
𝑤 𝑡+1 ← 𝑧∈𝑂 𝑡 𝑙𝑒𝑛(𝑧.𝑑𝑎𝑡𝑎) × 𝑤 𝑡+1
𝑧 /𝑛

2.1.4

The local-global accuracy trade-off

7

Complete

2.1.5

Flower

2.2

Related work

2.2.1

Limiting global model divergence

In order to tackle both statistical and systems heterogeneity, Li et al. [18] introduced
FedProx as a successor to FedAvg capable of tolerating partial work from clients
while smoothing the training process. It achieved this by modifying the local client
training process rather than the aggregation algorithm. The objective function of
a local client 𝐹𝑘 from Eq. (2.1) is combined with a “proximal term” (Eq. (2.2))
min ℎ 𝑘 (𝑤, 𝑤 𝑔 ) = 𝐹𝑘 (𝑤) + 𝜇2 ∥𝑤 𝑔 − 𝑤∥ 2

(2.2)

𝑤

which is meant to limit the distance of its model from the global one in accordance
to the hyperparameter 𝜇.
Discussion The experimental analysis conducted by Li et al. [18] prove that
higher weighing of the proximal term allow FedProx to better handle a certain
degree of statistical heterogeneity or percentage of stragglers. Of interest to this
examination is the interaction between the proximal term and the local-global
accuracy trade-off. Since highly heterogeneous clients would diverge more from
the global model during training, larger weighing of the proximal term should
impact their contribution disproportionately. This potential effect was beyond the
scope of the early FL work conducted by Li et al. [18].

2.2.2

Fair Federated Learning

The canonical loss function of FL presented in 2.1 trains the sole global model
without regards to the distribution of client loss values. Although no global model
can fit the exact distribution of each client, this standard formulation solely emphasizes performance on the average case with regard to the global data distribution.
As such, rather than incurring the training cost of constructing an additional local
model per client, Li et al. [19] propose a form of FL, Fair Federated Learning
8

(FFL), which imposes a different distribution of model performance.
The authors construct the objective function for q-FFL, a specific version of FFL,
as seen in Eq. (2.3)
𝑚
∑︁
𝑝𝑘 𝑞
(2.3)
min 𝑓 (𝑤) =
𝑞+1 𝐹𝑘 (𝑤)
𝑤

𝑘=1

where the new parameter 𝑞 controls the degree of desired fairness. A value of
𝑞 = 0 corresponds to standard FL, while larger values impose an increasingly fairer
distribution. As 𝑞 grows lim𝑞→∞ 𝑞, the objective function approaches optimizing
solely for the client with the largest loss.
Discussion The exact formulation of Eq. (2.3) was proposed by Li et al. [19] in
order to allow for tuning the degree of fairness through a single parameter. The
authors drew inspiration from fair resource allocation in wireless networks [17].
Unlike other potential definitions amounting to a linear or geometric re-weighing of
𝑝 𝑘 , such as those based on generalized Gini Social-evaluation Functions introduced
by Weymark [29], the exponential function of q-FFL has wide implications for
the entire training process. First, Li et al. [19] show that choosing a 𝑞 value is
highly domain specific with optimal q-values ranging from 𝑞 = 0.001 to 𝑞 = 5
across evaluated tasks. Second, the exponential scaling of the loss function heavily
impacts the convergence rate of the global model.
Q-FedAvg
Li et al. [19] show that their adaptation of the FedAvg algorithm to FFL, q-FedAvg
(Algorithm 2), is capable of reducing the variance in global model performance
across clients in a wide variety of task. By carefully tuning the value of 𝑞, the
authors have shown that this is feasible without incurring a significant decrease in
the test-performance of the global model or the convergence speed of the training
process.
To fit the convergence rate of the new 𝑞-based exponential loss function, q-FedAvg
adjusts the step-size of the client training process in relation to 𝑞. Rather than
directly tuning the step size for each client, the authors choose to derive it based on

9

Algorithm 2 Q-FedAvg, adapted from Li et al. [19].
Input: 𝑀, 𝐾, 𝑇
1: 𝑤 0 ← init()
2: for each round 𝑡 ← 1, . . . 𝑇 do
3:
𝑛, 𝑂 𝑡 ← 0, ∅
4:
𝑆𝑡 ← K selected clients out of M
5:
for for each client 𝑘 ∈ 𝑆𝑡 do
𝑡
6:
𝑤 𝑡+1
𝑘 ← train(k, 𝑤 )
7:
if 𝑤 𝑡+1
𝑘 ∉ ∅ then
8:
Δ𝑤 𝑡𝑘 = 𝐿 (𝑤 𝑡 − 𝑤 𝑡+1
𝑘 )
𝑞
9:
Δ𝑡𝑘 = 𝐹𝑘 (𝑤 𝑡 )Δ𝑤 𝑡𝑘
𝑞−1
𝑞
10:
ℎ𝑡𝑘 = 𝑞𝐹𝑘 (𝑤 𝑡 )∥𝑤 𝑡𝑘 ∥ 2 + 𝐿𝐹𝑘 (𝑤 𝑡 )
11:
𝑂𝑡 ← 𝑂𝑡 ∪ 𝑘
Í
Í
𝑡+1
12:
𝑤 ← 𝑤 𝑡 − 𝑧∈𝑂 𝑡 Δ𝑡𝑘 / 𝑧∈𝑂 𝑡 ℎ𝑡𝑘

an estimation the Lipschitz constant—to which the optimal step-size is inversely
related—of the functions gradient for 𝑞 = 0.
Discussion The estimation procedure of the Lipschitz constant consists of tuning a step-size for 𝑞 = 0 and then taking the inverse of the optimum. Despite its
empirical success, this method creates difficulties in assessing the impact of modifying q-FedAvg in manners which affect the convergence rate of the algorithm.
To date, no attempts to extend q-FFL beyond q-FedAvg have been made and no
investigation into its interaction with personalization techniques has been found.

2.2.3

Personalization techniques

On the other end of the spectrum from FFL, personalized local models can be
used to handle client heterogeneity and the local-global accuracy trade-off instead
of tuning the global model. The existing literature on model personalization is
extensive[13, 33], as surveyed by Kulkarni et al. [15], when compared to limited
number of publications on fairness. However, the primary concern of this paper
is in extending the experimental evaluation conducted by Yu et al. [33] which
10

add
citations
add
citations

covered a majority of preponderant techniques.
The experimental analysis of Yu et al. [33] established that not only does the global
model perform worse on highly heterogeneous clients, as previous investigations
had already noted [13, 19], it may produce worse results than training a model
locally. The relevance of this result becomes clear when taking into account the
significantly higher amount of data and computation used during the FL training
process.
Yu et al. [33] apply three distinct personalization methods which operate entirely
locally and do not require server involvement beyond providing a global model.
Fine-tuning (FT) When a client receives a global model after the FL process, it
can apply Fine-tuning (see Paulik et al. [24], Wang et al. [27] and Mansour et al.
[22, Section D.2]) to retrain the model parameters on its own local data. To avoid
potential Catastrophic forgetting [6, 8, 14], Yu et al. [33] also opt to use Freezebase
(FB) as an additional variant of FT which retrains only the top layer.
As noted by Mansour et al. [22, Section 5], the performance of FT in general has
only been demonstrated empirically, the technique lacks any theoretical bounds
on its potential for Catastrophic forgetting. Furthermore, the last layer of a Neural
Network performance has been shown to contribute disproportionately to performance in the sparsity literature [3, 7, 9], thus FB may also be susceptible to
forgetting.
Knowledge Distillation (KD) As an alternative to FT, Knowledge Distillation
(see Hinton et al. [10]) uses the global model as a teacher for a student client
model. While KD technically allows for the two to differ in structure, Yu et al.
[33] opt to maintain the same architecture across both and to initialize the student
with the teachers parameters—making it possible to re-introduce the client model
into FL later. For the pure logit outputs of the global model 𝐺 (𝑥) and client model
𝐶 (𝑥), the client minimizes Eq. (2.4)
𝑙 (𝐶, 𝑥) = 𝛼𝐾 2 𝐿 (𝐶, 𝑥) + (1 − 𝛼)𝐾 𝐿 (𝜎(𝐺 (𝑥) / 𝐾), 𝜎(𝐶 (𝑥) / 𝐾))

11

(2.4)

add
more

where 𝐿 is the client loss function, 𝐾𝑙 is the Kullback-Leibler [16] divergence, 𝜎
is the activation function for the final output, 𝛼 is the weighing of the clients loss
and 𝐾 is the temperature.
Equation (2.4) states the optimization objective as a mixture of minimizing the
loss on the local client data and the 𝐾 𝐿-dstance between the temperature-adjusted
outputs of 𝐺 and 𝐶. It is worth noting the practical similarity of this objective
to that of FedProx [18] from Eq. (2.2) as they both intend to maintain a level of
similarity between the global and local models.
Multi-task Learning (MTL) The task of the global model is to perform well
on the distributions of all clients while the local model must perform on the
distribution of a single client. Similarly to the other techniques, the global model
must be used to create a client model optimized for the local task. Framing this as
a Multi-task Learning (MTL) problem in Eq. (2.5)
𝑙 (𝐶, 𝑥) = 𝐿(𝐶, 𝑥) +

∑︁

2
𝜆
2 𝐹 [𝑖] (𝐶 [𝑖] − 𝐺 [𝑖])

(2.5)

𝑖

where 𝜆 determines the weighing between the two tasks, F is the Fisher information
matrix and 𝑖 indexes model parameters. The loss L optimizes for the client model
while the second term represents the task of improving performance over all
participants—i.e., using the pre-trained global model to improve performance on
the local task. Multiplying the squared distance of parameters by the 𝑖-th entry
of 𝐹 serves the role of mitigating Catastrophic forgetting via the Elastic Weight
Consolidation technique introduced by Kirkpatrick et al. [14]. The 𝐹 [𝑖] term acts
as a surrogate for the second derivative near minimums and serves the purpose of
maintaining weights which are particularly important to the global task loss close
to their initial values.
Discussion The findings of Yu et al. [33] established the strong version of the
local-global accuracy trade-off and serve as foundation for the present investigation.
Their experimental results established the benefits of personalization techniques
as relevant for two categories of clients. Clients with generally inaccurate models
obtain the largest accuracy boost both from FL generally and local adaptation
12

particularly. Those with local models more accurate than the global one gain some
benefit from participating in FL by receiving an adapted model. This paper is
interested in clients falling within both categories.
Yu et al. [33] undertook a relatively narrow research scope with regard to the investigated family of aggregation algorithms. The authors experimented using FedAvg
(Algorithm 2) with two variations in the form of differential privacy [28] and
robust aggregation [31]—both of which have a practical effect of reducing training
effectiveness. Furthermore, the paper makes no attempt to explore potential effects
of re-starting the FL process following personalization.
The literature review presented in this chapter points to several potentially conflicting directions within the field of Federated Learning, caused primarily by
divergent methods of handling heterogeneity Section 2.1.1. These methods reflect
prioritizing either global model convergence and performance (Section 2.2.1) or
its performance on individual client datasets. Prioritizing client performance may
take the form of creating a global model with a performance level more resilient
to their heterogeneity (Section 2.2.2) or by adapting it specifically for each client
(Section 2.2.3). While the two priorities are likely irreconcilable, no evidence for
the incompatibility of the two methods of improving performance on client data
distributions has been found.

13

Read
all
the
new
personalization
references

Chapter 3
Methods (10 page)
3.1

Hypotheses

1. Allowing a higher degree of divergence from the global model during training
reduces the need for local adaptation.
2. Using a fairer global model reduces the need for local adaptation.
3. Targeted local adaptation has a non-negligible cost in terms of both the
number of clients adapted and total training.
4. Using a fair aggregation algorithm or clustering are both more efficient
overall than targeted local adaptation.

3.2

Experimental Setup

The specific set of experiments is designed as to isolate the impact of statistical
heterogeneity on the global and client model accuracies. As such, they are divided
according to the specific goal.
All experiments will share the following characteristics.

14

3.2.1

Proximal Term Tuning

The FedAvg algorithm investigated by Yu et al. [33] is unpredictable in terms of
how far the local client model diverges from the global one received at the start
of the round. Since this divergence is potentially very large, the entire training
process may fail to converge if sufficiently heterogeneous clients are present.
The implications of this upon the accuracy of the global model on local client data
is unclear. The expectation expressed in H.1 is that the heterogeneous clients will
have large changes in the global model and thus impact the overall training process
more resulting in less of a need for local adaptation. However, multiple client
models can diverge in highly contradictory directions thus resulting in a global
model that does not perform particularly well on any one of them.
To tackle this issue, the first set of experiments attempts to answer H.11 by extending the work of Yu et al. [33]. This is achieved by incorporating the proximal term
from FedProx [18]. Values of 𝜇 ∈ {0, 0.5, 1.0} will be tested, 𝜇 = 0 corresponds
to standard FedAvg.
Importantly, the proximal term of FedProx [18] can be incorporated into the local
objective function of a client regardless of the specific aggregation algorithm. As
such, it can be used in conjunction with q-FedAvg[19].

3.2.2

Fairness Tuning

A modified version of q-FedAvg[19] containing the proximal term from FedProx
[18] is used for this set of experiments. The overall goal is to obtain a baseline
for how much accuracy can and needs to be recovered by using local adaptation
techniques after the usage of a fair aggregation algorithm.
The major drawback of q-FedAvg is the need to tune the fairness parameter 𝑞.
Given that Li et al. [19] do not experiment with or provide q-values for the specific
datasets used in this work, new q-values must be chosen for the experimental
design. The procedure for doing so will consist of a hyperparameter search over
potential q-values 𝑞 ∈ [0, 20]. Based on final accuracy and accuracy variance,
alongside 𝑞 = 0 two other q-values will be selected representing a moderate or
15

high degree of fairness.
Following the q-value choice for all datasets, the general set of experiments will
be ran with local adaptation techniques afterwards to again establish a baseline
in terms of the potential benefits of local adaptation when using Fair Federated
Learning.

3.2.3

Targeted Local Adaptation

16

Chapter 4
Results (10 page)

17

Chapter 5
Discussion (10 page)

18

Chapter 6
Summary and Conclusions (3-4)

19

Bibliography
[1] Md. Zahangir Alom, Tarek M. Taha, Chris Yakopcic, Stefan Westberg, Paheding Sidike, Mst Shamima Nasrin, Brian C. Van Essen, Abdul A. S. Awwal,
and Vijayan K. Asari. The history began from alexnet: A comprehensive
survey on deep learning approaches. ArXiv, abs/1803.01164, 2018.
[2] Manoj Ghuhan Arivazhagan, Vinay Aggarwal, Aaditya Kumar Singh, and
Sunav Choudhary. Federated learning with personalization layers. CoRR,
abs/1912.00818, 2019. URL http://arxiv.org/abs/1912.00818.
[3] Guillaume Bellec, David Kappel, Wolfgang Maass, and Robert A. Legenstein. Deep rewiring: Training very sparse deep networks. ArXiv,
abs/1711.05136, 2018.
[4] Ronan Collobert, Jason Weston, Léon Bottou, Michael Karlen, Koray
Kavukcuoglu, and Pavel P. Kuksa. Natural language processing (almost)
from scratch. CoRR, abs/1103.0398, 2011. URL http://arxiv.org/
abs/1103.0398.
[5] Yuyang Deng, Mohammad Mahdi Kamani, and Mehrdad Mahdavi. Adaptive
personalized federated learning. CoRR, abs/2003.13461, 2020. URL https:
//arxiv.org/abs/2003.13461.
[6] Robert M. French. Catastrophic forgetting in connectionist networks.
Trends in Cognitive Sciences, 3(4):128–135, 1999. ISSN 1364-6613.
doi: https://doi.org/10.1016/S1364-6613(99)01294-2. URL https://www.
sciencedirect.com/science/article/pii/S1364661399012942.
[7] Trevor Gale, Erich Elsen, and Sara Hooker. The state of sparsity in deep
neural networks. CoRR, abs/1902.09574, 2019. URL http://arxiv.org/
abs/1902.09574.
[8] Ian J. Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, and Yoshua
Bengio. An empirical investigation of catastrophic forgetting in gradientbased neural networks, 2013. URL https://arxiv.org/abs/1312.6211.
20

[9] Song Han, Jeff Pool, John Tran, and William J. Dally. Learning both weights
and connections for efficient neural networks. In Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume
1, NIPS’15, page 1135–1143, Cambridge, MA, USA, 2015. MIT Press.
[10] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a
neural network, 2015. URL https://arxiv.org/abs/1503.02531.
[11] Kevin Hsieh, Amar Phanishayee, Onur Mutlu, and Phillip Gibbons. The
non-IID data quagmire of decentralized machine learning. In Hal Daumé
III and Aarti Singh, editors, Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine
Learning Research, pages 4387–4398. PMLR, 13–18 Jul 2020. URL
https://proceedings.mlr.press/v119/hsieh20a.html.
[12] Yihan Jiang, Jakub Konečný, Keith Rush, and Sreeram Kannan. Improving
federated learning personalization via model agnostic meta learning. CoRR,
abs/1909.12488, 2019. URL http://arxiv.org/abs/1909.12488.
[13] Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi
Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham
Cormode, Rachel Cummings, et al. Advances and open problems in federated
learning. arXiv preprint arXiv:1912.04977, 2019.
[14] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho,
Agnieszka Grabska-Barwinska, et al. Overcoming catastrophic forgetting in
neural networks. Proceedings of the national academy of sciences, 114(13):
3521–3526, 2017.
[15] Viraj Kulkarni, Milind Kulkarni, and Aniruddha Pant. Survey of personalization techniques for federated learning. In 2020 Fourth World Conference
on Smart Trends in Systems, Security and Sustainability (WorldS4), pages
794–797, 2020. doi: 10.1109/WorldS450073.2020.9210355.
[16] S. Kullback and R. A. Leibler. On Information and Sufficiency. The Annals of Mathematical Statistics, 22(1):79 – 86, 1951. doi: 10.1214/aoms/
1177729694. URL https://doi.org/10.1214/aoms/1177729694.
[17] Tian Lan, David Kao, Mung Chiang, and Ashutosh Sabharwal. An axiomatic
theory of fairness in network resource allocation. In 2010 Proceedings IEEE
INFOCOM, pages 1–9, 2010. doi: 10.1109/INFCOM.2010.5461911.
[18] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar,

21

and Virginia Smith. Federated optimization in heterogeneous networks. arXiv
preprint arXiv:1812.06127, 2018.
[19] Tian Li, Maziar Sanjabi, Ahmad Beirami, and Virginia Smith. Fair resource
allocation in federated learning. arXiv preprint arXiv:1905.10497, 2019.
[20] Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges, methods, and future directions. IEEE Signal
Processing Magazine, 37(3):50–60, 2020.
[21] Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua
Zhang. On the convergence of fedavg on non-iid data. arXiv preprint
arXiv:1907.02189, 2019.
[22] Y. Mansour, Mehryar Mohri, Jae Ro, and Ananda Theertha Suresh. Three
approaches for personalization with applications to federated learning. ArXiv,
abs/2002.10619, 2020.
[23] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
Blaise Aguera y Arcas. Communication-efficient learning of deep networks
from decentralized data. In Artificial intelligence and statistics, pages 1273–
1282. PMLR, 2017.
[24] Matthias Paulik, Matt Seigel, Henry Mason, Dominic Telaar, Joris Kluivers, Rogier van Dalen, Chi Wai Lau, Luke Carlson, Filip Granqvist, Chris
Vandevelde, Sudeep Agarwal, Julien Freudiger, Andrew Byde, Abhishek
Bhowmick, Gaurav Kapoor, Si Beaumont, Áine Cahill, Dominic Hughes,
Omid Javidbakht, Fei Dong, Rehan Rishi, and Stanley Hung. Federated
evaluation and tuning for on-device personalization: System design & applications, 2022. URL https://arxiv.org/pdf/2102.08503.pdf.
[25] Joost Verbraeken, Matthijs Wolting, Jonathan Katzy, Jeroen Kloppenburg,
Tim Verbelen, and Jan S. Rellermeyer. A survey on distributed machine
learning. ACM Comput. Surv., 53(2), mar 2020. ISSN 0360-0300. doi:
10.1145/3377454. URL https://doi.org/10.1145/3377454.
[26] Athanasios Voulodimos, Nikolaos Doulamis, Anastasios Doulamis, Eftychios Protopapadakis, and Diego Andina. Deep learning for computer vision: A brief review. Intell. Neuroscience, 2018, jan 2018. ISSN 1687-5265.
doi: 10.1155/2018/7068349. URL https://doi.org/10.1155/2018/
7068349.
[27] Kangkang Wang, Rajiv Mathews, Chloé Kiddon, Hubert Eichner, Françoise
Beaufays, and Daniel Ramage. Federated evaluation of on-device person-

22

alization. CoRR, abs/1910.10252, 2019. URL http://arxiv.org/abs/
1910.10252.
[28] Kang Wei, Jun Li, Ming Ding, Chuan Ma, Howard H. Yang, Farhad Farokhi,
Shi Jin, Tony Q. S. Quek, and H. Vincent Poor. Federated learning with
differential privacy: Algorithms and performance analysis. IEEE Transactions on Information Forensics and Security, 15:3454–3469, 2020. doi:
10.1109/TIFS.2020.2988575.
[29] John A Weymark. Generalized gini inequality indices. Mathematical Social
Sciences, 1(4):409–430, 1981.
[30] White House. Consumer data privacy in a networked world: A framework for
protecting privacy and promoting innovation in the global digital economy.
Journal of Privacy and Confidentiality, 4(2), Mar. 2013. doi: 10.29012/
jpc.v4i2.623. URL https://journalprivacyconfidentiality.org/
index.php/jpc/article/view/623.
[31] Dong Yin, Yudong Chen, Ramchandran Kannan, and Peter Bartlett.
Byzantine-robust distributed learning: Towards optimal statistical rates. In
International Conference on Machine Learning, pages 5650–5659. PMLR,
2018.
[32] Tom Young, Devamanyu Hazarika, Soujanya Poria, and Erik Cambria. Recent trends in deep learning based natural language processing [review article]. IEEE Computational Intelligence Magazine, 13(3):55–75, 2018. doi:
10.1109/MCI.2018.2840738.
[33] Tao Yu, Eugene Bagdasaryan, and Vitaly Shmatikov. Salvaging federated
learning by local adaptation. arXiv preprint arXiv:2002.04758, 2020.
[34] Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas
Chandra. Federated learning with non-iid data, 2018.

23

Survey of Personalization Techniques for Federated Learning

arXiv:2003.08673v1 [cs.LG] 19 Mar 2020

Viraj Kulkarni1,2 , Milind Kulkarni1 , Aniruddha Pant2
1
Vishwakarma University
2
DeepTek Inc

Abstract
Federated learning enables machine learning models to learn from private decentralized data without
compromising privacy. The standard formulation
of federated learning produces one shared model
for all clients. Statistical heterogeneity due to nonIID distribution of data across devices often leads
to scenarios where, for some clients, the local models trained solely on their private data perform better than the global shared model thus taking away
their incentive to participate in the process. Several techniques have been proposed to personalize
global models to work better for individual clients.
This paper highlights the need for personalization
and surveys recent research on this topic.

1 Introduction
Many datasets are inherently decentralized in nature and
are distributed across multiple devices owned by different
users. Traditional machine learning settings involve aggregating data samples from these users into a central repository
and training a machine learning model on it. This movement
of data from local devices to a central repository poses two
key challenges. Firstly, it compromises the privacy and security of the data. Policies such as the General Data Protection Regulation (GDPR) [1] and Health Insurance Portability
and Accountability Act (HIPAA) [2] stipulate provisions that
make such movement difficult. Secondly, it imposes communication overheads which, depending on the setting, may be
prohibitively expensive.
Federated learning [3] is a framework that enables multiple
users known as clients to collaboratively train a shared global
model on their collective data without moving the data from
their local devices. A central server orchestrates the federated
learning process which consists of multiple rounds. At the
beginning of each round, the server sends the current global
model to the participating clients. Each client trains the model
on its local data and communicates only the model updates
back to the server. The server collects these updates from all
clients and makes a single update to the global model thereby
concluding the round. By removing the need to aggregate all
data on a single device, federated learning overcomes the pri-

vacy and communication challenges mentioned above and allows machine learning models to learn on decentralized data.
Federated learning has found numerous practical applications where data is decentralized and privacy is important.
For example, it has exhibited good performance and robustness for the problem of next-word-prediction on mobile devices [4]. Bonawitz et. al. [5] propose a scalable system
implementing large-scale federated learning for mobile devices. Kairouz et. al. [6] discuss broad challenges and open
problems in the field.
The primary incentive for clients to participate in federated
learning is obtaining better models. Clients who have insufficient private data to develop accurate local models stand to
benefit the most from collaboratively learned models. However, the benefit of participating in federated learning for
clients who have sufficient private data to train accurate local models is disputable. Yu et al. [7] show that, for many
tasks, some participants may gain no benefit by participating
since the global shared model is less accurate than the local
models they can train on their own. Hanzely et al. [8] question the utility of a global model that is too far removed from
the typical usage of a user. The distribution of data across
clients is highly non-IID for many applications. This statistical heterogeneity makes it difficult to train a single model that
will work well for all clients. The purpose of this paper is to
survey recent research regarding building personalized models for clients in a federated learning setting that are expected
to work better than the global shared model or the local individual models.

2 Need for Personalization
Wu et al. [9] list three challenges faced by federated learning
systems related to personalization: (1) device heterogeneity
in terms of storage, computation, and communication capabilities; (2) data heterogeneity arising due to non-IID distribution of data; (3) model heterogeneity arising from situations
where different clients need models specifically customized
to their environment. As an example of model heterogeneity, consider the sentence: “I live in .....”. The next-wordprediction task applied on this sentence needs to predict a
different answer customized for each user. If heterogeneity
does not exist in the data, it may exist in the labels; different
clients may assign different labels to the same data.

In the original federated learning design of McMahan et
al. [3], the model updates and the final model can leak participant data violating privacy [10] [11]. To preserve privacy,
McMahan et al. [12] propose differential privacy techniques
that limit the information the global model can reveal about
individual participants. However, Yu et al. [7] argue that such
privacy protection mechanisms introduce a fundamental conflict between protecting privacy and achieving higher performance for individual users. Bagdasaryan et al. [13] state that
the cost of differential privacy mechanisms is the reduction in
accuracy, and this cost is borne unequally by clients with the
underrepresented or tail participants being affected the worst.
Personalization of the global model becomes necessary to
handle the challenges posed by statistical heterogeneity and
non-IID distribution of data. Most techniques for personalization [14] generally involve two discrete steps. In the first
step, a global model is built in a collaborative fashion. In
the second step, the global model is personalized for each
client using the client’s private data. Jiang et al. [15] argue that optimizing solely for global accuracy yields models that are harder to personalize and propose that, in order
to make federated learning personalization useful in practice,
the three following objectives must all be addressed simultaneously and not independently: (1) developing improved personalized models that benefit a large majority of clients; (2)
developing an accurate global model that benefits clients who
have limited private data for personalization; (3) attaining fast
model convergence in a small number of training rounds. Out
of the local data samples stored with each client, it may happen that only a subset of samples are relevant for a particular
task, while the irrelevant samples adversely affect the model
training. Tuor et al. [16] propose a method where a relevance
model built on a small benchmark set is used to separate relevant and irrelevant samples at each client, and only the relevant samples are used in the federated learning process.

3 Techniques
This section surveys different methods for adapting global
models for individual clients.

3.1

Adding User Context

Before presenting methods to personalize a global model for
individual clients, we take a moment to point out that a shared
global model can also generate highly personalized predictions if the client’s context and personal information is suitably featurized and incorporated in the dataset. However,
most public datasets do not contain contextual features, and
developing techniques to effectively incorporate context remains an important open problem that has great potential to
improve the utility of federated learning models [6]. It also
remains to be studied if such context featurization can be performed without adversely affecting privacy. As an intermediate approach between a single global model and purely local models, Masour et al. [17] suggest user clustering where
similar clients are grouped together and a separate model is
trained for each group.

3.2

Transfer Learning

Transfer learning [18] enables deep learning models to utilize the knowledge gained in solving one problem to solve
another related problem. Schneider and Vlachos [19] discuss
using transfer learning to achieve model personalization in
non-federated settings. Transfer learning has also been used
in federated settings, e.g. Wang et al. [20], where some or
all parameters of a trained global model are re-learned on local data. A learning-theoretic framework with generalization
guarantees is provided in [17]. By using the parameters of the
trained global model to initialize training on local data, transfer learning is able to take advantage of the knowledge extracted by the global model instead of learning it from scratch.
To avoid the problem of catastrophic forgetting [21] [22], care
must be taken to not retrain the model for too long on local
data. A variant technique freezes the base layers of the global
model and retrains only the top layers on local data. Transfer
learning is also known as fine-tuning, and it integrates well
into the typical federated learning lifecycle.

3.3

Multi-task Learning

In multi-task learning [23], multiple related tasks are solved
simultaneously allowing the model to exploit commonalities and differences across the tasks by learning them jointly.
Smith et al. [24] show that multi-task learning is a natural
choice to build personalized federated models and develop
the MOCHA algorithm for multi-task learning in the federated setting that tackles challenges related to communication,
stragglers, and fault tolerance. One drawback of using multitask learning in federated settings is that since it produces one
model per task, it is essential that all clients participate in every round.

3.4

Meta-Learning

Meta-learning involves training on multiple learning tasks to
generate highly-adaptable models that can further learn to
solve new tasks with only a small number of training examples. Finn et al. [25] propose a model-agnostic meta-learning
(MAML) algorithm that is compatible with any model that is
trained using gradient descent. MAML builds an internal representation generally suitable for multiple tasks, so that fine
tuning the top layers for a new task can produce good results.
MAML proceeds in two connected stages: meta-training and
meta-testing. Meta-training builds the global model on multiple tasks, and meta-testing adapts the global model individually for separate tasks.
Jiang et al. [15] point out that if we consider the federated learning process as meta-training and the personalization
process as meta-testing, then Federated Averaging [3] is very
similar to Reptile [26], a popular MAML algorithm. The authors also make the observation that careful fine-tuning can
produce a global model with high accuracy that can be easily personalized, but naively optimizing for global accuracy
can hurt the model’s ability for subsequent personalization.
While other personalization approaches for federated learning treat development of the global model and its personalization as two distinct activities, Jiang et al. [15] propose
a modification to the Federated Averaging algorithm that al-

lows both to be addressed simultaneously resulting in better
personalized models.
A new formulation of the standard federated learning problem proposed by Fallah et al. [27] incorporates MAML and
seeks to find a global model which performs well after each
user updates it with respect to its own loss function. In addition, they propose Per-FedAvg, a personalized variant of
Federated Averaging, to solve the above-mentioned formulation. Khodak et al. [28] propose ARUBA, a meta-learning algorithm inspired by online convex optimization, and demonstrate an improvement in performance by applying it to Federated Averaging. Chen et al. [29] present a federated metalearning framework for building personalized recommendation models where both the algorithm and the model are parameterized and need to be optimized.

3.5

Knowledge Distillation

Caruana et al. [23] have demonstrated that it is possible to
compress the knowledge of an ensemble of models into a
single model which is easier to deploy. Knowledge distillation [30] further develops this idea and involves extracting
the knowledge of a large teacher network into a smaller student network by having the student mimic the teacher. Overfitting poses a significant challenge during personalization,
especially for clients whose local dataset is small. Yu et al.
[7] propose that by treating the global federated model as the
teacher and the personalized model as the student, the effects of overfitting during personalization can be mitigated.
Li et al. [31] propose FedMD, a federated learning framework
based on knowledge distillation and transfer learning that allows clients to independently design their own networks using their local private datasets and a global public dataset.

3.6

Base + Personalization Layers

In typical federated learning scenarios, data distribution
varies greatly across participating devices. To temper the adverse effects of this statistical heterogeneity, Arivazhagan et
al. [32] propose FedPer, a neural network architecture where
the base layers are trained centrally by Federated Averaging, and the top layers (also called personalization layers) are
trained locally with a variant of gradient descent. As opposed
to transfer learning where all the layers are first trained on
global data and then all or some layers are retrained on local
data, FedPer separately trains the base layers on global data
and the personalization layers on local data.

3.7

Mixture of Global and Local Models

The standard formulation of federated learning [3] is designed to find a single global model trained on private data
across all clients. Hanzely et al. [8] propose a different
formulation of the problem that seeks an explicit trade-off
between the global model and the local models. Instead of
learning a single global model, each device learns a mixture
of the global model and its own local model. To solve the
formulation, the authors develop a new variant of gradient
descent called Loopless Local Gradient Descent (LLGD). Instead of performing full averaging, LLGD only takes steps
towards averaging thus suggesting that full averaging methods such as Federated Averaging might be too aggressive.

4 Discussion
Federated learning encompasses a wide variety of settings,
devices, and datasets. When local datasets are small and the
data distribution is IID, global models typically outperform
local models, and a majority of clients benefit from participating in the federated learning process. However, when clients
have sufficiently large private datasets and the data distribution is non-IID, local models exhibit better performance than
the shared global model, and clients have no incentive to participate in the federated learning process. An open theoretical
question is to determine the conditions under which shared
global models can perform better than individual local models.
This paper surveys personalization techniques used to
adapt a global federated model to individual clients. With a
few exceptions, most prior work is focussed on measuring the
performance of the global model on aggregated data instead
of measuring its performance as seen by individual clients.
Global performance, however, has no relevance if the global
model is expected to be subsequently personalized before being put to use.
Personalized models usually show better performance for
individual clients than global or local models. In some cases,
however, personalized models fail to reach the same performance as local models, especially when differential privacy
and robust aggregation is implemented [7].

References
[1] P. Voigt and A. Von dem Bussche, “The eu general data
protection regulation (gdpr),” A Practical Guide, 1st
Ed., Cham: Springer International Publishing, 2017.
[2] G. J. Annas et al., “Hipaa regulations-a new era of
medical-record privacy?,” New England Journal of
Medicine, vol. 348, no. 15, pp. 1486–1490, 2003.
[3] H. B. McMahan, E. Moore, D. Ramage, S. Hampson, et al., “Communication-efficient learning of deep
networks from decentralized data,” arXiv preprint
arXiv:1602.05629, 2016.
[4] A. Hard, K. Rao, R. Mathews, S. Ramaswamy, F. Beaufays, S. Augenstein, H. Eichner, C. Kiddon, and D. Ramage, “Federated learning for mobile keyboard prediction,” arXiv preprint arXiv:1811.03604, 2018.
[5] K. Bonawitz, H. Eichner, W. Grieskamp, D. Huba,
A. Ingerman, V. Ivanov, C. Kiddon, J. Konecny, S. Mazzocchi, H. B. McMahan, et al., “Towards federated
learning at scale: System design,” arXiv preprint
arXiv:1902.01046, 2019.
[6] P. Kairouz, H. B. McMahan, B. Avent, A. Bellet,
M. Bennis, A. N. Bhagoji, K. Bonawitz, Z. Charles,
G. Cormode, R. Cummings, et al., “Advances and
open problems in federated learning,” arXiv preprint
arXiv:1912.04977, 2019.
[7] T. Yu, E. Bagdasaryan, and V. Shmatikov, “Salvaging
federated learning by local adaptation,” arXiv preprint
arXiv:2002.04758, 2020.

[8] F. Hanzely and P. Richtárik, “Federated learning of a
mixture of global and local models,” arXiv preprint
arXiv:2002.05516, 2020.
[9] Q. Wu, K. He, and X. Chen, “Personalized federated
learning for intelligent iot applications: A cloud-edge
based framework,” arXiv preprint arXiv:2002.10671,
2020.
[10] R. Shokri, M. Stronati, C. Song, and V. Shmatikov,
“Membership inference attacks against machine learning models,” in 2017 IEEE Symposium on Security and
Privacy (SP), pp. 3–18, IEEE, 2017.
[11] L. Melis, C. Song, E. De Cristofaro, and V. Shmatikov,
“Exploiting unintended feature leakage in collaborative
learning,” in 2019 IEEE Symposium on Security and
Privacy (SP), pp. 691–706, IEEE, 2019.
[12] H. B. McMahan, D. Ramage, K. Talwar, and L. Zhang,
“Learning differentially private recurrent language
models,” arXiv preprint arXiv:1710.06963, 2017.
[13] E. Bagdasaryan, O. Poursaeed, and V. Shmatikov, “Differential privacy has disparate impact on model accuracy,” in Advances in Neural Information Processing
Systems, pp. 15453–15462, 2019.
[14] K. C. Sim, P. Zadrazil, and F. Beaufays, “An investigation into on-device personalization of end-to-end
automatic speech recognition models,” arXiv preprint
arXiv:1909.06678, 2019.
[15] Y. Jiang, J. Konecny, K. Rush, and S. Kannan, “Improving federated learning personalization via model agnostic meta learning,” arXiv preprint arXiv:1909.12488,
2019.
[16] T. Tuor, S. Wang, B. J. Ko, C. Liu, and K. K. Leung, “Data selection for federated learning with relevant and irrelevant data at clients,” arXiv preprint
arXiv:2001.08300, 2020.
[17] Y. Mansour, M. Mohri, J. Ro, and A. T. Suresh, “Three
approaches for personalization with applications to
federated learning,” arXiv preprint arXiv:2002.10619,
2020.
[18] L. Y. Pratt, “Discriminability-based transfer between
neural networks,” in Advances in neural information
processing systems, pp. 204–211, 1993.
[19] J. Schneider and M. Vlachos, “Mass personalization of
deep learning,” arXiv preprint arXiv:1909.02803, 2019.
[20] K. Wang, R. Mathews, C. Kiddon, H. Eichner,
F. Beaufays, and D. Ramage, “Federated evaluation of on-device personalization,” arXiv preprint
arXiv:1910.10252, 2019.
[21] M. McCloskey and N. J. Cohen, “Catastrophic interference in connectionist networks: The sequential learning problem,” in Psychology of learning and motivation,
vol. 24, pp. 109–165, Elsevier, 1989.
[22] R. M. French, “Catastrophic forgetting in connectionist
networks,” Trends in cognitive sciences, vol. 3, no. 4,
pp. 128–135, 1999.

[23] R. Caruana, “Multitask learning,” Machine learning,
vol. 28, no. 1, pp. 41–75, 1997.
[24] V. Smith, C.-K. Chiang, M. Sanjabi, and A. S. Talwalkar, “Federated multi-task learning,” in Advances
in Neural Information Processing Systems, pp. 4424–
4434, 2017.
[25] C. Finn, P. Abbeel, and S. Levine, “Model-agnostic
meta-learning for fast adaptation of deep networks,” in
Proceedings of the 34th International Conference on
Machine Learning-Volume 70, pp. 1126–1135, JMLR.
org, 2017.
[26] A. Nichol, J. Achiam, and J. Schulman, “On
first-order meta-learning algorithms,” arXiv preprint
arXiv:1803.02999, 2018.
[27] A. Fallah, A. Mokhtari, and A. Ozdaglar, “Personalized
federated learning: A meta-learning approach,” arXiv
preprint arXiv:2002.07948, 2020.
[28] M. Khodak, M.-F. F. Balcan, and A. S. Talwalkar,
“Adaptive gradient-based meta-learning methods,” in
Advances in Neural Information Processing Systems,
pp. 5915–5926, 2019.
[29] F. Chen, Z. Dong, Z. Li, and X. He, “Federated
meta-learning for recommendation,” arXiv preprint
arXiv:1802.07876, 2018.
[30] G. Hinton, O. Vinyals, and J. Dean, “Distilling
the knowledge in a neural network,” arXiv preprint
arXiv:1503.02531, 2015.
[31] D. Li and J. Wang, “Fedmd: Heterogenous federated learning via model distillation,” arXiv preprint
arXiv:1910.03581, 2019.
[32] M. G. Arivazhagan, V. Aggarwal, A. K. Singh, and
S. Choudhary, “Federated learning with personalization
layers,” arXiv preprint arXiv:1912.00818, 2019.

Tackling the Impact of System and Data Heterogeneity on the Global
and Local Accuracy of Federated Learning

Alexandru-Andrei Iacob
Computer Laboratory
University of Cambridge

aai30@cam.ac.uk

Abstract
Federated Learning is a form of distributed Machine Learning working over large
numbers of resource constrained devices. It attempts to reduce communication costs
by alternating local (on-device) training with global (server-side) aggregation of model
parameters without ever directly sharing client data. While Federated Learning was
initially proposed as a way of training an accurate global model, recent work has shifted
towards optimising the accuracy of both the local model of a given client and the
global model. However, the high degree of statistical heterogeneity between the data
partitions of each client, together with differences in client system specifications, make
the simultaneous balancing of these two goals difficult. This research proposal reviews
the recent work in the field and suggests ways of handling data and system heterogeneity
by leveraging advances in Federated Learning and Neural Architecture Search. This can
be achieved by applying model adaptation techniques—such as clustering—for clients
with heterogeneous data, and optimizing the amount of local computation based on client
resources through reinforcement learning.

1

Introduction

The canonical Federated Learning (FL) problem was introduced by McMahan et al. [2017]. The optimization objective of FL was formalised by Li et al. [2018] as follows:
minw f (w) =

n
X

pk Fk (w),

k=1

where f is the objective function of the global model, formed as a weighted sum of the local client objective
functions Fk weighed by factors pk . Multiple versions of FL have since been devised (see Kairouz et al.
[2019]). This proposal focuses on the standard FL: the setting where a centralised server coordinates
training rounds.
The primary challenges which differentiate FL from other distributed Machine Learning methodologies
are data and system heterogeneity.
Data Heterogeneity: Devices may hold data partitions which are highly dissimilar from the global
distribution. Data heterogeneity encompasses multiple potential divergences which depend on the features,
labels, and quantity of data. For an overview, see Kairouz et al. [2019, sec. 3].
System Heterogeneity: Devices operating within the federated network are unlikely to have uniform
hardware specifications or reliable internet connections. As such, clients may disconnect during the training
process. Abdelmoniem et al. [2021] provide an investigation of the impact of system heterogeneity on FL
performance.
Yu et al. [2020], Kulkarni et al. [2020], and, Mansour et al. [2020b] have challenged the canonical objective
of training a shared global model. As indicated by Yu et al. [2020], global models perform significantly
worse for clients with unusual data and/or system characteristics. Consequently, optimizing solely for the
average global case means that such clients receive negligible benefit—outside of time efficiency—from
participating in the Federated Learning process compared to training a local model directly.

This local–global accuracy trade-off interacts with both data and system heterogeneity as well as the
architecture of the model being trained.

2

Proposal

The primary goal is to tackle the local–global trade-off while accounting for data and system heterogeneity.
This can be achieved via a combination of methods, each of which handles a different part of the problem
and could be applied independently.
2.1

System Heterogeneity

Li et al. [2018] introduces FedProx, an aggregation algorithm capable of handling system heterogeneity by
allowing for a varying amount of local training to be completed. However, the number of local updates must
be specified as no means of automatically determining the amount of local computation to be performed is
provided.
I propose a system for predicting local hyper-parameters, such as the number of epochs (times a model
is trained over the data), based on the model architecture and client system characteristics. The system
would encode the model architecture using a learnt neural representation, or embedding, such as arch2vec
[Yan et al., 2020] from the field of Neural Architecture Search. Client system characteristics would be
initially summarised using a hand-crafted feature vector. In order to train the system to predict values
for a given hyper-parameter, a reinforcement learning algorithm—such as the one presented by Williams
[1992]—would be applied during training with each client as an agent capable of learning parameter
settings from experience. This design is necessary to make the problem computationally tractable.
Federated Learning has a substantial training time and using such an embedding is crucial to allow transfer
between architectures to avoid re-training on each individual model. Furthermore, using the accuracy from
each training round rather than the final model accuracy alone—as other optimization methodologies like
genetic algorithms do—is necessary for efficiency and is the primary motivation for applying reinforcement
learning. It deserves mentioning that neural architecture representation is novel and therefore not tested
extensively.
2.2

Data Heterogeneity

While the above method handles system heterogeneity, it does not directly address data heterogeneity.
In fact, the system may fail to provide good local parameters if the data distribution of a client differs
significantly from those used in training. Consequently, training must be done alongside a technique that
mitigates the impact of data heterogeneity. The next section explores some potential solutions.
2.2.1

Clustering

Grouping, or clustering, clients with similar data and systems around a mutual server can help the
convergence of aggregate models by providing a balance between local versus cluster accuracy. The
version of clustering which is of interest in FL is that proposed by Mansour et al. [2020b], which groups
clients by minimising a loss function. This means that clients requiring similar models end up on the
same cluster. The work of Mansour et al. [2020b] can be developed through better initialization using
a procedure similar to Arthur and Vassilvitskii [2006]’s, or by applying one of the methods presented
by Yuan and Yang [2019]. In order for a clustered algorithm to interoperate with the local computation
optimizer, a version of the optimizer would have to be trained on each cluster. Consequently, the number
of clusters should be fairly low.
It is noteworthy that once clustering is applied, a single global model ceases to exist. In order to use
clustering in situations where a global model is necessary, we require a way to aggregate the models trained
for each cluster. A standard ensemble technique could be applied [Dong et al., 2020], however, I favour
using an iterative voting method for categorical tasks [Meir, 2017]. Iterative voting is a new development
in the field of Computational Social Choice [Brandt et al., 2016] where voting proceeds in rounds and
voters may change their preferred output. Previous investigations conducted during my undergraduate
research work indicate that this method of voting may improve compromise within a group of agents. If
applied, it would represent one of the first uses of iterative voting in a practical setting.
2

3

Related Work

The work of McMahan et al. [2017] directly poses some of the challenges tackled by this proposal. The
authors justified the need for Federated Learning on the basis of communication efficiency and privacy
by following the principles of focused collection and data minimisation outlined in White House [2013].
While privacy concerns in FL are outside the scope of this proposal, the curious reader may investigate
differential privacy [McMahan et al., 2018, Wei et al., 2020], secure aggregation [Segal et al., 2017], or the
overview provided by Kairouz et al. [2019, sec. 4].
While their update-averaging algorithm—FedAvg (A.1)—proved resilient towards data heterogeneity when
training a global model in practice, it did not offer a means of handling system heterogeneity directly, nor
did it provide strong bounds on the impact of highly unbalanced data distributions, resulting in potential
scenarios with large performance degradation.
Since the publication of McMahan et al. [2017], a series of methods for enhancing the usefulness of FL
in highly heterogeneous scenarios have been proposed. Furthermore, solutions tackling the previously
mentioned local–global accuracy trade-off are novel and warrant being addressed independently—although
they do occasionally address statistical heterogeneity as well.
3.1

Tackling Heterogeneity When Training a Global Model

Zhao et al. [2018] provide a bound on the impact of a skewed data distribution on model accuracy and
attempt to rectify its effects by using a small, globally shared data pool, deviating from the goal of Federated
Learning. Smith et al. [2018] tackle both data and system heterogeneity through MOCHA, a federated
multi-task learning framework which attempts to construct related models for each device. However, their
work is incapable of handling non-convex deep learning models.
From a pure system heterogeneity perspective, there have been two dominant directions: decreasing
computational, communication and memory costs, thus allowing more clients to participate; or allowing
for clients to provide varying contributions to the global model and to carry out different amounts of local
computation.
While reducing communication and computational costs has been a focus from the start (see the structured
and sketched updates introduced by Konečný et al. [2017]), it was intended to improve overall system
efficiency given slow internet connections rather than to allow clients with worse specifications to participate. Caldas et al. [2018] reduce communication costs by applying compression to both server-client
and client-server communication and reduce local computation costs via Federated Dropout—a technique
which allows each device to locally operate on a smaller sub-model of the overall architecture—with the
goal of allowing a wider array of client systems to participate in training. These methods are generic and
do not necessitate large changes to the overall aggregation algorithm, however, nor do they address the
root cause of the issue: they do not distinguish between the client system specifications. As such, they are
complementary to all methods proposed in this work.
Of higher interest is the aforementioned FedProx [Li et al., 2018], which operates similarly to FedAvg while
also accounting for system heterogeneity by allowing different amounts of work to be completed across
clients. Consequently, limiting how far each client model can diverge from the global via a “proximal
term” is necessary to obtain convergence for highly heterogeneous scenarios where some clients may
perform significantly less work than average. FedProx illustrates some of the challenges of FL aggregation
algorithms which have inspired this proposal as it does not define a standard means of deciding how much
work a client should do or how far a client model should diverge. Furthermore, it handles neither data
heterogeneity nor local–global trade-off.
3.2

Tackling local–global Accuracy Trade-off

As discussed, the lower accuracy that underrepresented clients receive is inherently tied to either their
statistical heterogeneity (they have unusual data), system heterogeneity (they do not get to participate in
training as much because of worse hardware), or both. One of the early systems, FedPer, which attempts to
address this issue was conceived by Arivazhagan et al. [2019]. FedPer allows all clients to train a set of
shared base layers in the Neural Network, while individual personalisation is achieved via one or more
top layers being trained for each client separately. Such layers help in situations with high statistical
heterogeneity while reducing variation between client accuracies.
Multiple other methods of personalisation, or local-adaptation, have been developed and applied since.
These have been covered and experimentally validated in the work of Yu et al. [2020]. They range from a
similar personalisation-layer setup Arivazhagan et al. [2019] to knowledge distillation [Hinton et al., 2015,
3

give equation

Gou et al., 2021] and multi-task learning [Kirkpatrick et al., 2017, Zhang and Yang, 2021] approaches.
Although such methods are generally applicable, they have two major shortcomings. First, they do not
intend to account for system heterogeneity explicitly. Second, they have been extensively tested alongside
FedAvg, makeing their interaction with more complex aggregation algorithms such as FedProx unclear.
Most influential towards the proposed system is Mansour et al. [2020a]. Their work focuses on developing
efficient personalisation methods. Specifically, they refer to data interpolation, model interpolation, and
client clustering. Data interpolation is applied after first training the global model by adapting a client
model initialised from the global one to minimise the chosen loss function over a combination of the client
data and the global data. Model interpolation refers to training both a local client model alongside the
global one. Their clustering personalisation method, HYPCLUSTER (), is particularly well-suited towards
a generic FL optimisation system as it does not require large changes to the aggregation algorithm and
can be used to tackle both local–global trade-off and data heterogeneity. It works similarly to k-means by
constructing a set of clusters, randomly sampling a number of clients and assigning them to the cluster
with lowest loss, and finally running an FL algorithm for each cluster thus updating the cluster models.
This design makes it ideal for interoperation with any black-box optimisation method as each cluster can
be paired with its own optimization process.
3.3

Model Aware Parameter Optimisation

While a survey of Reinforcement Learning (RL) [Arulkumaran et al., 2017, Kaelbling et al., 1996]—or
hyper-parameter optimisation [Yang and Shami, 2020] in general—and Neural Architecture Search [Elsken
et al., 2019, Wistuba et al., 2019, Ren et al., 2020] is beyond the scope of this work, two research directions
related to these fields warrant discussion.
To tackle large search spaces and allow for transfer-learning [Zhuang et al., 2021] to occur, recent work
in hyper-parameter optimisation has shifted from operating on a case-by-case basis, with complete handcrafted encodings, towards learnt abstract representations.
This shift is evident when considering device placement optimisation for computation graphs. REGAL
[Paliwal et al., 2019] uses a Graph Neural Network (GNN) [Wu et al., 2021] to construct node embeddings.
Such embeddings are then inputted into a policy network to predict the starting parameters of a genetic
algorithm, which does device placement optimisation, on a per-node basis. For training, it applies the
REINFORCE [Williams, 1992] algorithm with the memory consumption of the device placement found by
the genetic algorithm as its reward function. Concurrently with REGAL, Placeto [Addanki et al., 2019] use
a similar GNN-based embedding and RL algorithm to directly optimise device placement by outputting a
node placement based on both the current node’s embedding and the device placement of previous nodes.
To adapt such transferable approaches towards parameter optimisation to FL, it is necessary to construct an
embedding of the entire model which is being trained. A potential solution comes from the field of Neural
Architecture Search (NAS), an area which has seen its own shift from explicit complete encodings to more
generaliseable search spaces. Arch2vec [Yan et al., 2020] is a recent attempt at an unsupervised neural
architecture representation constructed outside the NAS process, without requiring the usage of accuracies
as labels. The authors find that their means of unsupervised encoding is a useful pre-processing step for
NAS because it projects similar architectures to similar, compact representations.

4

First-year Outline

The first year of research will be primarily dedicated towards constructing a research prototype (pilot
experiment) while investigating any new developments in the field. Notably, my main project for the MPhil
in Advanced Computer Science focuses on an empirical examination of the personalisation techniques
presented in Yu et al. [2020]. Any relevant findings will therefore be used to inform the first-year research
work.
Given the exploratory nature of the work, the following outline will be quite broad and cover the 9-month
period between the start of Michaelmas term and the first-year review on the 30th of June.
Months 1 and 2: Dedicated to detailed research on recent findings in the field, planning the experimental
design alongside a preliminary estimation of the necessary computational resources to carry out the
experimental design. Exploration of alternative avenues and potential improvements with supervisor
discussion and feedback.
4

add appendix

Months 3 and 4: Prototype implementation, using the Flower [Beutel et al., 2020] Federated Learning
framework to orchestrate the experiments. This will result in the delivery of the clustering algorithm to
Flower as well as an initial implementation of the federated Reinforcement Learning algorithm and model
embeddings. Running the small-scale experiments to gather preliminary data and practically decide the
viability of the proposed research direction. If the prototype does not prove viable, a series of alternative
optimisation methods, embeddings or different approaches may be considered to replace it (sec.5). It may
be possible to begin writing parts of the problem statement, introduction and background sections for the
first-year review document.
Months 5 and 6: If the prototype proves practical, the planned experiments will be carried out. Experimental write-up and interpretation for the first-year review will begin after the experiments are finished.
According to the results, the overall plan and course for the PhD will be re-evaluated—with input from the
supervisor—in preparation for the first-year review.
Months 7 and 8: First-year review document full write-up in parallel with the exploration of potential
avenues for developing a full system ready to be used externally and capable of being extended to other
research directions. A full draft should be finished within the first weeks of month 8 and sent out to the
supervisor for feedback.
Final month and first-year review: The period before the first-year review will be dedicated towards
editing and finalising the document while preparing for the oral examination. Based on assessor feedback,
all necessary modifications to the overall plan and first-year review document will be incorporated before
being sent to the Secretary of the Degree Committee.

5

Research Considerations

Reinforcement Learning Structure: Adapting Reinforcement Learning—initially intended for developing policies for agents that interact with a clearly defined environment—towards this abstract domain is not
straightforward. REGAL [Paliwal et al., 2019] receives one reward signal based on the performance of the
device placement solution found by the genetic algorithm, while Placeto [Addanki et al., 2019] allows for
intermediate rewards. In the context of the proposed system, two different approaches are apparent at the
time of writing. One would consider performance on the validation set at the end, whereas the other would
re-test performance either after every aggregation round or at set intervals while taking actions to change
hyper-parameters during training—a potential necessity to make the problem computationally tractable.
An argument could be made for the usefulness of having two reward signals: the first signal from the
performance on the cluster-level model validation performance and the second from client-level validation
performance using that client’s local data. Finally, RL has difficulties with large action spaces, as such,
optimising continuous hyper-parameters or trying to handle large numbers of them would require careful
consideration of the action space design.
Alternative Optimisation Methods: While Reinforcement Learning was initially considered because
of its promising application to device placement, it is not guaranteed to be successful given the large
training times—especially if rewards are only registered at the end of the entire training process—and
complexities of Federated Learning. Such difficulties would also affect other optimisation methods, e.g.
genetic algorithms, relying on a high number of evaluations. One viable alternative would be Bayesian
Optimisation [Frazier, 2018] because of its ability to minimise evaluations through the acquisition function
for selecting promising candidates. However, it is known that Bayesian Optimisation has difficulties scaling
to high-dimensional spaces [Shahriari et al., 2016], which may pose future challenges as FL algorithms
grow in terms of hyper-parameter count.

6

Conclusion

As a paradigm meant to allow computation on client devices and to restrict data-sharing as much as possible,
Federated Learning distinctly suffers from data and system heterogeneity, as well as a conflict between
the goal of training a global model and providing good results for each client’s particular characteristics.
This proposal has surveyed previous work addressing these issues and proposed several methods which
complement one-another—parameter optimisation for local computation, clustering, and iterative-voting
based ensembles—and could be used to construct a new FL system which is compatible with previous
aggregation algorithms. Such methods are intended as a starting point for PhD research and are meant to
evolve over the course of the first year.
5

References
Ahmed M Abdelmoniem, Chen-Yu Ho, Pantelis Papageorgiou, Muhammad Bilal, and Marco Canini. On the impact of
device and behavioral heterogeneity in federated learning. arXiv preprint arXiv:2102.07500, 2021.
Ravichandra Addanki, Shaileshh Bojja Venkatakrishnan, Shreyan Gupta, Hongzi Mao, and Mohammad Alizadeh.
Placeto: Learning generalizable device placement algorithms for distributed machine learning, 2019.
Manoj Ghuhan Arivazhagan, Vinay Aggarwal, Aaditya Kumar Singh, and Sunav Choudhary. Federated learning with
personalization layers, 2019.
David Arthur and Sergei Vassilvitskii. k-means++: The advantages of careful seeding. Technical Report 2006-13,
Stanford InfoLab, June 2006. URL http://ilpubs.stanford.edu:8090/778/.
Kai Arulkumaran, Marc Peter Deisenroth, Miles Brundage, and Anil Anthony Bharath. Deep reinforcement learning:
A brief survey. IEEE Signal Processing Magazine, 34(6):26–38, 2017. doi: 10.1109/MSP.2017.2743240.
Daniel J Beutel, Taner Topal, Akhil Mathur, Xinchi Qiu, Titouan Parcollet, Pedro PB de Gusmão, and Nicholas D
Lane. Flower: A friendly federated learning research framework. arXiv preprint arXiv:2007.14390, 2020.
Felix Brandt, Vincent Conitzer, Ulle Endriss, Jérôme Lang, and Ariel D Procaccia. Handbook of computational social
choice. Cambridge University Press, 2016.
Sebastian Caldas, Jakub Konečny, H. Brendan McMahan, and Ameet Talwalkar. Expanding the reach of federated
learning by reducing client resource requirements, 2018.
Xibin Dong, Zhiwen Yu, Wenming Cao, Yifan Shi, and Qianli Ma. A survey on ensemble learning. Frontiers of
Computer Science, 14(2):241–258, 2020.
Thomas Elsken, Jan Hendrik Metzen, and Frank Hutter. Neural architecture search: A survey. The Journal of Machine
Learning Research, 20(1):1997–2017, 2019.
Peter I. Frazier. A tutorial on bayesian optimization, 2018.
Jianping Gou, Baosheng Yu, Stephen J. Maybank, and Dacheng Tao. Knowledge distillation: A survey. International
Journal of Computer Vision, 129(6):1789–1819, Mar 2021. ISSN 1573-1405. doi: 10.1007/s11263-021-01453-z.
URL http://dx.doi.org/10.1007/s11263-021-01453-z.
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network, 2015.
Leslie Pack Kaelbling, Michael L. Littman, and Andrew W. Moore. Reinforcement learning: A survey. CoRR,
cs.AI/9605103, 1996. URL https://arxiv.org/abs/cs/9605103.
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista
Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances and open problems in federated
learning. arXiv preprint arXiv:1912.04977, 2019.
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran
Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan
Kumaran, and Raia Hadsell. Overcoming catastrophic forgetting in neural networks, 2017.
Jakub Konečný, H. Brendan McMahan, Felix X. Yu, Peter Richtárik, Ananda Theertha Suresh, and Dave Bacon.
Federated learning: Strategies for improving communication efficiency, 2017.
Viraj Kulkarni, Milind Kulkarni, and Aniruddha Pant. Survey of personalization techniques for federated learning. In
2020 Fourth World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4), pages 794–797.
IEEE, 2020.
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith. Federated
optimization in heterogeneous networks. arXiv preprint arXiv:1812.06127, 2018.
Yishay Mansour, Mehryar Mohri, Jae Ro, and Ananda Theertha Suresh. Three approaches for personalization with
applications to federated learning, 2020a.
Yishay Mansour, Mehryar Mohri, Jae Ro, and Ananda Theertha Suresh. Three approaches for personalization with
applications to federated. arXiv preprint arXiv:2002.10619, 2020b.
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communicationefficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages 1273–1282.
PMLR, 2017.
H. Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li Zhang. Learning differentially private recurrent language
models, 2018.

6

Reshef Meir. Iterative voting. Trends in computational social choice, pages 69–86, 2017.
Aditya Paliwal, Felix Gimeno, Vinod Nair, Yujia Li, Miles Lubin, Pushmeet Kohli, and Oriol Vinyals. Reinforced
genetic algorithm learning for optimizing computation graphs. arXiv preprint arXiv:1905.02494, 2019.
Pengzhen Ren, Yun Xiao, Xiaojun Chang, Po-Yao Huang, Zhihui Li, Xiaojiang Chen, and Xin Wang. A comprehensive
survey of neural architecture search: Challenges and solutions. arXiv preprint arXiv:2006.02903, 2020.
Aaron Segal, Antonio Marcedone, Benjamin Kreuter, Daniel Ramage, H. Brendan McMahan, Karn Seth, K. A.
Bonawitz, Sarvar Patel, and Vladimir Ivanov. Practical secure aggregation for privacy-preserving machine learning.
In CCS, 2017. URL https://eprint.iacr.org/2017/281.pdf.
Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P. Adams, and Nando de Freitas. Taking the human out of the
loop: A review of bayesian optimization. Proceedings of the IEEE, 104(1):148–175, 2016. doi: 10.1109/JPROC.
2015.2494218.
Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet Talwalkar. Federated multi-task learning, 2018.
Kang Wei, Jun Li, Ming Ding, Chuan Ma, Howard H. Yang, Farhad Farokhi, Shi Jin, Tony Q. S. Quek, and H. Vincent
Poor. Federated learning with differential privacy: Algorithms and performance analysis. IEEE Transactions on
Information Forensics and Security, 15:3454–3469, 2020. doi: 10.1109/TIFS.2020.2988575.
White House. Consumer data privacy in a networked world: A framework for protecting privacy and promoting
innovation in the global digital economy. Journal of Privacy and Confidentiality, 4(2), Mar. 2013. doi: 10.29012/jpc.
v4i2.623. URL https://journalprivacyconfidentiality.org/index.php/jpc/article/view/623.
Ronald J Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine
learning, 8(3):229–256, 1992.
Martin Wistuba, Ambrish Rawat, and Tejaswini Pedapati. A survey on neural architecture search. arXiv preprint
arXiv:1905.01392, 2019.
Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S. Yu. A comprehensive survey
on graph neural networks. IEEE Transactions on Neural Networks and Learning Systems, 32(1):4–24, 2021. doi:
10.1109/TNNLS.2020.2978386.
Shen Yan, Yu Zheng, Wei Ao, Xiao Zeng, and Mi Zhang. Does unsupervised architecture representation learning help
neural architecture search? arXiv preprint arXiv:2006.06936, 2020.
Li Yang and Abdallah Shami. On hyperparameter optimization of machine learning algorithms: Theory and practice.
Neurocomputing, 415:295–316, 2020. ISSN 0925-2312. doi: https://doi.org/10.1016/j.neucom.2020.07.061. URL
https://www.sciencedirect.com/science/article/pii/S0925231220311693.
Tao Yu, Eugene Bagdasaryan, and Vitaly Shmatikov. Salvaging federated learning by local adaptation. arXiv preprint
arXiv:2002.04758, 2020.
Chunhui Yuan and Haitao Yang. Research on k-value selection method of k-means clustering algorithm. J, 2(2):
226–235, 2019.
Yu Zhang and Qiang Yang. A survey on multi-task learning, 2021.
Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra. Federated learning with non-iid
data, 2018.
Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui Xiong, and Qing He. A
comprehensive survey on transfer learning. Proceedings of the IEEE, 109(1):43–76, 2021. doi: 10.1109/JPROC.
2020.3004555.

7

A

Appendix

H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, Blaise Agüera y Arcas

Algorithm 1 FederatedAveraging. The K clients are
indexed by k; B is the local minibatch size, E is the number
of local epochs, and η is the learning rate.
Server executes:
initialize w0
for each round t = 1, 2, . . . do
m ← max(C · K, 1)
St ← (random set of m clients)
for each client k ∈ St in parallel do
k
wt+1
← ClientUpdate(k, wt )
PK
k
wt+1 ← k=1 nnk wt+1
ClientUpdate(k, w): // Run on client k
B ← (split Pk into batches of size B)
for each local epoch i from 1 to E do
for batch b ∈ B do
w ← w − ηO`(w; b)
return w to server

Table 1: Effect of the client fraction C on the M
with E = 1 and CNN with E = 5. Note C =
sponds to one client per round; since we use 100
the MNIST data, the rows correspond to 1, 10
100 clients. Each table entry gives the numbe
of communication necessary to achieve a test-s
of 97% for the 2NN and 99% for the CNN, alo
speedup relative to the C = 0 baseline. Five
the large batch size did not reach the target accu
allowed time.
2NN
C

IID
B=∞

0.0 1455
0.1 1474 (1.0×)
0.2 1658 (0.9×)
0.5
— (—)
1.0
— (—)
CNN, E = 5
0.0 387
0.1 339 (1.1×)
0.2 337 (1.1×)
0.5 164 (2.4×)
1.0 246 (1.6×)

N ON -IID
B = 10

B=∞

316
87 (3.6×)
77 (4.1×)
75 (4.2×)
70 (4.5×)

4278
1796 (2.4×)
1528 (2.8×)
— (—)
— (—)

32
6
6
4
3

50
18 (2.8×)
18 (2.8×)
18 (2.8×)
16 (3.1×)

1181
1100 (1.1×)
978 (1.2×)
1067 (1.1×)
— (—)

9
2
2
2

1: FedAvg,Results
from McMahan et al. [2017]
3 Figure
Experimental
We are motivated by both image classification and language
modeling tasks where good models can greatly enhance the
usability of mobile devices. For each of these tasks we first
picked a proxy dataset of modest enough size that we could
thoroughly investigate the hyperparameters of the FedAvg
algorithm. While each individual training run is relatively
small, we trained over 2000 individual models for these
experiments. We then present results on the benchmark
CIFAR-10 image classification task. Finally, to demonstrate
the effectiveness of FedAvg on a real-world problem with
a natural partitioning of the data over clients, we evaluate
on a large language modeling task.
Our initial study includes three model families on two
datasets. The first two are for the MNIST digit recognition
task [26]: 1) A simple multilayer-perceptron with 2-hidden
layers with 200 units each using ReLu activations (199,210
total parameters), which we refer to as the MNIST 2NN.
2) A CNN with two 5x5 convolution layers (the first with
32 channels, the second with 64, each followed with 2x2
max pooling), a fully connected layer with 512 units and
ReLu activation, and a final softmax output layer (1,663,370
total parameters). To study federated optimization, we also
need to specify how the data is distributed over the clients.
We study two ways of partitioning the MNIST data over
clients: IID, where the data is shuffled, and then partitioned
into 100 clients each receiving 600 examples, and Non-IID,
where we first sort the data by digit label, divide it into 200
shards of size 300, and assign each of 100 clients 2 shards.
This is a pathological non-IID partition of the data, as most
clients will only have examples of two digits. Thus, this lets
us explore the degree to which our algorithms will break on
highly non-IID data. Both of these partitions are balanced,

8

however.4

For language modeling, we built a dataset from
plete Works of William Shakespeare [32]. We
client dataset for each speaking role in each p
least two lines. This produced a dataset with 1
For each client, we split the data into a set of tr
(the first 80% of lines for the role), and test lin
20%, rounded up to at least one line). The resul
has 3,564,579 characters in the training set, a
characters5 in the test set. This data is substant
anced, with many roles having only a few lines
with a large number of lines. Further, observe th
not a random sample of lines, but is temporall
by the chronology of each play. Using an identic
split, we also form a balanced and IID version of
also with 1146 clients.

On this data we train a stacked character-level
guage model, which after reading each charact
predicts the next character [22]. The model take
characters as input and embeds each of these in
8 dimensional space. The embedded characte
processed through 2 LSTM layers, each with
Finally the output of the second LSTM layer
softmax output layer with one node per charact
model has 866,578 parameters, and we traine
unroll length of 80 characters.

4
We performed additional experiments on unbalan
of these datasets, and found them to in fact be sligh
FedAvg.
5
We always use character to refer to a one byte st
role to refer to a part in the play.

Published as a conference paper at ICLR 2020

FAIR R ESOURCE A LLOCATION IN F EDERATED
L EARNING
Tian Li
CMU
tianli@cmu.edu

Ahmad Beirami
Facebook AI
beirami@fb.com

Maziar Sanjabi
Facebook AI
maziars@fb.com

Virginia Smith
CMU
smithv@cmu.edu

arXiv:1905.10497v2 [cs.LG] 14 Feb 2020

A BSTRACT
Federated learning involves training statistical models in massive, heterogeneous
networks. Naively minimizing an aggregate loss function in such a network may
disproportionately advantage or disadvantage some of the devices. In this work,
we propose q-Fair Federated Learning (q-FFL), a novel optimization objective
inspired by fair resource allocation in wireless networks that encourages a more fair
(specifically, a more uniform) accuracy distribution across devices in federated networks. To solve q-FFL, we devise a communication-efficient method, q-FedAvg,
that is suited to federated networks. We validate both the effectiveness of q-FFL
and the efficiency of q-FedAvg on a suite of federated datasets with both convex
and non-convex models, and show that q-FFL (along with q-FedAvg) outperforms
existing baselines in terms of the resulting fairness, flexibility, and efficiency.

1

I NTRODUCTION

Federated learning is an attractive paradigm for fitting a model to data generated by, and residing on,
a network of remote devices (McMahan et al., 2017). Unfortunately, naively minimizing an aggregate
loss in a large network may disproportionately advantage or disadvantage the model performance on
some of the devices. For example, although the accuracy may be high on average, there is no accuracy
guarantee for individual devices in the network. This is exacerbated by the fact that the data are often
heterogeneous in federated networks both in terms of size and distribution, and model performance
can thus vary widely. In this work, we therefore ask: Can we devise an efficient federated optimization
method to encourage a more fair (i.e., more uniform) distribution of the model performance across
devices in federated networks?
There has been tremendous recent interest in developing fair methods for machine learning (see, e.g.,
Cotter et al., 2019; Dwork et al., 2012). However, current approaches do not adequately address
concerns in the federated setting. For example, a common definition in the fairness literature is to
enforce accuracy parity between protected groups1 (Zafar et al., 2017a). For devices in massive
federated networks, however, it does not make sense for the accuracy to be identical on each device
given the significant variability of data in the network. Recent work has taken a step towards
addressing this by introducing good-intent fairness, in which the goal is instead to ensure that the
training procedure does not overfit a model to any one device at the expense of another (Mohri et al.,
2019). However, the proposed objective is rigid in the sense that it only maximizes the performance
of the worst performing device/group, and has only be tested in small networks (for 2-3 devices). In
realistic federated learning applications, it is natural to instead seek methods that can flexibly trade
off between overall performance and fairness in the network, and can be implemented at scale across
hundreds to millions of devices.
In this work, we propose q-FFL, a novel optimization objective that addresses fairness issues in
federated learning. Inspired by work in fair resource allocation for wireless networks, q-FFL
minimizes an aggregate reweighted loss parameterized by q such that the devices with higher loss
are given higher relative weight. We show that this objective encourages a device-level definition
1
While fairness is typically concerned with performance between “groups”, we define fairness in the federated
setting at a more granular scale in terms of the devices in the network. We note that devices may naturally
combine to form groups, and thus use these terms interchangeably in the context of prior work.

1

Published as a conference paper at ICLR 2020

of fairness in the federated setting, which generalizes standard accuracy parity by measuring the
degree of uniformity in performance across devices. As a motivating example, we examine the test
accuracy distribution of a model trained via a baseline
approach (FedAvg) vs. q-FFL in Figure 1. Due to the
variation in the data across devices, the model accuracy
is quite poor on some devices. By using q-FFL, we
can maintain the same overall average accuracy while
ensuring a more fair/uniform quality of service across
Increasing the accuracy of the
worst-performing devices
the network. Adaptively minimizing our q-FFL objective results in a flexible framework that can be tuned
depending on the desired amount of fairness.

Figure 1: Model performance (e.g.,
test accuracy) in federated networks can
vary widely across devices. Our objective, q-FFL, aims to increase the fairness/uniformity of model performance
while maintaining average performance.

To solve q-FFL in massive federated networks, we additionally propose a lightweight and scalable distributed
method, q-FedAvg. Our method carefully accounts for
important characteristics of the federated setting such
as communication-efficiency and low participation of
devices (Bonawitz et al., 2019; McMahan et al., 2017).
The method also reduces the overhead of tuning the hyperparameter q in q-FFL by dynamically estimating the
step-sizes associated with different values of q.

Through extensive experiments on federated datasets with both convex and non-convex models,
we demonstrate the fairness and flexibility of q-FFL and the efficiency of q-FedAvg compared
with existing baselines. In terms of fairness, q-FFL is able to reduce the variance of accuracies
across devices by 45% on average while maintaining the same overall average accuracy. In terms of
efficiency, our distributed method, q-FedAvg, is capable of solving the proposed objective orders-ofmagnitude more quickly than other baselines. Finally, while we consider our approaches primarily
in the context of federated learning, we also demonstrate that q-FFL can be applied to other related
problems such as meta-learning, helping to produce fair initializations across multiple tasks.

2

R ELATED W ORK

Fairness in Resource Allocation. Fair resource allocation has been extensively studied in fields such
as network management (Ee & Bajcsy, 2004; Hahne, 1991; Kelly et al., 1998; Neely et al., 2008) and
wireless communications (Eryilmaz & Srikant, 2006; Nandagopal et al., 2000; Sanjabi et al., 2014;
Shi et al., 2014). In these contexts, the problem is defined as allocating a scarce shared resource, e.g.,
communication time or power, among many users. In these cases, directly maximizing utilities such
as total throughput may lead to unfair allocations where some users receive poor service. As a service
provider, it is important to improve the quality of service for all users while maintaining overall
throughput. For this reason, several popular fairness measurements have been proposed to balance
between fairness and total throughput, including Jain’s index (Jain et al., 1984), entropy (Rényi et al.,
1961), max-min/min-max fairness (Radunovic & Le Boudec, 2007), and proportional fairness (Kelly,
1997). A unified framework is captured through α-fairness (Lan et al., 2010; Mo & Walrand, 2000),
in which the network manager can tune the emphasis on fairness by changing a single parameter, α.
To draw an analogy between federated learning and the problem of resource allocation, one can think
of the global model as a resource that is meant to serve the users (or devices). In this sense, it is
natural to ask similar questions about the fairness of the service that users receive and use similar
tools to promote fairness. Despite this, we are unaware of any works that use α-fairness from resource
allocation to modify objectives in machine learning. Inspired by the α-fairness metric, we propose a
similarly modified objective, q-Fair Federated Learning (q-FFL), to encourage a more fair accuracy
distribution across devices in the context of federated training. Similar to the α-fairness metric, our
q-FFL objective is flexible enough to enable trade-offs between fairness and other traditional metrics
such as accuracy by changing the parameter q. In Section 4, we show empirically that the use of
q-FFL as an objective in federated learning enables a more uniform accuracy distribution across
devices—significantly reducing variance while maintaining the average accuracy.
Fairness in Machine Learning. Fairness is a broad topic that has received much attention in the
machine learning community, though the goals often differ from that described in this work. Indeed,
2

Published as a conference paper at ICLR 2020

fairness in machine learning is typically defined as the protection of some specific attribute(s). Two
common approaches are to preprocess the data to remove information about the protected attribute, or
to post-process the model by adjusting the prediction threshold after classifiers are trained (Feldman,
2015; Hardt et al., 2016; Calmon et al., 2017). Another set of works optimize an objective subject to
some fairness constraints during training time (Agarwal et al., 2018; Cotter et al., 2019; Hashimoto
et al., 2018; Woodworth et al., 2017; Baharlouei et al., 2020; Zafar et al., 2017a;b; Dwork et al., 2012).
Our work also enforces fairness during training, although we define fairness as the uniformity of the
accuracy distribution across devices in federated learning (Section 3), as opposed to the protection
of a specific attribute. Although some works define accuracy parity to enforce equal error rates
among specific groups as a notion of fairness (Zafar et al., 2017a; Cotter et al., 2019), devices in
federated networks may not be partitioned by protected attributes, and our goal is not to optimize for
identical accuracy across all devices. Cotter et al. (2019) use a notion of ‘minimum accuracy’, which
is conceptually similar to our goal. However, it requires one optimization constraint for each device,
which would result in hundreds to millions of constraints in federated networks.
In federated settings, Mohri et al. (2019) recently proposed a minimax optimization scheme, Agnostic
Federated Learning (AFL), which optimizes for the performance of the single worst device. This
method has only been applied at small scales (for a handful of devices). Compared to AFL, our
proposed objective is more flexible as it can be tuned based on the desired amount of fairness; AFL
can in fact be seen as a special case of our objective, q-FFL, with large enough q. In Section 4,
we demonstrate that the flexibility of our objective results in more favorable accuracy vs. fairness
trade-offs than AFL, and that q-FFL can also be solved at scale more efficiently.
Federated Optimization. Federated learning faces challenges such as expensive communication,
variability in systems environments in terms of hardware or network connection, and non-identically
distributed data across devices (Li et al., 2019). In order to reduce communication and tolerate heterogeneity, optimization methods must be developed to allow for local updating and low participation
among devices (McMahan et al., 2017; Smith et al., 2017). We incorporate these key ingredients
when designing methods to solve our q-FFL objective efficiently in the federated setting (Section 3.3).

3

FAIR F EDERATED L EARNING

In this section, we first formally define the classical federated learning objective and methods, and
introduce our proposed notion of fairness (Section 3.1). We then introduce q-FFL, a novel objective
that encourages a more fair (uniform) accuracy distribution across all devices (Section 3.2). Finally,
in Section 3.3, we describe q-FedAvg, an efficient distributed method to solve the q-FFL objective
in federated settings.
3.1

P RELIMINARIES : F EDERATED L EARNING , F E D A V G , AND FAIRNESS

Federated learning algorithms involve hundreds to millions of remote devices learning locally on
their device-generated data and communicating with a central server periodically to reach a global
consensus. In particular, the goal is typically to solve:
m
X
min f (w) =
pk Fk (w) ,
(1)
w

k=1

P
where m is the total number of devices, pk ≥ 0, and k pkP= 1. The local objective Fk ’s can be
n
defined by empirical risks over local data, i.e., Fk (w) = n1k jkk=1 ljk (w), where nk is the number
P
of samples available locally. We can set pk to be nnk , where n = k nk is the total number of
samples to fit a traditional empirical risk minimization-type objective over the entire dataset.
Most prior work solves (1) by sampling a subset of devices with probabilities pk at each round,
and then running an optimizer such as stochastic gradient descent (SGD) for a variable number
of iterations locally on each device. These local updating methods enable flexible and efficient
communication compared to traditional mini-batch methods, which would simply calculate a subset of the gradients (Stich, 2019; Wang & Joshi, 2018; Woodworth et al., 2018; Yu et al., 2019).
FedAvg (McMahan et al., 2017), summarized in Algorithm 3 in Appendix C.1, is one of the leading
methods to solve (1) in non-convex settings. The method runs simply by having each selected device
apply E epochs of SGD locally and then averaging the resulting local models.
3

Published as a conference paper at ICLR 2020

Unfortunately, solving problem (1) in this manner can implicitly introduce highly variable performance between different devices. For instance, the learned model may be biased towards devices
with larger numbers of data points, or (if weighting devices equally), to commonly occurring devices.
More formally, we define our desired fairness criteria for federated learning below.
Definition 1 (Fairness of performance distribution). For trained models w and w̃, we informally say
that model w provides a more fair solution to the federated learning objective (1) than model w̃ if the
performance of model w on the m devices, {a1 , . . . am }, is more uniform than the performance of
model w̃ on the m devices.
In this work, we take ‘performance’, ak , to be the testing accuracy of applying the trained model w
on the test data for device k. There are many ways to mathematically evaluate the uniformity of the
performance. In this work, we mainly use the variance of the performance distribution as a measure
of uniformity. However, we also explore other uniformity metrics, both empirically and theoretically,
in Appendix A.1. We note that a tension exists between the fairness/uniformity of the final testing
accuracy and the average testing accuracy across devices. In general, our goal is to impose more
fairness/uniformity while maintaining the same (or similar) average accuracy.
Remark 2 (Connections to other fairness definitions). Definition 1 targets device-level fairness,
which has finer granularity than the classical attribute-level fairness such as accuracy parity (Zafar
et al., 2017a). We note that in certain cases where devices can be naturally clustered into groups
with specific attributes, our definition can be seen as a relaxed version of accuracy parity, in that we
optimize for similar but not necessarily identical performance across devices.
3.2

T HE OBJECTIVE : q-FAIR F EDERATED L EARNING (q-FFL)

A natural idea to achieve fairness as defined in (1) would be to reweight the objective—assigning
higher weights to devices with poor performance, so that the distribution of accuracies in the
network shifts towards more uniformity. Note that this reweighting must be done dynamically, as the
performance of the devices depends on the model being trained, which cannot be evaluated a priori.
Drawing inspiration from α-fairness, a utility function used in fair resource allocation in wireless
networks, we propose the following objective. For given local non-negative cost functions Fk and
parameter q > 0, we define the q-Fair Federated Learning (q-FFL) objective as:
m
X
pk
min fq (w) =
F q+1 (w) ,
w
q+1 k

(2)

k=1

where Fkq+1 (·) denotes Fk (·) to the power of (q+1). Here, q is a parameter that tunes the amount of
fairness we wish to impose. Setting q = 0 does not encourage fairness beyond the classical federated
learning objective (1). A larger q means that we emphasize devices with higher local empirical
losses, Fk (w), thus imposing more uniformity to the training accuracy distribution and potentially
inducing fairness in accordance with Definition 1. Setting fq (w) with a large enough q reduces to
classical minimax fairness (Mohri et al., 2019), as the device with the worst performance (largest
loss) will dominate the objective. We note that while the (q+1) term in the denominator in (2) may
be absorbed in pk , we include it as it is standard in the α-fairness literature and helps to ease notation.
For completeness, we provide additional background on α-fairness in Appendix B.
As mentioned previously, q-FFL generalizes prior work in fair federated learning (AFL) (Mohri et al.,
2019), allowing for a flexible trade-off between fairness and accuracy as parameterized by q. In our
theoretical analysis (Appendix A), we provide generalization bounds of q-FFL that generalize the
learning bounds of the AFL objective. Moreover, based on our fairness definition (Definition 1), we
theoretically explore how q-FFL results in more uniform accuracy distributions with increasing q.
Our results suggest that q-FFL is able to impose ‘uniformity’ of the test accuracy distribution in
terms of various metrics such as variance and other geometric and information-theoretic measures.
In our experiments (Section 4.2), on both convex and non-convex models, we show that using the
q-FFL objective, we can obtain fairer/more uniform solutions for federated datasets in terms of both
the training and testing accuracy distributions.
4

Published as a conference paper at ICLR 2020

3.3

T HE SOLVER : F EDAVG - STYLE q-FAIR F EDERATED L EARNING (q-F E D A V G )

In developing a functional approach for fair federated learning, it is critical to consider not only what
objective to solve but also how to solve such an objective efficiently in a massive distributed network.
In this section, we provide methods to solve q-FFL. We start with a simpler method, q-FedSGD,
to illustrate our main techniques. We then provide a more efficient counterpart, q-FedAvg, by
considering local updating schemes. Our proposed methods closely mirror traditional distributed
optimization methods—mini-batch SGD and federated averaging (FedAvg)—but with step-sizes
and subproblems carefully chosen in accordance with the q-FFL problem (2).
Achieving variable levels of fairness: tuning q. In devising a method to solve q-FFL (2), we begin
by noting that it is crucial to first determine how to set q. In practice, q can be tuned based on the
desired amount of fairness (with larger q inducing more fairness). As we describe in our experiments
(Section 4.2), it is therefore common to train a family of objectives for different q values so that a
practitioner can explore the trade-off between accuracy and fairness for the application at hand.
One concern with solving such a family of objectives is that it requires step-size tuning for every
value of q. In particular, in gradient-based methods, the step-size inversely depends on the Lipschitz
constant of the function’s gradient, which will change as we change q. This can quickly cause the
search space to explode. To overcome this issue, we propose estimating the local Lipschitz constant
for the family of q-FFL objectives by using the Lipschitz constant we infer by tuning the step-size
(via grid search) on just one q (e.g., q = 0). This allows us to dynamically adjust the step-size of our
gradient-based optimization method for the q-FFL objective, avoiding manual tuning for each q. In
Lemma 3 below we formalize the relation between the Lipschitz constant, L, for q = 0 and q > 0.
Lemma 3. If the non-negative function f (·) has a Lipschitz gradient with constant L, then for any
q ≥ 0 and at any point w,
Lq (w) = Lf (w)q + qf (w)q−1 k∇f (w)k2

(3)

1
f q+1 (·) at point w.
is an upper-bound for the local Lipschitz constant of the gradient of q+1



1
Proof. At any point w, we can compute the Hessian ∇2 q+1
f q+1 (w) as:


1
2
q+1
∇
f
(w) = qf q−1 (w) ∇f (w)∇T f (w) +f q (w) ∇2 f (w) .
|
{z
}
| {z }
q+1
k∇f (w)k2 ×I

(4)

L×I

1
As a result, k∇2 q+1
f q+1 (w)k2 ≤ Lq (w) = Lf (w)q + qf (w)q−1 k∇f (w)k2 .

A first approach: q-FedSGD. Our first fair federated learning method, q-FedSGD, is an extension of the well-known federated mini-batch SGD (FedSGD) method (McMahan et al., 2017).
q-FedSGD uses a dynamic step-size instead of the normal fixed step-size of FedSGD. Based
on Lemma 3, for each local device k, the upper-bound of the local Lipschitz constant is
LFk (w)q + qFk (w)q−1 k∇Fk (w)k2 . In each step of q-FedSGD, ∇Fk and Fk on each selected
device k are computed at the current iterate and communicated to the central node. This information
is used to compute the step-sizes (weights) for combining the updates from each device. The details
are summarized in Algorithm 1. Note that q-FedSGD is reduced to FedSGD when q = 0. It is also
important to note that to run q-FedSGD with different values of q, we only need to estimate L once
by tuning the step-size on q = 0 and can then reuse it for all values of q > 0.
Improving communication-efficiency: q-FedAvg. In federated settings, communication-efficient
schemes using local stochastic solvers (such as FedAvg) have been shown to significantly improve
convergence speed (McMahan et al., 2017). However, when q > 0, the Fkq+1 term is not an empirical
average of the loss over all local samples due to the q + 1 exponent, preventing the use of local
SGD as in FedAvg. To address this, we propose to generalize FedAvg for q > 0 using a more
sophisticated dynamic weighted averaging scheme. The weights (step-sizes) are inferred from the
upper bound of the local Lipschitz constants of the gradients of Fkq+1 , similar to q-FedSGD. To
extend the local updating technique of FedAvg to the q-FFL objective (2), we propose a heuristic
where we replace the gradient ∇Fk in the q-FedSGD steps with the local updates that are obtained
by running SGD locally on device k. Similarly, q-FedAvg is reduced to FedAvg when q = 0. We
5

Published as a conference paper at ICLR 2020

Algorithm 1 q-FedSGD
1: Input: K, T , q, 1/L, w0 , pk , k = 1, · · · , m
2: for t = 0, · · · , T − 1 do
3:
Server selects a subset St of K devices at random (each device k is chosen with prob. pk )
4:
Server sends wt to all selected devices
5:
Each selected device k computes:

∆tk = Fkq (wt )∇Fk (wt )
htk = qFkq−1 (wt )k∇Fk (wt )k2 + LFkq (wt )
Each selected device k sends ∆tk and htk back to the server
P
Server updates wt+1 as:
∆tk
t+1
t
w
= w − Pk∈St t
k∈St hk
8: end for
6:
7:

Algorithm 2 q-FedAvg
1: Input: K, E, T , q, 1/L, η, w0 , pk , k = 1, · · · , m
2: for t = 0, · · · , T − 1 do
3:
Server selects a subset St of K devices at random (each device k is chosen with prob. pk )
4:
Server sends wt to all selected devices
Each selected device k updates wt for E epochs of SGD on Fk with step-size η to obtain w̄kt+1
5:
6:
Each selected device k computes:

∆wkt = L(wt − w̄kt+1 )
∆tk = Fkq (wt )∆wkt

htk = qFkq−1 (wt )k∆wkt k2 + LFkq (wt )
Each selected device k sends ∆tk and htk back to the server
Server updates wt+1 as:
P
∆tk
t+1
t
w
= w − Pk∈St t
k∈St hk
9: end for
7:
8:

provide additional details on q-FedAvg in Algorithm 2. As we will see empirically, q-FedAvg can
solve q-FFL objective much more efficiently than q-FedSGD due to the local updating heuristic.
Finally, recall that as q → ∞ the q-FFL objective recovers that of the AFL. However, we empirically
notice that q-FedAvg has a more favorable convergence speed compared to AFL while resulting in
similar performance across devices (see Figure 9 in the appendix).

4

E VALUATION

We now present empirical results of the proposed objective, q-FFL, and proposed methods, q-FedAvg
and q-FedSGD. We describe our experimental setup in Section 4.1. We then demonstrate the improved
fairness of q-FFL in Section 4.2, and compare q-FFL with several baseline fairness objectives in Section 4.3. Finally, we show the efficiency of q-FedAvg compared with q-FedSGD in Section 4.4. All
code, data, and experiments are publicly available at github.com/litian96/fair_flearn.
4.1

E XPERIMENTAL SETUP

Federated datasets. We explore a suite of federated datasets using both convex and non-convex
models in our experiments. The datasets are curated from prior work in federated learning (McMahan
et al., 2017; Smith et al., 2017; Li et al., 2020; Mohri et al., 2019) as well as recent federated learning
benchmarks (Caldas et al., 2018). In particular, we study: (1) a synthetic dataset using a linear
regression classifier, (2) a Vehicle dataset collected from a distributed sensor network (Duarte & Hu,
2004) with a linear SVM for binary classification, (3) tweet data curated from Sentiment140 (Go
et al., 2009) (Sent140) with an LSTM classifier for text sentiment analysis, and (4) text data built
6

Published as a conference paper at ICLR 2020

from The Complete Works of William Shakespeare (McMahan et al., 2017) and an RNN to predict
the next character. When comparing with AFL, we use the two small benchmark datasets (Fashion
MNIST (Xiao et al., 2017) and Adult (Blake, 1998)) studied in Mohri et al. (2019). When applying
q-FFL to meta-learning, we use the common meta-learning benchmark dataset Omniglot (Lake et al.,
2015). Full dataset details are given in Appendix D.1.
Implementation. We implement all code in Tensorflow (Abadi et al., 2016), simulating a federated
network with one server and m devices, where m is the total number of devices in the dataset
(Appendix D.1). We provide full details (including all hyperparameter values) in Appendix D.2.
4.2

FAIRNESS OF q-FFL

In our first experiments, we verify that the proposed objective q-FFL leads to more fair solutions
(Definition 1) for federated data. In Figure 2, we compare the final testing accuracy distributions of
two objectives (q = 0 and a tuned value of q > 0) averaged across 5 random shuffles of each dataset.
We observe that while the average testing accuracy remains fairly consistent, the objectives with q > 0
result in more centered (i.e., fair) testing accuracy distributions with lower variance. In particular,
while maintaining roughly the same average accuracy, q-FFL reduces the variance of accuracies
across all devices by 45% on average. We further report the worst and best 10% testing accuracies
and the variance of the final accuracy distributions in Table 1. Comparing q = 0 and q > 0, we
see that the average testing accuracy remains almost unchanged with the proposed objective despite
significant reductions in variance. We report full results on all uniformity measurements (including
variance) in Table 5 in the appendix, and show that q-FFL encourages more uniform accuracies under
other metrics as well. We observe similar results on training accuracy distributions in Figure 6 and
Table 6, Appendix E. In Table 1, the average accuracy is with respect to all data points, not all devices;
however, we observe similar results with respect to devices, as shown in Table 7, Appendix E.

Figure 2: q-FFL leads to fairer test accuracy distributions. While the average accuracy remains
almost identical (see Table 1), by setting q > 0, the distributions shift towards the center as low
accuracies increase at the cost of potentially decreasing high accuracies on some devices. Setting
q = 0 corresponds to the original objective (1). The selected q values for q > 0 on the four datasets,
as well as distribution statistics, are also shown in Table 1.
Table 1: Statistics of the test accuracy distribution for q-FFL. By setting q > 0, the accuracy of the
worst 10% devices is increased at the cost of possibly decreasing the accuracy of the best 10% devices.
While the average accuracy remains similar, the variance of the final accuracy distribution decreases
significantly. We provide full results of other uniformity measurements (including variance) in Table
5, Appendix E.1, and show that q-FFL encourages more uniform distributions under all metrics.
Dataset
Synthetic
Vehicle
Sent140
Shakespeare

Objective
q=0
q=1
q=0
q=5
q=0
q=1
q=0
q = .001

Average
(%)
80.8 ± .9
79.0 ± 1.2
87.3 ± .5
87.7 ± .7
65.1 ± 4.8
66.5 ± .2
51.1 ± .3
52.1 ± .3

Worst 10%

(%)
18.8 ± 5.0
31.1 ± 1.8
43.0 ± 1.0
69.9 ± .6
15.9 ± 4.9
23.0 ± 1.4
39.7 ± 2.8
42.1 ± 2.1

7

Best 10%
(%)
100.0 ± 0.0
100.0 ± 0.0
95.7 ± 1.0
94.0 ± .9
100.0 ± 0.0
100.0 ± 0.0
72.9 ± 6.7
69.0 ± 4.4

Variance
724 ± 72
472 ± 14
291 ± 18
48 ± 5
697 ± 132
509 ± 30
82 ± 41
54 ± 27

Published as a conference paper at ICLR 2020

Choosing q. As discussed in Section 3.3, a natural question is to determine how q should be tuned in
the q-FFL objective. Our framework is flexible in that it allows one to choose q to tradeoff between
fairness/uniformity and average accuracy. We empirically show that there are a family of q’s that
can result in variable levels of fairness (and accuracy) on synthetic data in Table 11, Appendix E.
In general, this value can be tuned based on the data/application at hand and the desired amount of
fairness. Another reasonable approach in practice would be to run Algorithm 2 with multiple q’s in
parallel to obtain multiple final global models, and then select amongst these based on performance
(e.g., accuracy) on the validation data. Rather than using just one optimal q for all devices, for
example, each device could pick a device-specific model based on their validation data. We show
additional performance improvements with this device-specific strategy in Table 12 in Appendix
E. Finally, we note that one potential issue is that increasing the value of q may slow the speed of
convergence. However, for values of q that result in more fair results on our datasets, we do not
observe significant decrease in the convergence speed, as shown in Figure 8, Appendix E.
4.3

C OMPARISON WITH OTHER OBJECTIVES

Next, we compare q-FFL with other objectives that are likely to impose fairness in federated networks.
One heuristic is to weight each data point equally, which reduces to the original objective in (1) (i.e.,
q-FFL with q = 0) and has been investigated in Section 4.2. We additionally compare with two
alternatives: weighting devices equally when sampling devices, and weighting devices adversarially,
namely, optimizing for the worst-performing device, as proposed in Mohri et al. (2019).
Weighting devices equally. We compare q-FFL with uniform sampling schemes and report testing
accuracy in Figure 3. A table with the final accuracies and three fairness metrics is given in the
appendix in Table 9. While the ‘weighting each device equally’ heuristic tends to outperform our
method in training accuracy distributions (Figure 7 and Table 8 in Appendix E), we see that our
method produces more fair solutions in terms of testing accuracies. One explanation for this is that
uniform sampling is a static method and can easily overfit to devices with very few data points,
whereas q-FFL will put less weight on a device once its loss becomes small, potentially providing
better generalization performance due to its dynamic nature.

Figure 3: q-FFL (q > 0) compared with uniform sampling. In terms of testing accuracy, our objective
produces more fair solutions than uniform sampling. Distribution statistics are provided in Table 9 in
the appendix. q-FFL achieves similar average accuracies and more fair solutions.

Weighting devices adversarially. We further compare with AFL (Mohri et al., 2019), which is the
only work we are aware of that aims to address fairness issues in federated learning. We implement a
non-stochastic version of AFL where all devices are selected and updated each round, and perform
grid search on the AFL hyperparameters, γw and γλ . In order to devise a setup that is as favorable
to AFL as possible, we modify Algorithm 2 by sampling all devices and letting each of them run
gradient descent at each round. We use the same small datasets (Adult (Blake, 1998) and subsampled
Fashion MNIST (Xiao et al., 2017)) and the same logistic regression model as in Mohri et al. (2019).
Full details of the implementation and hyperparameters (e.g., values of q1 and q2 ) are provided in
Appendix D.2.3. We note that, as opposed to AFL, q-FFL is flexible depending on the amount of
fairness desired, with larger q leading to more accuracy uniformity. As discussed, q-FFL generalizes
AFL in this regard, as AFL is equivalent to q-FFL with a large enough q. In Table 2, we observe that
q-FFL can in fact achieve higher testing accuracy than AFL on the device with the worst performance
(i.e., the problem that the AFL was designed to solve) with appropriate q. This also indicates that
q-FFL obtains the most fair solutions in certain cases. We also observe that q-FFL converges faster
8

Published as a conference paper at ICLR 2020

in terms of communication rounds compared with AFL to obtain similar performance (Appendix E),
which we speculate is due to the non-smoothness of the AFL objective.
Table 2: Our objective compared with weighing devices adversarially (AFL (Mohri et al., 2019)). In
order to be favorable to AFL, we use the two small, well-behaved datasets studied in (Mohri et al.,
2019). q-FFL (q > 0) outperforms AFL on the worst testing accuracy of both datasets. The tunable
parameter q controls how much fairness we would like to achieve—larger q induces less variance.
Each accuracy is averaged across 5 runs with different random initializations.
Adult
Fashion MNIST
average PhD non-PhD average shirt pullover T-shirt
Objectives
(%)
(%)
(%)
(%)
(%)
(%)
(%)
q-FFL, q=0 83.2 ± .1 69.9 ± .4 83.3 ± .1 78.8 ± .2 66.0 ± .7
84.5 ± .8
85.9 ± .7
AFL
82.5 ± .5 73.0 ± 2.2 82.6 ± .5 77.8 ± 1.2 71.4 ± 4.2 81.0 ± 3.6
82.1 ± 3.9
78.9 ± .4
80.4 ± .6
q-FFL, q1 >0 82.6 ± .1 74.1 ± .6 82.7 ± .1 77.8 ± .2 74.2 ± .3
q-FFL, q2 >q1 82.3 ± .1 74.4 ± .9 82.4 ± .1 77.1 ± .4 74.7 ± .9
77.9 ± .4
78.7 ± .6

E FFICIENCY OF THE METHOD q-F E D A V G

4.4

In this section, we show the efficiency of our proposed distributed solver, q-FedAvg, by comparing
Algorithm 2 with its non-local-updating baseline q-FedSGD (Algorithm 1) to solve the same objective
(same q > 0 as in Table 1). At each communication round, we have each method perform the same
amount of computation, with q-FedAvg running one epoch of local updates on each selected device
while q-FedSGD runs gradient descent with the local training data. In Figure 4, q-FedAvg converges
faster than q-FedSGD in terms of communication rounds in most cases due to its local updating
scheme. The slower convergence of q-FedAvg compared with q-FedSGD on the synthetic dataset
may be due to the fact that when local data distributions are highly heterogeneous, local updating
schemes may allow local models to move too far away from the initial global model, potentially
hurting convergence; see Figure 10 in Appendix E for more details.
 s Ğ Ś ŝ Đ ů Ğ

 Ƌ Ͳ & Ğ Ě  ǀ Ő
 Ƌ Ͳ & Ğ Ě ^ ' 
 ď Ğ Ɛ ƚ  ƚ Ƶ Ŷ Ğ Ě  & Ğ Ě ^ ' 

 Ϭ ͘ ϰ
 Ϭ ͘ Ϯ
 Ϭ

 ϱ Ϭ Ϭ

 ϭ Ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ Ϭ

 Ϯ Ϭ Ϭ Ϭ

 Ϭ ͘ ϲ
 Ϭ ͘ ϰ
 Ϭ ͘ Ϯ
 Ϭ ͘ Ϭ

 Ϭ

 Ϯ

 ϰ

 ϲ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϴ

 ϭ Ϭ

 Ϭ ͘ ϲ ϱ
 Ϭ ͘ ϲ Ϭ
 Ϭ ͘ ϱ ϱ
 Ϭ ͘ ϱ Ϭ
 Ϭ

 Ϯ Ϭ Ϭ

 ϰ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ^ Ś Ă Ŭ Ğ Ɛ Ɖ Ğ Ă ƌ Ğ

 Ϭ ͘ ϱ

 d Ğ Ɛ ƚ ŝ Ŷ Ő  Ă Đ Đ Ƶ ƌ Ă Đ Ǉ

 Ϭ ͘ ϲ

 ^ Ğ Ŷ ƚ ϭ ϰ Ϭ

 Ϭ ͘ ϳ Ϭ

 Ϭ ͘ ϴ

 d Ğ Ɛ ƚ ŝ Ŷ Ő  Ă Đ Đ Ƶ ƌ Ă Đ Ǉ

 d Ğ Ɛ ƚ ŝ Ŷ Ő  Ă Đ Đ Ƶ ƌ Ă Đ Ǉ

 d Ğ Ɛ ƚ ŝ Ŷ Ő  Ă Đ Đ Ƶ ƌ Ă Đ Ǉ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ
 Ϭ ͘ ϴ

 ϲ Ϭ Ϭ

 Ϭ ͘ ϰ
 Ϭ ͘ ϯ
 Ϭ ͘ Ϯ
 Ϭ ͘ ϭ
 Ϭ ͘ Ϭ

 Ϭ

 ϱ Ϭ Ϭ

 ϭ Ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ Ϭ

 Ϯ Ϭ Ϭ Ϭ

Figure 4: For a fixed objective (i.e., q-FFL with the same q), the convergence of q-FedAvg (Alg.2),
q-FedSGD (Alg.1), and FedSGD. For q-FedAvg and q-FedSGD, we tune a best step-size on q = 0
and apply that step-size to solve q-FFL with q > 0. For q-FedSGD, we tune the step-size directly.
We observe that (1) q-FedAvg converges faster in terms of communication rounds; (2) our proposed
q-FedSGD solver with a dynamic step-size achieves similar convergence behavior compared with a
best-tuned FedSGD.

To demonstrate the optimality of our dynamic step-size strategy in terms of solving q-FFL, we also
compare our solver q-FedSGD with FedSGD with a best-tuned step-size. For q-FedSGD, we tune
a step-size on q = 0 and apply that step-size to solve q-FFL with q > 0. q-FedSGD has similar
performance with FedSGD, which indicates that (the inverse of) our estimated Lipschitz constant on
q > 0 is as good as a best tuned fixed step-size. We can reuse this estimation for different q’s instead
of manually re-tuning it when q changes. We show the full results on other datasets in Appendix E.
We note that both proposed methods q-FedAvg and q-FedSGD can be easily integrated into existing
implementations of federated learning algorithms such as TensorFlow Federated (TFF).
9

Published as a conference paper at ICLR 2020

B EYOND FEDERATED LEARNING : A PPLYING q-FFL TO META - LEARNING

4.5

Finally, we generalize the proposed q-FFL objective to other learning tasks beyond federated learning.
One natural extension is to apply q-FFL to meta-learning, where each task can be viewed as a
device in federated networks. The goal of meta-learning is to learn a model initialization such that
it can be quickly adapted to new tasks using limited training samples. However, as the new tasks
can be heterogeneous, the performance distribution of the final personalized models may also be
non-uniform. Therefore, we aim to learn a better initialization such that it can quickly solve unseen
tasks in a fair manner, i.e., reduce the variance of the accuracy distribution of the personalized models.
Omniglot
q=0
q=.1

# Tasks

15

Table 3: Statistics of the accuracy distribution of personalized
models using q-MAML. The method with q = 0 corresponds to
MAML. Similarly, we see that the variance is reduced while the
accuracy of the worst 10% devices is increased.

10
5
0

0.0

0.2

0.4

0.6

Testing accuracy

0.8

1.0

Figure 5: q-FFL results in
fairer (more centered) initializations for meta-learning
tasks.

Dataset

Objective

Omniglot

q=0
q = .1

Average Worst 10% Best 10% Variance
(%)
(%)
(%)
79.1 ± 9.8 61.2 ± 3.2 94.0 ± .5 93 ± 23
79.3 ± 9.6 62.5 ± 5.3 93.8 ± .9 86 ± 28

To achieve this goal, we propose a new method, q-MAML, by combining q-FFL with the popular metalearning method MAML (Finn et al., 2017). In particular, instead of updating the global model in the
way described in MAML, we update the global parameters using the gradients of the q-FFL objective
q+1
1
(w), with weights inferred from Lemma 3. Similarly, q-MAML with q = 0 reduces to MAML,
q+1 Fk
and q-MAML with q → ∞ corresponds to MAML with a most ‘fair’ initialization and a potentially
lower average accuracy. The detailed algorithm is summarized in Algorithm 4 in Appendix C.2.
We sample 10 tasks at each round during meta-training, and train for 5 iterations of (mini-batch)
SGD for personalization on meta-testing tasks. We report test accuracy of personalized models on
the meta-testing tasks. From Figure 5 and Table 3 above, we observe that q-MAML is able to learn
initializations which result in fairer personalized models with lower variance.

5

C ONCLUSION

In this work, we propose q-FFL, a novel optimization objective inspired by fair resource allocation
in wireless networks that encourages fairer (more uniform) accuracy distributions across devices
in federated learning. We devise a scalable method, q-FedAvg, to solve this objective in massive
networks. Our empirical evaluation on a suite of federated datasets demonstrates the resulting fairness
and flexibility of q-FFL, as well as the efficiency of q-FedAvg compared with existing baselines.
We show that our framework is useful not only for federated learning tasks, but also for other learning
paradigms such as meta-learning.

ACKNOWLEDGMENTS
We thank Sebastian Caldas, Chen Dan, Neel Guha, Anit Kumar Sahu, Eric Tan, and Samuel Yeom
for their helpful discussions and comments. The work of TL and VS was supported in part by the
National Science Foundation grant IIS1838017, a Google Faculty Award, a Carnegie Bosch Institute
Research Award, and the CONIX Research Center. Any opinions, findings, and conclusions or
recommendations expressed in this material are those of the author(s) and do not necessarily reflect
the National Science Foundation or any other funding agency.
10

Published as a conference paper at ICLR 2020

R EFERENCES
Tensorflow federated: Machine learning on decentralized data.
tensorflow.org/federated.

URL https://www.

Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin,
Sanjay Ghemawat, Geoffrey Irving, Michael Isard, Manjunath Kudlur Kudlur, Josh Levenberg,
Rajat Monga, Sherry Moore, Derek G. Murray, Benoit Steiner, Paul Tucker, Vijay Vasudevan, Pete
Warden, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. Tensorflow: A system for large-scale
machine learning. In Operating Systems Design and Implementation, 2016.
Alekh Agarwal, Alina Beygelzimer, Miroslav Dudik, John Langford, and Hanna Wallach. A
reductions approach to fair classification. In International Conference on Machine Learning, 2018.
Sina Baharlouei, Maher Nouiehed, Ahmad Beirami, and Meisam Razaviyayn. Rényi fair inference.
In International Conference on Learning Representations, 2020.
Ahmad Beirami, Robert Calderbank, Mark M Christiansen, Ken R Duffy, and Muriel Médard. A
characterization of guesswork on swiftly tilting curves. IEEE Transactions on Information Theory,
65(5):2850–2871, 2019.
Catherine
L
Blake.
Uci
repository
http://www.ics.uci.edu/~mlearn/MLRepository, 1998.

of

machine

learning

databases.

Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir
Ivanov, Chloe Kiddon, Jakub Konecny, Stefano Mazzocchi, H Brendan McMahan, Timon Van
Overveldt, David Petrou, Daniel Ramage, and Jason Roselande. Towards federated learning at
scale: System design. In Conference on Machine Learning and Systems, 2019.
Sebastian Caldas, Peter Wu, Tian Li, Jakub Konečnỳ, H Brendan McMahan, Virginia Smith, and
Ameet Talwalkar. Leaf: A benchmark for federated settings. arXiv preprint arXiv:1812.01097,
2018.
Flavio Calmon, Dennis Wei, Bhanukiran Vinzamuri, Karthikeyan Natesan Ramamurthy, and Kush R
Varshney. Optimized pre-processing for discrimination prevention. In Advances in Neural
Information Processing Systems, 2017.
Andrew Cotter, Heinrich Jiang, Serena Wang, Taman Narayan, Maya Gupta, Seungil You, and
Karthik Sridharan. Optimization with non-differentiable constraints with applications to fairness,
recall, churn, and other goals. Journal of Machine Learning Research, 2019.
Mina Dashti, Paeiz Azmi, and Keivan Navaie. Harmonic mean rate fairness for cognitive radio
networks with heterogeneous traffic. Transactions on Emerging Telecommunications Technologies,
2013.
Marco F Duarte and Yu Hen Hu. Vehicle classification in distributed sensor networks. Journal of
Parallel and Distributed Computing, 2004.
Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. Fairness through
awareness. In Innovations in Theoretical Computer Science, 2012.
Cheng Tien Ee and Ruzena Bajcsy. Congestion control and fairness for many-to-one routing in sensor
networks. In International Conference on Embedded Networked Sensor Systems, 2004.
Atilla Eryilmaz and R Srikant. Joint congestion control, routing, and mac for stability and fairness in
wireless networks. IEEE Journal on Selected Areas in Communications, 2006.
Michael Feldman. Computational fairness: Preventing machine-learned discrimination. 2015.
Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of
deep networks. In International Conference on Machine Learning, 2017.
Alec Go, Richa Bhayani, and Lei Huang. Twitter sentiment classification using distant supervision.
Stanford CS224N Project Report, 2009.
11

Published as a conference paper at ICLR 2020

Ellen L. Hahne. Round-robin scheduling for max-min fairness in data networks. IEEE Journal on
Selected Areas in communications, 1991.
Moritz Hardt, Eric Price, and Nati Srebro. Equality of opportunity in supervised learning. In Advances
in Neural Information Processing Systems, 2016.
Tatsunori Hashimoto, Megha Srivastava, Hongseok Namkoong, and Percy Liang. Fairness without
demographics in repeated loss minimization. In International Conference on Machine Learning,
2018.
Rajendra K Jain, Dah-Ming W Chiu, and William R Hawe. A quantitative measure of fairness and
discrimination. Eastern Research Laboratory, Digital Equipment Corporation, 1984.
Frank Kelly. Charging and rate control for elastic traffic. European Transactions on Telecommunications, 1997.
Frank P Kelly, Aman K Maulloo, and David KH Tan. Rate control for communication networks:
shadow prices, proportional fairness and stability. Journal of the Operational Research society,
1998.
Brenden M Lake, Ruslan Salakhutdinov, and Joshua B Tenenbaum. Human-level concept learning
through probabilistic program induction. Science, 2015.
Tian Lan, David Kao, Mung Chiang, and Ashutosh Sabharwal. An axiomatic theory of fairness in
network resource allocation. In Conference on Information Communications, 2010.
Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges,
methods, and future directions. arXiv preprint arXiv:1908.07873, 2019.
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith.
Federated optimization in heterogeneous networks. In Conference on Machine Learning and
Systems, 2020.
H Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Agüera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In International
Conference on Artificial Intelligence and Statistics, 2017.
Jeonghoon Mo and Jean Walrand. Fair end-to-end window-based congestion control. IEEE/ACM
Transactions on Networking, 2000.
Mehryar Mohri, Gary Sivek, and Ananda Theertha Suresh. Agnostic federated learning. In International Conference on Machine Learning, 2019.
Thyagarajan Nandagopal, Tae-Eun Kim, Xia Gao, and Vaduvur Bharghavan. Achieving mac layer
fairness in wireless packet networks. In International Conference on Mobile Computing and
Networking, 2000.
Michael J Neely, Eytan Modiano, and Chih-Ping Li. Fairness and optimal stochastic control for
heterogeneous networks. IEEE/ACM Transactions On Networking, 2008.
Jeffrey Pennington, Richard Socher, and Christopher Manning. Glove: Global vectors for word
representation. In Empirical Methods in Natural Language Processing, 2014.
Bozidar Radunovic and Jean-Yves Le Boudec. A unified framework for max-min and min-max
fairness with applications. IEEE/ACM Transactions on Networking, 2007.
Alfréd Rényi et al. On measures of entropy and information. In Proceedings of the Fourth Berkeley
Symposium on Mathematical Statistics and Probability, 1961.
Maziar Sanjabi, Meisam Razaviyayn, and Zhi-Quan Luo. Optimal joint base station assignment and
beamforming for heterogeneous networks. IEEE Transactions on Signal Processing, 2014.
Ohad Shamir, Nati Srebro, and Tong Zhang. Communication-efficient distributed optimization using
an approximate newton-type method. In International Conference on Machine Learning, 2014.
12

Published as a conference paper at ICLR 2020

Huaizhou Shi, R Venkatesha Prasad, Ertan Onur, and IGMM Niemegeers. Fairness in wireless
networks: Issues, measures and challenges. IEEE Communications Surveys and Tutorials, 2014.
Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet S Talwalkar. Federated multi-task
learning. In Advances in Neural Information Processing Systems, 2017.
Virginia Smith, Simone Forte, Ma Chenxin, Martin Takáč, Michael I Jordan, and Martin Jaggi. Cocoa:
A general framework for communication-efficient distributed optimization. Journal of Machine
Learning Research, 2018.
Sebastian U Stich. Local sgd converges fast and communicates little. In International Conference on
Learning Representations, 2019.
Jianyu Wang and Gauri Joshi. Cooperative sgd: A unified framework for the design and analysis of
communication-efficient sgd algorithms. arXiv preprint arXiv:1808.07576, 2018.
Blake Woodworth, Suriya Gunasekar, Mesrob I. Ohannessian, and Nathan Srebro. Learning nondiscriminatory predictors. In Conference on Learning Theory, 2017.
Blake E Woodworth, Jialei Wang, Adam Smith, Brendan McMahan, and Nati Srebro. Graph oracle
models, lower bounds, and gaps for parallel stochastic optimization. In Advances in Neural
Information Processing Systems, 2018.
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking
machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017.
Hao Yu, Sen Yang, and Shenghuo Zhu. Parallel restarted sgd for non-convex optimization with faster
convergence and less communication. In AAAI Conference on Artificial Intelligence, 2019.
Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, and Krishna P Gummadi. Fairness beyond disparate treatment & disparate impact: Learning classification without disparate
mistreatment. In International Conference on World Wide Web, 2017a.
Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rogriguez, and Krishna P Gummadi. Fairness constraints: Mechanisms for fair classification. In International Conference on Artificial
Intelligence and Statistics, 2017b.

13

Published as a conference paper at ICLR 2020

A

T HEORETICAL A NALYSIS OF THE PROPOSED OBJECTIVE q-FFL

A.1

UNIFORMITY INDUCED BY q-FFL

In this section, we theoretically justify that the q-FFL objective can impose more uniformity of the
performance/accuracy distribution. As discussed in Section 3.2, q-FFL can encourage more fair
solutions in terms of several metrics, including (1) the variance of accuracy distribution (smaller
variance), (2) the cosine similarity between the accuracy distribution and the all-ones vector 1 (larger
similarity), and (3) the entropy of the accuracy distribution (larger entropy). We begin by formally
defining these fairness notions.
Definition 4 (Uniformity 1: Variance of the performance distribution). We say that the performance
distribution of m devices {F1 (w), . . . , Fm (w)} is more uniform under solution w than w0 if
Var(F1 (w), . . . , Fm (w)) < Var(F1 (w0 ), . . . , Fm (w0 )).

(5)

Definition 5 (Uniformity 2: Cosine similarity between the performance distribution and 1). We say
that the performance distribution of m devices {F1 (w), . . . , Fm (w)} is more uniform under solution
w than w0 if the cosine similarity between {F1 (w), . . . , Fm (w)} and 1 is larger than that between
{F1 (w0 ), . . . , Fm (w0 )} and 1, i.e.,
Pm
Pm
1
1
Fk (w0 )
k=1 Fk (w)
m
m
q P
≥ q Pk=1
.
(6)
m
m
1
1
2 (w)
2 (w 0 )
F
F
k=1 k
k=1 k
m
m
Definition 6 (Uniformity 3: Entropy of performance distribution). We say that the performance
distribution of m devices {F1 (w), . . . , Fm (w)} is more uniform under solution w than w0 if
e (w)) ≥ H(F
e (w0 )),
H(F

(7)

e (w)) is the entropy of the stochastic vector obtained by normalizing
where H(F
{F1 (w), . . . , Fm (w)}, defined as


m
X
Fk (w)
Fk (w)
e
P
P
H(F (w)) := −
log
.
(8)
m
m
k=1 Fk (w)
k=1 Fk (w)
k=1

To enforce uniformity/fairness (defined in Definition 4, 5, and 6), we propose the q-FFL objective to
impose more weights on the devices with worse performance. Throughout the proof, for the ease of
mathematical exposition, we consider a similar unweighted objective:


1
! q+1
m


X
1
min fq (w) =
Fkq+1 (w)
,
w 

m
k=1

and we denote wq∗ as the global optimal solution of minw fq (w).
We first investigate the special case of q = 1 and show that q = 1 results in more fair solutions than
q = 0 based on Definition 4 and Definition 5.
Lemma 7. q = 1 leads to a more fair solution (smaller variance of the model performance distribution) than q = 0, i.e., Var(F1 (w1∗ ), . . . , Fm (w1∗ )) < Var(F1 (w0∗ ), . . . , Fm (w0∗ )).
Proof. Use the fact that w1∗ is the optimal solution of minw f1 (w), and w0∗ is the optimal solution of
minw f0 (w), we get
!2
!2
Pm
Pm
m
m
2
2
∗
∗
1 X
1 X
∗
∗
k=1 Fk (w1 )
k=1 Fk (w0 )
−
Fk (w1 )
≤
−
Fk (w1 )
m
m i=1
m
m i=1
!2
Pm
m
2
∗
X
F
(w
)
1
0
∗
k
≤ k=1
−
Fk (w0 ) .
(9)
m
m i=1

14

Published as a conference paper at ICLR 2020

Lemma 8. q = 1 leads to a more fair solution (larger cosine similarity between the performance
distribution and 1) than q = 0, i.e.,
Pm
Pm
1
1
∗
Fk (w0∗ )
k=1 Fk (w1 )
m
m
q
≥ q k=1
.
1
1
2
∗
2
∗
m Fk (w1 )
m Fk (w0 )
Pm
Pm
Pm
Pm
1
1
1
1
∗
∗
2
∗
2
∗
Proof. As m
k=1 Fk (w1 ) ≥ m
k=1 Fk (w0 ) and m
k=1 Fk (w1 ) ≥ m
k=1 Fk (w0 ), it
directly follows that
Pm
Pm
1
1
∗
Fk (w0∗ )
k=1 Fk (w1 )
m
m
q
≥ q k=1
.
1
1
2 (w ∗ )
2 (w ∗ )
F
F
1
0
m k
m k

We next provide results based on Definition 6. It states that for arbitrary q ≥ 0, by increasing q for a
small amount, we can get more uniform performance distributions defined over higher-orders of the
performance.
Lemma 9. Let F (w) be twice differentiable in w with ∇2 F (w)  0 (positive definite). The derivative
e q (wp∗ )) with respect to the variable p evaluated at the point p = q is non-negative, i.e.,
of H(F
∂ e q ∗
≥ 0,
H(F (wp ))
∂p
p=q
e q (w∗ )) is defined in equation 8.
where H(F
p
Proof.
q
∂ X Fk (wp∗ )
∂ e q ∗
P q ∗ ln
=−
H(F (wp ))
∂p
∂p
κ Fκ (wp )
p=q
k

=−



F q (w∗ )
P k qp ∗
κ Fκ (wp )

q

∂ X Fk (wp∗ )
P q ∗ ln Fkq (wp∗ )
∂p
κ Fκ (wp )
k


(10)
p=q

p=q

X
∂
ln
Fκq (wp∗ )
(11)
∂p
κ
p=q
>

∂
∗
∇w Fkq (wq∗ )
X ∂p wp p=q

P q ∗
ln Fkq (wq∗ )
=−
κ Fκ (wq )
k

>
∂
∗
∇w Fkq (wq∗ )
∂p wp
X Fkq (wq∗ )
p=q
P q ∗
−
(12)
Fkq (wq∗ )
κ Fκ (wq )
k

>
∂
∗
w
∇w Fkq (wq∗ )
X ∂p p p=q


P q ∗
=−
ln Fkq (wq∗ ) + 1 .
(13)
κ Fκ (wq )
k
P
. We know that k ∇w Fkp (wp∗ ) = 0 by definition. Taking the
+

∂
Now, let us examine ∂p
wp∗

p=q

derivative with respect to p, we have
X
X

∂
∇2w Fkp (wp∗ ) wp∗ +
ln Fkp (wp∗ ) + 1 ∇w Fkp (wp∗ ) = 0.
∂p
k

(14)

k

Invoking implicit function theorem,
X
∂ ∗
wp = −
∇2w Fkp (wp∗ )
∂p

!−1
X

k

k

15


ln Fkp (wp∗ ) + 1 ∇w Fkp (wp∗ ).

(15)

Published as a conference paper at ICLR 2020

∂
Plugging ∂p
wp∗

p=q

∂ e
into (13), we get that ∂p
H(F q (wp∗ ))

p=q

≥ 0 completing the proof.

∗
p
∗
Lemma 9 states that for any p, the performance distribution of {F1p (wp+
), . . . , Fm
(wp+
)} is
p
∗
p
∗
guaranteed to be more uniform based on Definition 6 than that of {F1 (wp ), . . . , Fm (wp )} for a small
enough . Note that Lemma 9 is different from the existing results on the monotonicity of entropy
∂ e
under the tilt operation, which would imply that ∂q
H(F q (wp∗ )) ≤ 0 for all q ≥ 0 (see Beirami et al.
(2019, Lemma 11)).

Ideally, we would like to prove a result more general than Lemma 9, implying that the distribution
∗
q
∗
q
{F1q (wp+
), . . . , Fm
(wp+
)} is more uniform than {F1q (wp∗ ), . . . , Fm
(wp∗ )} for any p, q and small
enough . We prove this result for the special case of m = 2 in the following.
Lemma 10. Let F (w) be twice differentiable in w with ∇2 F (w)  0 (positive definite). If m = 2,
e q (wp∗ )) with respect to the variable p is non-negative, i.e.,
for any q ∈ R+ , the derivative of H(F
∂ e q ∗
H(F (wp )) ≥ 0,
∂p
e q (w∗ )) is defined in equation 8.
where H(F
p
Proof. First, we invoke Lemma 9 to obtain that
∂ e q ∗
H(F (wp ))
≥ 0.
∂p
p=q

(16)

F1q (w)
.
q
F1 (w) + F2q (w)

(17)

Let
θq (w) :=

Without loss of generality assume that θq (wp∗ ) ∈ (0, 21 ], as we can relabel F1 and F2 otherwise. Then,
given that m = 2, we conclude from equation 16 along with the monotonicity of the binary entropy
function in (0, 12 ] that
∂
≥ 0,
(18)
θq (wp∗ )
∂p
p=q
which in conjunction with equation 17 implies that

q
∂ F1 (wp∗ )
≥ 0.
∂p F2 (wp∗ )
p=q

(19)

Given the monotonicity of xq with respect to x for all q > 0, it can be observed that the above is
sufficient to imply that for any q > 0,

q
∂ F1 (wp∗ )
≥ 0.
(20)
∂p F2 (wp∗ )
Going all of the steps back we would obtain that for all p > 0
∂ e q ∗
H(F (wp )) ≥ 0.
∂p

(21)

This completes the proof of the lemma.
We conjecture that the statement of Lemma 9 is true for all q ∈ R+ , which would be equivalent to the
statement of Lemma 10 holding true for all m ∈ N.
Thus far, we provided results that showed that q-FFL promotes fairness in three different senses.
Next, we further provide a result on equivalence between the geometric and information-theoretic
notions of fairness.
16

Published as a conference paper at ICLR 2020

Lemma 11 (Equivalence between uniformity in entropy and cosine distance). q-FFL encourages
more uniform performance distributions in the cosine distance sense (Definition 5) if any only if it
encourages more uniform performance distributions in the entropy sense (Definition 6), i.e., (a) holds
if and only if (b) holds where
(a) for any p, q ∈ R, the derivative of H(F q (wp∗ )) with respect to p is non-negative,
f (w∗ )

f (w∗ )

(b) for any 0 ≤ t ≤ r, 0 ≤ v ≤ u, frt (wu∗ ) ≥ frt (wv∗ ) .
u

v

e q (wp∗ )) increases with p
Proof. Definition 6 is a special case of H(F q (wp∗ )) with q = 1. If H(F
for any p, q, then we are guaranteed to get more fair solutions based on Definition 6. Similarly,
f (w∗ )
f (w∗ )
Definition 5 is a special case of frt (wu∗ ) with t = 0, r = 1. If frt (wu∗ ) increases with u for any t ≤ r,
u
u
q-FFL can also obtain more fair solutions under Definition 5.
Next, we show that (a) and (b) are equivalent measures of fairness.
For any r ≥ t ≥ 0, and any u ≥ v ≥ 0,
ft (wu∗ )
ft (wv∗ )
ft (wu∗ )
ft (wv∗ )
≥
⇐⇒
ln
−
ln
≥0
fr (wu∗ )
fr (wv∗ )
fr (wu∗ )
fr (wv∗ )
Z u
ft (wτ∗ )
∂
ln
dτ ≥ 0
⇐⇒
fr (wτ∗ )
v ∂τ
ft (wp∗ )
∂
⇐⇒
ln
≥ 0, for any p ≥ 0
∂p fr (wp∗ )
∂
∂
⇐⇒
ln fr (wp∗ ) −
ln ft (wp∗ ) ≤ 0, for any p ≥ 0
∂p
∂p
Z r
∂2
ln fq (wp∗ )dq ≤ 0 for any p, q ≥ 0
⇐⇒
t ∂p∂q
∂2
⇐⇒
ln fq (wp∗ ) ≤ 0, for any p, q ≥ 0
∂p∂q
∂ e q ∗
⇐⇒
H(F (wp )) ≥ 0, for any p, q ≥ 0.
∂p

(22)
(23)
(24)
(25)
(26)
(27)
(28)

The last inequality is obtained using the fact that by taking the derivative of ln fq (wp∗ ) with respect to
e q (w∗ )).
q, we get −H(F
p
Discussions. We give geometric (Definition 5) and information-theoretic (Definition 6) interpretations
of our uniformity/fairness notion and provide uniformity guarantees under the q-FFL objective in
some cases (Lemma 7, Lemma 8, and Lemma 9). We reveal interesting relations between the
geometric and information-theoretic interpretations in Lemma 11. Future work would be to gain
further understandings for more general cases indicated in Lemma 11.
A.2

G ENERALIZATION BOUNDS

In this section, we first describe the setup we consider in more detail, and then provide generalization
bounds of q-FFL. One benefit of q-FFL is that it allows for a flexible trade-off between fairness and
accuracy, which generalizes AFL (a special case of q-FFL with q → ∞). We also provide learning
bounds that generalize the bounds of the AFL objective, as described below.
Suppose the service provider is interested in minimizing the loss over a distributed network of devices,
with possibly unknown weights on each device:
Lλ (h) =

m
X

λk E(x,y)∼Dk [l(h(x), y)],

(29)

k=1

where λ is in a probability simplex Λ, m is the total number of devices, Dk is the local data distribution
for device k, h is the hypothesis function, and l is the loss. We use L̂λ (h) to denote the empirical
17

Published as a conference paper at ICLR 2020

loss:
L̂λ (h) =

nk
m
X
λk X
k=1

nk j=1

l(h(xk,j ), yk,j ),

(30)

where nk is the number of local samples on device k and (xk,j , yk,j ) ∼ Dk .
We consider a slightly different, unweighted version of q-FFL:
m

min fq (w) =
w

1 X q+1
Fk (w) ,
m

(31)

k=1

which is equivalent to minimizing the empirical loss
L̃q (h) =

max

nk
m
X
νi X

ν,kνkp ≤1

k=1

nk j=1

l(h(xk,j ), yk,j ),

(32)

1
where p1 + q+1
= 1 (p ≥ 1, q ≥ 0).

Lemma 12 (Generalization bounds of q-FFL for a specific λ). Assume that the loss l is bounded by
M > 0 and the numbers of local samples are (n1 , · · · , nm ). Then, for any δ > 0, with probability at
least 1 − δ, the following holds for any λ ∈ Λ, h ∈ H:
v
um


uX λ2k
1
(33)
Lλ (h) ≤ Aq (λ)L̃q (h) + E max Lλ (h) − L̂λ (h) + M t
log ,
h∈H
2nk
δ
k=1

where Aq (λ) = kλkp , and 1/p + 1/(q + 1) = 1.
Proof. Similar to the proof in Mohri et al. (2019), for any δ > 0, the following inequality holds with
probability at least 1 − δ for any λ ∈ Λ, h ∈ H:
v
um


uX λ2k
1
Lλ (h) ≤ L̂λ (h) + E max Lλ (h) − L̂λ (h) + M t
(34)
log .
h∈H
2nk
δ
k=1

Denote the empirical loss on device k n1k
have
! p1
m
m
X
X
p
L̂λ (h) =
λk Fk ≤
λk
k=1

k=1

Pnk

j=1 l(h(xk,j ), yk,j ) as Fk . From Hölder’s inequality, we

m
X

1
! q+1

Fkq+1

k=1

= Aq (λ)L̃q (h),

1
1
+
= 1.
p q+1

Plugging L̂λ (h) ≤ Aq (λ)L̃q (h) into (34) yields the results.
Theorem 13 (Generalization bounds of q-FFL for any λ). Assume that the loss l is bounded by
M > 0 and the number of local samples is (n1 , · · · , nm ). Then, for any δ > 0, with probability at
least 1 − δ, the following holds for any λ ∈ Λ, h ∈ H:
v


um


uX λ2k
1
Lλ (h) ≤ max (Aq (λ)) L̃q (h) + max E max Lλ (h) − L̂λ (h) + M t
log  , (35)
λ∈Λ
λ∈Λ
h∈H
2nk
δ
k=1

where Aq (λ) = kλkp , and 1/p + 1/(q + 1) = 1.
Proof. This directly follows from Lemma 12, by taking the maximum over all possible λ’s in Λ.

1
1
Discussions. From Lemma 12, letting λ = m
,··· , m
and q → ∞, we recover the generalization
bounds in AFL (Mohri et al., 2019). In that sense, our generalization results extend those of AFL’s.
In addition, it is not straightforward to derive an optimal q with the tightest generalization bound
from Lemma 12 and Theorem 13. In practice, our proposed method q-FedAvg allows us to tune a
family of q’s by re-using the step-sizes.
18

Published as a conference paper at ICLR 2020

B

α- FAIRNESS AND q-FFL

As discussed in Section 2, while it is natural to consider the α-fairness framework for machine
learning, we are unaware of any work that uses α-fairness to modify machine learning training
objectives. We provide additional details on the framework below; for further background on αfairness and fairness in resource allocation more generally, we defer the reader to Shi et al. (2014);
Mo & Walrand (2000).
α-fairness (Lan et al., 2010; Mo & Walrand, 2000) is a popular fairness metric widely-used in
resource allocation problems. The framework defines a family of overall utility functions that can be
derived by summing up the following function of the individual utilities of the users in the network:
(
ln(x),
if α = 1
Uα (x) =
1
1−α
, if α ≥ 0, α 6= 1 .
1−α x
Here Uα (x) represents the individual utility of some specific user given x allocated resources
(e.g., bandwidth). The goal is to find a resource allocation strategy to maximize the sum of the
individual utilities. This family of functions includes a wide range of popular fair resource allocation
strategies. In particular, the above function represents zero fairness with α = 0, proportional
fairness (Kelly, 1997) with α = 1, harmonic mean fairness (Dashti et al., 2013) with α = 2, and
max-min fairness (Radunovic & Le Boudec, 2007) with α = +∞.
Note that in federated learning, we are dealing with costs and not utilities. Thus, max-min in
resource allocation corresponds to min-max in our setting. With this analogy, it is clear that in our
proposed objective q-FFL (2), the case where q = +∞ corresponds to min-max fairness since it is
optimizing for the worst-performing device, similar to what was proposed in Mohri et al. (2019).
Also, q = 0 corresponds to zero fairness, which reduces to the original FedAvg objective (1). In
resource allocation problems, α can be tuned for trade-offs between fairness and system efficiency.
In federated settings, q can be tuned based on the desired level of fairness (e.g., desired variance of
accuracy distributions) and other performance metrics such as the overall accuracy. For instance,
in Table 2 in Section 4.3, we demonstrate on two datasets that as q increases, the overall average
accuracy decreases slightly while the worst accuracies are increased significantly and the variance of
the accuracy distribution decreases.

19

Published as a conference paper at ICLR 2020

C

P SEUDO - CODE OF A LGORITHMS

C.1

T HE F E D A V G A LGORITHM

Algorithm 3 Federated Averaging McMahan et al. (2017) (FedAvg)
Input: K, T , η, E, w0 , N , pk , k = 1, · · · , N
for t = 0, · · · , T − 1 do
Server randomly chooses a subset St of K devices (each device k is chosen with probability pk )
Server sends wt to all chosen devices
Each device k updates wt for E epochs of SGD on Fk with step-size η to obtain wkt+1
Each chosen device k sends wkt+1 back P
to the server
Server aggregates the w’s as wt+1 = K1 k∈St wkt+1
end for
C.2

T HE q-MAML A LGORITHM

Algorithm 4 q-FFL applied to MAML: q-MAML
1: Input: K, T , η, w0 , N , pk , k = 1, · · · , N
2: for t = 0, · · · , T − 1 do
3:
Sample a batch of St (|St | = K) tasks randomly (each task k is chosen with probability pk )
4:
Send wt to all sampled tasks
5:
Each task k ∈ St samples data Dk from the training set and Dk0 from the testing set, and
6:
7:

computes updated parameters on D: wkt = wt − η∇Fk (wt )
Each task k ∈ St computes the gradients ∇Fk (wkt ) on D0
Each task k ∈ St computes:
∆tk = Fkq (wkt )∇Fk (wkt )

htk = qFkq−1 (wkt )k∇Fk (wkt )k2 + LFkq (wkt )
8:

wt+1 is updated as:
w

t+1

P
∆tk
= w − Pk∈St t
k∈St hk
t

9: end for

20

Published as a conference paper at ICLR 2020

D

E XPERIMENTAL D ETAILS

D.1

DATASETS AND M ODELS

We provide full details on the datasets and models used in our experiments. The statistics of
four federated datasets used in federated learning (as opposed to meta-learning) experiments are
summarized in Table 4. We report the total number of devices, the total number of samples, and mean
and deviation in the sizes of total data points on each device. Additional details on the datasets and
models are described below.
• Synthetic: We follow a similar set up as that in Shamir et al. (2014) and impose additional
heterogeneity. The model is y = argmax(softmax(W x+b)), x ∈ R60 , W ∈ R10×60 , b ∈ R10 , and
the goal is to learn a global W and b. Samples (Xk , Yk ) and local models on each device k satisfies
Wk ∼ N (uk , 1), bk ∼ N (uk , 1), uk ∼ N (0, 1); xk ∼ N (vk , Σ), where the covariance matrix Σ
is diagonal with Σj,j = j −1.2 . Each element in vk is drawn from N (Bk , 1), Bk ∼ N (0, 1). There
are 100 devices in total and the number of samples on each devices follows a power law.
• Vehicle2 : We use the same Vehicle Sensor (Vehicle) dataset as Smith et al. (2017), modelling each
sensor as a device. This dataset consists of acoustic, seismic, and infrared sensor data collected
from a distributed network of 23 sensors Duarte & Hu (2004). Each sample has a 100-dimension
feature and a binary label. We train a linear SVM to predict between AAV-type and DW-type
vehicles. We tune the hyperparameters in SVM and report the best configuration.
• Sent140: This dataset is a collection of tweets curated from 1,101 accounts from Sentiment140 (Go et al., 2009) (Sent140) where each Twitter account corresponds to a device. The
task is text sentiment analysis which we model as a binary classification problem. The model
takes as input a 25-word sequence, embeds each word into a 300-dimensional space using pretrained Glove (Pennington et al., 2014), and outputs a binary label after two LSTM layers and one
densely-connected layer.
• Shakespeare: This dataset is built from The Complete Works of William Shakespeare (McMahan
et al., 2017). Each speaking role in the plays is associated with a device. We subsample 31 speaking
roles to train a deep language model for next character prediction. The model takes as input an
80-character sequence, embeds each character into a learnt 8-dimensional space, and outputs one
character after two LSTM layers and one densely-connected layer.
• Omniglot: The Omniglot dataset (Lake et al., 2015) consists of 1,623 characters from 50 different
alphabets. We create 300 meta-training tasks from the first 1,200 characters, and 100 meta-testing
tasks from the last 423 characters. Each task is a 5-class classification problem where each
character forms a class. The model is a convolutional neural network with two convolution layers
and two fully-connected layers.
Table 4: Statistics of federated datasets
Dataset

Devices Samples Samples/device

Synthetic
100
Vehicle
23
Sent140
1,101
Shakespeare 31

D.2

12,697
43,695
58,170
116,214

mean stdev
127 73
1,899 349
53
32
3,749 6,912

I MPLEMENTATION D ETAILS

D.2.1

M ACHINES

We simulate the federated setting (one server and m devices) on a server with 2 Intel R Xeon R
E5-2650 v4 CPUs and 8 NVidia R 1080Ti GPUs.
2

http://www.ecs.umass.edu/~mduarte/Software.html

21

Published as a conference paper at ICLR 2020

D.2.2

S OFTWARE

We implement all code in TensorFlow (Abadi et al., 2016) Version 1.10.1.
github.com/litian96/fair_flearn for full details.
D.2.3

Please see

H YPERPARAMETERS

We randomly split data on each local device into 80% training set, 10% testing set, and 10%
validation set. We tune a best q from {0.001, 0.01, 0.1, 0.5, 1, 2, 5, 10, 15} on the validation set and
report accuracy distributions on the testing set. We pick up the q value where the variance decreases
the most, while the overall average accuracy change (compared with the q = 0 case) is within 1%.
For each dataset, we repeat this process for five randomly selected train/test/validation splits, and
report the mean and standard deviation across these five runs where applicable. For Synthetic, Vehicle,
Sent140, and Shakespeare, optimal q values are 1, 5, 1, and 0.001, respectively. For all datasets, we
randomly sample 10 devices each round. We tune the learning rate and batch size on FedAvg and
use the same learning rate and batch size for all q-FedAvg experiments of that dataset. The learning
rates for Synthetic, Vehicle, Sent140, and Shakespeare are 0.1, 0.01, 0.03, and 0.8, respectively. The
batch sizes for Synthetic, Vehicle, Sent140, and Shakespeare are 10, 64, 32, and 10. The number of
local epochs E is fixed to be 1 for both FedAvg and q-FedAvg regardless of the values of q.
In comparing q-FedAvg’s efficiency with q-FedSGD, we also tune a best learning rate for q-FedSGD
methods on q = 0. For each comparison, we fix devices selected and mini-batch orders across all
runs. We stop training when the training loss F (w) does not decrease for 10 rounds. When running
AFL methods, we search for a best γw and γλ such that AFL achieves the highest testing accuracy on
the device with the highest loss within a fixed number of rounds. For Adult, we use γw = 0.1 and
γλ = 0.1; for Fashion MNIST, we use γw = 0.001 and γλ = 0.01. We use the same γw as step-sizes
for q-FedAvg on Adult and Fashion MNIST. In Table 2, q1 = 0.01, q2 = 2 for q-FFL on Adult and
q1 = 5, q2 = 15 for q-FFL on Fashion MNIST. Similarly, the number of local epochs is fixed to 1
whenever we perform local updates.

22

Published as a conference paper at ICLR 2020

E

F ULL E XPERIMENTS

E.1

F ULL RESULTS OF PREVIOUS EXPERIMENTS

Fairness of q-FFL under all uniformity metrics. We demonstrate the fairness of q-FFL in Table 1
in terms of variance. Here, we report similar results in terms of other uniformity measures (the last
two columns).
Table 5: Full statistics of the test accuracy distribution for q-FFL. q-FFL increases the accuracy of
the worst 10% devices without decreasing the average accuracies. We see that q-FFL encourages
more uniform distributions under all uniformity metrics defined in Appendix A.2: (1) the variance
of the accuracy distribution (Definition 4), (2) the cosine similarity/geometric angle between the
accuracy distribution and the all-ones vector 1 (Definition 5), and (3) the KL-divergence between the
normalized accuracy vector a and the uniform distribution u, which can be directly translated to the
entropy of a (Definition 6) .
Dataset

Objective

q=0
q=1
q=0
Vehicle
q=5
q=0
Sent140
q=1
q=0
Shakespeare
q = .001
Synthetic

Average Worst 10% Best 10% Variance Angle KL(a||u)
(%)
(%)
(%)
(◦ )
80.8 ± .9 18.8 ± 5.0 100.0 ± 0.0 724 ± 72 19.5 ± 1.1 .083 ± .013
79.0 ± 1.2 31.1 ± 1.8 100.0 ± 0.0 472 ± 14 16.0 ± .5 .049 ± .003
87.3 ± .5 43.0 ± 1.0 95.7 ± 1.0 291 ± 18 11.3 ± .3 .031 ± .003
87.7 ± .7 69.9 ± .6
94.0 ± .9
48 ± 5
4.6 ± .2 .003 ± .000
65.1 ± 4.8 15.9 ± 4.9 100.0 ± 0.0 697 ± 132 22.4 ± 3.3 .104 ± .034
66.5 ± .2 23.0 ± 1.4 100.0 ± 0.0 509 ± 30 18.8 ± .5 .067 ± .006
51.1 ± .3 39.7 ± 2.8 72.9 ± 6.7 82 ± 41 9.8 ± 2.7 .014 ± .006
52.1 ± .3 42.1 ± 2.1 69.0 ± 4.4 54 ± 27 7.9 ± 2.3 .009 ± .05

Fairness of q-FFL with respect to training accuracy. The empirical results in Section 4 are with
respect to testing accuracy. As a sanity check, we show that q-FFL also results in more fair training
accuracy distributions in Figure 6 and Table 6.

Figure 6: q-FFL (q > 0) results in more centered (i.e., fair) training accuracy distributions across
devices without sacrificing the average accuracy.
Table 6: q-FFL results in more fair training accuracy distributions in terms of all uniformity
measurements—(a) the accuracy variance, (b) the cosine similarity (i.e., angle) between the accuracy distribution and the all-ones vector 1, and (c) the KL divergence between the normalized
accuracy a and uniform distribution u.
Dataset

Objective

q=0
q=1
q=0
Vehicle
q=5
q=0
Sent140
q=1
q=0
Shakespeare
q = .001
Synthetic

Average Worst 10% Best 10% Variance Angle KL(a||u)
(%)
(%)
(%)
(◦ )
81.7 ± .3 23.6 ± 1.1 100.0 ± .0 597 ± 10 17.5 ± .3 .061 ± .002
78.9 ± .2 41.8 ± 1.0
96.8 ± .5 292 ± 11 12.5 ± .2 .027 ± .001
87.5 ± .2 49.5 ± 10.2 94.9 ± .7 237 ± 97 10.2 ± 2.4 .025 ± .011
87.8 ± .5 71.3 ± 2.2 93.1 ± 1.4 37 ± 12
4.0 ± .7 .003 ± .001
69.8 ± .8 36.9 ± 3.1 94.4 ± 1.1 278 ± 44 13.6 ± 1.1 .032 ± .006
68.2 ± .6
46.0 ± .3
88.8 ± .8 143 ± 4 10.0 ± .1 .017 ± .000
72.7 ± .8 46.4 ± 1.4
79.7 ± .9 116 ± 8
9.9 ± .3 .015 ± .001
66.7 ± 1.2 48.0 ± .4
71.2 ± 1.9
56 ± 9
7.1 ± .5 .008 ± .001

23

Published as a conference paper at ICLR 2020

Average testing accuracy with respect to devices. In Section 4.2, we show that q-FFL leads to
more fair accuracy distributions while maintaining approximately the same testing accuracies. Note
that we report average testing accuracy with respect to all data points in Table 1. However, we
observe similar results on average accuracy with respect to all devices between q = 0 and q > 0
objectives, as shown in Table 7. This indicates that q-FFL can reduce the variance of the accuracy
distribution without sacrificing the average accuracy over devices or over data points.
Table 7: Average testing accuracy under q-FFL objectives. We show that the resulting solutions of
q = 0 and q > 0 objectives have approximately the same average accuracies both with respect to all
data points and with respect to all devices.
Dataset

Objective

q=0
q=1
q=0
Vehicle
q=5
q=0
Sent140
q=1
q=0
Shakespeare
q = .001
Synthetic

Accuracy w.r.t. Data Points Accuracy w.r.t. Devices
(%)
(%)
80.8 ± .9
77.3 ± .6
79.0 ± 1.2
76.3 ± 1.7
87.3 ± .5
85.6 ± .4
87.7 ± .7
86.5 ± .7
65.1 ± 4.8
64.6 ± 4.5
66.5 ± .2
66.2 ± .2
51.1 ± .3
61.4 ± 2.7
52.1 ± .3
60.0 ± .5

Comparison with uniform sampling. In Figure 7 and Table 8, we show that in terms of training
accuracies, the uniform sampling heuristic may outperform q-FFL (as opposed to the testing accuracy
results in Section 4). We suspect that this is because the uniform sampling baseline is a static method
and is likely to overfit to those devices with few samples. In additional to Figure 3 in Section 4.3, we
also report the average testing accuracy with respect to data points, best 10%, worst 10% accuracies,
and the variance (along with two other uniformity measures) in Table 9.

Figure 7: q-FFL (q > 0) compared with uniform sampling in training accuracy. We see that on some
datasets uniform sampling has higher (and more fair) training accuracies due to the fact that it is
overfitting to devices with few samples.
Table 8: More statistics comparing the uniform sampling objective with q-FFL in terms of training
accuracies. We observe that uniform sampling could result in more fair training accuracy distributions
with smaller variance in some cases.
Dataset

Objective

uniform
q=1
uniform
Vehicle
q=5
uniform
Sent140
q=1
uniform
Shakespeare
q = .001
Synthetic

Average Worst 10% Best 10% Variance Angle KL(a||u)
(%)
(%)
(%)
(◦ )
83.5 ± .2 42.6 ± 1.4 100.0 ± .0 366 ± 17 13.4 ± .3 .031 ± .002
78.9 ± .2 41.8 ± 1.0
96.8 ± .5 292 ± 11 12.5 ± .2 .027 ± .001
87.3 ± .3
46.6 ± .8
94.8 ± .5 261 ± 10 10.7 ± .2 .027 ± .001
87.8 ± .5 71.3 ± 2.2 93.1 ± 1.4 37 ± 12 4.0 ± .7 .003 ± .001
69.1 ± .5 42.2 ± 1.1 91.0 ± 1.3 188 ± 19 11.3 ± .5 .022 ± .002
68.2 ± .6
46.0 ± .3
88.8 ± .8 143 ± 4 10.0 ± .1 .017 ± .000
57.7 ± 1.5 54.1 ± 1.7 72.4 ± 3.2
32 ± 7
5.2 ± .5 .004 ± .001
66.7 ± 1.2 48.0 ± .4
71.2 ± 1.9
56 ± 9
7.1 ± .5 .008 ± .001

24

Published as a conference paper at ICLR 2020

Table 9: More statistics showing more fair solutions induced by q-FFL compared with the uniform
sampling baseline in terms of test accuracies. Again, we observe that under q-FFL, the testing
accuracy of the worst 10% devices tends to increase compared with uniform sampling, and the
variance of the final testing accuracies is smaller. Similarly, q-FFL is also more fair than uniform
sampling in terms of other uniformity metrics.
Dataset

Objective

uniform
q=1
uniform
Vehicle
q=5
uniform
Sent140
q=1
uniform
Shakespeare
q = .001
Synthetic

E.2

Average Worst 10% Best 10% Variance Angle KL(a||u)
(%)
(%)
(%)
(◦ )
82.2 ± 1.1 30.0 ± .4
100.0 ± .0 525 ± 47 15.6 ± .8 .048 ± .007
79.0 ± 1.2 31.1 ± 1.8 100.0 ± 0.0 472 ± 14 16.0 ± .5 .049 ± .003
86.8 ± .3
45.4 ± .3
95.4 ± .7
267 ± 7 10.8 ± .1 .028 ± .001
87.7 ± 0.7 69.9 ± .6
94.0 ± .9
48 ± 5
4.6 ± .2 .003 ± .000
66.6 ± 2.6 21.1 ± 1.9 100.0 ± 0.0 560 ± 19 19.8 ± .7 .076 ± .006
66.5 ± .2 23.0 ± 1.4 100.0 ± 0.0 509 ± 30 18.8 ± .5 .067 ± .006
50.9 ± .4 41.0 ± 3.7 70.6 ± 5.4 71 ± 38 9.1 ± 2.8 .012 ± .006
52.1 ± .3 42.1 ± 2.1 69.0 ± 4.4 54 ± 27 7.9 ± 2.3 .009 ± .05

A DDITIONAL E XPERIMENTS

Effects of data heterogeneity and the number of devices on unfairness. To study how data
heterogeneity and the total number of devices affect unfairness in a more direct way, we investigate
into a set of synthetic datasets where we can quantify the degree of heterogeneity. The results are
shown in Table 10 below. We generate three synthetic datasets following the process described in
Appendix D.1, but with different parameters to control heterogeneity. In particular, we generate
an IID data— Synthetic (IID) by setting the same W and b on all devices and setting the samples
xk ∼ N (0, 1) for any device k. We instantiate two non-identically distributed datasets (Synthetic (1,
1) and Synthetic (2, 2)) from Synthetic (α, β) where uk ∼ N (0, α) and Bk ∼ N (0, β). Recall that
α, β allows to precisely manipulate the degree of heterogeneity with larger α, β values indicating
more statistical heterogeneity. Therefore, from top to bottom in Table 10, data are more heterogeneous.
For each dataset, we further create two variants with different number of participating devices. We
see that as data become more heterogeneous and as the number of devices in the network increases,
the accuracy distribution tends to be less uniform.
Table 10: Effects of data heterogeneity and the number of devices on unfairness. For a fixed number
of devices, as data heterogeneity increases from top to bottom, the accuracy distributions become
less uniform (with larger variance) for both q = 0 and q > 0. Within each dataset, the decreasing
number of devices results in a more uniform accuracy distribution. In all scenarios (except on IID
data), setting q > 0 helps to encourage more fair solutions.
Dataset

Objective Average Worst 10% Best 10% Variance
q=0
89.2 ± .6
70.9 ± 3
100.0 ± 0 85 ± 15
100 devices
q=1
89.0 ± .5
70.3 ± 3
100.0 ± 0 88 ± 19
Synthetic (IID)
q=0
87.1 ± 1.5 66.5 ± 3
100.0 ± 0 107 ± 14
50 devices
q=1
86.8 ± 0.8 66.5 ± 2
100.0 ± 0 109 ± 13
q=0
83.0 ± .9
36.8 ± 2
100.0 ± 0 452 ± 22
100 devices
q=1
82.7 ± 1.3 43.5 ± 5
100.0 ± 0 362 ± 58
Synthetic (1, 1)
q=0
84.5 ± .3
43.3 ± 2
100.0 ± 0 370 ± 37
50 devices
q=1
85.1 ± .8
47.3 ± 3
100.0 ± 0 317 ± 41
q=0
82.6 ± 1.1 25.5 ± 8
100.0 ± 0 618 ± 117
100 devices
q=1
82.2 ± 0.7 31.9 ± 6
100.0 ± 0 484 ± 79
Synthetic (2, 2)
q=0
85.9 ± 1.0 36.8 ± 7
100.0 ± 0 421 ± 85
50 devices
q=1
85.9 ± 1.4 39.1 ± 6
100.0 ± 0 396 ± 76
A family of q’s results in variable levels of fairness. In Table 11, we show the accuracy distribution statistics of using a family of q’s on synthetic data. Our objective and methods are not sensitive
to any particular q since all q > 0 values can lead to more fair solutions compared with q = 0. In
our experiments in Section 4, we report the results using the q values selected following the protocol
described in Appendix D.2.3.
25

Published as a conference paper at ICLR 2020

Table 11: Test accuracy statistics of using a family of q’s on synthetic data. We show results with q’s
selected from our candidate set {0.001, 0.01, 0.1, 1, 2, 5, 10, 15}. q-FFL allows for a more flexible
trade-off between fairness and accuracy. A larger q results in more fairness (smaller variance),
but potentially lower accuracy. Similarly, a larger q imposes more uniformity in terms of other
metrics—(a) the cosine similarity/angle between the accuracy distribution and the all-ones vector 1,
and (b) the KL divergence between the normalized accuracy a and a uniform distribution u.
Dataset

Objective Average Worst 10% Best 10% Variance Angle KL(a||u)
(%)
(%)
(%)
(◦ )
q=0
80.8 ± .9 18.8 ± 5.0 100.0 ± 0.0 724 ± 72 19.5 ± 1.1 .083 ± .013
q= 0.1
81.1 ± 0.8 22.1 ± .8 100.0 ± 0.0 666 ± 56 18.4 ± .8 .070 ± .009
Synthetic q=1
79.0 ± 1.2 31.1 ± 1.8 100.0 ± 0.0 472 ± 14 16.0 ± .5 .049 ± .003
q=2
74.7 ± 1.3 32.2 ± 2.1
99.9 ± .2 410 ± 23 15.6 ± 0.7 .044 ± .005
q=5
67.2 ± 0.9 30.0 ± 4.8 94.3 ± 1.4 369 ± 51 16.3 ± 1.2 .048 ± .010
Device-specific q. In these experiments, we explore a device-specific strategy for selecting q in
q-FFL. We solve q-FFL with q ∈ {0, 0.001, 0.01, 0.1, 1, 2, 5, 10} in parallel. After training, each
device selects the best resulting model based on the validation data and tests the performance of
the model using the testing set. We report the results in terms of testing accuracy in Table 12.
Interestingly, using this device-specific strategy the average accuracy in fact increases while the
variance of accuracies is reduced, in comparison with q = 0. We note that this strategy does induce
more local computation and additional communication load at each round. However, it does not
increase the number of communication rounds if run in parallel.
Table 12: Effects of running q-FFL with several q’s in parallel. We train multiple global models
(corresponding to different q’s) independently in the network. After the training finishes, each
device picks up a best, device-specific model based on the performance (accuracy) on the validation
data. While this adds additional local computation and more communication load per round, the
device-specific strategy has the added benefit of increasing the accuracies of devices with the worst
10% accuracies and devices with the best 10% accuracies simultaneously. This strategy is built upon
the proposed primitive Algorithm 2, and in practice, people can develop other heuristics to improve
the performance (similar to what we explore here), based on the method of adaptively averaging
model updates proposed in Algorithm 2.
Dataset

Objective Average Worst 10% Best 10% Variance Angle KL(a||u)
(%)
(%)
(%)
(◦ )
q=0
87.3 ± .5 43.0 ± 1.0 95.7 ± 1.0 291 ± 18 11.3 ± .3 .031 ± .003
Vehicle
q=5
87.7 ± .7 69.9 ± .6
94.0 ± .9
48 ± 5
4.6 ± .2 .003 ± .000
multiple q 88.5 ± .3 70.0 ± 2.0
95.8 ± .6
52 ± 7
4.7 ± .3 .004 ± .000
q=0
51.1 ± .3 39.7 ± 2.8 72.9 ± 6.7 82 ± 41 9.8 ± 2.7 .014 ± .006
Shakespeare q=.001
52.1 ± .3 42.1 ± 2.1 69.0 ± 4.4 54 ± 27 7.9 ± 2.3 .009 ± .05
multiple q 52.0 ± 1.5 41.0 ± 4.3 72.0 ± 4.8 72 ± 32 10.1 ± .7 .017 ± .000
Convergence speed of q-FFL. Since q−FFL (q > 0) is more difficult to optimize, a natural
question one might ask is: will the q-FFL q > 0 objectives slow the convergence compared with
FedAvg? We empirically investigate this on the four datasets. We use q-FedAvg to solve q-FFL,
and compare it with FedAvg (i.e., solving q-FFL with q = 0). As demonstrated in Figure 8, the q
values that result in more fair solutions also do not significantly slow down convergence.

Figure 8: The convergence speed of q-FFL compared with FedAvg. We plot the distance to the
highest accuracy achieved versus communication rounds. Although q-FFL with q>0 is a more
difficult optimization problem, for the q values we choose that could lead to more fair results, the
convergence speed is comparable to that of q = 0.

26

Published as a conference paper at ICLR 2020

Efficiency of q-FFL compared with AFL. One added benefit of q-FFL is that it leads to faster
convergence than AFL—even when we use non-local-updating methods for both objectives. In Figure
9, we show with respect to the final testing accuracy for the single worst device (i.e., the objective that
AFL is trying to optimize), q-FFL converges faster than AFL. As the number of devices increases
(from Fashion MNIST to Vehicle), the performance gap between AFL and q-FFL becomes larger
because AFL introduces larger variance.

q-

q-

Figure 9: q-FFL is more efficient than AFL. With the worst device achieving the same final testing
accuracy, q-FFL converges faster than AFL. For Vehicle (with 23 devices) as opposed to Fashion
MNIST (with 3 devices), we see that the performance gap is larger. We run full gradient descent at
each round for both methods.
Efficiency of q-FedAvg under different data heterogeneity. As mentioned in Appendix E.1, one
potential cause for the slower convergence of q-FedAvg on the synthetic dataset may be that local
updating schemes could hurt convergence when local data distributions are highly heterogeneous.
Although it has been shown that applying updates locally results in significantly faster convergence in
terms of communication rounds (McMahan et al., 2017; Smith et al., 2018), which is consistent with
our observation on most datasets, we note that when data is highly heterogeneous, local updating
may hurt convergence. We validate this by creating an IID synthetic dataset (Synthetic-IID) where
local data on each device follow the same global distribution. We call the synthetic dataset used
in Section 4 Synthetic-Non-IID. We also create a hybrid dataset (Synthetic-Hybrid) where half of
the total devices are assigned IID data from the same distribution, and half of the total devices are
assigned data from different distributions. We observe that if data is perfectly IID, q-FedAvg is
more efficient than q-FedSGD. As data become more heterogeneous, q-FedAvg converges more
slowly than q-FedSGD in terms of communication rounds. For all three synthetic datasets, we repeat
the process of tuning a best constant step-size for FedSGD and observe similar results as before —
our dynamic solver q-FedSGD behaves similarly (or even outperforms) a best hand-tuned FedSGD.
 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ Ͳ , Ǉ ď ƌ ŝ Ě

 Ϭ ͘ ϲ

 Ƌ Ͳ & Ğ Ě  ǀ Ő
 Ƌ Ͳ & Ğ Ě ^ ' 
 ď Ğ Ɛ ƚ  ƚ Ƶ Ŷ Ğ Ě  & Ğ Ě ^ ' 

 Ϭ ͘ ϰ
 Ϭ ͘ Ϯ
 Ϭ

 ϱ Ϭ Ϭ

 ϭ Ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ Ϭ

 Ϯ Ϭ Ϭ Ϭ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ Ͳ / / 

 Ϭ ͘ ϲ

 d Ğ Ɛ ƚ ŝ Ŷ Ő  Ă Đ Đ Ƶ ƌ Ă Đ Ǉ

 d Ğ Ɛ ƚ ŝ Ŷ Ő  Ă Đ Đ Ƶ ƌ Ă Đ Ǉ

 d Ğ Ɛ ƚ ŝ Ŷ Ő  Ă Đ Đ Ƶ ƌ Ă Đ Ǉ

 ^ Ǉ Ŷ ƚ Ś Ğ ƚ ŝ Đ Ͳ E Ž Ŷ Ͳ / / 
 Ϭ ͘ ϴ

 Ϭ ͘ ϰ
 Ϭ ͘ Ϯ
 Ϭ

 ϱ Ϭ Ϭ

 ϭ Ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ Ϭ

 Ϯ Ϭ Ϭ Ϭ

 Ϭ ͘ ϴ
 Ϭ ͘ ϲ
 Ϭ ͘ ϰ
 Ϭ ͘ Ϯ
 Ϭ

 ϱ Ϭ Ϭ

 ϭ Ϭ Ϭ Ϭ

 η  Z Ž Ƶ Ŷ Ě Ɛ

 ϭ ϱ Ϭ Ϭ

 Ϯ Ϭ Ϭ Ϭ

Figure 10: Convergence of q-FedAvg compared with q-FedSGD under different data heterogeneity.
When data distributions are heterogeneous, it is possible that q-FedAvg converges more slowly than
q-FedSGD. Again, the proposed dynamic solver q-FedSGD performs similarly (or better) than a best
tuned fixed-step-size FedSGD.

27

Relative Fair Federated Learning

Alexandru-Andrei Iacob
aai30@cam.ac.uk

Abstract
The canonical loss function of Federated Learning is a weighted average of the
local client objective functions without regard to performance distribution amongst
clients. A recently proposed class of algorithms, q-FFL, promotes fairness by
raising the loss function to an exponent. While promising, this mechanism is
sensitive to loss magnitude and requires extensive tuning to the dataset. This work
proposes p-FFL, a relative form of fair aggregation where client loss functions are
weighted solely on the basis of their position in the sorted order. Multiple algorithm
versions based on p-FFL are implemented to emphasise different fairness functions
which weigh a client’s position linearly, geometrically or logarithmically. They
are tested both in terms of fairness and convergence speed on three different ML
applications. The results show that while p-FFL can improve the fairness of client
performance distribution it is not yet competitive in its current form to q-FFL.

1

Introduction

The data and system heterogeneity inherent to Federated Learning McMahan et al. [2017], Kairouz
et al. [2019] make difficult the construction of a global model capable of providing satisfactory results
for all potential devices that it may be trained or deployed. Such heterogeneity may be intrinsic to
the explored setting, e.g languages being heavily localised, meaning that decreased performance
of the global model on a subset of clients could be unavoidable. A potential solution to this issue
is to construct a “fairer” global model. In this context, fairness refers to the uniformity of model
performance across devices with different data and system characteristics. Constructing a fairer
model requires modifying the objective function used in FL.
The canonical Federated Learning (FL) objective was was formalised by Li et al. [2018] as follows:
minf (w) =
w

m
X

pk Fk (w)

(1)

k=1

where f is the global loss, w is the model, m is the total number of client, Fk are the local client loss
functions and pk are the weights associated with each client—generally chosen as its proportion of
the training examples. The first version of Fair FL (FFL) was proposed by Li et al. [2019] who define
a family of FFL algorithms, q-FFL, based around the following modification to the loss function
minfq (w) =
w

m
X
pk
F q+1 (w)
q+1 k

(2)

k=1

where q is a parameter controlling the fairness of the weighing based on the value of the loss. A larger
q implies a higher degree of fairness. When q tends towards infinity, the objective becomes identical
to improving performance on only the worst-performing client. While Li et al. [2019] show a great
deal of improvement over classical FL algorithms, their approach has two primary shortcomings.
First, if one of the clients is an extreme outlier, they can skew the results significantly for high q
values. Thus the model can either be made to diverge, or potentially manipulated to over-emphasise
the needs of a specific client. Second, the optimal q-values vary significantly across domains. Li et al.

[2019] report q’s ranging from 0.001 to 5 according to task. The primary hypothesis explored in this
report is that developing a less loss-sensitive FFL algorithm could improve the robustness of results
and require reduced parameter tuning between tasks.
This work brings three main contributions to the field of FFL. First, it provides a new class of relatively
fair FL algorithms deemed p-FFL. This class uses a fairness mechanism based on generalised Gini
social-evaluation functions [Weymark, 1981] rather than the α-fairness [Lan et al., 2010] of qFFL. Second, it constructs three implementations—one of which has two variations—of p-FFL by
modifying FedAvg to weigh client models using a linear, geometric or logarithmic function of their
loss-sorted position. Third, it provides an experimental evaluations of these algorithms on three of
the ML tasks from Li et al. [2019], showing that they can achieve a fairer distribution of performance
than standard FedAvg but not q-FedAvg.

2

Background

2.1

q-FedAvg

The most important implementation detail of the q-FedAvg algorithm, the main exponent of the
q-FFL class, is that it accounts for the change in objective function by scaling the model-training
step-size according to an estimation of the objective function’s Lipschitz constant. There are also two
particular properties of q-FedAvg of relevance to this report. First, it uses the proportion of training
examples held by a client as the probability of selecting that client rather than weighing the model
updates by it. The authors justify this decision as being more efficient for q-FedAvg and show that it
outperforms uniform sampling with weighted aggregation. Second, a q value of 0 makes q-FedAvg
behaviour correspond to classical FedAvg with a tunable aggregate learning rate.
Li et al. [2019] defines a “fair” FL algorithm as one with a more uniform client testing accuracy
distribution when running the global model on their individual partitions. Of course, every model
having an accuracy of 0 would be perfectly fair, as such, the focus is on maintaining a similar average
accuracy to a classical FL algorithm.
2.2

Relative Fairness

The proposed solution to the shortcomings of q-FFL relies on fairness metrics based on generalised
Gini social-evaluation functions (G2SFs). It was inspired by the work of Sim et al. [2021] on Fair
Collaborative Bayesian Optimisation.
2.2.1

Gini Social-evaluation Function

The original Gini index is a relative index for measuring inequality, initially formulated for specifically
for income inequality. For the purposes of this work, the particular unit of measurement is not relevant
and metrics can be calculated for any vector u ∈ Rn —although it can be seen as representing some
form of utility vector. According to Weymark [1981] , the Gini index I(u) it can be defined as
 Pn

1
1 (2i − 1)ϕ(u)i
(3)
I(u) = 1 − 2
n
µ(u)
where ϕ is a sorting operator inducing a descending permutation of values in u and µ(u) is the
mean. The innermost sum assigns higher weights to lower values using the first n odd numbers as
coefficients. This is known as the Gini Social-evaluation Function(GSF):
!
n
1 X
GSF (u) = 2
(2i − 1)ϕ(u)i
(4)
n
1
where n2 is the sum of the first n odd numbers and is used as a normalisation factor. The Gini
index creates a measure of inequality by subtracting mean-normalised fairness from 1. All elements
being equal to the mean would make the GSF also equal to the mean and thus I(u) = 1 − µ/µ = 0.
Consequently, minimising the inequality of a distribution based on the Gini index is equivalent to
maximising fairness based on the GSF by bringing all elements as close to the mean as possible.
2

2.3

Generalised Gini Social-evaluation Functions

The specific coefficients used in the GSF are arbitrary, according to Weymark [1981]. Allowing for
the usage of different sets of weights creates an entire family of tunable fairness measures. Weymark
[1981] defines the generalised Gini social-evaluation functions (G2SFs) as weighted sums of vector
elements with non-increasing or non-decreasing weights p where the sorted order induced by ϕ
decides the element-weight pairing
G2SF (u) = pT · ϕ(u)

(5)

For example, an ascending order with non-increasing weights would put the highest emphasis on the
smallest values in u. The particular choice of sort order is arbitrary as long as p follows the opposite
direction. For the purposes of designing an FFL algorithm, tuning the weight vector is equivalent
to tuning both how fair the distribution should be based on the relative order of elements and the
specific importance placed on an element being at a given index. Similarly to q-based fairness, the
most extreme case of this would be to define p = (1, 0, ..., 0) which would optimise only for the
lowest value in the list.

3

Methods

3.1

Relative-FFL Formulation

Given a particular weight vector p ∈ Rm , we can re-state the FL objective function from eq.1
F(w) = (F1 (w), ..., Fm (w))
minfp (w) = pT · ϕ(F(w))

(6)

w

This allows for the creation of a family of p-FedAvg algorithms where the client models are weighed
by the corresponding element of p. However, the original FedAvg [McMahan et al., 2017] assigned
the weights pk as the proportion of total examples seen by a clients. To maintain parity with q-FedAvg,
p-FedAvg will also use the proportion of total examples of a client as the probability of picking that
client rather than as a weight. However, if a scenario does not allow for such selection, multiplying
by the proportion of total examples before applying the fairness-focused weighing is also a viable
option.
One of the primary advantages of q-FedAvg is that the degree of fairness is controlled through a
single parameter. As such, for an algorithm in the p-FedAvg family to prove useful it should also
require as little manual tuning as possible in order to arrive at a fair performance distribution. This
severely restricts the potential means of generating p. Additionally, given that Federated Learning
is not guaranteed to receive a constant number of client models and losses each round, any means
of generating a weight vector must be resilient to changes in the number of clients—unlike more
traditional applications [Sim et al., 2021].
3.2

Algorithm Formulations

Every version of the p-FedAvg uses the same underlying structure while only changing p. The
common structure is shown in algorithm 1, the programmer must only provide standard FedAvg
parameters alongside the sorting operator—ascending or descending—and a method for dynamically
generating a weight vector as long as the number of received models at a given round. All of the
following methods divide the coefficients by their sum at the end as to avoid being heavily impacted
by a variable number of clients.
3.2.1

Arithmetic Series

An arithmetic series-based version of p-FedAvg requires providing the starting value p1 and the
increment d while using an ascending sorting operator ϕ.
pk = p1 + (k − 1)d
3

(7)

The original GSF (sec.2.2.1) is equivalent to such a series with p1 = 1, d = 2. It is important to
note that since the weights are linearly spaced and normalised by the total sum, the specific choice
of a and d are not relevant outside of the magnitude of their difference. For very large values of
d and small values of a, the first element will be largely ignored from the aggregation. If this gap
between the first element and the rest is removed then the weight of an element depends entirely on
its position and the overall number of values pk = 2(k + 1) × 1/n(n+1). Given the similar behaviour
of weights generated through such an arithmetic series, the rest of this report will specifically use the
gini coefficients as the most time-tested of them.
3.2.2

Geometric Series

Using a geometric series for p-FedAvg is significantly simpler as normalising its terms by the total
sum of the series makes the weights invariant with respect to the starting value. As such, it can be
written entirely on the basis of the geometric term z and number of elements n. Unlike the arithmetic
series, such a spacing is very sensitive to the geometric term with a strong trend for optimising for
the worst-performing client as z values rise. This makes it the most similar of the p-FedAvg versions
to q-FedAvg as choosing a good value of z may require quite a significant amount of trial-and-error.
However, unlike q-FedAvg it is still resistant to the absolute loss values of the clients meaning that
once found a good z value could potentially better generalise across domains.
pk =

q k (q − 1)
qn − 1

(8)

Bounding z to values between 0 and 1.0 and using a descending sorting operator allow for a more
intuitive understanding of the relation between z and the degree of fairness. Since limz→1.0 pk = 1/n
values of z close to 1.0 tend to result in a simple weighted average similar to the original FedAvg.
On the other hand, as the values approach 0.0 the behaviour of p-FedAvg approaches only optimising
for the worst-performing client.
3.2.3

Harmonic Series

The prior two versions of p-FedAvg may both emphasise fairness to an extent that significantly harms
final model performance. A promising alternative for applications where global model performance
is the foremost priority but still desire some fairness mechanism is to use the harmonic numbers for
weight generation. For the n-th harmonic number Hn ∈ O(log(n)), making the spacing between
weights increase only logarithmically.
pk = Hk =

k
X

1/i

(9)

i=1

3.3

Experimental Setup

The experimental design is meant to replicate that of Li et al. [2019] as closely as possible. Great care
has been taken to use the exact same datasets, data partitions, models and TensorFlow version [Abadi
et al., 2015] by first forking the open-source repo and following the parameters and instructions of
the authors verbatim. However, computational and space constraints limit the ability to compare
p-FedAvg against q-FedAvg on every single ML application present in the original paper. An AWS
EC2 instance equipped with an Nvidia T4 GPU with 16GB of VRAM has was used for training and
testing all the models. This hardware setup is limited compared to the 8 NVidia 1080Ti GPUs used
by Li et al. [2019].
3.3.1

Datasets and Models

The datasets and models used by Li et al. [2019] are curated from previous work in FL and meant
to allow for easy evaluation of fair FL algorithms. For the purposes of this report three dataset and
model combinations were chosen. The first is a synthetic dataset with highly non-IID data paired
with a simple linear classifier. The second is the Vehicle dataset constructed by Duarte and Hu [2004]
from a sensor network, paired with a linear SVM used for binary classification. The final data set is
FMNIST [Xiao et al., 2017], paired with with a dense neural network.
4

3.3.2

Experimental Design

The experimental design intends to compare p-FedAvg variants against q-FedAvg with q = 0,
corresponding to standard FedAvg, and against q-FedAvg with with q set to the optimal value found
by Li et al. [2019] for each task. The versions of p-FedAvg used are the gini-based arithmetically
weighed p-FedAvg, harmonic p-FedAvg and two variants of geometrically weighed p-FedAvg with
z ∈ {0.85, 0.5}. There are several avenues of comparison.
3.4

Fairness

All p-FedAvg versions will have their average accuracy, variance, top 10% worst accuracy and top
10% best accuracy compared for the three datasets. The expectation is that p-FedAvg and q-FedAvg
with q > 0 will have a similar average accuracy to FedAvg (i.e q-FedAvg with q = 0) whils having a
lower variance and better worst 10% results. The effect is expected to be least pronounced for the
harmonic version of p-FedAvg and most pronounced for the geometric version. Importantly, since
geometric p-FedAvg most closely resembles q-FedAvg in terms of having one value which needs to
be tuned it will be used to test the hypothesis that relative FFL allows for better transferability across
domains. As such, instead of tuning the geometric term for each application the same values will be
kept across with the expectation that similar improvements in fairness will be seen.
Besides these direct measurements, the accuracy distribution of clients will be graphed for each
p-FedAvg variant in comparison with q-FedAvg at q = 0 and at the optimal q. Doing this for all three
datasets would results in 12 total graphs, as such only the distribution for one dataset will be graphed
in the main text with the rest relegated to the appendix.
3.5

Convergence Speed

While all discussion thus far has focused on the final fairness outcome of the experiments, it is
inevitable that using a fair weighing scheme will affect the speed of convergence for a particular
application and thus the communication efficiency of the FL algorithm. To understand the impact on
this dimension, the accuracies per round of p-FedAvg and q-FedAvg conditions are graphed against
one-another on the most relevant datasets.

4

Evaluation

4.1

Fairness Comparison

Table 1 shows the testing accuracy results for all tested experimental conditions. It shows that
p-FedAvg variations are indeed capable of reducing accuracy variance and improving worst 10%
performance—for the Vehicle dataset—when compared to the q = 0 condition. However, they fail
to outperform q-FedAvg with any q value on any other metric for the other datasets. Furthermore,
the mentioned improvements for the Vehicle dataset against q = 0 are meager at best. These
experimental results immediately disprove any potential benefits that p-FedAvg was hypothesised
to have over q-FedAvg. In the case of q = 0 one of the primary reasons for this is likely the tuned
aggregation-algorithm-level learning-rate of q-FedAvg which p-FedAvg did not benefit from given
the impracticality of doing a large parameter sweep with limited computational resources. For the
optimal q it is rather clear that the extensively tested q value itself provides a very large advantage
over the parameter-less gini and harmonic p-FedAvg variants. Most importantly, the hypothesis that
the geometric p-FedAvg parameter would show better generalizsability than q is not supported by
the current evidence as geometric p-FedAvg shows very high variance in terms of average accuracy
between dataset/model combinations.
In terms of the relation between p-FedAvg variations, the assumptions made during algorithm creation
hold up much better. Harmonic p-FedAvg shows the lowest variability between datasets, as expected
given the logarithmic rate of growth of its weights. This comes at the cost of having a very low
impact on the overall training process. Gini and geometric have a larger, but not still remarkably
low, effect on variance and the worst 10% client performance. While gini p-FedAvg causes a 10%
drop in average accuracy on the more complex non-Vehicle tasks, the magnitude of the impact for
geometric p-FedAvg is largely dependent on the specific geometric term. As expected, the choice
between a geometric term of 0.5 and 0.85 results in wildly varying outcomes with 0.5 doing more
5

Dataset

Synthetic

Vehicle

FMNIST

Objective

Average(%)

Worst 10%(%)

Best 10%(%)

Variance

q=0
q=1

72.8
70.3

12.1
20.0

100
100

0.08
0.06

Gini
Harmonic

56.8
66.6

0.00
0.00

100
100

0.144
0.141

Geo = 0.5
Geo = 0.85

38.6
62.1

0.00
0.00

100
100

0.154
0.132

q=0
q=5

85.5
86.6

41.9
66.8

97.4
95.2

0.034
0.007

Gini
Harmonic

85.6
85.5

44.1
41.6

97.1
97.3

0.031
0.034

Geo = 0.5
Geo = 0.85

85.1
85.7

45.7
43.7

96.2
96.9

0.028
0.032

q=0
q = 15

69.5
79.0

NaN
NaN

NaN
NaN

0.015
0.047

Gini
Harmonic

50.7
63.3

NaN
NaN

NaN
NaN

0.350
0.064

Geo = 0.5
Geo = 0.85

53.5
65.8

NaN
NaN

NaN
NaN

0.396
0.100

Table 1: Results for all datasets. Shown in bold is the best value for a column in a given dataset.
The FMNIST application only has three clients, meaning that its worst% and best% metrics are not
defined—nonetheless the variance results still serve as a proxy for the effectiveness of FFL.

to homogenise accuracy than 0.85. However, the slight decrease in variance brought by setting the
geometric term to 0.5 comes with an upwards of a 24% drop in accuracy for the synthetic benchmark
which violates the need to maintain rough accuracy-parity for FFL to be practically useful.
The impact of p-FedAvg variants on specific clients becomes more clear when inspecting the accuracy
distribution for the synthetic benchmark in fig.1 and fig.2. The intended behaviour of an FFL
algorithm, a largely homogeneous accuracy distribution without any immense peaks, is shown by
q-FedAvg with q = 1 in fig.1. Unlike q = 1, gini p-FedAvg and harmonic p-FedAvg have large parts
of their average accuracy determined by a group of clients with near 100% accuracy—although this
is worse under the harmonic weighing. The geometric p-FedAvg shown in fig.2 with a parameter of
0.85 behaves similarly to the previous two versions. Setting the geometric term to 0.5% does in fact
produce a “fair distribution” albeit with much worse average outcomes. The same trends hold under
the Vehicle dataset in fig.5 and fig.6—relegated to the appendix.
4.2

Convergence Comparison

Figure 3 shows how the different p-FedAvg variations compare to q-FedAvg in terms of testing
accuracy of the global model after each aggregation round. These results are mixed when compared
to the fairness section as p-FedAvg is much more competitive at the global-model level than on
a client-by-client basis. For q-fedAvg, a q = 1 is strongly associated with a colder start in terms
of global model accuracy while no p-FedAvg, even the most extreme geometric one, shares this
behaviour. This is potentially caused by the client model step-size tuning done by q-FedAvg for
q > 0, since it relies on a mere estimation of the Lipchitz constant as a bound for the step-size.
Despite this fact, the accuracy rapidly improves for q-FedAvg with q = 1 after the early training
rounds. While the most performant algorithm remains q-FedAvg with q = 0, the results of harmonic
p-FedAvg—as the least “fairness” focused variation—stay competitive with q-FedAvg with q = 1
6

30

q=0
gini

25

25

15

q=1
harmonic

25

20
# Clients

15

30

q=1
gini

25

20
# Clients

# Clients

20

30

q=0
harmonic

20
# Clients

30

15

15

10

10

10

10

5

5

5

5

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

Figure 1: Fairness results comparing gini p-FedAvg and harmonic p-FedAvg against q-FedAvg for
the the multi linear regression model trained on the Syntetic dataset . The q-values used are q=0
(Equivalent to normal FedAvg) and q=1 (The optimal q as reported by Li et al. [2019])
30

q=0
Geo=0.85

25

25

15

q=1
Geo=0.5

25

20
# Clients

15

30

q=1
Geo=0.85

25

20
# Clients

# Clients

20

30

q=0
Geo=0.5

20
# Clients

30

15

15

10

10

10

10

5

5

5

5

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

Figure 2: Fairness results comparing geometric p-FedAvg with the geometric term at z ∈ {0.85, 0.5}
against q-FedAvg for the linear classification model trained on the Synthetic dataset.

0.8

0.6
0.4
gini
harmonic
q=0
q=1

0.2
0

500

1000

1500

# Rounds

Testing accuracy

Testing accuracy

0.8

2000

0.6
0.4
Geo = 0.85
Geo = 0.5
q=0
q=1

0.2
0

500

1000

1500

# Rounds

2000

Figure 3: Convergence results comparing gini p-FedAvg, harmonic p-FedAvg and geometric pFedAvg with parameters 0.5 and 0.85 against q-FedAvg for the the linear classification model trained
on the Syntetic dataset.

7

Testing accuracy

Testing accuracy

0.8
0.6
0.4
0.2
0.0

gini
harmonic
q=0
q=1

0

5

10

# Rounds

15

0.8
0.6
0.4
0.2
0.0

20

Geo = 0.85
Geo = 0.5
q=0
q=1

0

5

10

# Rounds

15

20

Figure 4: Convergence results comparing gini p-FedAvg, harmonic p-FedAvg and geometric pFedAvg with parameters 0.5 and 0.85 against q-FedAvg for the the binary linear SVM model trained
on the Vehicle dataset.
throughout while exceeding those of q-FedAvg with q = 1. A less encouraging trend is present for
geometric p-FedAvg as both geometric term values fail to outperform either q-FedAvg.
4.3

Discussion

Using the relative order of elements was intended as a means of reducing the impact of task-specific
loss values on aggregation algorithm behaviour and thus allow for more transferability across
domains. As the large gaps between the three datasets show, inherent task difficulty and structure
can paradoxically affect p-FedAvg more than q-FedAvg. The absolute gap in performance between
p-FedAvg and q-FedAvg may be, as discussed, partially attributable to the better tuning of q-FedAvg,
however, the much higher between-dataset variance is not explained by this fact. While task difficulty
is relevant to any ML algorithm—the Vehicle application is easy enough that all algorithms converge
to more-or-less the same value (fig4)—the very large performance collapse from the comparably
difficult FMNIST to the synthetic dataset is unusual.
There are several potential explanations for this fact. The most plausible is that by taking away
the loss-based scaling of objective functions, the algorithm is in fact deprived of important taskspecific information and must instead rely on the task-independent weights. Rather than improving
generalisability, p-FFL may in fact harm it. Another potential factor is that the automatic step-size
scaling done by q-FedAvg may help independently of the q-value by simply attempting to adapt the
learning process to the losses dynamically.

5

Conclusion

The goal of this work was the creation of an alternative form of Fair Federated Learning, p-FFL, by
replacing the q-FFL fairness mechanism from one dependent on the absolute client loss values to a
relative one based on their sorted order. While the proposed algorithms do indeed promote fairness to
different extents, and thus represent a viable alternative formulation, their intended robustness against
task heterogeneity proved to be lacking. This was shown across three datasets with four variations of
p-FedAvg, and two of q-FedAvg. In fact, q-FedAvg was superior both in terms of reliability, absolute
performance, and fairness to all p-FedAvg algorithms except for the one using the harmonic weighing.
Consequently, the hypothesis that relative FL can provide improvements in robustness cannot be
accepted.
There are a number of avenues through which p-FFL could be extended to a practically relevant FFL
class. One is to close part of the implementation gap between p-FedAvg and q-FedAvg by tuning the
aggregation learning rate of p-FedAvg similarly. In the same vein, dynamically changing the model
learning rate similarly to how q-FedAvg uses the Lipschitz constant could improve convergence.
Finally, a wider class of weightings could be explored, such as generalised Harmonic series.

8

References
Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy
Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving,
Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion
Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit
Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas,
Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow:
Large-scale machine learning on heterogeneous systems, 2015. URL https://www.tensorflow.org/.
Software available from tensorflow.org.
Marco F Duarte and Yu Hen Hu. Vehicle classification in distributed sensor networks. Journal of Parallel and
Distributed Computing, 64(7):826–838, 2004.
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji,
Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances and open problems
in federated learning. arXiv preprint arXiv:1912.04977, 2019.
Tian Lan, David Kao, Mung Chiang, and Ashutosh Sabharwal. An axiomatic theory of fairness in network
resource allocation. In 2010 Proceedings IEEE INFOCOM, pages 1–9, 2010. doi: 10.1109/INFCOM.2010.
5461911.
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith. Federated
optimization in heterogeneous networks. arXiv preprint arXiv:1812.06127, 2018.
Tian Li, Maziar Sanjabi, and Virginia Smith.
abs/1905.10497, 2019.

Fair resource allocation in federated learning.

ArXiv,

Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communicationefficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages
1273–1282. PMLR, 2017.
Rachael Hwee Ling Sim, Yehong Zhang, Bryan Kian Hsiang Low, and Patrick Jaillet. Collaborative bayesian
optimization with fair regret. In Marina Meila and Tong Zhang, editors, Proceedings of the 38th International
Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 9691–
9701. PMLR, 18–24 Jul 2021. URL https://proceedings.mlr.press/v139/sim21b.html.
John A Weymark. Generalized gini inequality indices. Mathematical Social Sciences, 1(4):409–430, 1981.
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine
learning algorithms. CoRR, abs/1708.07747, 2017. URL http://arxiv.org/abs/1708.07747.

A

Appendix

A.1

Algorithm

Algorithm 1 Baseline p-FedAvg
Input: g, ϕ, T , η, E, w0 , M
1: for each round t = 0,1...T-1 do
2:
Sever attempts to select a set St of M devices probabilistically weighed by their sample sizes
3:
for for each client k ∈ St do
4:
Client trains wt locally for E epochs with step-size η
5:
if Client is trained successfully then
6:
Client returns their trained model wkt+1 and the size of their dataset nk and loss Fk
7:
end if
8:
end for
9:
Server generates the weight vector p = g(c), where c is the number of received models
10:
Server sorts w based on the sorted order of client losses ϕ(F)
11:
Server multiplies client parameters by their weight and aggregates them
12:
w = pT P
·w
c
13:
wt+1 = k=1 wkt+1
14: end for
A.2

Vehicle Fairness Data

9

10

q=0
gini

10

q=0
harmonic

10

q=5
gini

8

8

6

6

6

6

4

4

# Clients

8

# Clients

8

# Clients

# Clients

10

4

q=5
harmonic

4

2

2

2

2

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

Figure 5: Fairness results comparing gini p-FedAvg and harmonic p-FedAvg against q-FedAvg for
the SVM model trained on the Vehicle dataset. The q-values used are q=0 (Equivalent to normal
FedAvg) and q=5 (The optimal q as reported by Li et al. [2019])

10

q=0
Geo=0.85

10

q=0
Geo=0.5

10

q=5
Geo=0.85

8

8

6

6

6

6

4

4

4

# Clients

8

# Clients

8

# Clients

# Clients

10

q=5
Geo=0.5

4

2

2

2

2

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

Figure 6: Fairness results comparing geometric p-FedAvg with the geometric term at z ∈ {0.85, 0.5}
against q-FedAvg for the SVM model trained on the Vehicle dataset. The q-values used are q=0
(Equivalent to normal FedAvg) and q=5 (The optimal q as reported by Li et al. [2019])

10

Relative Fair Federated Learning

Alexandru-Andrei Iacob
aai30@cam.ac.uk

Abstract
The canonical loss function of Federated Learning is a weighted average of the
local client objective functions without regard to performance distribution amongst
clients. A recently proposed class of algorithms, q-FFL, promotes fairness by
raising the loss function to an exponent. While promising, this mechanism is
sensitive to loss magnitude and requires extensive tuning to the dataset. This work
proposes p-FFL, a relative form of fair aggregation where client loss functions are
weighted solely on the basis of their position in the sorted order. Multiple algorithm
versions based on p-FFL are implemented to emphasise different fairness functions
which weigh a client’s position linearly, geometrically or logarithmically. They
are tested both in terms of fairness and convergence speed on three different ML
applications. The results show that while p-FFL can improve the fairness of client
performance distribution it is not yet competitive in its current form to q-FFL.

1

Introduction

The data and system heterogeneity inherent to Federated Learning McMahan et al. [2017], Kairouz
et al. [2019] make difficult the construction of a global model capable of providing satisfactory results
for all potential devices that it may be trained or deployed. Such heterogeneity may be intrinsic to
the explored setting, e.g languages being heavily localised, meaning that decreased performance
of the global model on a subset of clients could be unavoidable. A potential solution to this issue
is to construct a “fairer” global model. In this context, fairness refers to the uniformity of model
performance across devices with different data and system characteristics. Constructing a fairer
model requires modifying the objective function used in FL.
The canonical Federated Learning (FL) objective was was formalised by Li et al. [2018] as follows:
minf (w) =
w

m
X

pk Fk (w)

(1)

k=1

where f is the global loss, w is the model, m is the total number of client, Fk are the local client loss
functions and pk are the weights associated with each client—generally chosen as its proportion of
the training examples. The first version of Fair FL (FFL) was proposed by Li et al. [2019] who define
a family of FFL algorithms, q-FFL, based around the following modification to the loss function
minfq (w) =
w

m
X
pk
F q+1 (w)
q+1 k

(2)

k=1

where q is a parameter controlling the fairness of the weighing based on the value of the loss. A larger
q implies a higher degree of fairness. When q tends towards infinity, the objective becomes identical
to improving performance on only the worst-performing client. While Li et al. [2019] show a great
deal of improvement over classical FL algorithms, their approach has two primary shortcomings.
First, if one of the clients is an extreme outlier, they can skew the results significantly for high q
values. Thus the model can either be made to diverge, or potentially manipulated to over-emphasise
the needs of a specific client. Second, the optimal q-values vary significantly across domains. Li et al.

[2019] report q’s ranging from 0.001 to 5 according to task. The primary hypothesis explored in this
report is that developing a less loss-sensitive FFL algorithm could improve the robustness of results
and require reduced parameter tuning between tasks.
This work brings three main contributions to the field of FFL. First, it provides a new class of relatively
fair FL algorithms deemed p-FFL. This class uses a fairness mechanism based on generalised Gini
social-evaluation functions [Weymark, 1981] rather than the α-fairness [Lan et al., 2010] of qFFL. Second, it constructs three implementations—one of which has two variations—of p-FFL by
modifying FedAvg to weigh client models using a linear, geometric or logarithmic function of their
loss-sorted position. Third, it provides an experimental evaluations of these algorithms on three of
the ML tasks from Li et al. [2019], showing that they can achieve a fairer distribution of performance
than standard FedAvg but not q-FedAvg.

2

Background

2.1

q-FedAvg

The most important implementation detail of the q-FedAvg algorithm, the main exponent of the
q-FFL class, is that it accounts for the change in objective function by scaling the model-training
step-size according to an estimation of the objective function’s Lipschitz constant. There are also two
particular properties of q-FedAvg of relevance to this report. First, it uses the proportion of training
examples held by a client as the probability of selecting that client rather than weighing the model
updates by it. The authors justify this decision as being more efficient for q-FedAvg and show that it
outperforms uniform sampling with weighted aggregation. Second, a q value of 0 makes q-FedAvg
behaviour correspond to classical FedAvg with a tunable aggregate learning rate.
Li et al. [2019] defines a “fair” FL algorithm as one with a more uniform client testing accuracy
distribution when running the global model on their individual partitions. Of course, every model
having an accuracy of 0 would be perfectly fair, as such, the focus is on maintaining a similar average
accuracy to a classical FL algorithm.
2.2

Relative Fairness

The proposed solution to the shortcomings of q-FFL relies on fairness metrics based on generalised
Gini social-evaluation functions (G2SFs). It was inspired by the work of Sim et al. [2021] on Fair
Collaborative Bayesian Optimisation.
2.2.1

Gini Social-evaluation Function

The original Gini index is a relative index for measuring inequality, initially formulated for specifically
for income inequality. For the purposes of this work, the particular unit of measurement is not relevant
and metrics can be calculated for any vector u ∈ Rn —although it can be seen as representing some
form of utility vector. According to Weymark [1981] , the Gini index I(u) it can be defined as
 Pn

1
1 (2i − 1)ϕ(u)i
(3)
I(u) = 1 − 2
n
µ(u)
where ϕ is a sorting operator inducing a descending permutation of values in u and µ(u) is the
mean. The innermost sum assigns higher weights to lower values using the first n odd numbers as
coefficients. This is known as the Gini Social-evaluation Function(GSF):
!
n
1 X
GSF (u) = 2
(2i − 1)ϕ(u)i
(4)
n
1
where n2 is the sum of the first n odd numbers and is used as a normalisation factor. The Gini
index creates a measure of inequality by subtracting mean-normalised fairness from 1. All elements
being equal to the mean would make the GSF also equal to the mean and thus I(u) = 1 − µ/µ = 0.
Consequently, minimising the inequality of a distribution based on the Gini index is equivalent to
maximising fairness based on the GSF by bringing all elements as close to the mean as possible.
2

2.3

Generalised Gini Social-evaluation Functions

The specific coefficients used in the GSF are arbitrary, according to Weymark [1981]. Allowing for
the usage of different sets of weights creates an entire family of tunable fairness measures. Weymark
[1981] defines the generalised Gini social-evaluation functions (G2SFs) as weighted sums of vector
elements with non-increasing or non-decreasing weights p where the sorted order induced by ϕ
decides the element-weight pairing
G2SF (u) = pT · ϕ(u)

(5)

For example, an ascending order with non-increasing weights would put the highest emphasis on the
smallest values in u. The particular choice of sort order is arbitrary as long as p follows the opposite
direction. For the purposes of designing an FFL algorithm, tuning the weight vector is equivalent
to tuning both how fair the distribution should be based on the relative order of elements and the
specific importance placed on an element being at a given index. Similarly to q-based fairness, the
most extreme case of this would be to define p = (1, 0, ..., 0) which would optimise only for the
lowest value in the list.

3

Methods

3.1

Relative-FFL Formulation

Given a particular weight vector p ∈ Rm , we can re-state the FL objective function from eq.1
F(w) = (F1 (w), ..., Fm (w))
minfp (w) = pT · ϕ(F(w))

(6)

w

This allows for the creation of a family of p-FedAvg algorithms where the client models are weighed
by the corresponding element of p. However, the original FedAvg [McMahan et al., 2017] assigned
the weights pk as the proportion of total examples seen by a clients. To maintain parity with q-FedAvg,
p-FedAvg will also use the proportion of total examples of a client as the probability of picking that
client rather than as a weight. However, if a scenario does not allow for such selection, multiplying
by the proportion of total examples before applying the fairness-focused weighing is also a viable
option.
One of the primary advantages of q-FedAvg is that the degree of fairness is controlled through a
single parameter. As such, for an algorithm in the p-FedAvg family to prove useful it should also
require as little manual tuning as possible in order to arrive at a fair performance distribution. This
severely restricts the potential means of generating p. Additionally, given that Federated Learning
is not guaranteed to receive a constant number of client models and losses each round, any means
of generating a weight vector must be resilient to changes in the number of clients—unlike more
traditional applications [Sim et al., 2021].
3.2

Algorithm Formulations

Every version of the p-FedAvg uses the same underlying structure while only changing p. The
common structure is shown in algorithm 1, the programmer must only provide standard FedAvg
parameters alongside the sorting operator—ascending or descending—and a method for dynamically
generating a weight vector as long as the number of received models at a given round. All of the
following methods divide the coefficients by their sum at the end as to avoid being heavily impacted
by a variable number of clients.
3.2.1

Arithmetic Series

An arithmetic series-based version of p-FedAvg requires providing the starting value p1 and the
increment d while using an ascending sorting operator ϕ.
pk = p1 + (k − 1)d
3

(7)

The original GSF (sec.2.2.1) is equivalent to such a series with p1 = 1, d = 2. It is important to
note that since the weights are linearly spaced and normalised by the total sum, the specific choice
of a and d are not relevant outside of the magnitude of their difference. For very large values of
d and small values of a, the first element will be largely ignored from the aggregation. If this gap
between the first element and the rest is removed then the weight of an element depends entirely on
its position and the overall number of values pk = 2(k + 1) × 1/n(n+1). Given the similar behaviour
of weights generated through such an arithmetic series, the rest of this report will specifically use the
gini coefficients as the most time-tested of them.
3.2.2

Geometric Series

Using a geometric series for p-FedAvg is significantly simpler as normalising its terms by the total
sum of the series makes the weights invariant with respect to the starting value. As such, it can be
written entirely on the basis of the geometric term z and number of elements n. Unlike the arithmetic
series, such a spacing is very sensitive to the geometric term with a strong trend for optimising for
the worst-performing client as z values rise. This makes it the most similar of the p-FedAvg versions
to q-FedAvg as choosing a good value of z may require quite a significant amount of trial-and-error.
However, unlike q-FedAvg it is still resistant to the absolute loss values of the clients meaning that
once found a good z value could potentially better generalise across domains.
pk =

q k (q − 1)
qn − 1

(8)

Bounding z to values between 0 and 1.0 and using a descending sorting operator allow for a more
intuitive understanding of the relation between z and the degree of fairness. Since limz→1.0 pk = 1/n
values of z close to 1.0 tend to result in a simple weighted average similar to the original FedAvg.
On the other hand, as the values approach 0.0 the behaviour of p-FedAvg approaches only optimising
for the worst-performing client.
3.2.3

Harmonic Series

The prior two versions of p-FedAvg may both emphasise fairness to an extent that significantly harms
final model performance. A promising alternative for applications where global model performance
is the foremost priority but still desire some fairness mechanism is to use the harmonic numbers for
weight generation. For the n-th harmonic number Hn ∈ O(log(n)), making the spacing between
weights increase only logarithmically.
pk = Hk =

k
X

1/i

(9)

i=1

3.3

Experimental Setup

The experimental design is meant to replicate that of Li et al. [2019] as closely as possible. Great care
has been taken to use the exact same datasets, data partitions, models and TensorFlow version [Abadi
et al., 2015] by first forking the open-source repo and following the parameters and instructions of
the authors verbatim. However, computational and space constraints limit the ability to compare
p-FedAvg against q-FedAvg on every single ML application present in the original paper. An AWS
EC2 instance equipped with an Nvidia T4 GPU with 16GB of VRAM has was used for training and
testing all the models. This hardware setup is limited compared to the 8 NVidia 1080Ti GPUs used
by Li et al. [2019].
3.3.1

Datasets and Models

The datasets and models used by Li et al. [2019] are curated from previous work in FL and meant
to allow for easy evaluation of fair FL algorithms. For the purposes of this report three dataset and
model combinations were chosen. The first is a synthetic dataset with highly non-IID data paired
with a simple linear classifier. The second is the Vehicle dataset constructed by Duarte and Hu [2004]
from a sensor network, paired with a linear SVM used for binary classification. The final data set is
FMNIST [Xiao et al., 2017], paired with with a dense neural network.
4

3.3.2

Experimental Design

The experimental design intends to compare p-FedAvg variants against q-FedAvg with q = 0,
corresponding to standard FedAvg, and against q-FedAvg with with q set to the optimal value found
by Li et al. [2019] for each task. The versions of p-FedAvg used are the gini-based arithmetically
weighed p-FedAvg, harmonic p-FedAvg and two variants of geometrically weighed p-FedAvg with
z ∈ {0.85, 0.5}. There are several avenues of comparison.
3.4

Fairness

All p-FedAvg versions will have their average accuracy, variance, top 10% worst accuracy and top
10% best accuracy compared for the three datasets. The expectation is that p-FedAvg and q-FedAvg
with q > 0 will have a similar average accuracy to FedAvg (i.e q-FedAvg with q = 0) whils having a
lower variance and better worst 10% results. The effect is expected to be least pronounced for the
harmonic version of p-FedAvg and most pronounced for the geometric version. Importantly, since
geometric p-FedAvg most closely resembles q-FedAvg in terms of having one value which needs to
be tuned it will be used to test the hypothesis that relative FFL allows for better transferability across
domains. As such, instead of tuning the geometric term for each application the same values will be
kept across with the expectation that similar improvements in fairness will be seen.
Besides these direct measurements, the accuracy distribution of clients will be graphed for each
p-FedAvg variant in comparison with q-FedAvg at q = 0 and at the optimal q. Doing this for all three
datasets would results in 12 total graphs, as such only the distribution for one dataset will be graphed
in the main text with the rest relegated to the appendix.
3.5

Convergence Speed

While all discussion thus far has focused on the final fairness outcome of the experiments, it is
inevitable that using a fair weighing scheme will affect the speed of convergence for a particular
application and thus the communication efficiency of the FL algorithm. To understand the impact on
this dimension, the accuracies per round of p-FedAvg and q-FedAvg conditions are graphed against
one-another on the most relevant datasets.

4

Evaluation

4.1

Fairness Comparison

Table 1 shows the testing accuracy results for all tested experimental conditions. It shows that
p-FedAvg variations are indeed capable of reducing accuracy variance and improving worst 10%
performance—for the Vehicle dataset—when compared to the q = 0 condition. However, they fail
to outperform q-FedAvg with any q value on any other metric for the other datasets. Furthermore,
the mentioned improvements for the Vehicle dataset against q = 0 are meager at best. These
experimental results immediately disprove any potential benefits that p-FedAvg was hypothesised
to have over q-FedAvg. In the case of q = 0 one of the primary reasons for this is likely the tuned
aggregation-algorithm-level learning-rate of q-FedAvg which p-FedAvg did not benefit from given
the impracticality of doing a large parameter sweep with limited computational resources. For the
optimal q it is rather clear that the extensively tested q value itself provides a very large advantage
over the parameter-less gini and harmonic p-FedAvg variants. Most importantly, the hypothesis that
the geometric p-FedAvg parameter would show better generalizsability than q is not supported by
the current evidence as geometric p-FedAvg shows very high variance in terms of average accuracy
between dataset/model combinations.
In terms of the relation between p-FedAvg variations, the assumptions made during algorithm creation
hold up much better. Harmonic p-FedAvg shows the lowest variability between datasets, as expected
given the logarithmic rate of growth of its weights. This comes at the cost of having a very low
impact on the overall training process. Gini and geometric have a larger, but not still remarkably
low, effect on variance and the worst 10% client performance. While gini p-FedAvg causes a 10%
drop in average accuracy on the more complex non-Vehicle tasks, the magnitude of the impact for
geometric p-FedAvg is largely dependent on the specific geometric term. As expected, the choice
between a geometric term of 0.5 and 0.85 results in wildly varying outcomes with 0.5 doing more
5

Dataset

Synthetic

Vehicle

FMNIST

Objective

Average(%)

Worst 10%(%)

Best 10%(%)

Variance

q=0
q=1

72.8
70.3

12.1
20.0

100
100

0.08
0.06

Gini
Harmonic

56.8
66.6

0.00
0.00

100
100

0.144
0.141

Geo = 0.5
Geo = 0.85

38.6
62.1

0.00
0.00

100
100

0.154
0.132

q=0
q=5

85.5
86.6

41.9
66.8

97.4
95.2

0.034
0.007

Gini
Harmonic

85.6
85.5

44.1
41.6

97.1
97.3

0.031
0.034

Geo = 0.5
Geo = 0.85

85.1
85.7

45.7
43.7

96.2
96.9

0.028
0.032

q=0
q = 15

69.5
79.0

NaN
NaN

NaN
NaN

0.015
0.047

Gini
Harmonic

50.7
63.3

NaN
NaN

NaN
NaN

0.350
0.064

Geo = 0.5
Geo = 0.85

53.5
65.8

NaN
NaN

NaN
NaN

0.396
0.100

Table 1: Results for all datasets. Shown in bold is the best value for a column in a given dataset.
The FMNIST application only has three clients, meaning that its worst% and best% metrics are not
defined—nonetheless the variance results still serve as a proxy for the effectiveness of FFL.

to homogenise accuracy than 0.85. However, the slight decrease in variance brought by setting the
geometric term to 0.5 comes with an upwards of a 24% drop in accuracy for the synthetic benchmark
which violates the need to maintain rough accuracy-parity for FFL to be practically useful.
The impact of p-FedAvg variants on specific clients becomes more clear when inspecting the accuracy
distribution for the synthetic benchmark in fig.1 and fig.2. The intended behaviour of an FFL
algorithm, a largely homogeneous accuracy distribution without any immense peaks, is shown by
q-FedAvg with q = 1 in fig.1. Unlike q = 1, gini p-FedAvg and harmonic p-FedAvg have large parts
of their average accuracy determined by a group of clients with near 100% accuracy—although this
is worse under the harmonic weighing. The geometric p-FedAvg shown in fig.2 with a parameter of
0.85 behaves similarly to the previous two versions. Setting the geometric term to 0.5% does in fact
produce a “fair distribution” albeit with much worse average outcomes. The same trends hold under
the Vehicle dataset in fig.5 and fig.6—relegated to the appendix.
4.2

Convergence Comparison

Figure 3 shows how the different p-FedAvg variations compare to q-FedAvg in terms of testing
accuracy of the global model after each aggregation round. These results are mixed when compared
to the fairness section as p-FedAvg is much more competitive at the global-model level than on
a client-by-client basis. For q-fedAvg, a q = 1 is strongly associated with a colder start in terms
of global model accuracy while no p-FedAvg, even the most extreme geometric one, shares this
behaviour. This is potentially caused by the client model step-size tuning done by q-FedAvg for
q > 0, since it relies on a mere estimation of the Lipchitz constant as a bound for the step-size.
Despite this fact, the accuracy rapidly improves for q-FedAvg with q = 1 after the early training
rounds. While the most performant algorithm remains q-FedAvg with q = 0, the results of harmonic
p-FedAvg—as the least “fairness” focused variation—stay competitive with q-FedAvg with q = 1
6

30

q=0
gini

25

25

15

q=1
harmonic

25

20
# Clients

15

30

q=1
gini

25

20
# Clients

# Clients

20

30

q=0
harmonic

20
# Clients

30

15

15

10

10

10

10

5

5

5

5

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

Figure 1: Fairness results comparing gini p-FedAvg and harmonic p-FedAvg against q-FedAvg for
the the multi linear regression model trained on the Syntetic dataset . The q-values used are q=0
(Equivalent to normal FedAvg) and q=1 (The optimal q as reported by Li et al. [2019])
30

q=0
Geo=0.85

25

25

15

q=1
Geo=0.5

25

20
# Clients

15

30

q=1
Geo=0.85

25

20
# Clients

# Clients

20

30

q=0
Geo=0.5

20
# Clients

30

15

15

10

10

10

10

5

5

5

5

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

Figure 2: Fairness results comparing geometric p-FedAvg with the geometric term at z ∈ {0.85, 0.5}
against q-FedAvg for the linear classification model trained on the Synthetic dataset.

0.8

0.6
0.4
gini
harmonic
q=0
q=1

0.2
0

500

1000

1500

# Rounds

Testing accuracy

Testing accuracy

0.8

2000

0.6
0.4
Geo = 0.85
Geo = 0.5
q=0
q=1

0.2
0

500

1000

1500

# Rounds

2000

Figure 3: Convergence results comparing gini p-FedAvg, harmonic p-FedAvg and geometric pFedAvg with parameters 0.5 and 0.85 against q-FedAvg for the the linear classification model trained
on the Syntetic dataset.

7

Testing accuracy

Testing accuracy

0.8
0.6
0.4
0.2
0.0

gini
harmonic
q=0
q=1

0

5

10

# Rounds

15

0.8
0.6
0.4
0.2
0.0

20

Geo = 0.85
Geo = 0.5
q=0
q=1

0

5

10

# Rounds

15

20

Figure 4: Convergence results comparing gini p-FedAvg, harmonic p-FedAvg and geometric pFedAvg with parameters 0.5 and 0.85 against q-FedAvg for the the binary linear SVM model trained
on the Vehicle dataset.
throughout while exceeding those of q-FedAvg with q = 1. A less encouraging trend is present for
geometric p-FedAvg as both geometric term values fail to outperform either q-FedAvg.
4.3

Discussion

Using the relative order of elements was intended as a means of reducing the impact of task-specific
loss values on aggregation algorithm behaviour and thus allow for more transferability across
domains. As the large gaps between the three datasets show, inherent task difficulty and structure
can paradoxically affect p-FedAvg more than q-FedAvg. The absolute gap in performance between
p-FedAvg and q-FedAvg may be, as discussed, partially attributable to the better tuning of q-FedAvg,
however, the much higher between-dataset variance is not explained by this fact. While task difficulty
is relevant to any ML algorithm—the Vehicle application is easy enough that all algorithms converge
to more-or-less the same value (fig4)—the very large performance collapse from the comparably
difficult FMNIST to the synthetic dataset is unusual.
There are several potential explanations for this fact. The most plausible is that by taking away
the loss-based scaling of objective functions, the algorithm is in fact deprived of important taskspecific information and must instead rely on the task-independent weights. Rather than improving
generalisability, p-FFL may in fact harm it. Another potential factor is that the automatic step-size
scaling done by q-FedAvg may help independently of the q-value by simply attempting to adapt the
learning process to the losses dynamically.

5

Conclusion

The goal of this work was the creation of an alternative form of Fair Federated Learning, p-FFL, by
replacing the q-FFL fairness mechanism from one dependent on the absolute client loss values to a
relative one based on their sorted order. While the proposed algorithms do indeed promote fairness to
different extents, and thus represent a viable alternative formulation, their intended robustness against
task heterogeneity proved to be lacking. This was shown across three datasets with four variations of
p-FedAvg, and two of q-FedAvg. In fact, q-FedAvg was superior both in terms of reliability, absolute
performance, and fairness to all p-FedAvg algorithms except for the one using the harmonic weighing.
Consequently, the hypothesis that relative FL can provide improvements in robustness cannot be
accepted.
There are a number of avenues through which p-FFL could be extended to a practically relevant FFL
class. One is to close part of the implementation gap between p-FedAvg and q-FedAvg by tuning the
aggregation learning rate of p-FedAvg similarly. In the same vein, dynamically changing the model
learning rate similarly to how q-FedAvg uses the Lipschitz constant could improve convergence.
Finally, a wider class of weightings could be explored, such as generalised Harmonic series.

8

References
Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy
Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving,
Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion
Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit
Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas,
Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow:
Large-scale machine learning on heterogeneous systems, 2015. URL https://www.tensorflow.org/.
Software available from tensorflow.org.
Marco F Duarte and Yu Hen Hu. Vehicle classification in distributed sensor networks. Journal of Parallel and
Distributed Computing, 64(7):826–838, 2004.
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji,
Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances and open problems
in federated learning. arXiv preprint arXiv:1912.04977, 2019.
Tian Lan, David Kao, Mung Chiang, and Ashutosh Sabharwal. An axiomatic theory of fairness in network
resource allocation. In 2010 Proceedings IEEE INFOCOM, pages 1–9, 2010. doi: 10.1109/INFCOM.2010.
5461911.
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith. Federated
optimization in heterogeneous networks. arXiv preprint arXiv:1812.06127, 2018.
Tian Li, Maziar Sanjabi, and Virginia Smith.
abs/1905.10497, 2019.

Fair resource allocation in federated learning.

ArXiv,

Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communicationefficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages
1273–1282. PMLR, 2017.
Rachael Hwee Ling Sim, Yehong Zhang, Bryan Kian Hsiang Low, and Patrick Jaillet. Collaborative bayesian
optimization with fair regret. In Marina Meila and Tong Zhang, editors, Proceedings of the 38th International
Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 9691–
9701. PMLR, 18–24 Jul 2021. URL https://proceedings.mlr.press/v139/sim21b.html.
John A Weymark. Generalized gini inequality indices. Mathematical Social Sciences, 1(4):409–430, 1981.
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine
learning algorithms. CoRR, abs/1708.07747, 2017. URL http://arxiv.org/abs/1708.07747.

A

Appendix

A.1

Algorithm

Algorithm 1 Baseline p-FedAvg
Input: g, ϕ, T , η, E, w0 , M
1: for each round t = 0,1...T-1 do
2:
Sever attempts to select a set St of M devices probabilistically weighed by their sample sizes
3:
for for each client k ∈ St do
4:
Client trains wt locally for E epochs with step-size η
5:
if Client is trained successfully then
6:
Client returns their trained model wkt+1 and the size of their dataset nk and loss Fk
7:
end if
8:
end for
9:
Server generates the weight vector p = g(c), where c is the number of received models
10:
Server sorts w based on the sorted order of client losses ϕ(F)
11:
Server multiplies client parameters by their weight and aggregates them
12:
w = pT P
·w
c
13:
wt+1 = k=1 wkt+1
14: end for
A.2

Vehicle Fairness Data

9

10

q=0
gini

10

q=0
harmonic

10

q=5
gini

8

8

6

6

6

6

4

4

# Clients

8

# Clients

8

# Clients

# Clients

10

4

q=5
harmonic

4

2

2

2

2

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

Figure 5: Fairness results comparing gini p-FedAvg and harmonic p-FedAvg against q-FedAvg for
the SVM model trained on the Vehicle dataset. The q-values used are q=0 (Equivalent to normal
FedAvg) and q=5 (The optimal q as reported by Li et al. [2019])

10

q=0
Geo=0.85

10

q=0
Geo=0.5

10

q=5
Geo=0.85

8

8

6

6

6

6

4

4

4

# Clients

8

# Clients

8

# Clients

# Clients

10

q=5
Geo=0.5

4

2

2

2

2

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

0
0.00 0.25 0.50 0.75 1.00
Testing accuracy

Figure 6: Fairness results comparing geometric p-FedAvg with the geometric term at z ∈ {0.85, 0.5}
against q-FedAvg for the SVM model trained on the Vehicle dataset. The q-values used are q=0
(Equivalent to normal FedAvg) and q=5 (The optimal q as reported by Li et al. [2019])

10

Salvaging Federated Learning by Local Adaptation
Tao Yu 1 Eugene Bagdasaryan 1 Vitaly Shmatikov 1

Abstract

arXiv:2002.04758v3 [cs.LG] 3 Mar 2022

Federated learning (FL) is a heavily promoted approach for training ML models on sensitive data,
e.g., text typed by users on their smartphones. FL
is expressly designed for training on data that are
unbalanced and non-iid across the participants. To
ensure privacy and integrity of the fedeated model,
latest FL approaches use differential privacy or
robust aggregation.
We look at FL from the local viewpoint of an
individual participant and ask: (1) do participants
have an incentive to participate in FL? (2) how
can participants individually improve the quality
of their local models, without re-designing the FL
framework and/or involving other participants?
First, we show that on standard tasks such as nextword prediction, many participants gain no benefit
from FL because the federated model is less accurate on their data than the models they can train
locally on their own. Second, we show that differential privacy and robust aggregation make this
problem worse by further destroying the accuracy
of the federated model for many participants.
Then, we evaluate three techniques for local adaptation of federated models: fine-tuning, multi-task
learning, and knowledge distillation. We analyze
where each is applicable and demonstrate that all
participants benefit from local adaptation. Participants whose local models are poor obtain big accuracy improvements over conventional FL. Participants whose local models are better than the
federated model—and who have no incentive to
participate in FL today—improve less, but sufficiently to make the adapted federated model better
than their local models.

1. Introduction
Federated learning (McMahan et al., 2017) is a framework
for large-scale, distributed learning on sensitive data, e.g.,
training a next-word prediction model on texts typed by
users into their smartphones or a medical treatment model
1

Department of Computer Science, Cornell University. Correspondence to: Tao Yu <tyu@cs.cornell.edu>, Eugene Bagdasaryan <eugene@cs.cornell.edu>.

on patient records from multiple hospitals. Designed for unbalanced, non-iid data distributions, federated learning has
demonstrated good performance and scalability (Bonawitz
et al., 2019) and is promoted by Google (Pichai, 2019) and
other companies as the solution to privacy problems in predictive keyboards (Hard et al., 2018), medicine (de Brouwer,
2019), and other domains (Kairouz et al., 2019).
The original approach (McMahan et al., 2017) creates the
federated model by repeatedly averaging model updates
from small subsets of participants. Both the updates and the
final model can leak participants’ training data, violating
privacy (Shokri et al., 2017; Melis et al., 2019). Averagingbased aggregation is also vulnerable to attacks on model
integrity because malicious participants can introduce unwanted behavior into the model (Bagdasaryan et al., 2018).
To protect privacy, differentially private federated learning (McMahan et al., 2018) bounds how much the model
can reveal about the inputs from any individual participant.
To protect integrity, robust aggregation (Yin et al., 2018)
replaces average with median to bound the influence of
outliers on the model.
Users have an incentive to participate in federated learning only if federated models are more accurate than the
models they can train independently on their own data. Privacy and robustness mechanisms introduce a fundamental
conflict into this reasoning. To take advantage of the data
of the unusual participants—which is one of the principal
design objectives of federated learning—aggregation must
incorporate their contributions into the federated model. To
protect privacy and integrity, aggregation must restrict these
contributions from having much influence on the federated
model.
Our contributions. We look at federated learning (FL)
from the local perspective of individual participants and
investigate whether they have an incentive to participate.
Does federated learning yield more accurate models for
them? If no, what can they do locally to improve the quality
of models they obtain from FL.
First, we demonstrate that privacy and robustness protections destroy the accuracy of federated models for many
participants, removing their main incentive to join federated
learning. We use standard federated learning tasks: nextword prediction and image classification. With very few
exceptions (see Section 2), prior work focused on measur-

Salvaging Federated Learning by Local Adaptation

ing the overall accuracy of federated models. By contrast,
we (a) measure their accuracy for the individual participants,
and (b) show that many participants gain no benefit because
the federated model achieves worse accuracy on their data
than a model they can train independently. For example,
when training a word-prediction model on a Reddit dataset,
the federated model based on robust median aggregation
achieves worse accuracy than the local models for the majority of participants.

ence of individual participants, several robust, “Byzantinetolerant” aggregation schemes have been proposed (Blanchard et al., 2017; El Mhamdi et al., 2018; Damaskinos
et al., 2019; Rajput et al., 2019; Chen et al., 2017). Alternative aggregation schemes (Yurochkin et al., 2019; Guha
et al., 2019; Hsu et al., 2019) for various flavors of federated
learning provide neither privacy, nor robustness. Peer-topeer (not federated) learning with convex losses and without
robustness is studied in (Bellet et al., 2018).

Next, we solve this fundamental tradeoff between privacy/robustness and individual accuracy. Instead of a single
model that should be accurate for all participants, we use local adaptation to convert the federated model into individual
models for each participant.

Accuracy for individual participants. Federated learning
is explicitly designed for non-iid participants, but most prior
work does not measure their individual accuracy. Training
of participant-specific models is studied in (Smith et al.,
2017), without privacy or robustness and at the cost of replacing the entire federated learning framework. Differential
privacy disproportionately reduces model accuracy for underrepresented participants (Bagdasaryan et al., 2019). No
previous work investigated the impact of robust aggregation
on individual accuracy.

Crucially, we are interested in local methods that an individual participant can deploy on their own. We do not aim to
change FL aggregation algorithms because FL frameworks
are controlled by platform operators such as Google and
cannot be changed unilaterally by a single participant (e.g.,
a single smartphone). We are also not interested in solutions that require all or most participants to change their
algorithms because they require cooperation and are hard to
deploy in practice.
We investigate three adaptation mechanisms: fine-tuning,
multi-task learning, and knowledge distillation. We analyze
where each is applicable, and show how local adaptation
helps participants recover the accuracy destroyed by differential privacy and robust aggregation. Participants who had
no incentive to join federated learning because their local
models are better than the federated model benefit because
the adapted federated model becomes better than the local
models. For example, for 80% of the participants in the
word-prediction task, the adapted robust model outperforms
their local models. Participants whose local models are
inaccurate—and thus already benefit from federated learning—experience the biggest accuracy improvements due to
local adaptation and benefit even further. Finally, we relate
the effects of adaptation to the complexity of participants’
data.

2. Related Work
Privacy and integrity of federated learning. Participants’
model updates leak their training data (Melis et al., 2019),
and malicious participants can inject unwanted behaviors
into the model (Bagdasaryan et al., 2018; Bhagoji et al.,
2019). Secure aggregation (Bonawitz et al., 2017) prevents
the global server from observing individual updates, but it
also makes attacks on integrity impossible to detect and the
final model may still leak training data.
Federated learning with differential privacy (McMahan et al.,
2018) limits the leakage of training data. To limit the influ-

Prior work on personalization of ML models focused on
speaker adaptation of acoustic models (see (Yu & Li, 2017)).
Many techniques are not compatible with federated learning because they require an ensemble of models (Tan et al.,
2015) or are speech-specific (Miao et al., 2015), but (Huang
et al., 2015) connects personalization and multi-task learning.
Recent papers on personalizing federated models (Wang
et al., 2019; Jiang et al., 2019; Fallah et al., 2020; Dinh
et al., 2020) propose various methods to improve the accuracy for individual participants; (Jiang et al., 2019) also
connects meta learning with personalization. These papers
do not investigate (a) if federated models are more accurate
than the models individual participants can train on their
own, (b) the impact of privacy and integrity protections on
individual participants’ accuracy, and (c) purely local adaptation techniques other than fine-tuning (the only exception
is a short paper (Peterson et al., 2019) that uses domain
adaptation to counteract the reduction in accuracy due to
differential privacy). While there are dozens of alternative
aggregation algorithms that may improve the quality of local
models (see the survey in (Kairouz et al., 2019)), all of them
involve global changes to the federated learning framework,
require all participants to replace their algorithms, and cannot be deployed locally and unilaterally by a participant.
As explained in Section 1, we are interested in local techniques that an individual participant can use to mitigate
the damage from privacy and robustness mechanisms.

3. Background
Federated learning is a distributed learning paradigm for
training a model on multiple participants’ data (McMahan

Salvaging Federated Learning by Local Adaptation

et al., 2017). The global server creates the initial model
G0 . In each round t = 1..T , the server selects a subset
of m participants from some pool Q of size n and sends
them the current model Gt−1 . Each selected participant
i ∈ m updates the model on his local data Di and sends the
resulting model Pit to the global server, which averages it
with the other updates using the aggregation learning rate η
to obtain the new global model Gt . For direct comparison,
we use the formula from (McMahan et al., 2018):
m

Gt = Gt−1 +

η X t
(P − Gt−1 )
m i=1 i

(1)

All motivating applications of federated learning, such as
predictive keyboards and collaborative analysis of biomedical data, involve participants with non-idd data, and federated learning is specifically designed to accommodate
training with millions of participants. Recently, a federated
language model was trained on 7.5 billion sentences from
1.5 million North American participants (Hard et al., 2018).
Adding privacy.
ML models can leak their training
data (Song et al., 2017; Shokri et al., 2017). In federated learning, participants’ model updates can leak even
more (Melis et al., 2019). Differential privacy (Dwork,
2008; 2011) has been promoted as the solution to privacy
problems in deep learning (Abadi et al., 2016) and federated learning (McMahan et al., 2018). Differential privacy
(DP) provides (, δ) privacy guarantee when the federated
mechanism M and two set of users Q, Q0 that differ by one
participant produce models in any set G with probabilities
that satisfy:
Pr[M(Q) ∈ G] ≤ e Pr[M(Q0 ) ∈ G] + δ

(2)

In practice, applying differential privacy to federated learning involves (a) clipping each participant’s update, and (b)
adding random noise (McMahan et al., 2018). Aggregation
is modified as follows:
m

η X
(Clip(Pit − Gt−1 , S)) + N (0, σ)
m i=1
(3)
Achieving a given (, δ) privacy guarantee involves carefully selecting the clipping bound S and noise σ using the
moments accountant method (Abadi et al., 2016). We omit
the details and instead using parameters from previous work
with a similar setup (McMahan et al., 2018).
Gt = Gt−1 +

Adding integrity. Training with millions of participants
is inherently vulnerable to malicious participants who can
prevent the training from converging and/or inject a backdoor into the model (Bagdasaryan et al., 2018). To ensure
that malicious participants and other outliers cannot influence the joint model, robust aggregation replaces average

by median (Yin et al., 2018; Chen et al., 2019):
Gt = Gt−1 + η(P̃ t − Gt−1 ),

(4)

where P̃ t is the element-wise median among the updates
submitted in round t. We focus on median aggregation,
but our adaptation techniques also apply to other so called
“Byzantine-tolerant” aggregation schemes (Blanchard et al.,
2017; El Mhamdi et al., 2018; Damaskinos et al., 2019).

4. Tasks
We use two standard tasks from the federated learning literature: next-word prediction and CIFAR-10 image classification (McMahan et al., 2017). We evaluate the original
averaging aggregation (McMahan et al., 2017), differentially private aggregation (McMahan et al., 2018), and robust median aggregation (Chen et al., 2019; Yin et al., 2018):
BASIC-FED, DP-FED, and ROBUST-FED, resp.
For DP-FED, we follow (McMahan et al., 2018) and use the
clipping bound S = 15 and Gaussian noise with σ = 0.01
for Equation 3 (the model does not converge with bigger
noise). For ROBUST-FED, we compute the coordinatewise median instead of the mean of participants’ gradients. Each participant trains locally using cross-entropy
loss Lcross (P, x). All code was implemented in PyTorch
1.2 and executed on an Ubuntu 18.04 machine with 4 Nvidia
GeForce RTX 2080 Ti GPUs and 12GB RAM. We release
our code publicly for reproducibility.1
4.1. Next-word prediction
We train word prediction models on a randomly chosen
month (November 2017) of the Reddit dataset (Reddit) with
80,000 participants (i.e., Reddit users) who have between
150 and 500 posts, treating each post as one sentence. This
task is a realistic application of federated learning, involving unbalanced data from different distributions (see Appendix A.3 in supplementary materials). Some users have
posts with a few simple, repeating phrases, while others
write in sophisticated prose.
We compiled a dictionary of 50, 000 most frequent words
and replaced all others with the unk token. To create
BASIC-FED, DP-FED, and ROBUST-FED models, we train
2-layer LSTM models with 200 hidden units and 10 million
parameters (pytorch). Following (McMahan et al., 2018),
we train for 5,000 rounds with m = 100 participants per
round, aggregation learning rate η = 1, batch size 20, and
B = 2 internal epochs using SGD. For training participants’
models, we tried inner learning rates of 0.1, 1, 10, 20, and
40, yielding global test accuracy of, respectively, 9.07%,
14.34%, 18.83%, 19.20% and 19.29%. We thus set the in1
https://github.com/ebagdasa/federated_
adaptation

Salvaging Federated Learning by Local Adaptation

(a) BASIC-FED

(b) DP-FED

(c) ROBUST-FED

Figure 1. Accuracy improvements of federated models over local, trained-from-scratch models for word prediction (top row) and image
classification (bottom row) tasks.

ner learning rate to lr = 40. To measure test accuracy, we
split each participant’s Reddit posts into the training and
test sets in chronological order at the 9 : 1 ratio.
4.2. Image classification
We split the CIFAR-10 (Krizhevsky, 2009) training set into
100 participants. To simulate a non-iid distribution, we allocate images from each class to participants using Dirichlet
distribution with α = 0.9, similar to (Hsu et al., 2019).
We train all federated models for 1,000 rounds with the
aggregation learning rate η = 1 and batch size of 32. Following (McMahan et al., 2017), in every round we aggregate
10 randomly selected participants, each of whom trains a
ResNet-18 model (with 11.2 million parameters) with the
inner learning rate of 0.1 and B = 2 internal epochs using
SGD with momentum 0.9 and weight decay 0.0005.
CIFAR-10 is not divided into distinct participants. To measure the test accuracy of a model on a participant’s distribution, we calculate its per-class accuracy on the CIFAR-10
global test dataset, multiply it by the corresponding class’s
ratio in the participant’s training dataset, and sum up the
resulting values.

5. Privacy and robustness destroy individual
accuracy
Federated learning relies on the participation of thousands or
millions of users. Some may be motivated by altruism, but
rational users need an incentive to participate. For example,
they benefit if the federated model is more accurate than the

models they can train locally on their own data.
Accuracy of federated models is typically measured—often
on tasks such as MNIST that are not representative of the
intended applications of federated learning—on a holdout
dataset compiled from all participants’ data (McMahan et al.,
2017). When the participants are not iid and some have their
own, idiosyncratic data, global accuracy does not represent
whether the model is accurate for a specific participant.
In realistic motivating scenarios, such as predictive keyboards, fraud detection, and biomedical research, an aggregated model may perform well on the global test data but
poorly on an individual participant’s test data, thus removing their main incentive to participate. In the rest of this
paper, we focus on the accuracy of federated models for
individual participants.
Figure 1(a) compares the BASIC-FED models with the local,
trained-from-scratch models of individual participants. The
BASIC-FED word prediction model (top row) is worse than
the local models of 9.22% (7377) participants, which are
trained for 100 epochs with the learning rate of 1. On the
image classification task (bottom row), there is less diversity
among participants and BASIC-FED outperforms the local
models of all but 1 participant. The local models were
trained for 500 epochs with the learning rate of 0.001.
With privacy or integrity protections, the comparison is
unfavorable for federated learning. Figure 1(b) shows that
DP-FED is less accurate than the local models of many
participants: 16,931 (21.16%) on word prediction (top row)
and 11 (11%) on image classification (bottom row). Even
worse, ROBUST-FED shown in Figure 1(c) is less accurate

Salvaging Federated Learning by Local Adaptation

(a) BASIC-FED

(b) DP-FED

(c) ROBUST-FED

Figure 2. Accuracy improvements of adapted federated models over local, trained-from-scratch models for word prediction (top row) and
image classification (bottom row) tasks.

than the local models for the majority of participants
(41720, or 52.15%) on word prediction and 34 (34%) on
image classification.
These results illustrate the tradeoff at the heart of federated learning. To learn a joint model that is accurate for
individual participants, aggregation must incorporate contributions from every participant. To protect data privacy
and model integrity, aggregation must limit the influence of
these contributions, producing an inaccurate model.

6. Local adaptation
We investigate several techniques for adapting the federated
model to an individual participant. Local word prediction
models are trained for B = 100 epochs with the learning
rate of 1, image classification models for B = 200 epochs
with the learning rate of 0.001.
Fine-tuning (FT). Fine-tuning is a natural adaptation technique, used, e.g., in (Wang et al., 2019). It re-trains all
parameters of a trained federated model on the participant’s
local training data (using the above hyperparameters). Finetuning takes advantage of the federated model’s feature extraction network instead of learning it from scratch. Freezebase (FB) is a variant that freezes the base layers of the
federated model and fine-tunes only the top layer. When
using fine-tuning for local adaptation, we experimented on
1,000 participants with the learning rates of 0.1, 1, and 10,
yielding mean accuracy of, respectively, 20.58%, 20.99%
and 18.28%. Therefore, we set lr = 1.

Multi-task learning (MTL). With non-iid distribution, a
participant’s local data may be very different from the other
participants. To mitigate overfitting, we treat local adaptation as a multi-task learning problem, where task X requires
high performance on the union of all participants and task
Y requires high performance on a single participant. We
take the federated model GT optimized for task X and aim
to create an adapted model A (initialized as GT ) optimized
for task Y . To overcome the catastrophic forgetting (French,
1999) of task X while learning Y , we use elastic weight
consolidation (Kirkpatrick et al., 2017) which selectively
slows down learning on the weights important for X. To
learn task Y , we use the same cross-entropy loss Lcross as
in Section 4 and aim to minimize:
Xλ
`(A, x) = Lcross (A, x) +
Fi (Ai − GTi )2
(5)
2
i
where λ is the importance of task X vs. Y , F is the Fisher
information matrix (computed on a public auxiliary dataset),
i is the label of each parameter. Following (Kirkpatrick
et al., 2017), we use λ = 5000.
Knowledge distillation (KD). Knowledge distillation (Hinton et al., 2015) extracts information from a “teacher” model
into a “student” model. We treat the federated model GT
as the teacher and the adapted model A as the student, except that in our case both models have the same structure
and A is initialized to GT but the local dataset on which
A is trained is a small subset of the dataset on which GT
is trained. We conjecture that enforcing the similarity of
logits between GT and A using the loss function from the

Salvaging Federated Learning by Local Adaptation

(a) BASIC-FED

(b) DP-FED

(c) ROBUST-FED

Figure 3. Accuracy improvements of adapted over unadapted federated models vs. vocabulary size (top row) and total words (bottom row).

knowledge distillation literature helps mitigate overfitting
on the small dataset.
We represent GT (x), A(x) as the pre-softmax logit outputs
of the two models and minimize:
`(A, x) = αK 2 Lcross (A, x)
+ (1 − α)KL(σ(

GT (x)
A(x)
), σ(
))
K
K

(6)

where KL is Kullback-Leibler divergence loss, σ is softmax,
α is the weight parameter, K is the temperature constant.
The K 2 term equalizes gradient magnitudes for both losses.
We did not observe significant differences when varying
α = [0.1, 0.5, 0.95, 0.99] and K = [4, 6, 10] and set α =
0.95, K = 6.

7. Local adaptation gives an incentive to
participate in federated learning
We investigate the effects of the FT, FB, MTL, KD adaptation techniques from Section 6 on the accuracy of BASICFED, DP-FED, ROBUST-FED models for individual participants. Dots and bars in the figures are color-coded according
to the technique that yielded the best accuracy improvement.
For the word-prediction task, there are 80,000 participants,
but we only adapt the 79,097 participants whose vocabulary
size (i.e., number of unique symbols) is over 100, the percentage of utility symbols (e.g., punctuation) is under 40%,
and the difference between total and utility symbols is over
1,000.

7.1. Results of adaptation
On word prediction, mean accuracy improvements due to
adaptation are 2.32%, 2.12%, and 2.12% for BASIC-FED,
DP-FED and ROBUST-FED, respectively. These improvements make up the loss of accuracy due to differential privacy (-1.42%) and robust aggregation (-2.81%). On image
classification, mean accuracy improvements due to adaptation are 2.98%, 6.83%, and 6.34% for BASIC-FED, DPFED, and ROBUST-FED, respectively. These improvements make up the loss of accuracy due to differential privacy (-7.83%) and robust aggregation (-11.89%).
Figure 2(a) shows the improvements of the adapted BASICFED model over the participants’ local models for word
prediction in the top row. There are only 28 (0.04%) participants for whom the adapted BASIC-FED underperforms the
local model. median accuracy of the adapted BASIC-FED
are 22.41% and 21.00%. The bottom row of Figure 2(a)
shows the results for image classification. Adapted BASICFED outperforms all local models.
Figure 2(b) shows the improvements of the adapted DPFED model over the participants’ local models for word
prediction in the top row. There are only 1465 (1.85%)
participants for whom the adapted DP-FED underperforms
the local model. The bottom row of Figure 2(b) shows the
results for image classification. Adapted DP-FED outperforms all local models.
Figure 2(c) shows the improvements of the adapted
ROBUST-FED model over the participants’ local models for
word prediction in the top row. There are 14809 (18.72%)

Salvaging Federated Learning by Local Adaptation

(a) BASIC-FED

(b) DP-FED

(c) ROBUST-FED

Figure 4. Accuracy improvements of adapted federated models over local (top row) and unadapted federated models (bottom row).

participants for whom the adapted ROBUST-FED underperforms the local model. The bottom row of Figure 2(c) shows
the results for image classification. Adapted ROBUST-FED
outperforms all local models.
7.2. Analysis
Our baselines are respective accuracies of (1) the participant’s local model and (2) the unadapted federated model,
both measured on that participant’s test data.
Adapted models vs. trained-from-scratch models. In subsection 7.1, we showed that the adapted federated models
outperform the local models for most participants. Top row
of Figure 4 visualizes the effects of adaptation on different types of participants. Accuracy is divided into 0.2%
intervals and the improvements for all participants whose
local model accuracy falls into a given interval are averaged,
yielding a single bar. The color of the bar corresponds to
the adaptation technique that accounts for the biggest share
of the total improvement of the participants in the interval.
Participants with inaccurate local models are on the left side
of the X-axis. The original federated model was already
more accurate than their local models (Figure 1), yet local
adaptation yields the biggest improvements for them and
thus a stronger incentive to participate.
Participants with accurate local models did not benefit from
federated learning (Figure 1(a)), but adaptation now gives
them an incentive to participate because the adapted model
outperforms the local model—even though the improvement
is smaller than for the low-accuracy participants.

Adapted vs. unadapted federated models. Bottom row
of Figure 4 shows how adaptation improves the accuracy
of federated models. The biggest improvements accrue to
“tail” participants whose local models have low accuracy.
Adaptation also improves the federated model for the “head”
participants, for whom the unadapted model is already accurate.
To explain these effects, we measure the size (total number of words) and complexity (vocabulary, i.e., number of
unique words) for each participant in our Reddit-based corpus. Figure 3 plots accuracy improvement vs. these features.
Adaptations improve accuracy the most for the participants
with simple (small vocabulary) and small (few total words)
data. We conjecture that the participants who obtain large
accuracy improvements in the bottom row of Figure 4 have
simpler, smaller data. To show this for the BASIC-FED
model, Figure 6 plots the relationship between model accuracy and vocabulary size (respectively, total words).
The participants with the highest and lowest BASIC-FED
accuracy indeed have few, simple words. We hypothesize
that “tail” participants (i.e., those with low BASIC-FED
accuracy) use regular sentences that are similar to other
participants: e.g., ‘appreciation series has posts for an author
you mentioned.’ The low accuracy of BASIC-FED is simply
due to the lack of local data. Local adaptations make better
use of the available data, improving accuracy of the model.
“Head” participants (i.e., those with high BASIC-FED accuracy) also have few, simple words, but their sentences are
very different from the other participants: e.g., “gucci gang
gucci gang gucci gang.” Therefore, (a) their local models

Salvaging Federated Learning by Local Adaptation

Figure 5. Cumulative accuracy improvements of different adaptations on BASIC-FED (left), DP-FED (middle), and ROBUST-FED
(right).

models below that of the locally trained models of many
participants, removing their main incentive to join federated learning. We showed how local adaptation techniques
based on fine-tuning, multi-task learning, and knowledge
distillation help improve the accuracy of private and robust
federated models for individual participants, enabling them
to reap the benefits of federated learning.
Figure 6. Accuracy of the BASIC-FED model vs. vocabulary size
(left) and total words (right).

outperform the unadapted federated model, and (b) local
adaptations improve accuracy for them, but not as much as
for the “tail” participants.
Some participants never recover accuracy. In our image
classification experiments, adapted models are always more
accurate than the local models regardless of the aggregation method. In the word prediction experiments, however,
adapted models never reach the same accuracy as the local
models of some participants, especially with ROBUST-FED.
We conjecture that median aggregation (Yin et al., 2018)
prevents these participants from contributing to the federated model at all. As a consequence, the federated model is
so bad for these participants than when it is used to initialize local adaptation, the final adapted model still has poor
accuracy (Grosse et al., 2019; Hanin & Rolnick, 2018).
Cumulative benefit of different adaptations. Figure 5
shows cumulative improvement due to different adaptations.
For BASIC-FED, the simplest FB technique performs best.
For DP-FED and ROBUST-FED, MTL performs better for
the “tail” participants.

8. Conclusion
Federated learning is a promising approach to large-scale
model training on sensitive data. Unfortunately, differential
privacy and robust aggregation reduce accuracy of federated

Salvaging Federated Learning by Local Adaptation

References
Abadi, M., Chu, A., Goodfellow, I., McMahan, H. B.,
Mironov, I., Talwar, K., and Zhang, L. Deep learning
with differential privacy. In CCS, 2016.

Dwork, C. Differential privacy: A survey of results. In
TAMC, 2008.
Dwork, C. Differential privacy. In Encyclopedia of Cryptography and Security, pp. 338–340. Springer, 2011.

Bagdasaryan, E., Veit, A., Hua, Y., Estrin, D., and
Shmatikov, V. How to backdoor federated learning.
arXiv:1807.00459, 2018.

El Mhamdi, E., Guerraoui, R., and Rouault, S. The hidden
vulnerability of distributed learning in Byzantium. In
ICML, 2018.

Bagdasaryan, E., Poursaeed, O., and Shmatikov, V. Differential privacy has disparate impact on model accuracy. In
NeurIPS, 2019.

Fallah, A., Mokhtari, A., and Ozdaglar, A. Personalized federated learning: A meta-learning approach.
arXiv:2002.07948, 2020.

Bellet, A., Guerraoui, R., Taziki, M., and Tommasi, M.
Personalized and private peer-to-peer machine learning.
In AISTATS, 2018.

French, R. M. Catastrophic forgetting in connectionist networks. Trends in Cognitive Sciences, 3(4):128–135, 1999.

Bhagoji, A. N., Chakraborty, S., Mittal, P., and Calo, S.
Analyzing federated learning through an adversarial lens.
In ICML, 2019.
Blanchard, P., El Mhamdi, E., Guerraoui, R., and Stainer,
J. Machine learning with adversaries: Byzantine tolerant
gradient descent. In NIPS, 2017.

Grosse, K., Trost, T. A., Mosbach, M., Backes, M., and
Klakow, D. Adversarial initialization–when your network
performs the way I want. arXiv:1902.03020, 2019.
Guha, N., Talwalkar, A., and Smith, V. One-shot federated
learning. arXiv:1902.11175, 2019.
Hanin, B. and Rolnick, D. How to start training: The effect
of initialization and architecture. In NIPS, 2018.

Bonawitz, K., Ivanov, V., Kreuter, B., Marcedone, A.,
McMahan, H. B., Patel, S., Ramage, D., Segal, A.,
and Seth, K. Practical secure aggregation for privacypreserving machine learning. In CCS, 2017.

Hard, A., Rao, K., Mathews, R., Beaufays, F., Augenstein, S., Eichner, H., Kiddon, C., and Ramage,
D. Federated learning for mobile keyboard prediction.
arXiv:1811.03604, 2018.

Bonawitz, K., Eichner, H., Grieskamp, W., Huba, D., Ingerman, A., Ivanov, V., Kiddon, C., Konecny, J., Mazzocchi,
S., McMahan, H. B., Van Overveldt, T., Petrou, D., Ramage, D., and Roselander, J. Towards federated learning at
scale: System design. In SysML, 2019.

Hinton, G., Vinyals, O., and Dean, J. Distilling the knowledge in a neural network. In NIPS Deep Learning and
Representation Learning Workshop, 2015.

Chen, X., Chen, T., Sun, H., Wu, Z. S., and Hong, M.
Distributed training with heterogeneous data: Bridging
median and mean based algorithms. arXiv:1906.01736,
2019.

Hsu, T.-M. H., Qi, H., and Brown, M. Measuring the effects
of non-identical data distribution for federated visual classification. arXiv:1909.06335, 2019.
Huang, Z., Li, J., Siniscalchi, S. M., Chen, I.-F., Wu, J., and
Lee, C.-H. Rapid adaptation for deep neural networks
through multi-task learning. In INTERSPEECH, 2015.

Chen, Y., Su, L., and Xu, J. Distributed statistical machine
learning in adversarial settings: Byzantine gradient descent. In POMACS, 2017.

Jiang, Y., Konečnỳ, J., Rush, K., and Kannan, S. Improving
federated learning personalization via model agnostic
meta learning. arXiv:1909.12488, 2019.

Damaskinos, G., El Mhamdi, E., Guerraoui, R., Guirguis, A.
H. A., and Rouault, S. L. A. AGGREGATHOR: Byzantine machine learning via robust gradient aggregation. In
SysML, 2019.

Kairouz, P. et al. Advances and open problems in federated
learning. arXiv:1912.04977, 2019.

de Brouwer, W.
The federated future is ready
for shipping.
https://doc.ai/blog/
federated-future-ready-shipping/, 2019.

Krizhevsky, A. Learning multiple layers of features from
tiny images, 2009.

Dinh, C. T., Tran, N. H., and Nguyen, T. D. Personalized federated learning with Moreau envelopes.
arXiv:2006.08848, 2020.

Kirkpatrick, J. et al. Overcoming catastrophic forgetting in
neural networks. Proc. NAS, 114(13):3521–3526, 2017.

McMahan, H. B., Moore, E., Ramage, D., Hampson, S., and
Agüera y Arcas, B. Communication-efficient learning
of deep networks from decentralized data. In AISTATS,
2017.

Salvaging Federated Learning by Local Adaptation

McMahan, H. B., Ramage, D., Talwar, K., and Zhang, L.
Learning differentially private recurrent language models.
In ICLR, 2018.
Melis, L., Song, C., De Cristofaro, E., and Shmatikov, V.
Exploiting unintended feature leakage in collaborative
learning. In S&P, 2019.
Miao, Y., Zhang, H., and Metze, F. Speaker adaptive
training of deep neural network acoustic models using
i-vectors. IEEE/ACM Trans. AUDIO SPE, 23(11):1938–
1949, 2015.
Peterson, D. W., Kanani, P., and Marathe, V. J. Private federated learning with domain adaptation. arXiv:1912.06733,
2019.
Pichai, S.
At I/O ’19: Building a more helpful Google for everyone.
https://www.
blog.google/technology/developers/
io19-helpful-google-everyone/, 2019.
pytorch. PyTorch examples. https://github.com/
pytorch/examples/tree/master/word_
language_model/, 2019.
Rajput, S., Wang, H., Charles, Z., and Papailiopoulos, D.
Detox: A redundancy-based framework for faster and
more robust gradient aggregation. In NeurIPS, 2019.
Reddit. Reddit comments. https://bigquery.
cloud.google.com/dataset/fh-bigquery:
reddit_comments, 2019.
Shokri, R., Stronati, M., Song, C., and Shmatikov, V. Membership inference attacks against machine learning models. In S&P, 2017.
Smith, V., Chiang, C.-K., Sanjabi, M., and Talwalkar, A.
Federated multi-task learning. In NIPS, 2017.
Song, C., Ristenpart, T., and Shmatikov, V. Machine learning models that remember too much. In CCS, 2017.
Tan, T., Qian, Y., Yin, M., Zhuang, Y., and Yu, K. Cluster
adaptive training for deep neural network. In ICASSP,
2015.
Wang, K., Mathews, R., Kiddon, C., Eichner, H., Beaufays,
F., and Ramage, D. Federated evaluation of on-device
personalization. arXiv:1910.10252, 2019.
Yin, D., Chen, Y., Ramchandran, K., and Bartlett, P.
Byzantine-robust distributed learning: Towards optimal
statistical rates. In ICML, 2018.
Yu, D. and Li, J. Recent progresses in deep learning based
acoustic models. IEEE/CAA J. Automatica Sinica, 4(3):
396–409, 2017.

Yurochkin, M., Agarwal, M., Ghosh, S., Greenewald, K.,
Hoang, T. N., and Khazaeni, Y. Bayesian nonparametric
federated learning of neural networks. In ICML, 2019.

Salvaging Federated Learning by Local Adaptation

erated models whose test accuracy is, respectively, 91.15%,
92.64%, and 89.22%.
With the right learning rate and number of epochs, aggregating adapted models can potentially produce a more accurate
federated model—at the cost of significantly increasing the
training time for each participant. We leave an exploration
of these tradeoffs to future work.
A.2. Removing disincentivized participants
As shown in section 5, there are 7,377 participants in the
word-prediction task whose local models are more accurate on their data than the federated model and who thus
have no incentive to participate. If we re-train the federated model on the remaining 72,623 participants, it achieves
mean/median accuracy of 20.008% / 19.570% vs., respectively, 20.021% / 19.563% achieved by the original model
on 80,000 participants. The new model performs well even
on the removed 7,377 participants, with mean accuracy of
20.076% vs. 20.301% for the original. Among the 72,623
participants used to train both models, the new model underperforms the original only on 974 (1.34%) participants.
Figure 7. Size and complexity of participants’ local data. Top:
word prediction; Bottom: image classification.

A. Additional experiments

As discussed in subsection 7.2, the removed participants
have (a) simpler and fewer words, and (b) their sentences
are outliers, very different from the rest of the participants.
We conjecture that after removing these participants, the remaining set is more regular yet sufficiently complex to train
a model that performs comparably to the original model.

A.1. Adapting, then aggregating again
To investigate whether it is beneficial to aggregate the
adapted models yet again, we use BASIC-FED on image
classification. We first train a conventional federated model
for 200 epochs with the learning rate of 0.1 and 2 internal
epochs per participant, reaching 90.44% test accuracy. We
adapt by fine-tuning with the learning rate of 0.001 for 5, 50,
or 100 epochs. Averaging the adapted models produces fed-

A.3. Imbalance of participants’ local datasets
We measure the imbalance between participants’ local
datasets. Figure 7 (Top) shows the size (total words) and
complexity (vocabulary size) of each participant’s local data
for the word prediction task. Figure 7 (Bottom) shows the
size (total images) of each participant’s local data for the
image classification task.

A Closer Look at Personalization in Federated Image Classification
Changxing Jing,1 Yan Huang, 2 Yihong Zhuang 1 Liyan Sun 1 Yue Huang 1 Zhenlong Xiao 1
Xinghao Ding 1 *

arXiv:2204.11841v1 [cs.LG] 22 Apr 2022

2

1
School of Informatics, Xiamen University, Xiamen, Fujian, 361005, China
College of Computing and Software Engineering, Kennesaw State University, Kennesaw, GA, 30144, U.S.A.

Abstract
Federated Learning (FL) is developed to learn a single global
model across the decentralized data, while is susceptible
when realizing client-specific personalization in the presence
of statistical heterogeneity. However, studies focus on learning a robust global model or personalized classifiers, which
yield divergence due to inconsistent objectives. This paper
shows that it is possible to achieve flexible personalization
after the convergence of the global model by introducing representation learning. In this paper, we first analyze and determine that non-IID data harms representation learning of
the global model. Existing FL methods adhere to the scheme
of jointly learning representations and classifiers, where the
global model is an average of classification-based local models that are consistently subject to heterogeneity from nonIID data. As a solution, we separate representation learning
from classification learning in FL and propose RepPer, an
independent two-stage personalized FL framework. We first
learn the client-side feature representation models that are robust to non-IID data and aggregate them into a global common representation model. After that, we achieve personalization by learning a classifier head for each client, based on
the common representation obtained at the former stage. Notably, the proposed two-stage learning scheme of RepPer
can be potentially used for lightweight edge computing that
involves devices with constrained computation power. Experiments on various datasets (CIFAR-10/100, CINIC-10) and
heterogeneous data setup show that RepPer outperforms alternatives in flexibility and personalization on non-IID data.

1

Introduction

The enormous amount of edge devices and various terminals continually generating large-scale datasets, which draw
a magnificent concern regarding data privacy and sensitivity (Konečnỳ et al. 2016; Bonawitz et al. 2017; Mohri, Sivek,
and Suresh 2019). Federated learning (FL) (McMahan et al.
2017), a distributed machine learning paradigm, has shown
great promise in reducing privacy risk and communication
costs (Kairouz et al. 2019; Li et al. 2020; Zhang et al.
2021a). It enables multiple clients to learn a global model
collaboratively over distributed partitions of data under the
management of a central server with a built-in privacypreserving design. One challenge associated with decentralized data in FL is statistically heterogeneous across the
* Corresponding author: dxh@xmu.edu.cn

client (Zhao et al. 2018; Hsieh et al. 2020; Zhang et al.
2021b). The non-IID data due to the different contexts
and preferences of the distributed clients. Indeed, statistical heterogeneity describes distributions of labels among
clients. Specifically, local computations in a supervised setting on such non-IID data are unavoidably inherited with
label bias, bringing local models to drift significantly from
each other (Li et al. 2018; Karimireddy et al. 2020; Deng,
Kamani, and Mahdavi 2020). Consequently, the resultant
global model may result in poor decentralized data adaptation.
The problem of statistical heterogeneity in FL has been
extensively investigated in the literature on personalized FL.
Two active strands of work involve learning a robust global
model with meta-learning (Finn, Abbeel, and Levine 2017;
Chen et al. 2018; Khodak, Balcan, and Talwalkar 2019; Fallah, Mokhtari, and Ozdaglar 2020) and regularization training for better generalization performance (T Dinh, Tran,
and Nguyen 2020; Huang et al. 2021), and personalized
models on heterogeneous data with transfer learning (Arivazhagan et al. 2019; Chen et al. 2020b). Recent advances
fueled by contrastive representation learning (Tian, Krishnan, and Isola 2020; He et al. 2020b; Grill et al. 2020;
Chen et al. 2020a; Chen and He 2021) suggest a possible
route for further improvements of FL. Specifically, federated representation learning (FRL) suggests that learning local representations among their local data and exploring the
reduced-dimensional representations on the server can alleviate the influence of statistic heterogeneous on personalized
FL (Zhang et al. 2020; Zhuang et al. 2021; Chen and Chao
2021; Oh, Kim, and Yun 2021). Though the FRL methods
are intuitive and experimentally effective, they are not without limitations: e.g., the local representations need to be uploaded to the server, which results in an increased risk of
privacy leakage. More importantly, representation and classification training are bound together in a supervised fashion
(even if the decoupling process is subsequently performed in
FedRep (Collins et al. 2021)). The local training is driven by
the client’s empirical risk, which will inevitably be affected
by label bias (Luo et al. 2021). We further observe that nonIID data lead to biased feature representations. This is depicted in Figure 1, where the feature representations of the
global model of the FedAvg (McMahan et al. 2017), LGFedAvg (Liang et al. 2020), FedRep (Collins et al. 2021),

Bad separation
for tail class

Bad separation
for tail class

(a) FedAvg

(b) LG-FedAvg
Better separation
for tail class

Mixed class
boundary

Clearer boundary

Bad separation
for tail class

(c) FedRep

(d) RepPer

Figure 1: Comparing the feature representations of
RepPer with the jointly learning schemes, including FedAvg (McMahan et al. 2017), LG-FedAvg (Liang et al.
2020), and FedRep (Collins et al. 2021) on the local data
of the CIFAR-10 dataset under the non-IID settings. TSNE
visualization shows that non-IID data can result in poor class
separation, particularly for instance-scarce (or tail) classes.
The vanilla FL and FRL approaches suffer from biased
and mixed representations, while RepPer benefits to shape
clear class boundaries, leading to more apparent separation and improved performance. The classification accuracy
comparison results are shown in Table. 2.

and RepPer on local data. This observation illustrates that
the negative effects of non-IID persist not only in the classification accuracy but also in the feature representations.
Is it possible to learn and exploit a common representation model on non-IID data while maintaining good personalized predictions for all the clients? To answer this question
affirmatively, we propose RepPer, a two-stage framework
for learning from non-IID data, which eliminates the correlation between representation learning and personalized prediction. Instead of learning representations from the classification objective, our key idea is to separate representation learning from classification in the local update, from
which to mitigate the adverse effect of label bias and clientdrift. Specifically, we built a two-stage training procedure:
(1) Common representation learning (CRL) stage. We construct a common feature space with discriminative capability
by averaging local representation model updates. The participants proceed with local computations based on supervised contrastive (SC) loss (Khosla et al. 2020) to learn local representation models and update the global representation model similar to the standard FedAvg. (2) Personalized

classification learning (PCL) stage. We learn a personalized
classifier head for each client on their distribution, using
the common representation model obtained from the CRL
stage. Since the two stages of RepPer are optimized independently and separately, every client can obtain a fully
customized classification model with low complexity after
the first stage has been converged. As shown in Fig. 2, we
show that the parameters of the global representation model
can be updated by aggregating local representation model
parameters, where each local model aims to learn feature
representation from the heterogeneous data. Local personalization depends on satisfying client-specific target distributions upon the learned global representation model. With
this strategy, local clients learn discriminative feature representation in the CRL stage and leverage the aggregated
global representation model to optimize their personalized
classifiers w.r.t local data in the PCL stage.
RepPer is flexible in Internet of Things (IoT) applications in the actual federated scenario, especially in conditions where edge devices have less computation power. In
RepPer, personalized classifiers can be flexibly designed
by traditional machine learning and deep learning techniques, such as support vector machine (SVM (Cortes and
Vapnik 1995)), logistic regression (LR) and multi-layer perceptron (MLP) neural network. Even for clients who can
only support classification that is incompetent to participate
in feature representation, they can flexibly train their personalized classifier derived from the common representation
from the CRL stage.
We evaluate RepPer on federated image classification
and show that it outperforms recently proposed alternatives
on different levels of statistical heterogeneity among clients.
We also consider and perform experiments on out-of-localdistribution generalization, wherein one client personalization can optimize for newly targeting distributions in the federation that differ from the raw data distribution. Finally, we
explore the flexibility for specific clients considering the insufficient computational power in the realistic federation.
The main contributions of this work can be summarized
as follows:
i) We establish RepPer, an independent two-stage personalized FL framework that separates traditional FL into
representation and classification learning. First, we explore to learn a common representation model from the
non-IID data. Then, each client can design a personalized classifier on their local data flexibly by using the
well-learned common representation model.
ii) We make a practical consideration of FL in edge computing and out-of-local-distribution generalization. The
RepPer allows edge devices with different computing
powers to participate in FL. New clients or target distributions can be well generalized based on RepPer when
the CRL stage is available.
iii) Experimental results validate the generalization and classification accuracy of the RepPer in (a) different levels
of statistical heterogeneity; (b) generalization on out-oflocal-distribution data; (c) various computing powers devices.

2
2.1

Related Work

Federated Learning

In FL, the central server coordinating a total of K clients
jointly solve the following optimization problem:
(
)
K
X
(1)
min F (w) :=
qi fi (w) ,
w

i=1

where the global objective function F (w) is the average of
the local objectives fi (w) with the weight qi of the participant K clients. In particular, fi (w) measures local empirical
risk across local data distribution Di = {xi1 , xi2 , · · · , xini },
defined as
ni
1 X
fi (w; xij ),
fi (w) =
(2)
ni j=1
whereP
ni is the count of indices of samples on i-th client,
n =
i (ni ) is the sum of samples across all the clients.
We set qi = ni /n, where i ∈ [K]. Recent methods have
studied the personalization of FL over multiple sources of
non-IID data. The personalized FL optimizes the objective
in Eq. (1) and (2), aiming to 1) learn a global model w from
the decentralized data; 2) achieve client-specific personalization. Federated meta-learning proposes to find a good initial condition shared across participating clients as an initial global model and then optimize for personalization in
cooperating with meta-learning (Chen et al. 2018; Fallah,
Mokhtari, and Ozdaglar 2020; Khodak, Balcan, and Talwalkar 2019). Federated transfer learning offers to transfer
the global model to each client by freezing the distributed
lower layers of the global model while fine-turning its higher
layers in terms of local data (Arivazhagan et al. 2019; Chen
et al. 2020b). Federated regularization training introduces a
unit L2 -norm to constrain the difference of model parameters between the global and local models to stabilize convergence (Huang et al. 2021; T Dinh, Tran, and Nguyen 2020;
Li et al. 2018). In all of these methods, each client in the
federation is trained in a jointly learning scheme, limited by
label bias and client-drift from non-IID data.

2.2

Contrastive Representation Learning

Contrastive representation learning has seen remarkable success in learning representations, especially on unlabeled
data (Tian, Krishnan, and Isola 2020; He et al. 2020b; Grill
et al. 2020; Chen et al. 2020a; Chen and He 2021). The
common motivation behind it is introducing a contrastive
loss (Gutmann and Hyvärinen 2010) in representation learning. Contrastive loss maximizes the consistency between
augmented views of the same image by contrasting the
agreement between different images. Supervised contrastive
learning (Khosla et al. 2020) incorporates label information
to maximize features from the same class. Contrastive representation learning has been widely investigated in longtailed and class imbalanced classification (Kang et al. 2020;
Wang et al. 2021). It helps to learn discriminative features
and ease classifier learning in imbalance cases.

2.3

Federated Representation Learning

Recent researchers focus on learning representations across
participant clients on heterogeneous data, and further optimizing personalization for each client. FedCA (Zhang
et al. 2020) and FedU (Zhuang et al. 2021) learn representations from unlabeled non-IID data. LG-FedAvg (Liang
et al. 2020) and FedRep (Collins et al. 2021) are similar to
RepPer, but they jointly learn representation on each local
data constrained by classification objectives, such as crossentropy loss, leading to biased representations, as shown in
Fig. 1(b) and 1(c). Moreover, the most recent FRL methods
upload the representations learned from local data, leading
to privacy leakage. Our approach separates representation
learning from classification training in local updating. We
introduce the recently proposed supervised contrastive (SC)
loss for the local representation model updating on non-IID
data, and prevent transferring feature representation vectors
to the server to avoid privacy leakage. RepPer is a general
framework that mitigates the non-IID problem, makes flexibility, and reduces personalization computation.

3

Methodology

To effectively learn an independent common representation
model on non-IID data and perform personalized prediction for each client on local data, we show a two-stage
personalized federated learning with simple procedures. An
overview of RepPer is shown in Fig. 2.
Stage 1: Common Representation Learning (CRL). Typically, the objective fi (w; x) in Eq. (2) is generally a crossentropy loss corresponding to client classification on nonIID data. The feature distribution learned on such decentralized data can be highly skewed (shown in Fig. 1), and the
decision boundary can be affected by label bias on classification optimization. The CRL stage suggests local models
to learn distinguishable feature representations in the federation by introducing contrastive semantic clustering constraints. To do this, we build on SC loss for local data in each
client, which pulls samples with the same class closer in feature space and pushes samples apart from other classes. In
each communication round of the CRL stage, local representation models learn corresponding feature representations
from both instance-rich (or head) and instance-scarce (or
tail) classes. The global representation model allows clientserver synchronously updating in the federation. It should be
emphasized that the server takes a weighted average of the
local representation model parameters without extra feature
representation vectors learned from each client or raw data
to decrease the risk of privacy leakage.
Stage 2: Personalized Classification Learning (PCL).
Benefitting from the CRL stage, a personalized classification
model is trained for each client using the generated global
representation model to create a personalized classifier head
on local data. Here, we consider different amounts of available computing power on each client in edge computing and
adapt to the personalized classification process by learning
local classifier heads with different sizes and complexity.
Some clients who lack computing power in participating in
the iterations of FL can flexibly train their personalized low-

Aggregation

𝝋𝒕
𝝋𝒏𝒕

𝝋𝟏𝒕

𝜽𝟏𝝉

Client 𝟏

⋯

𝜽𝒗𝝉

New client 𝒗

𝜽𝒏𝝉

⋯

Client 𝒏

Client 𝒊 (sorted class index)

Common representation learning (CRL)

Representation learning model

Supervised contrastive loss

Personalized classification learning (PCL)

Personalized classification model

Share weights

Figure 2: Left: RepPer allows local and global feature representation learning on heterogeneous data and flexible design
in personalized classification. Black line: Common representation learning (CRL) stage shows client-server synchronization
representation optimization in the federation. Blue and green indicate local representation models, and grey denotes the global
server. Each client communicates the local representation model updates to the server. There these updates are aggregated to
generate a shared global representation model. Orange line: Personalized classification learning (PCL) stage shows that each
local client leverages the resulting global representation model to optimize its desired personalized classifier with local data.
Similarly, it is only necessary to update the new classifier head according to the global representation model when facing new
client data. Right: Local representation training with the supervised contrastive (SC) loss (Khosla et al. 2020) on client data.
The SC loss focuses on clustering the features with semantic discrimination, resulting in less skewed features.
dimensional classifier, such as SVM, logistic regression, or
neural networks, by using the ready-made global representation model from the CRL stage. We describe how the stages
of CRL (in Section 3.1) and PCL (in Section 3.2) operate
learning on non-IID data. We then analyze the advantage of
representation learning on non-IID data in RepPer.

3.1

Common Representation Learning (CRL)

Instead of optimizing the objective in Eq. (1), we instruct
a server to coordinate local clients to train a common representation model. Specifically, each client conducts representation learning with SC loss, communicates local representation model updates to the server, and aggregates these
updates to the common representation model. We rewrite the
objective Eq. (1) to optimize the following objective:
(
)
K
X
min F (φ) :=
qi fi (φ) ,
(3)
φ

i=1

where the global objective function F (φ) is the average of
local objectives fi (φ) weighted by participants.
In local model training, each client learns to map input sample x ∈ Rd to a lower-dimensional feature vector
r ∈ Rg wherein d  g, which is then normalized to the
projection vector z onto the unit hypersphere called feature space. Then we adopt SC loss to constrain distances
of projection vectors from different classes. In order to increase the number of samples for each class, especially for

tail classes, we make two augmentations to each input image x. Thus, each client i ∈ [K] obtains sample-label pairs
i
Di = {(xij , yji )}2n
j=1 that consist of data augmentations. In
the client i, for each sample xij acts as an anchor, A(j)
is the set of all indices in the client i distinct from xij ,
P (j) = {xp |yp = yj , p 6= j} is the set of indices of samples
originating from the same class with xij but does not contain
xij , N (j) = {A(j)\P (j)} is the set of indices of samples
with different classes than xij . Indices in P (j) are called the
positives, and indices in N (j) are called the negatives. For
the projection vectors normalized into the feature space, the
SC loss clusters the positives close to the anchor and separates the anchor from the negatives. Eq. (4) and (5) present
the details of fi (φ) in Eq. (3) as follows:
fi (φ) =

2ni
X

`j ,

(4)

j=1




 1
X
exp(zj · zp /τ )
P
, (5)
`j = − log
|P (j)|
a∈A(j) exp(zj · za /τ )
p∈P (j)

where z refers to the normalized representation of input x,
the · symbol denotes the inner product, τ ∈ R+ is a scalar
temperature parameter. Critically, in CRL stage, the label information is required only for clustering feature representa-

tions in the feature space rather than intended to classify data
from all clients.

3.2

Personalized Classification Learning (PCL)

After the global representation model has converged, a personalized classifier using global representation can be a
much smaller model with less computation. In PCL stage,
each client create a personalized classifier θ locally, which
flexibly fits their client’s local data distribution. For each
client i ∈ [K], here we train a conventional classification
model by minimizing the loss function `cls : RC × RC → R
between the ground-truth and prediction, i.e., cross-entropy
loss. The goal of this stage for each client is formulated as
follows:
1 X
arg min
`cls (θi (φ(xij )), yj ),
(6)
θi Di
j∈[Di ]

where φ is the fixed global representation model learned
from the previous CRL stage. Each client i ∈ [K] trains
their classifier θi to map from representations to label space.
Indeed, we study and experiment on various local classification heads with low complexity, including SVM, logistic
regression and MLP neural network. More details are shown
in Section 6.4.

4

Optimization

During the optimization, RepPer alternates between the
client’s local update and a server update on each communication round until convergence in the CRL stage and then
optimizes a personalized classifier for each client in the PCL
stage. Every client performs τr iterations of SGD to compute a local update in the CRL stage and τc iterations to
compute in PCL stage. The subscript r denotes the representation procedure in both client and server updates, and
c indicates personalized classification. The overall training
procedure is shown in Algorithm 1.
Client Update. In communication round t, a fraction C ∈
(0, 1] of the total clients is uniformly randomly selected for
local updating. In the client update, the selected client i ∈
[C · K] updates the local representation model φit with τr
iterations by using gradient descent with respect to its joint
data as the following:
φit,τr +1 = φit,τr − ηr ∇fi (φit,τr ),

(7)

where ηr is the learning rate, ∇fi (φit,τ ) denotes one step of
stochastic gradient according to Eq. (4) using the current local representation model φit . Non-selected clients will keep
their previous local model parameters.
Server Update. After iterating the local client updates for
τr times in round t, the participating clients upload parameters with respect to the recent local representation model to
the server for aggregation:
X
φt+1 =
qi φit ,
(8)
i∈[St ]

where St = max(C ·K, 1) is a client set that is randomly selected with a participation rate of C in communication round
t, qi is the weight of the participant client in set St .

Algorithm 1: RepPer
Parameter: K clients are indexed by i; participation rate C; learning rate ηr , ηc ; number of iterations τr , τc ; number of communication rounds T .
Stage 1: Common representation learning
Server executes:
initialized global representation model with weights φ0
for round t = 0, 1, · · · , T − 1 do
m ← max(C · K, 1)
St ←(random set of m clients)
for each client i ∈ St in parallel do
φit+1 ← Client Update (i, φit )
end for P
i
i
φt+1 ← i∈St D
D φt+1
end for
Client Update (i, φit ):
Br ← (split local data Di into batch)
for τ = 0, 1, · · · , τr − 1 do
for batch br ∈ Br do
φiτ +1 ← φiτ − ηr ∇fi (φiτ ; br )
end for
end for
return φi to server
Stage 2: Personalized classification learning
Clients execute: //update each local classifier with the
global representation φ frozen
initialized i-th local classification model with weights θi
Bc ← (split local data Di into batch)
for τ = 0, 1, · · · , τc − 1 do
for batch bc ∈ Bc do
θτi +1 ← θτi − ηc ∇`i (θτi , φ; bc )
end for
end for

Personalized Classifier Update. The parameters of classifiers are updated according to the fixed global representation model. Each personalized classifier only needs a few
iteration to converge. Client i ∈ [K] updates the current
classifier model as follows:
θτi c +1 = θτi c − ηc ∇`i (θτi c ; Di ),

(9)

where ηc is the learning rate. Personalized classifiers for
each client on their local data can be simply learned using
a linear classifier or a shallow neural network.

5

Analysis

In this section, we provide an analysis of using SC loss for
local representation learning on non-IID data. As shown in
Fig. 1, statistic heterogeneity leads to biased representations
across clients. In non-IID settings, clients often contain tail
classes associated with only a few samples, which are susceptible to miss-classified of the majority. In local model
training of CRL stage, the SC loss contributes gradient from
minorities are large while those for majority samples are

small, leading to a more robust local representation clustering both on head and tail classes. As shown in the Appendix A, the gradient for Eq. (5) with respect to the normalized representation vector zj has the following form:




X
X
∂`j
1
zp (Pjp − Xjp ) +
zn Pjn ,
=

∂zj
τ
p∈P (j)

n∈N (j)

(10)
where
e

(zj ·zp /τ )

a∈A(j)

e(zj ·za /τ )

,

e(zj ·zp /τ )
.
0
p0 ∈P (j) e(zj · zp /τ )

Xjp = P

(11)
(12)

In Sec. 3.1, we define r the feature vector before normalization, i.e., zj = rj /krj k. The gradient of SC loss with
respect to r has the form:
∂`j
∂`j
∂`j
=
+
,
∂rj
∂zj P(j)
∂zj N(j)

(13)

X
1
(zp −(zj ·zp )zj )(Pjp −Xjp ),
τ krj k

(14)

where

∂`j
∂zj

=

p∈P (j)

P(j)

=
N(j)

X

(zn − (zj · zn ) zj )Pjn .

(15)

n∈N (j)

We show that the SC loss is structured so that tail classes
with few samples have large gradient contributions while
head classes have small ones. If xj is sampled from the tail
class, which acts as an anchor, the set of positives P (j) is
irregular and difficult to discriminate from large amounts of
negatives, zj · zp ≈ 0, so
q
2
(16)
k (zp − (zj · zp ) zj ) k= 1 − (zj · zp ) ≈ 1.
If xj is sampled from the head class as an anchor, the corresponding positives are numerous, and easy to measure their
similarities, zj · zp = 1, thus
q
2
k (zp − (zj · zp ) zj ) k= 1 − (zj · zp ) = 0.
(17)
We observe that tail classes with few samples have
large gradient contributions, therefore obtaining more compact representations in feature space. This implicit property avoids representation learning being affected by label
bias. Furthermore, the label information here applies to robust representation clustering rather than classification tasks.
Consequently, well-learned feature clustering in each client
is the original drive of RepPer. We provide a full derivation
of the property from the gradient descent in Appendix A.
The common global representation model receives and averages these local updates can perform better clustering than
recently proposed methods. Fig. 4 validates the feature representation capability of the server in RepPer.

Experiments

In this section, we validate the performance of RepPer with
non-IID data across clients from three aspects: (i) the discriminative of feature representations of the server and local
clients learned in the CRL stage; (ii) the personalized classification performance for each client and generalization to
the new client; (iii) the effect of adapting to lower computation powers in representation and classification learning.

6.1
Pjp = P

∂`j
∂zj

6

Experiments Setup

Datasets with the heterogeneous distribution We consider the federated image classification problem using
the following three real-world image datasets: CIFAR10 (Krizhevsky 2012), CIFAR-100 (Krizhevsky 2012), and
CINIC-10 (Darlow et al. 2018). CIFAR-10/100 consist of
10/100 categories with 6000 and 600 samples per category,
respectively. CINIC-10 is comprised of images from 10 categories with 9,000 samples per category. We distribute these
complete datasets to control heterogeneity using Dirichlet distribution as (Lin et al. 2020; Yurochkin et al. 2019;
Hsu, Qi, and Brown 2019). The concentration parameter
α = {100, 1, 0.5} in Dirichlet distribution defines the degree
of non-identicalness for client-partitioned data distribution.
The possibility of the client holding samples from classes is
positively correlated with the value of the concentration parameter: α = 100 equals to identical distribution across all
the clients, and as the α gets smaller, the clients are more
likely to have samples from extremely class imbalance. We
consider three data partition strategies to simulate FL scenarios and visualize how samples distributed among 20 clients
for CIFAR-10, CINIC-10, and CIFAR-100 on different α in
Fig. 3.
Baselines We evaluate and compare against personalized
FL methods as well as global shared methods with personalized fine-tuning. (1) FedAvg (McMahan et al. 2017) is the
classical framework of FL and is treated as the baseline in
this experiment. (2) FedProx (Li et al. 2018) leverages a
regularization term to restrict local updates not far from the
global model. (3) LG-FedAvg (Liang et al. 2020) applies
the representation learning strategy to learn local representation models and aggregates them into a global model to
adapt to local data. (4) FedRep (Collins et al. 2021) learns
the global representation based on supervised cross-entropy
loss and then updates personalized classifiers locally. (5) FedAVG+FT and FedProx+FT. For global shared models like
FedAvg and FedProx, we train its global model first and then
fine-tuning the classifier heads for 10 SGD epochs on its local training data, named FedAVG+FT and FedProx+FT for
personalization and compute the final test accuracy.
Implementation In each experiment, all the baseline
methods and RepPer share the same backbone network
(ResNet34 (He et al. 2016)), as well as the same number of epochs (E = {10, 20} ), participant rate (C =
{0.2, 0.4, 0.8}), batch sizes (B = 256), learning rate
(η=0.001, with a learning rate decay of 0.1.) and communication round (T = 100). We use Adam (Kingma and
Ba 2014) as an optimizer, and the weight decay is set to

4

Class labels

6

6

4

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19

Client IDs

(a) CIFAR-10: α = 100

4

0

0

0

6

2

2

2

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19

Client IDs

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19

(b) CIFAR-10: α = 1

Client IDs

(c) CIFAR-10: α = 0.5

100

100

80

80

4
2

6
4
2

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19

Client IDs
(d) CINIC-10: α = 1

60
40

Client IDs
(e) CINIC-10: α = 0.5

40

0

0
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19

60

20

20

0

0

Class labels

Class labels

6

Class labels

8

8

Class labels

8

8

Class labels

Class labels

8

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19

Client IDs
(f) CIFAR-100: α = 1

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19

Client IDs
(g) CIFAR-100: α = 0.5

Figure 3: Illustration of various degrees of non-IID data across clients is sampled using Dirichlet distribution with α =
{100, 1, 0.5} and indicated by dot sizes. The horizontal axis represents the total clients, and the vertical axis represents the
classification labels.
1 × 10−4 . The value of hyperparameter temperature (τ ) in
Eq. (5) is fixed at 0.1. Each global shared model baseline
does for fine-turning its classifier head by running 10 local
epochs of SGD. Personalized FL methods and PCL stage
of RepPer did likewise. Federated classification accuracies
are shown by averaging the local accuracy of each client
on the corresponding test dataset. To better evaluate adaptation in realistic FL scenarios with heterogeneous settings,
we show the accuracy of each client on non-IID test datasets.
We implement our experiments based on the FedML (He
et al. 2020a), an open-source federated learning library.

6.2

Representations Visualization

To validate the feature representation capability of the CRL
stage in RepPer, we visualize representations learned from
global and local local models using t-Distributed Stochastic
Neighbor Embedding (t-SNE) (Van der Maaten and Hinton
2008), as shown in Fig. 4. Different colors in the figure represent different data categories.
We first show representations of the seven randomly selected clients on their respective local data. In the non-IID
setting of α = 0.5, as shown in Fig. 3(c), local data exhibit
varying class imbalances among the clients. Despite this,
we observe that local models can cluster well for various
degrees of instance-rich/scarce classes, leading to sharper
boundaries and better discrimination of tail categories in tSNE. In RepPer, the server collects local representation
model parameters to update a global representation model.
We then further show representation on the server over all
the data and we observe that the global representation model
consistently performs well even though the local representa-

tion models are trained on the non-IID data.
Fig. 4 illustrates that RepPer learns local representing
models on heterogeneous data and obtains a common global
model unaffected by non-IID data. We further show evaluation of the effectiveness of personalized classification based
on the common representation model in the next section.

6.3

Model Performance

In this section, we performed a detailed comparison of
RepPer and baselines on federated image classification.
We first investigate the effect of hyperparameters on the classification accuracy of FedAvg, LG-FedAvg, FedRep, and
RepPer, in both IID and various degrees of the non-IID settings. Then, we compare the performance of RepPer with
baselines in the non-IID setting. Finally, the out-of-localdistribution generalization of RepPer is compared to that
of FL methods.
Effect of hyperparameters The key factors considered
in FL that affect performance include: the fraction (C) of
clients participating on each round, the number of local
epochs (E), and degrees of heterogeneity (α) in the dataset.
To understand the critical factors that affect the convergence
of RepPer in both IID and non-IID settings, we evaluate RepPer and compare it with baseline methods on the
CIFAR-10 dataset. We compare the test performance of the
proposed RepPer with baseline methods for different local training settings: non-IID degrees α = {100, 1, 0.5};
randomly select a fraction C = {0.2, 0.4, 0.8} of the total
20 clients; the number of communications is 100, and local
epochs E = {10, 20} per communication round. The vari-

0
1

2
3

4

5

6

0
1

(a) Client A

0
1

2
3

4
5

(e) Client E

6
7

2
3

4
5

6
7

8
9

0
1

(b) Client B

8

0
1

2
3

4
5

6
7

(f) Client F

2
3

4
5

6
7

9

0
1

(c) Client C

8
9

0
1

2
3

4
5

6
7

(g) Client G

2
3

4
5

6
7

8
9

(d) Client D

8
9

0
1

2
3

4
5

6
7

8
9

(h) Server

Figure 4: T-SNE visualization of representations learned from global and local models in RepPer on the CIFAR-10
under non-IID setting with α = 0.5. For local data, each client contains an unequal number or category of images, and the
number of categories in the enumerated randomly selected clients is shown in the respective legends. From left to right, the
data distribution becomes increasingly skewed. Client A includes samples from 7 categories, and the number of samples per
category is relatively equal. Clients B, C, and D contain a small number of tail categories and a relatively large number of
samples from the remaining categories. Clients E, F, and G include samples with extremely class imbalance, containing some
categories with minimal numbers. The server aggregates and updates with local models, achieving well-clustering results on
the whole data.
ous values of the three critical parameters and their effects
on the methods are described in Table 1.
• Effect of α. Statistic heterogeneous is the main factor
affecting the performance of FL models. In this experiment, only the value of α reduces from 100 to 1 and
finally to 0.5, we notice that almost all the baseline methods are suffered from statistic heterogeneous on classification. This is because the model aggregation is highly
dependent on local models. The non-IID data lead to
biased local models and inferior global model. However, RepPer still allows high accuracy of the continuous classification. The reason is that RepPer focuses
on learning representation clusters instead of decision
boundaries for classification on non-IID data, which is
impervious to label bias and client-drift, as illustrated in
Fig. 4.
• Effect of C. The fraction (C) of clients controls parallelism in each communication round. We show the effect
of varying C for baseline models and RepPer. According to Table 1, the down arrow (↓) represents a decrease
in classification accuracy as the number of clients participating increases. We observe that increasing C may
not always be positively correlated with performance improvement of baseline methods, but has a limited impact

on RepPer, neither in the IID nor non-IID cases. This
observation reminds us that not all methods benefit from
increasing the number of participating clients, and the
value of C should be carefully chosen for the remaining
experiments.
• Effect of E. Intuitively, small E increases the communication burden. Meanwhile, more local epochs (E) typically lead to divergence in FL. In this experiment, we fix
C and α, and increasing E shows that the larger value of
E brings negative effects on almost all the baseline methods, which is consistent with observations in (McMahan et al. 2017; Wang et al. 2020; Caldas et al. 2018).
The longer training epochs bring greater client diversity, resulting in inferior global model aggregation. In
contrast, RepPer can benefit from more local epochs
(E). RepPer focuses on learning representations from
non-IID local data, and more local training epochs boost
representation ability to target various heterogeneous FL
scenarios. Therefore, as the local epochs increases, the
performance of RepPer is improved.
The analysis of these key factors shows that RepPer can
benefit from more local epochs (E), a specific number of
participant clients (C), and robustness on various non-IID
data with α, and result in a steady rise in federated classifi-

Table 1: Evaluation of different FL approaches in various heterogeneous settings with three key parameters: client
sampling fractions C, local epochs E, and non-IID degrees α. We show classification test accuracy, and the best results are in
bold. We adopt the same backbone as ResNet-34 for each method and evaluate the performance on the CIFAR-10 dataset.
C = 0.2

C = 0.4

C = 0.8

Method

Local epochs
IID

α = 1.

α = 0.5.

IID

α = 1.

α = 0.5.

IID

α = 1.

α = 0.5.

FedAvg (McMahan et al. 2017)

10
20

78.04
77.61

72.58
72.39

66.56
66.43

78.58
78.28

72.64
73.65

70.91
71.67

79.05
78.66

74.73
74.90

75.64
75.99

LG-FedAvg (Liang et al. 2020)

10
20

78.87
77.25

75.67
74.27

73.62
73.82

78.25↓
76.81↓

74.68
73.90↓

74.88
72.98↓

78.03↓
77.03

74.53↓
74.06

75.88
74.26

FedRep (Collins et al. 2021)

10
20

80.43
78.21

67.04
71.24

61.08
71.83

80.53
79.64

73.03
69.45↓

76.36
71.35↓

79.86
80.03

74.57
74.21

75.49↓
71.85

RepPer

10
20

90.62
91.90

84.98
86.88

81.04
83.48

91.16
91.57

86.22
87.71

82.17
83.18

90.84↓
91.80

86.63
87.73

82.48
83.11↓

Table 2: Top-1 accuracy (%) comparison on non-IID settings of CINIC-10, CIFAR-10/100 datasets. We keep randomly
selected the fraction C = 0.2 of 20 clients and epochs E = 10 in iterations constant and evaluated the performance of SOTA
baselines and RepPer on degrees of non-IID data, which is synthetically controlled by α = {1, 0.5}. Best results are marked
in bold, and suboptimal results are marked with underline. RepPer outperforms prior work across non-IID settings.

Method
FedAvg (McMahan et al. 2017)
FedAvg+FT
FedProx (Li et al. 2018)
FedProx+FT
FedRep (Collins et al. 2021)
LG-FedAvg (Liang et al. 2020)
RepPer

CINIC-10

CIFAR-10

CIFAR-100

α = 1.

α = 0.5.

α = 1.

α = 0.5.

α = 1.

α = 0.5.

57.77
60.90
65.09
64.31
59.45
59.95
74.67

56.73
60.91
63.28
63.69
59.33
59.12
65.09

72.58
72.62
72.75
72.85
67.04
75.67
84.98

66.56
69.41
72.88
72.92
61.08
73.62
81.04

40.87
41.35
43.00
43.19
40.06
45.08
55.38

40.21
40.89
41.53
41.79
36.36
44.85
53.86

cation accuracy.
Performance Comparison In order to highlight the personalization performance of the RepPer, we continue to
compare it with more FL methods, including FedAvg, FedProx, LG-FedAvg, FedRep, and the global model with finetuning the classifier heads for personalization, including FedAvg+FT and FedProx+FT. In all scenarios, we consider the
heterogeneous setting including: degrees of non-IID with
α = {1, 0.5}, a fraction C = 0.2 of the total 20 clients are
randomly selected in iteration, 100 communication rounds
with 10 local epochs in each.
Table 2 shows the top-1 classification accuracies (with the
same hyperparameters) on the various non-IID degrees of
CINIC-10, CIFAR-10, and CIFAR-100 datasets. The comparison on the CINIC-10 dataset shows that RepPer in nonIID degrees α = {1, 0.5} have 9.58% and 1.4% more accurate than the best performing alternatives, FedProx and
FedProx+FT, respectively. For the CIFAR-10 and CIFAR100 datasets, we observe the best-performing alternative on
non-IID degrees α = {1, 0.5} is LG-FedAvg. Table 2 shows
that RepPer has a 9.31% and 7.42% improvement in accuracy than LG-FedAvg on the CIFAR-10 dataset. RepPer

achieves 10.3% and 9.01% more accuracy on CIFAR-100
datasets than LG-FedAvg.
We further evaluate the classification accuracy of the FL
methods for each category of the client’s local data. In the
non-IID data setting, the number of samples and categories
varies widely within each client. Figure 5 lists two randomly selected clients and shows corresponding classification accuracy for each category. The results in Figure 5 show
that the baseline methods on non-IID data can perform better in head classes while performance drops in predicting
tail classes. Our results provide stable performance for each
client in classification, both on head and tail classes.
The comparison between baseline methods indicates that
the RepPer outperforms all the other methods in classification accuracy. The results show that RepPer leads to more
robust and stable convergence than alternatives on heterogeneous datasets. We attribute this to the fact that the reasonable local representation models improve the robustness
and quality of the global model, and RepPer allows the
global representation model to be personalized for each specific client.

  5 H S 3 H U
  ) H G $ Y J
  ) H G 5 H S
  / *  ) H G $ Y J

  
  
  
  
  
  

 

 

 

 

 & D W H J R U \  L Q G H [  R I  F O L H Q W  $

 

 

   

 7 R S    D F F X U D F \  R Q  W H V W  G D W D V H W

 7 R S    D F F X U D F \  R Q  W H V W  G D W D V H W

   

  5 H S 3 H U
  ) H G $ Y J
  ) H G 5 H S
  / *  ) H G $ Y J

  
  
  
  
  
  

 

 

 

 

 

 

 & D W H J R U \  L Q G H [  R I  F O L H Q W  %

 

 

Figure 5: Classification accuracy of two randomly selected clients in their respective classes. Each client contains local
training data with different categories, and category indexes are sorted by the number of samples in each category in descending
order.

 7 R S    D F F X U D F \  R Q  W H V W  G D W D V H W

  
  
  
  
  
  

  5 H S 3 H U
  ) H G $ Y J
  ) H G 5 H S
  ) H G 3 U R [
  / *  ) H G $ Y J

  
  

                                                 

 & O L H Q W  , ' V

Figure 6: Comparing the effect of generalization on new
20 clients with retraining classifier heads of baseline methods and RepPer on the CIFAR-10 dataset. We consider 20
new clients with C = 1 participation ratio and the degree
of non-IID with α = 1. After iterating 100 times for each
personalized classifier head, RepPer can better personalize
for all the 20 new clients compared with alternatives. The
increasing number of new clients makes it harder to personalize; however, RepPer outperforms alternatives.

Generalization to New Clients We evaluate the strength
of RepPer to adapt to new clients. We consider the non-IID
federated setting where the resultant global model optimizes
for a new client with new target distribution. This can be
done by performing a few local updates to learn personalized
classifier heads from the given global representation model
in RepPer.
Accordingly, we train FedAvg, FedProx, LG-FedAvg, FedRep, and RepPer on the non-IID CIFAR-100 dataset,
which contains images of 100 categories. For new clients
with local data distribution from the new target domain,
which is the CIFAR-10 dataset in the setting of this experiment, we train classifier heads for 100 iterations on its local
data while keeping the global representation model parameters fixed.
Figure 6 shows the results of applying ready learned FL
methods to new clients that update one-layer MLP as their
corresponding classifier heads on the CIFAR-10 dataset. In
this experiment, either CIFAR-100 or CIFAR-10 datasets

are under heterogeneous settings with the non-IID degree
with α = 1. We show the classification accuracy of the test
datasets for 20 new joint clients in Figure 6. RepPer consistently outperforms alternatives over all the new clients.
We attribute the effective personalization for new clients of
RepPer due to the semantic discrimination capability of the
global representation model, which can be well adapted to a
new client with different data distribution.

6.4

Flexibility for Low Power Internet-of-Things

FL in the Internet of Things (IoT) involves edge devices with
diverse hardware and different computation power(Ning
et al. 2018; Min et al. 2019; Pang et al. 2020). Significantly,
some clients with less computation power or even clients
that only support classification, can barely participate in FL
iterations. To mitigate this problem, we exploit the personalized properties of the RepPer to define various simple
classifiers for each client flexibly.
We investigate three machine learning classifiers in the
PCL stage of RepPer for personalized prediction: support
vector machine (SVM), logistic regression (LR) and multilayer perceptron (MLP) neural network. For clients with
limited computational power, only classifiers need to be retrained by the obtained representations from the global representation model. MLP classifiers can be considered a dividing hyperplane in the feature representation space, only
learning to make classification decisions. Therefore, we retrain these classifiers for clients with limited computation
power. Likewise, we retrain linear classifiers (in particular,
logistic regression and SVM) for trainable baseline methods
personalization with their global representations.
We compared the performance of RepPer with baseline
methods. As shown in Table 3, RepPer consistently outperform alternatives in personalized classification accuracy. We
attribute this to a well-learned global representation model
and flexibility in machine learning classifier choosing. As
IoT applications are incredibly diversified, there is a strong
need for flexible solutions in the federated learning frameworks. We evaluate that RepPer could be a viable option
for low computational power IoT devices.

Table 3: Top-1 accuracy (%) personalized classification
with flexible classifiers by using the trained global model.
RepPer outperforms other alternatives across MLP, SVM
and logistic regression (LR). Best results are marked in bold.

6.5

Method

MLP

SVM

LR

FedAvg
LG-FedAvg
FedRep
RepPer

72.64
74.64
73.03
86.22

68.66
59.82
70.71
82.67

68.79
60.05
71.14
83.78

Robustness of Different Backbones

In this section, we conduct and analyze the robustness of
the backbones to characterize the RepPer. We claim that
the CRL stage in RepPer can learn semantic feature representation clusters for each client and consequently lead to
a better global model in the federation. To validate that it
is more robust than alternatives, we extend the comparisons
above to the representation model size.
We consider the comparison at different scales of backbones, i.e., ResNet-34 (∼ 22million parameters) and MobileNet (Howard et al. 2017) (∼ 3million parameters), which
is frequently used in low-power devices. Accordingly, we
train the respective global models with suggested backbones
and corresponding personalized classifiers to compare the
performance with each other. The experiment evaluates this
two backbones and heterogeneous data with α = 1, the fraction of clients C = 0.4 for 20 clients. There are 100 communication rounds and 10 local training epochs per round.
Table 4 visualized the result of FedAvg, LG- FedAvg,
FedRep, and RepPer on the CIFAR-10/100 dataset. For
MobileNet, it shows that RepPer’s personalized model
is 17.47% and 3.19% more accurate than alternatives on
CIFAR-10 and CIFAR-100, respectively. For larger model
ResNet-34, RepPer shows superior classification accuracy
by 11.54% and 14.18% than alternatives on CIFAR-10 and
CIFAR-100. We show that the proposed RepPer dominates test classification accuracy in each network architecture as backbones. All these results further corroborate that
RepPer provides the possibility of mitigating system heterogeneity that alleviates extra effort in altering neural architectures. Table 4 visualizes RepPer deployed to the
portable backbone, such as MobileNet, exhibiting better stability, and higher accuracy than alternatives in personalized
FL.

7

Conclusion and future work

In this work, we propose RepPer as a personalized FL
framework that can adapt to non-IID data to improve the
personalized FL performance. We divide the traditional FL
into two stages that first enable the server to learn a common representation from heterogeneous data in the federation. We then personalize by allowing each client to compute
a personalized classifier on their local data using the common representation from stage one. We simulate numbers

Table 4: Top-1 classification accuracy (%) on the commonly used backbone (ResNet-34) and mobile backbone
(MobileNet) on the test set of CIFAR-10/100. We consider 20 clients for CIFAR-10/100 with C = 0.4, α = 1,
E = 10 local epochs per communication round. Best results
are marked in bold.
Method

CIFAR-10
MobileNet

ResNet-34

CIFAR-100
MobileNet

ResNet-34

FedAvg

59.22

72.64

33.36

42.57

LG-FedAvg

61.63

74.68

34.38

44.67

FedRep

60.50

73.03

34.48

40.57

RepPer

79.10

86.22

37.67

58.85

of non-IID distribution scenarios, where experiments results
show our method outperforms previous methods in flexibility and personalization. The two-stage training scheme
opens questions about the optimal learning scheme compared with end-to-end learning as general training methods.
We expected the proposed two-stage personalized federated
learning scheme to provide a more flexible paradigm for FL
and IoT applications.

References
Arivazhagan, M. G.; Aggarwal, V.; Singh, A. K.; and
Choudhary, S. 2019. Federated learning with personalization layers. arXiv preprint arXiv:1912.00818.
Bonawitz, K.; Ivanov, V.; Kreuter, B.; Marcedone, A.;
McMahan, H. B.; Patel, S.; Ramage, D.; Segal, A.; and
Seth, K. 2017. Practical secure aggregation for privacypreserving machine learning. In proceedings of the 2017
ACM SIGSAC Conference on Computer and Communications Security, 1175–1191.
Caldas, S.; Duddu, S. M. K.; Wu, P.; Li, T.; Konečnỳ,
J.; McMahan, H. B.; Smith, V.; and Talwalkar, A. 2018.
Leaf: A benchmark for federated settings. arXiv preprint
arXiv:1812.01097.
Chen, F.; Luo, M.; Dong, Z.; Li, Z.; and He, X. 2018. Federated meta-learning with fast convergence and efficient communication. arXiv preprint arXiv:1802.07876.
Chen, H.-Y.; and Chao, W.-L. 2021. On Bridging Generic
and Personalized Federated Learning for Image Classification. In International Conference on Learning Representations.
Chen, T.; Kornblith, S.; Norouzi, M.; and Hinton, G. 2020a.
A simple framework for contrastive learning of visual representations. In International conference on machine learning,
1597–1607. PMLR.
Chen, X.; and He, K. 2021. Exploring simple siamese representation learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 15750–
15758.

Chen, Y.; Qin, X.; Wang, J.; Yu, C.; and Gao, W. 2020b. Fedhealth: A federated transfer learning framework for wearable healthcare. IEEE Intelligent Systems, 35(4): 83–93.
Collins, L.; Hassani, H.; Mokhtari, A.; and Shakkottai, S.
2021. Exploiting Shared Representations for Personalized
Federated Learning. arXiv preprint arXiv:2102.07078.
Cortes, C.; and Vapnik, V. 1995. Support-vector networks.
Machine learning, 20(3): 273–297.
Darlow, L. N.; Crowley, E. J.; Antoniou, A.; and Storkey,
A. J. 2018. Cinic-10 is not imagenet or cifar-10. arXiv
preprint arXiv:1810.03505.
Deng, Y.; Kamani, M. M.; and Mahdavi, M. 2020. Adaptive personalized federated learning.
arXiv preprint
arXiv:2003.13461. Client-drift.
Fallah, A.; Mokhtari, A.; and Ozdaglar, A. 2020. Personalized federated learning with theoretical guarantees: A
model-agnostic meta-learning approach. Advances in Neural Information Processing Systems, 33: 3557–3568.
Finn, C.; Abbeel, P.; and Levine, S. 2017. Model-agnostic
meta-learning for fast adaptation of deep networks. In International Conference on Machine Learning, 1126–1135.
PMLR.
Grill, J.-B.; Strub, F.; Altché, F.; Tallec, C.; Richemond,
P. H.; Buchatskaya, E.; Doersch, C.; Pires, B. A.; Guo, Z. D.;
Azar, M. G.; et al. 2020. Bootstrap your own latent: A
new approach to self-supervised learning. arXiv preprint
arXiv:2006.07733.
Gutmann, M.; and Hyvärinen, A. 2010. Noise-contrastive
estimation: A new estimation principle for unnormalized
statistical models. In Proceedings of the thirteenth international conference on artificial intelligence and statistics,
297–304. JMLR Workshop and Conference Proceedings.
He, C.; Li, S.; So, J.; Zeng, X.; Zhang, M.; Wang, H.; Wang,
X.; Vepakomma, P.; Singh, A.; Qiu, H.; et al. 2020a. Fedml:
A research library and benchmark for federated machine
learning. arXiv preprint arXiv:2007.13518.
He, K.; Fan, H.; Wu, Y.; Xie, S.; and Girshick, R. 2020b.
Momentum contrast for unsupervised visual representation
learning. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, 9729–9738.
He, K.; Zhang, X.; Ren, S.; and Sun, J. 2016. Deep residual learning for image recognition. In Proceedings of the
IEEE conference on computer vision and pattern recognition, 770–778.
Howard, A. G.; Zhu, M.; Chen, B.; Kalenichenko, D.; Wang,
W.; Weyand, T.; Andreetto, M.; and Adam, H. 2017. Mobilenets: Efficient convolutional neural networks for mobile
vision applications. arXiv preprint arXiv:1704.04861.
Hsieh, K.; Phanishayee, A.; Mutlu, O.; and Gibbons, P.
2020. The non-iid data quagmire of decentralized machine
learning. In International Conference on Machine Learning,
4387–4398. PMLR.
Hsu, T.-M. H.; Qi, H.; and Brown, M. 2019. Measuring the
effects of non-identical data distribution for federated visual
classification. arXiv preprint arXiv:1909.06335.

Huang, Y.; Chu, L.; Zhou, Z.; Wang, L.; Liu, J.; Pei, J.; and
Zhang, Y. 2021. Personalized Cross-Silo Federated Learning on Non-IID Data. Proceedings of the AAAI Conference
on Artificial Intelligence, 35(9): 7865–7873.
Kairouz, P.; McMahan, H. B.; Avent, B.; Bellet, A.; Bennis,
M.; Bhagoji, A. N.; Bonawitz, K.; Charles, Z.; Cormode, G.;
Cummings, R.; et al. 2019. Advances and open problems in
federated learning. arXiv preprint arXiv:1912.04977.
Kang, B.; Li, Y.; Xie, S.; Yuan, Z.; and Feng, J. 2020. Exploring balanced feature spaces for representation learning.
In International Conference on Learning Representations.
Karimireddy, S. P.; Kale, S.; Mohri, M.; Reddi, S.; Stich, S.;
and Suresh, A. T. 2020. Scaffold: Stochastic controlled averaging for federated learning. In International Conference
on Machine Learning, 5132–5143. PMLR.
Khodak, M.; Balcan, M.; and Talwalkar, A. 2019. Adaptive
Gradient-Based Meta-Learning Methods. In Neural Information Processing Systems.
Khosla, P.; Teterwak, P.; Wang, C.; Sarna, A.; Tian,
Y.; Isola, P.; Maschinot, A.; Liu, C.; and Krishnan, D.
2020. Supervised contrastive learning. arXiv preprint
arXiv:2004.11362.
Kingma, D. P.; and Ba, J. 2014. Adam: A method for
stochastic optimization. arXiv preprint arXiv:1412.6980.
Konečnỳ, J.; McMahan, H. B.; Yu, F. X.; Richtárik, P.;
Suresh, A. T.; and Bacon, D. 2016. Federated learning:
Strategies for improving communication efficiency. arXiv
preprint arXiv:1610.05492.
Krizhevsky, A. 2012. Learning Multiple Layers of Features
from Tiny Images. University of Toronto.
Li, T.; Sahu, A. K.; Talwalkar, A.; and Smith, V. 2020. Federated learning: Challenges, methods, and future directions.
IEEE Signal Processing Magazine, 37(3): 50–60.
Li, T.; Sahu, A. K.; Zaheer, M.; Sanjabi, M.; Talwalkar, A.;
and Smith, V. 2018. Federated optimization in heterogeneous networks. arXiv preprint arXiv:1812.06127.
Liang, P. P.; Liu, T.; Ziyin, L.; Allen, N. B.; Auerbach,
R. P.; Brent, D.; Salakhutdinov, R.; and Morency, L.-P. 2020.
Think locally, act globally: Federated learning with local and
global representations. arXiv preprint arXiv:2001.01523.
Lin, T.; Kong, L.; Stich, S. U.; and Jaggi, M. 2020. Ensemble distillation for robust model fusion in federated learning.
arXiv preprint arXiv:2006.07242.
Luo, M.; Chen, F.; Hu, D.; Zhang, Y.; Liang, J.; and Feng,
J. 2021. No fear of heterogeneity: Classifier calibration for
federated learning with non-iid data. Advances in Neural
Information Processing Systems, 34.
McMahan, B.; Moore, E.; Ramage, D.; Hampson, S.; and
y Arcas, B. A. 2017. Communication-efficient learning of
deep networks from decentralized data. In Artificial intelligence and statistics, 1273–1282. PMLR.
Min, M.; Xiao, L.; Chen, Y.; Cheng, P.; Wu, D.; and Zhuang,
W. 2019. Learning-based computation offloading for IoT
devices with energy harvesting. IEEE Transactions on Vehicular Technology, 68(2): 1930–1941.

Mohri, M.; Sivek, G.; and Suresh, A. T. 2019. Agnostic
federated learning. In International Conference on Machine
Learning, 4615–4625. PMLR.
Ning, Z.; Dong, P.; Kong, X.; and Xia, F. 2018. A cooperative partial computation offloading scheme for mobile edge
computing enabled Internet of Things. IEEE Internet of
Things Journal, 6(3): 4804–4814.
Oh, J.; Kim, S.; and Yun, S.-Y. 2021. FedBABU: Towards
Enhanced Representation for Federated Image Classification. arXiv preprint arXiv:2106.06042.
Pang, J.; Huang, Y.; Xie, Z.; Han, Q.; and Cai, Z. 2020. Realizing the heterogeneity: a self-organized federated learning
framework for IoT. IEEE Internet of Things Journal, 8(5):
3088–3098.
T Dinh, C.; Tran, N.; and Nguyen, T. D. 2020. Personalized
Federated Learning with Moreau Envelopes. Advances in
Neural Information Processing Systems, 33.
Tian, Y.; Krishnan, D.; and Isola, P. 2020. Contrastive multiview coding. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XI 16, 776–794. Springer.
Van der Maaten, L.; and Hinton, G. 2008. Visualizing data
using t-SNE. Journal of machine learning research, 9(11).
Wang, H.; Yurochkin, M.; Sun, Y.; Papailiopoulos, D.; and
Khazaeni, Y. 2020. Federated learning with matched averaging. arXiv preprint arXiv:2002.06440.
Wang, P.; Han, K.; Wei, X.-S.; Zhang, L.; and Wang, L.
2021. Contrastive learning based hybrid networks for longtailed image classification. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition,
943–952.
Yurochkin, M.; Agarwal, M.; Ghosh, S.; Greenewald, K.;
Hoang, N.; and Khazaeni, Y. 2019. Bayesian nonparametric federated learning of neural networks. In International
Conference on Machine Learning, 7252–7261. PMLR.
Zhang, C.; Xie, Y.; Bai, H.; Yu, B.; Li, W.; and Gao, Y.
2021a. A survey on federated learning. Knowledge-Based
Systems, 216: 106775.
Zhang, F.; Kuang, K.; You, Z.; Shen, T.; Xiao, J.; Zhang,
Y.; Wu, C.; Zhuang, Y.; and Li, X. 2020.
Federated unsupervised representation learning. arXiv preprint
arXiv:2010.08982.
Zhang, W.; Li, X.; Ma, H.; Luo, Z.; and Li, X. 2021b. Federated learning for machinery fault diagnosis with dynamic
validation and self-supervision. Knowledge-Based Systems,
213: 106679.
Zhao, Y.; Li, M.; Lai, L.; Suda, N.; Civin, D.; and Chandra, V. 2018. Federated learning with non-iid data. arXiv
preprint arXiv:1806.00582.
Zhuang, W.; Gan, X.; Wen, Y.; Zhang, S.; and Yi, S. 2021.
Collaborative Unsupervised Visual Representation Learning
from Decentralized Data. In Proceedings of the IEEE/CVF
International Conference on Computer Vision, 4912–4921.

A

Gradient Derivation

We combine Eq. (18) and (22) thus give the following:

In Section 5, we claim that SC loss helps RepPer to learn
local representations on the non-IID data. In this section, we
perform gradient derivations with respect to normalized representation z and feature representation before normalization r, proving an intrinsic property of SC loss that works
well for learning representations on non-IID data. We start
by deriving the gradient with respect to z of Eq. (5):
∂`j
∂zj
=−




∂
1
log
 |P (j)|
∂zj

e

X

(zj ·zp /τ )

P
p∈P (j)

a∈A(j) e




(zj ·za /τ ) 

X
X
∂
∂
log
e(zj ·za /τ ) −
log
e(zj ·zp /τ )
∂zj
∂zj
a∈A(j)
p∈P (j)
P
P
(zj ·za /τ )
(z ·z /τ )
1 p∈P (j) zp e j p
1 a∈A(j) za e
P
−
= P
(zj ·za /τ )
zj ·zp /τ )
τ
τ
a∈A(j) e
p∈P (j) e
P
P
(z ·z /τ )
(z ·z /τ )
1 p∈P (j) zp e j p + n∈N (j) zn e j n
P
=
(zj ·za /τ )
τ
a∈A(j) e
P
(z ·z /τ )
1 p∈P (j) zp e j p
P
−
(zj ·zp /τ )
τ
p∈P (j) e



X
1 X
zp (Pjp − Xjp ) +
zn Pjn ,
=

τ

=

p∈P (j)

n∈N (j)

(18)
where
e(zj ·zp /τ )
,
(zj ·za /τ )
a∈A(j) e

(19)

e(zj ·zp /τ )
.
0
p0 ∈P (j) e(zj · zp /τ )

(20)

Pjp = P
Xjp = P

In local representation learning, the normalized representation z and representation before normalized r have the relation: zj = rj /krj k. Therefore, the gradient of the SC loss
with respect to r is related to that with respect to z via the
chain rule:
∂`j (zj )
∂`j (zj ) ∂zj
=
·
,
(21)
∂rj
∂zj
∂rj
where
∂zj
∂
=
∂rj ∂rj



rj
k rj k

=



∂(1/ k rj k)
∂rj
!
rj · rjT
I−
k rj k2

1
=
I − rj
k rj k
1
=
k rj k



1
(I − zj · zjT ),
k rj k

T
(22)

∂`j
∂rj

 X

1
=
zp (Pjp − Xjp )
I − zj zjT

τ k rj k
p∈P (j)


X
+
zn Pjn

n∈N (j)

(23)
 X
1
(zp − (zj · zp ) zj ) (Pjp − Xjp )
=
τ k rj k 
p∈P (j)


X
+
(zn − (zj · zn ) zj ) Pjn

n∈N (j)

=

∂`j
∂`j
+
,
∂zj P(j)
∂zj N(j)

where
∂`j
∂zj
∂`j
∂zj

=

X
1
(zp −(zj ·zp )zj )(Pjp −Xjp ),
τ krj k

(24)

p∈P (j)

P(j)

=
N(j)

X
n∈N (j)

(zn − (zj · zn ) zj )Pjn .

(25)

Decentralized Training of Acoustic
Models for Speech Recognition
PhD Proposal

Yan Gao

Fitzwilliam

First year report submitted in partial fulfilment of the requirements for the degree of
Doctor of Philosophy

Contents
1 Introduction

5

2 Background and Related Work
2.1 End-to-end Automatic Speech Recognition (ASR) . . . . . . . . . . . . . .
2.1.1 CTC-based model . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.1.2 RNN-transducer . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.1.3 Attention-based model . . . . . . . . . . . . . . . . . . . . . . . . .
2.2 New training schemes for ASR . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.1 Knowledge distillation . . . . . . . . . . . . . . . . . . . . . . . . .
2.2.2 Self-supervised learning . . . . . . . . . . . . . . . . . . . . . . . . .
2.3 Federated learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.1 Core challenges . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.2 Federated optimization . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.3 Federated learning in speech area . . . . . . . . . . . . . . . . . . .
2.4 Data distillation and extraction . . . . . . . . . . . . . . . . . . . . . . . .
2.5 Neural Architecture Search (NAS) . . . . . . . . . . . . . . . . . . . . . . .
2.5.1 Search algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.5.2 NAS applications . . . . . . . . . . . . . . . . . . . . . . . . . . . .

9
9
10
11
12
13
13
15
16
17
18
19
20
21
22
22

3 Completed Work
3.1 Multi-teacher distillation of acoustic models . . . . . . . . . . . . . . . . .
3.2 Acoustic model training in federated conditions . . . . . . . . . . . . . . .
3.3 Virtual IMU extraction pipeline . . . . . . . . . . . . . . . . . . . . . . . .

25
25
27
27

4 Proposed Research
4.1 Federated multi-teacher distillation . . . . . . . . . . . . . . . . . . . . . .
4.2 Data enhancement for efficient federated learning . . . . . . . . . . . . . .
4.3 Unified FL system via multi-objective search . . . . . . . . . . . . . . . . .
4.4 Self-supervised federated learning . . . . . . . . . . . . . . . . . . . . . . .

29
29
31
31
32

5 Timeline

33

Bibliography

35

A Attached papers

49

Chapter 1
Introduction
Neural networks are now the state-of-the-art in automatic speech recognition (ASR) tasks.
This success highly relies on powerful computer hardware (e.g. GPUs in the data centre)
and large-scale data to train the model. With the increasing proliferation of mobile
devices (e.g. phones, tablets), an unprecedented amount of user data collected by the
devices’ microphones provide an opportunity for even more robust and accurate ASR
models – if this additional data could be harnessed. However, mobile devices usually
have constrained computational capabilities, limited communication/network and power
consumption. Additionally, audio and speech data is by its nature very sensitive, requiring
strong anonymity and privacy guarantees of any training method that may utilize it.
To exploit the treasured user data for model training without violating privacy, federated
learning (FL) [81] provides a possible solution. FL is a decentralised computation paradigm
that can be used to train neural networks directly on-device. Particularly, it reduces
privacy and security risks, while still being able to utilise user data in the training process.
Federated training involves the data that is distributed on the mobile devices (refer to
as clients), and learns a global model by aggregating updates from local computation on
a central server. The local training data on each client is never uploaded to the server,
and only the locally-computed updates are communicated, from which model training is
decoupled from the requirement of directly accessing the raw user data. FL has achieved
much success within a diverse range of practical applications, such as Gboard mobile
keyboard [94, 48, 126], Pixel phones [1], Android Messages [113], medical research [24],
hot-word detection [70], etc. However, federated training of acoustic models for speech
recognition has received very little scientific study, and even the most basic questions as
to how to train ASR models using federated methods remain unresolved.
There are many challenges impeding the development of federated training for ASR
models. First, the training data on each mobile device is generated from a particular user,
and the recording conditions of the devices are varied due to diverse types of microphones
and acoustic environments. This is likely to cause the distribution of user data not

5

to be identical and independent, and hence not to be representative of the population
distribution. Second, the amount of local data on the devices may dramatically vary,
perhaps even by several orders of magnitude, because some users may make more frequent
use of their devices than others. Third, a more complex model is required for ASR tasks to
gain an acceptable level of performance relative to other types of data (e.g. images), due to
the complex structure of audio (long sequences, variable-length and high-dimension) [120].
Speech models usually contains a robust encoder to extract features from raw data and a
decoder for transcription, leading to a much larger model size [2, 98, 20]. Training ASR
models on resource-constricted mobile devices will therefore likely cause computational
efficiency problems. Forth, speech models require more data in each client to converge
[46, 2, 110], but this may not be available on the clients - especially those devices that
are less frequently used. Fifth and finally, labels of speech data might not be easy to
collect on mobile devices than other data, e.g., image labels can be defined by natural
user interaction with their photo app, but labeling is much less intuitive and difficult to
segment correctly [81, 58].
In my thesis, I will dive into the difficulties that prevent effective speech model to be
trained under federated settings and propose solutions associated with the challenges above.
Concretely, I plan to divide my investigation into three stages as follows. First, study
the existing approaches in federated training and cosider how they can be integrated into
state-of-the-art methods for ASR modeling. Second, explore novel FL training schemes
by introducing new techniques including knowledge distillation (KD), data selection, selfsupervision and neural architecture search (NAS). Third, enable the proposed algorithms
to be realised in real edge devices. The overarching goal of my thesis is to achieve
efficient federated training of ASR models while diminishing communication and compute
bottlenecks and in doing so enable clients to produce models customized to users and their
environments.
Towards advancing these various research aims I have completed three projects in my
1st year. The first one [34] proposes three multi-teacher distillation strategies for acoustic
models, which integrates the error rate metric to the teacher selection. In this way, it
directly distills and optimises the student toward the relevant metric for speech recognition.
I developed these methods have the potential to address a number of the challenges
faced under FL settings. Currently they have been studied under a centralized training
context, but the next step will be to study them under FL conditions. The second one
[35] presents the first empirical study on attention-based Seq2Seq ASR model for realistic
FL scenarios with three aggregation weighting strategies – standard FedAvg, loss-based
aggregation and a novel word error rate (WER)-based aggregation. The methods are
evaluated with cross-silo and cross-device FL with up to 2k clients on the naturallypartitioned and heterogeneous French Common Voice dataset. The third project [67]

6

develops an automated processing pipeline that integrates existing computer vision and
signal processing techniques to convert videos of human activity into virtual streams of
IMU data, and hence achieve robust and generalised on-body sensor-based human activity
recognition (HAR). Similar to the first project, this work - in its current form - also lacks
a direct FL element. However, I intend to extend this pipeline so that it can be trained
under an FL setting. This first design assumes centralized training. But enabling on-body
sensor devices to collectively train and revise their models will be a key next step, and
how to do this remains largely an open question.
This document starts by providing a full detailed literature survey related to this report
in Chapter 2. Chapter 3 elaborates the projects carried out in my first year. To further
explain and justify the direction of FL training of acoustic models for speech recognition,
Chapter 4 details a concrete proposal of work for the next two years of my PhD. This
document concludes a research timeline proposed in Chapter 5.

7

8

Chapter 2
Background and Related Work
Following the challenges and problems raised in the introduction, I investigate the related
work and existing methods in this chapter. Since this thesis links to many different areas,
this chapter is organised by introducing the recent development and new training schemes
of ASR, followed by the separate field of FL, and finally elaborating two techniques that
could enhance federated training.

2.1

End-to-end Automatic Speech Recognition (ASR)

Automatic speech recognition, as a very natural human-machine interacting mechanism,
has been widely studied in machine learning area since the 1970s [12], with linear prediction
[55] and dynamic programming technology [117] been introduced into ASR. In the 1980s,
hidden Markov model (HMM) technology began to be applied to speech recognition,
and for a long time, the HMM-based models were the mainstream framework of speech
recognition [68]. The speech states were modelled by HMM and use Gaussian mixed
model (GMM) to model HMM states’ observation probability, making milestone level
progress in ASR tasks. More recently, deep neural networks (DNNs) were applied to
speech recognition and have been integrated with HMM [23]. At the same time, deep
learning techniques also aroused the development of an alternative approach — end-to-end
ASR. Compared to the HMM-based model, the end-to-end model directly maps audio to
transcriptions using a single model without domain expertise requirements. Here, we first
make a comparison between conventional models (HMM-based) and end-to-end models.
• HMM-Based Model. The HMM-based model typically contains three independent components: acoustic, pronunciation and language model (Figure 2.1). The
acoustic model aims to map input audio to feature sequence (e.g. phoneme). The
pronunciation model is to build a mapping between phonemes and graphemes, which
is constructed by professional human linguists. The language model is responsible

9

Figure 2.1: HMM-based and end-to-end ASR pipelines.
for mapping the character sequence to the final transcription. These three models
are trained separately and require expert knowledge to create pronunciation lexicon
and define phoneme sets.
• End-to-End Model. Other than disconnecting the training process in HMM-based
model, the end-to-end model directly maps input speech to the sequence of words,
which implicitly or explicitly contains two parts — 1) encoder, extracting feature from
raw speech sequence; 2) decoder, building the alignment between feature sequence
and transcription, and decoding the final prediction sentences (Figure 2.1). End-toend speech recognition dramatically simplifies the process of HMM-based speech
recognition without carefully-designed intermediate states and links the optimisation
to final evaluation criteria (typically error rate). Based on the types of alignment, the
end-to-end model can divide into three different categories: connectionist temporal
classification (CTC)-based, transducers, and attention-based.

2.1.1

CTC-based model

In end-to-end training, the loss functions of DNN are calculated based on each time step
of the sequence, which requires the explicit alignment between the output sequence of
DNN and target sequence (labels). To solve this data alignment problem, CTC loss was
proposed in [42] as a milestone of the development of end-to-end speech recognition. In the
CTC process, the output sequence of the network, typically longer than the label sequence,
can be regarded as a probability distribution over all possible label sequences, conditioned
on a given input sequence. Note that there are multiple ways to align label sequences
with the input sequence (paths) [42]. Then, the total probability can be calculated by
summing the probabilities of all paths, followed by a path aggregation step via a dynamic
programming method. Since the objective function is differential, the whole network can
be trained with back propagation (Figure 2.2).
The emergence of CTC technology not only solves data alignment problem in endto-end speech recognition but also can directly output the target transcriptions without
any human expertise to build various dictionaries. Since then, there were plenty of works
applying CTC in ASR tasks.

10

Figure 2.2: Architectures of end-to-end ASR models.
The early work [31] designed a 3-layer network including one feed forward layer and two
Long Short-Term Memory (LSTM) layer, trained with CTC loss. The results showed that
the recognition performance could be effectively improved by increasing the network’s
depth and the number of units for each layer, which has also been confirmed by [72].
The work [41] trained a deeper network with five layers of bidirectional LSTM having
500 hidden units for each layer, and achieved state-of-the-art performance at that time.
Encouraged by this five-layer network structure, several other works [46, 47, 80, 105] were
conducted for further improvements.
Afterwards, people made a great exploration of networks in terms of structure and
depth. Song et al. [111] introduced a convolutional neural network (CNN) to extract more
robust feature before RNN layers. [131] designed a pure CNN-based model trained by
CTC loss, which conducted convolution operations in both time and frequency dimensions.
In terms of network depth, deep speech 2 [2] expanded the network to nine layers, with a
work [110] training a model with seven layers of bidirectional LSTM having 1000 hidden
units each layer. However, the research in networks’ structure and depth does not mean
that the deeper model works in any situation. More recent works [4, 73, 5] chose to use
shallower networks as their experimental datasets are not suitable for training deeper
networks.

2.1.2

RNN-transducer

In CTC-based training process, 1) the model can not infer the interdependence within the
different tokens of the output sequence as it assumes that elements of output sequence are

11

independent, 2) and it only works in the scenario where output sequences are shorter than
inputs. RNN-transducer was proposed in [40], which solves the aforementioned defects
of CTC. RNN-transducer model includes three components: 1) transcription network,
playing a role of an acoustic model, which can map input audio to output sequences; 2)
prediction network, which is an RNN network and can models the interdependence within
output sequence (playing the role of language model); 3) joint network, connecting both
components and mapping to the final output sequence. (Figure 2.2) Since one input speech
generates a label sequence of arbitrary length, RNN-transducer is capable of mapping
input sequence to output sequence with any length. Also, prediction network can learn
interdependence within the output sequence, achieving joint training of language model
and the acoustic model.
The later work [43] improved original RNN-transducer by changing the joint network
from simple addition to a layer connection, and pre-training the transcription and prediction
network. The experiment results demonstrated that training RNN-transducer from scratch
is difficult. Another work [98] enhanced RNN-transducer by increasing the depth of
transcription and prediction network and using a pre-training strategy.
RNN-transducer has its advantages over the CTC-based model. However, it also causes
other defects: it may generate many unreasonable paths due to its flexible schemes. For
instance, the first frame of audio may incorrectly produce all output sequences, leading to
other positions all empty. To solve this problem, a new auxiliary framework was proposed
in [106, 29], which developed a recurrent neural aligner that can restrict each input frame
only producing one output.

2.1.3

Attention-based model

Attention-based models were first used on machine translation tasks in the paper [8]. In
this work, given a input text the encoder generates a sequence of vectors rather than a
single vector, and the decoder uses an attention mechanism at each time step of the output
by assigning different weights to each vector in this sequence. The prediction of the next
time step of output is determined by two elements: the historical output sequence and a
weighted summation of the encoding result sequence. Attention-based end-to-end model
can also be split into two sub-networks: encoder and decoder (with attention mechanism)
(Figure 2.2). This technique has the potential to be applied to speech recognition due to
the similar sequence-to-sequence process.
Latency problem. The attention mechanism is applied to the whole encoding sequence,
so the training process moves on to decoder only when the encoding process is total
completed, which highly increases the delay of model training. Additionally, the encoding

12

process may lead to lots of useless, redundant information to attention mechanism. The
early works using attention for speech recognition [19, 20] ignored this issue. Bahdanau
et al. [9] first noticed this problem and introduced time-dimension pooling during the
encoding phase, which highly accelerates the model. Another work, LAS [17], adopted
different solutions. The encoder consists of 4 bidirectional LSTM layers, where each layer
uses the concatenation of two consecutive frames from the previous layer as its input. A
pyramid structure is built in encoder and can reduce RNN loop steps.
Attention types. The attention mechanism may have three types: context-based,
location-based, and hybrid. As for context-based, it only considers the input sequence and
the previous hidden state to compute the weight at each time step [8]. The location-based
method uses the previous weight as location information at each time step to compute
current weight, without considering input feature sequence. The hybrid approach [19, 124]
considers all three elements: input feature sequence, the previous hidden state and the
previous weight.

2.2

New training schemes for ASR

With the rapid development of end-to-end ASR, many works began to explore new training
situations using various approaches. Here, I introduce two popular techniques (knowledge
distillation and self-supervised learning) in the area of deep learning and their applications
in ASR.

2.2.1

Knowledge distillation

Knowledge distillation (KD) [51], also known as teacher-student training, is commonly
used to narrow the gap of performance between a smaller and larger models. A typical
KD training procedure consists of two stages. First, a deep neural network referred as
the teacher is trained in line with standard supervised training rules based on numerous
samples and their corresponding ground truth labels. Second, a compressed network,
the student model, is trained on a selection of original ground truths and soft targets
labelled by the teacher. These soft targets are the posterior probabilities obtained from
the pre-trained teacher. There are two primary purposes using KD: one is to reduce
the student size while matching its performance to that of the teacher, the other one
focuses solely on increasing the performances of the student model without considering its
complexity.
End-to-End ASR models are particularly well suited for KD as the whole pipeline is
composed of neural networks only. One set of E2E ASR systems commonly rely either on
the CTC loss [41], Sequence to Sequence models (Seq2Seq) [9], or a combination of the
13

two [62]. The KD works on ASR system also developed along with these types of training
models.
KD for CTC-based model. The naive approach of KD typically minimises KullbackLeibler (KL) divergence between posterior distributions of student and teacher models at
each frame, assuming that both models have the same frame-wise alignments between the
input speech and corresponding output sequences. As for the CTC-based models, however,
the output symbols of teacher and student models may be different at the same time step.
[66] proposed an improved frame-level KD method for CTC, which first selects a similar
posterior distribution from teacher model at the preceding or the same time steps, and
then train the student by minimising the KL divergence. Another work [27] used a method
of dynamic time warping to align the output of student and teacher while proposing the
other approach that splits the sequence of teacher output into small segments. Then, they
extract N-best hypotheses and their posterior probabilities for each segment, which can be
used to train student model. Theses two works aforementioned assume certain alignments
exist between student and teacher models at the frame level. Other work [54] conducted
sequence-level KD on a CTC-based model, which calculates the posterior distribution given
the whole input audio and the teacher model, instead of computing the teacher posterior
distribution at each frame. The N-best hypotheses from teacher model are extracted
by beam search; then the student is trained in the fashion of cross entropy KD. Several similar works [114, 59, 115] explored the sequence-level KD on different types of models.
KD for attention-based model. Raden et al. [87] first applied KD on attention-based
ASR model. Similar to [54], they extract the hypotheses from a pre-trained teacher model
using beam search and train the student on the sequence-level cross-entropy criterion. More
recent work [61] proposed a KD method on self-attention ASR models, which introduces
an exponential weight to the sequence-level knowledge distillation loss function reflecting
the word error rate of the teacher model output based on the ground-truth word sequences.
Multi-teacher distillation. Ensembles of teacher models capture complementary information by making different errors that can be further distilled to a student model.
A critical aspect of multi-teacher distillation in the context of ASR is to find suitable
strategies to maximise the distillation with respect to a specific set of teachers. [18]
proposed to pre-assign weights to teachers based on their oracle error rate, to control the
impact on the distilled information. Another work [33] uses the same pre-assign weights
to all teachers or randomly selects the considered teachers . However, both strategies may
give higher weighting, and thus higher importance, to teachers that perform worse than
others in the teacher set when applied to specific sentences. The work I completed last

14

year (in Appendix A) proposed three new multi-teacher distillation strategies, integrating
the error rate metric to the teacher selection during each mini-batch training.

2.2.2

Self-supervised learning

The success of deep learning techniques mainly relies on large-scale labelled training data.
However, collecting large amounts of annotated samples is very costly and time-consuming.
A possible way to alleviate these issues is self-supervised learning, where targets are
calculated from the signal itself. Although self-supervision has been used in computer
vision fields [28, 38, 84], applying self-supervised learning to speech is challenging since
the speech signal is characterised by long, variable-length and high-dimensional sequences.
This is, hence, very hard to infer without ground truth labels (e.g. phonemes). There are
many works focusing on learning general and meaningful representations via self-supervised
tasks to solve these issues. Here, we introduce four popular approaches.
Contrastive Predictive Coding (CPC). Van Den Oord et al. proposed a CTC approach to learn robust representations from unlabelled data. The main component of
this framework is a multi-layer CNN that transforms the raw input data into general
representation. The objective function is a contrastive loss [45], training by distinguishing
a true future encoded representation from negatives given the past context as input. This
method has been demonstrated on different domains, including phoneme classification in
speech, image and text. Another work, Wav2vec [107], applied the learned representations
from the CPC method to improve strong supervised ASR systems.
Autoregressive Predictive Coding (APC). Motivated by RNN-based language models (LMs) for text, the method of APC [21] built an RNN model to encode temporal
information of past acoustic sequence but replace the Softmax layer in LMs with a regression layer. This way, the RNN output at each time step can produce future frames. The
model is optimised with reconstruction loss (L1 loss). Compared to CPC-based works, this
method focuses on predicting the spectrum of a future frame rather than a wave sample.
Also, CPC focuses on the most discriminative information with respect to the target and
negative frames, while APC encodes information more sufficient. On the other hand, in
contrast to the fully convolutional architecture in CPC, APC is an RNN-based model over
time, potentially leading to an efficiency problem.
BERT-based. The recently proposed vq-wav2vec [7] first applied BERT [25] algorithm
on audio data to learn high-level representation from unlabelled data. The raw speech
is encoded by discretizing to a K-way quantized embedding space, which is effective but
computing resources-consuming. An improved work [76] modified the BERT algorithm.

15

This approach exploited a multi-layer transformer encoder and multi-head self-attention to
extract representations, achieving bidirectional encoding. Unlike unidirectional methods,
this framework can integrate both past and future contexts into computation metrics at
the same time. To train the model in an unsupervised fashion, they proposed a masked
acoustic modelling task, where the frames of input speech are masked randomly, and
the model is trained to learn reconstructing and predicting the original frames. As for
objective function, the L1 loss is used to minimise reconstruction error between prediction
and ground-truth frames.
Multi-tasks. Multiple self-supervised tasks may bring different view or constraint on
learning representation. Problem-agnostic speech encoder (PASE) [91] is designed to
learn general, robust, and transferable features via training with various self-supervised
tasks. The encoder maps the raw speech waveform into a representation after several
CNN blocks, then feeding into four regressors including waveform, log power spectrum
(LPS), mel-frequency cepstral coefficients (MFCC) and prosody, and three discriminators,
including local info max (LIM) [99], global info max (GIM) and sequence predicting coding
(SPC). The regressors are trained to minimise the mean squared error (MSE) between the
target features and the network predictions, while discriminators are trained to minimise
binary cross-entropy by feeding positive or negative samples. As an improved version of
PASE, PASE+ [100] introduced an online speech distortion module to transform clean
audio to contaminated variants via reverberation, additive noise, temporal/frequency
masking, clipping, and overlapped speech. Also, the original CNN encoder from PASE has
been enhanced by integrating with a quasi-recurrent neural network (QRNN) [99] that can
learn long-term dependencies across the time steps. Additionally, some novel regressors
are also introduced into this framework.

2.3

Federated learning

Edge devices and the modern internet of things (IoT), such as smartphones, wearable
devices, and autonomous vehicles, have gained rapid development in the recent decades.
These devices generate a wealth of data each day from their various sensors (e.g. images,
text, etc.) in real-time. It is non-trivial to build a robust model to power applications by
jointly learning the user data across a large pool of edge devices. However, users may not
be willing to share their data due to their privacy requirements, and the connectivity of
each device might be limited (e.g. bandwidth/battery power).
Due to the growing storage and computational capabilities of edge devices, it is possible
to push model computation to the edge. Federated learning [81] has the potential to train
statistical models directly on devices while storing data locally to alleviate the privacy

16

Figure 2.3: General federated learning architecture.
issue. This technique has been used in various real-world applications, such as next-word
prediction [48], medical research [53, 24] and hot-word detection [70]. Here, we provide a
brief survey of federated learning in terms of its core challenges, schemes for federated
optimisation, and its application in the speech field.

2.3.1

Core challenges

Unlike centralised training, there are more constraints when training model on devices.
The core challenges of federated learning are divided into four aspects.
• Limited communication. In a real federated learning setting, there are a massive
number of devices in the federated networks, and communication between devices
and server is slow due to the limited resources (e.g. bandwidth, energy, and power).
It is crucial to develop communication-efficient approaches to send model updates
during the training process, instead of sending the entire dataset over the network.
Two key aspects could consider to reduce communication cost, 1) the number of
communication rounds, and 2) size of the sending messages at each round.
• Systems heterogeneity. The storage, computational, and communication ability
of each edge device in the federated system may differ due to their diverse hardware
situations. In addition, these constraints may cause only a small partition of the
devices being active at the same time, and the active devices may drop out at any
time due to connectivity or energy problems. These system-based challenges require
that the federated learning approaches must tolerate the heterogeneous hardware
and be robust to low training participants and dropped devices.

17

• Data heterogeneity. Since the frequency of using certain applications on edge
devices for specific users varies dramatically, each user’s amount of training data
generated from there is also different. This cause the distribution of user data
highly heterogeneous, which violate the assumption of independent and identical
distribution (i.i.d.) in centralised optimisation. Many works are focusing on this
issue, such as the earlier method leveraging a single global model [81], and FL in
multitask learning frameworks [109] or meta-learning [71].
• Privacy guarantee. As a major concern in federated learning, privacy could be
protected by only sharing model updates, instead of the raw data, in the training
process. However, the users’ sensitive information may still be revealed during
communication between edge devices and server. Some recent works [13, 82] enhance
the privacy by secure multiparty computation (SMC) or differential privacy, while
the performance or system efficiency drops. It is a challenging problem to balance
these trade-offs.

2.3.2

Federated optimization

To achieve robust model training in federated settings, especially data in a non-i.i.d.
fashion, a proper optimisation method is the key point. There exist many works using
meta-learning and multitask learning to tackle data heterogeneity problem. [109] proposed
a federated optimisation framework, MOCHA, which allows each device to learn model
separately and aggregate using a shared representation via multitask learning. This
method achieves personalisation for updating convex objectives but it is hard to scale to
massive networks. Another work [22] designed a Bayesian network within a star topology,
which can execute variational inference during learning. This approach can deal with
non-convex functions but also has generalisation problem to large networks. Khodak et al.
[60] used meta-learning framework to learn a within-task learning rate by treating devices
as different tasks and gained improved accuracy over FedAvg method. The work [30]
proposed semi-cyclic federated training framework which can dynamically select global or
device-specific models.
Fairness is another crucial aspect when conducting federated optimisation across devices.
The learned model may drift away from the original task and become biased toward devices
containing a larger number of data. Some recent works are aiming to reduce the variance
of the local training on the devices. Mohri et al. [85] proposed an agnostic federated
learning method that uses a mini-max optimisation strategy to force the global model to
a mixed distribution of specific devices. Another more general work, q-FFL [75], assigns
weights to each device based on their training loss, from which the devices with higher
loss are given higher weight to boost less variance in the final accuracy distribution.

18

Forcing the federated model convergence is much more challenging than centralised
training. There exist several works [103, 121, 129] analysing the convergence behaviour of
FedAvg and its related variants, but the results depend on the i.i.d. assumption which is
not the real-world federated environment. Another recent work FedProx [74] conducted
an analysis of FedAvg performance in heterogeneous settings. They modified the vanilla
FedAvg method to allow partial training work to be executed across devices and then
used a proximal term to integrate the partial work. This method can highly adapt the
heterogeneous environments that some devices may be disabled due to system constraints,
which boosts more well-behaved local updates and provides convergence guarantees for
convex and non-convex functions. In addition to these provable approaches, there are
several heuristic methods proposed for the problem of data heterogeneity via sharing local
data on devices or using proxy data on server-side [53, 56]. However, these approaches
can not provide privacy guarantee due to the data sharing process.

2.3.3

Federated learning in speech area

To my best knowledge, there are few works regarding federated learning in the speech
area. Based on the type of tasks, the works involve keyword spotting, speaker verification
and ASR.
FL for keyword spotting. Keyword spotting (KWS) has become an important research
area for virtual assistants, which is used to start an interaction with a voice assistant, such
as Apple’s “Hey Siri” or Google’s “OK Google”. Compared to standard ASR, KWS is a
relatively easy speech-based task. [70] first trained keyword spotting model in FL manner.
The model they built is CNN-based, and training was performed with the Adam optimiser.
As for federated optimization, the federated averaging (FedAvg) algorithm [81] was used in
this paper. The other work [49] trained KWS model with a more real FL environment on
non-IID data. An encoder-decoder architecture with multiple SVDF (single value decomposition filter) layers [88] was used for this task. Then, they investigated various federated
optimization methods and implemented them to model training, including FedAvg [81],
FedAdam [63] and FedYogi [127], while also replacing classical momentum with Nesterov
accelerated gradients (NAG) [89] for each method.
FL for speaker verification. Speaker verification aims to determine whether the speaker
is a specific person or someone else, typically used for securely accessing the devices via a
“wake-up phrase”. Granqvist et al. [39] first exploited federated learning with privacy to
improve on-device speaker verification. They conducted federated training using FedAvg
[81] method on a vocal classification model with speaker characteristics as ground truth
stored privately on devices. This trained model can provide side information to the

19

downstream speaker verification system, and hence improving speaker recognition accuracy.
To further protect user privacy, differential privacy is applied to add noise to the model
updates during communication with the server.
FL for ASR. [26] is the only work on FL for ASR. They trained an ASR model in
federated fashion on LibriSpeech dataset using FedAvg [81] method and achieved good
performance on the test set. There are several improved aspects: 1) two separate optimiser
are established for client and server; 2) running an additional training iteration over
held-out data on the server after aggregation, in order to avoid the model drifted away
from the original task; 3) using softmax values of losses of each client as weights for
aggregation step, to avoid the case that some clients contain data that are represented
by the model. However, the training setting is not pure FL environment as they used
a pre-trained model for initialisation on the server side, and LibriSpeech dataset is not
designed for FL where the data distribution is relatively uniform. There has been no work
on classic FL for ASR, and also in the non-i.i.d. setting.

2.4

Data distillation and extraction

Deep learning models have achieved remarkable performance on various tasks, which
requires a considerable amount of labelled data to learn their large number of parameters.
In addition, the accuracy of deep learning models is often not saturated with increasing
dataset size. However, labelling a dataset is an expensive and time-consuming task. On the
other hand, their performance is susceptible to the structure and domain of the training
data, and training on out-of-domain data can cause worse model accuracy. Hence, a
data extraction process is non-trivial before or during model training, from which the
small and valuable core set can be generated. This concentrated dataset is capable of
accelerating training and gaining competitive performance over the whole dataset, which
has the potential to be applied to federated training. Here, I briefly introduce the existing
techniques in this direction.
Data selection. Data selection methods were used in domain adaptation problem for a
wide range of tasks in some early works [86, 6, 57, 32]. These approaches used heuristic
algorithms to measure domain similarity. Another application of data selection is denoising
or dealing with undesirable data [118, 93], where they selected training data similar to
data on valid set. Yet, these methods rely on features specific to the task. More recent
work [123] proposed a more robust data usage optimisation method using reinforcement
learning (RL). They use scorer network to minimise the model loss on the valid set while
the main model being trained. Also, the gradient similarity between training examples

20

and the validation set is used as a reward signal to train the scorer network. This bi-level
optimisation framework is generalisable to various tasks.
Instance weighting. Instead of pruning dataset, some works are focusing on enhancing
training by weighing the examples in the dataset. [108] reweighs data based on a computed
weight vector optimised by minimising the error rate on the validation set. However, in
this work, only a single number is used to weigh the subgroups of augmented data and
requiring a heuristic approach to update the weights. In contrast, another work [104] uses
meta-learning to compute a locally optimised weight vector for each processing mini-batch.
Curriculum learning. Difficulty-based curriculum learning [95, 130, 44] can rank the
presentation order of data based on human understanding of the hardness of examples,
such that the model can learn faster and effectively from the easier examples. These
approaches have limited generalisation ability since the difficulty measurement process
is task-specific. The other direction of curriculum learning, namely self-paced learning
[69, 65], determines the difficulty level of the data based on the loss of training model and
with an assumption that the model should learn from easy examples.
Dataset distillation. The work [122] proposed distilling the dataset: keeping the
model fixed and synthesising a small number of data points from a huge dataset, which
approximates the original data distribution and achieves close to the original performance.
Concretely, they extract the model weights as a differentiable function of the target
generated training data, followed by optimising the feature values (e.g. pixels in an image)
of the distilled data. As the results show, this method can compress 60, 000 training
images of MNIST dataset into 10 synthetic distilled images (one each class) and achieve
the almost same accuracy as original training with only a few steps of gradient descent.

2.5

Neural Architecture Search (NAS)

Neural architecture search (NAS) aims to automatically design neural network architectures
and optimise hyperparameter, by sampling the search space and evaluating candidate
architectures based on certain metrics to gain improvements of accuracy or co-optimisation
with latency and memory consumption in recent hardware-aware NAS. In federated
settings, NAS could be used to search decent data and models for each edge device to
achieve personalisation. Here, I briefly introduce the main search algorithms with their
applications.

21

2.5.1

Search algorithms

Reinforcement learning (RL) can be used to search over the search space, where an
agent modifies the candidate architectures using a set of actions via Q-learning [10] or
proximal policy optimisation [135]. Alternatively, Bayesian optimisation is another popular
method for hyperparameter search. Zela et al. [128] applied Bayesian optimisation to
NAS achieving jointly optimise for a network’s architecture and hyperparameters by
searching a categorical distribution. Evolutionary algorithms are also be used to design
neural networks, early raised by Miller et al. [83] in 1989, by choosing parent neural
architectures and abandon the worse ones in a crossover step with a certain mutation
probability [101, 102]. Note that in this process, the crossover and mutation steps require
meticulous design.
The aforementioned algorithms, however, have relatively high overhead of sampling.
To alleviate this issue, several techniques were developed, such as weight sharing [92] which
initialise the weights of current candidate model by the ones from previous candidates,
or hyper-networks [14] that generates the weights of the main model conditioned on that
model’s architecture and search process can be completed in a single training run. Similarly,
Liu et al. [77] proposed an auxiliary model to predict the accuracy of a candidate network
in light of its architecture, albeit introducing another model to predict performance may
lead to potential problems (e.g. lack of training data). The recently proposed work, a
differentiable NAS — DARTS [78], significantly reduces the overhead of sampling as all
candidate models can be trained at once.
Memory consumption is another concern for NAS algorithms. ProxylessNAS [15]
reduces the memory cost by relaxing the constraint of training on the proxy tasks but
causes a longer run-time penalty. Another work [119] accelerates ProxylessNAS while
retaining the memory consumption.

2.5.2

NAS applications

In addition to some popular tasks in computer vision [102, 116], and natural language
processing [64], NAS can also apply to other training situations and problems, such as
producing compact models [112, 79]. Other work has developed a NAS approach to train
models suited for deployment across a variety of devices within training a single model [16].
NAS can also be used to find graph neural network (GNN) architectures using RL-based
methods [36] or differential NAS scheme [132]. In speech recognition, NAS has been
applied to search model architectures [11] or hyperparameters [52] for further improvement
of performance.
There are several works introducing NAS to FL. Zhu et al. [133] proposed to optimise network architectures in FL by a multi-objective evolutionary algorithm, albeit

22

all clients participating in training, which significantly increasing both computation and
communication costs. Client sampling can be used to alleviate this issue [125]. To achieve
simultaneous optimization of weight training and architecture search, the gradient-based
[50] and EA-based methods [134] were proposed in the federated environment. However,
jointly optimising the global on clients causes much heavier computation and memory
consumption, impeding the deployment to edge devices. Another work [134] proposed
a light-weighted real-time evolutionary NAS framework (RT-FedEvoNAS) to reduce the
memory usage of local devices.

23

24

Chapter 3
Completed Work
In my first year at Oxford, I have mainly carried out three projects that lead to conference
and journal papers, respectively. All of them are included in the Appendix A section.
The first one [34] aims to improve the performance of acoustic models using multi-teacher
distillation and proposed three error rate based strategies by linking the error rate metric
to the teacher selection. The second project presents the first study on end-to-end ASR
model for realistic FL scenarios including cross-silo and cross-device FL settings. A new
aggregation strategy based on WER was proposed to further integrate the specificity of ASR
to FL. Both above papers are currently to be submitted to a proper conference. The third
paper [67] developed an automatic extraction pipeline of virtual on-body Accelerometry
from the video for human activity recognition, which has been published at the ”ACM on
Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT) 2020”.

3.1

Multi-teacher distillation of acoustic models

Modern deep learning-based ASR systems have been shown to benefit from multi-teacher
distillation strategies strongly [18, 33], as different E2E ASR systems often lead to different
transcriptions given a fixed audio sample strongly increasing the diversity of the teachable
distributions that could be distilled to the student.
“Distilling Knowledge from Ensembles of Acoustic Models for Joint CTC-Attention Endto-End Speech Recognition” [34] (Appendix A) proposed novel multi-teacher distillation
methods for joint CTC-attention end-to-end ASR systems, which considers error rate as
an indicator to assess the teacher quality. This way, it directly distillates and optimises
the student toward the relevant metric for speech recognition (Figure 3.1). The distillation
strategies are depicted as follows:
• Weighted strategy enables the student to directly assign weights to all the teachers
in the course of training based on the average observed ER on the training processed

25

Dataset

Mini-batch

Student

Teacher Set
x

Encoder

Encoder

Encoder

Softmax Layer

Softmax Layer

Softmax Layer

he
Attention
ct
yt-1

Decoding

CTC loss

Distillation
Strategies

Attention

WER
Calculation

Decoder
Softmax Layer

Decoding

“You can too”
“I have a tree”
“I don’t know ”

yt

…

ct
yt-1

CE loss

he

“You can too”

Ground Truth “I have a tree”

Decoder

he
Attention
ct

yt-1

Decoder

Softmax Layer

Softmax Layer

“You can too”
“I have a tree”
“I don’t know ”

“You can too”
“I have a tree”
“I don’t know ”

yt

yt

“I don’t know ”

Dataset

Figure 3.1: Illustration of the error rate multi-teacher distillation strategies connected to a
Joint CTC-Attention E2E ASR system.
mini-batch. The impact of the teachers is, therefore, dynamically changed between
mini-batches.
• Top-1 strategy offers the student an option to choose a single teacher with respect
to the best ER observed at the sentence level on the processed mini-batch.
• Top-k strategy allows the student to learn from a set of best teachers that perform
equally in terms of error rate on the processed mini-batch.
• Word-level distillation. This strategy enables the student to select teacher models
at each word position of the processed sentence. In the case that certain words are
never recognised by all teacher models, supervised training (annotation from the
dataset as training labels) is conducted in stead of distilling from pre-trained teacher
models. This extension is yet integrated into this paper.
The strategies are evaluated on the TIMIT [37] phoneme recognition task and achieve a
Phoneme Error Rate (PER) of 13.11% representing a state-of-the-art score for end-to-end
ASR systems. The proposed distillation methods could be exploited in federated learning
settings, which are elaborated in the following chapter.

26

3.2

Acoustic model training in federated conditions

Federated learning (FL) offers new opportunities to advance ASR quality given the
unprecedented amount of user data directly available on-device. With FL, the training
process leverages large and diverse amounts of data collected locally by user devices, while
also offering the requisite privacy protection. An existing paper [26] presented a first study
on FL for ASR model training, but their experiments were conducted on LibriSpeech [90]
with clean and homogeneous audio data which is not realistic FL setting.
“End-to-End Speech Recognition from Federated Acoustic Models” [35] (Appendix A)
investigates FL in a more realistic setting with the French Common Voice (CV) dataset
[3]. It provides a large set of speakers that used their own devices to record a given
set of sentences, naturally fitting to federated learning with various speakers, acoustic
conditions, microphones and accents. We conduct an empirical study of three different
weighting strategies during model aggregation to approach the difficulty of non-IID FL. In
particular, this work introduces a word error rate (WER) based strategy to further adapt
ASR training to federated learning. The methods were evaluated with both a cross-silo
and a cross-device (i.e. large number of clients with few non-IID data) FL setups.
Table 3.1: Speech recognition results (WER %) observed on the test set of French
Common Voice dataset for different scenarios and weighting strategies.

Centralised

10-client FL

2k-client FL

Training Scenario
training on all data (lower bound)
training on 1st half data
online training on 2nd half data
count-based
loss-based
WER-based
count-based
loss-based
WER-based

WER (%)
20.18
25.26
20.94
21.26
21.10
20.99
22.83
22.67
22.42

Table 3.1 shows the main results presented in this paper. Compared to different
weighting strategies, WER-based and loss-based methods obtain a better performance,
which indicates that weakening the effects of low-quality clients can assist the aggregation
process in federated training with heterogeneous data distribution.

3.3

Virtual IMU extraction pipeline

Labelled data in human activity recognition is scarce and hard to come by, as sensor
data collection is expensive, and the annotation is time-consuming and sometimes even
impossible for privacy or other practical reasons.

27

Figure 3.2: The proposed IMUTube system replaces the conventional data recording and
annotation protocol (upper left) for developing sensor-based human activity recognition
(HAR) systems (upper right). We utilise existing, large-scale video repositories from which
we generate virtual IMU data that is then used for training the HAR system (bottom
part).
“IMUTube: Automatic Extraction of Virtual on-body Accelerometry from Video
for Human Activity Recognition” [67] (Appendix A) develops an automated framework
that exploits existing video data from large-scale repositories, such as YouTube, and
automatically generate data for virtual, body-worn movement sensors (IMUs) that will
then be used for deriving sensor-based human activity recognition systems.
The extraction steps are as follows. First, we apply standard pose tracking and 3D
scene understanding techniques to estimate full 3D human motion from a video segment
that captures a target activity. Second, visual tracking information is translated into
virtual motion sensors (IMU) placed on dedicated body positions. Then, we adapt the
virtual IMU data towards the target domain through distribution matching. Finally, the
activity recognisers are derived from the generated virtual sensor data, potentially enriched
with small amounts of real sensor data.
The pipeline (Figure 3.2) integrates several off-the-shelf computer vision and graphics
techniques so that IMUTube is fully automated and thus directly applicable to a wide
variety of existing videos. We demonstrate the virtually-generated IMU data can improve
the performance of a variety of models on known HAR datasets, and this should lead to onbody, sensor-based HAR becoming yet another success story in large-dataset breakthroughs
in recognition.

28

Chapter 4
Proposed Research
As the background chapter describes, training effective ASR models in federated environments is still an unsolved problem. The core objective of this PhD is to address this
situation, and radically improve our ability to federate speech models. This this end, I
aim to develop novel FL training approaches, and extending them to diverse federated
acoustic applications, with the end-goal of enabling these algorithms to be realised in real
edge devices. The following three research directions are tentative, with the exact scope
and purpose of each project expected be refined during their execution.

4.1

Federated multi-teacher distillation

Due to non-i.i.d. and unbalanced data distributions on edge devices, some clients may
contain data not represented by the model. This causes the training model to drift away
from the original task, and hence leading to a performance reduction or even preventing
the training process altogether. Filtering or alleviating the negative effect of these clients
is very crucial for high-quality federated learning. I believe, a multi-teacher distillation
based approach has untapped potential to solve this problem, by considering clients as
teacher models. Examples of these are described in my completed work [34] (Appendix
A). The distillation strategies in that work can link error rate (ER) metric to the teacher
selection. In this way, the effects of each client are measured by their ERs, and only
highly-performed local models are selected to train the global model.
Under conventional distillation, the student model is trained on a selection of ground
truth and soft targets (posterior probabilities) labelled by the teacher on the same training
dataset. This is, however, impractical in federated settings as data sharing is not allowed
due to user privacy guarantee. Additionally, transmitting posterior distributions from
clients to the server is also restricted due to the resource-constraint environment on edge
devices (e.g. bandwidth).
To achieve distillation in FL settings while reducing communication, the knowledge

29

distillation (KD) training could be established on the server side via a proxy dataset, after
receiving parameters of models from local training on devices. Concretely, soft targets
are collected from the inference outputs on the proxy dataset using pre-trained local
models. A student model with the same architecture is then trained in line with distillation
rules proposed in [34]. The distilled model weights are transmitted back to the clients
while triggering the next round of local training. In this way, the out-of-scope clients
are filtered from the distillation procedure, ensuring a robust federated training within
non-i.i.d. environments.
While the out-of-shelf distillation strategies proposed in [34] can be directly integrated into FL settings, the following aspects are non-trivial to be considered for further
improvements.
• Model architectures exploration. Different architectures may have their advantages over the challenges in FL settings. Attention-based sequence-to-sequence
models within distillation training framework have achieved success in our completed
work, yet other model architectures (e.g. transformer, RNN-Transducer) have not
been verified. Exploring diverse model architectures within FL environments would
establish a good foundation for the downstream federated optimisation.
• Unified error rate-based distillation scheme. Typical ASR models are trained
by CTC or cross-entropy loss which corresponds to improving the log-likelihood of
the data. However, system performance is usually measured in terms of error rate,
not log-likelihood. The process of teacher selection is directed toward the metric
relevant for speech recognition (i.e. error rate) in my completed work. Intuitively,
ASR system can further benefit from integrating minimum word error rate training
[96], an error rate-based optimisation criteria, into distillation framework to build a
more unified distillation training scheme.
• Recursive training mechanism. During the distillation process on the server
side described above, all local models are simultaneously integrated into calculation
metrics to generate soft targets for student model. This may be non-applicable in
real-word federated environments as the number of clients is typically in hundreds or
thousands level, which will cause an unaccepted memory consumption. To alleviate
this issue, a clients sampling operation could be conducted before model inference,
from which the student model can be trained with only partial clients at once. The
distilled model is then recursively re-trained with a new set of clients as teachers
from another sampling step. In case the student model is highly converged on the
first round of distillation, the last layer is re-initialised randomly at the beginning of
each training round.

30

4.2

Data enhancement for efficient federated learning

A crucial concern in federated learning is the resource-constrained environments (e.g. CPU,
memory and network connectivity) on edge devices. This leads to limited capabilities
of computational, storage and communication. Training deep networks on these devices
usually costs much longer time to obtain high performance, especially for ASR models —
typically requires larger model size and more training data [98, 2, 110].
To achieve efficient training in FL settings, a potential effort direction is to reduce
the scale of the training dataset. Some existing works, such as core-set construction [123]
and dataset distillation [122], aim to summarise the entire dataset and hence decrease the
amount of training data while remaining the same performance. These techniques could
be integrated on each client before local training. This way, the reduced data size could
match the computational capability of edge devices, leading to an adequate training time.
Indeed, this method could integrate with the federated distillation framework in Section
4.1 in order to accelerate the training process — extracting a compressed set from the
proxy dataset on the server side, then conducting distillation training. Additionally, if the
size of the compressed dataset is smaller than that of parameters of the model, we could
transmit this dataset to the clients instead of model weights. This way, the KD process is
migrated to edge device, reducing the overhead of communication.

4.3

Unified FL system via multi-objective search

In a real-word federated environment, the training situations are much more challenging.
In addition to the aforementioned difficulties (e.g. privacy guarantee, non-i.i.d. and
unbalanced distribution, limited communication), there is a myriad of practical issues: 1)
the local dataset changes with data adding and deleting by users; 2) client availability
affects the local data distribution; 3) clients may not respond or send updates. If considering
user’s preferences, the case will be more complex (e.g. users have different requirements
with respect to accuracy, latency, etc.). A more robust and unified FL training system, by
integrating all situations above into optimisation metrics, is required.
Neural architecture search (NAS) [135], aiming to automate the process of designing
and tweaking neural network architectures, is a potential approach to tackle these issues.
However, the existing NAS methods in FL [133, 125, 50] only consider the architecture
optimisation based on model accuracy, ignoring communication costs as the evaluation
metric. Also, data and users’ preference are not integrated into search space. In this
regard, a multi-objective search system can be built, which not only customises both
model and data for each client, but also provides trade-off solutions between accuracy
and latency based on the user’s preferences. This is a large-scale project but worthy of

31

investigation, if time allowing.

4.4

Self-supervised federated learning

The success of deep learning techniques mainly relies on large-scale labelled training data.
Federated learning provides an opportunity to exploit the unprecedented amount of user
data for more robust mode training. However, collecting large amounts of annotated
samples is very expensive, time-consuming, and even error-prone. This is more deteriorating
in federated settings as the data stores on inaccessible users’ device, and the annotation
can only be collected by inferring from user interaction. Thus, it is intuitive to promote
federated learning towards self-supervision on unlabelled data. With the development of
self-supervision at the avenue of end-to-end speech recognition [91, 76, 100, 100], these
techniques could be integrated into the federated training system.
Instead of training local models using ground truth labels in standard FL, selfsupervision is conducted with unlabelled data on devices. Then, the weights of all
self-supervised models are aggregated on the server side as standard federated training.
This global model obtained after certain training rounds could be used for any downstream
tasks (e.g. speech recognition, speaker verification, etc.).
In addition to taking advantage of unlabelled user data on clients, accessible unlabelled
data from the server side also has the potential to enhance federated training. Here, I
introduce two explorations in line with this assumption.
• Self-supervised feature extraction. First, a robust self-supervised model is
trained using numerous unlabelled data on the server side, followed by transmitting
the model to clients. Then, this pre-trained model can be used to extract the
enhanced features (representations) via inference process on user data. These deep
features will then be used as input for standard federated training, instead of using
the surface features (e.g. Mel filter banks, MFCCs) that can poorly reveal the
abundant information within speech.
• Improve FL via semi-supervision. To further enhance the trained model under
standard federated training rules, data distillation [97] could be conducted on the
server side. Concretely, we first generate pseudo labels on unlabelled data using
the pre-trained model and then re-train the model using these extra generated
annotations to gain further improvement.

32

Chapter 5
Timeline
Term

Planned work

MT 2020

Re-visit existing methods in FL for speech and implement KD
framework into FL. Replicate popular self-supervision methods
in speech area.

LT 2021

Explore new approaches based on proposal for further
improvement of KD-based FL. Achieve self-supervised FL
framework. Summarise the completed works and write up for
conference submissions if promising results. Clean up related
code and open source.

ET 2021

Take steps towards data side, implementing data extraction
approaches and integrating into FL. Sequentially, integrating
this with KD-based FL.

Summer 2021

Internship

MT 2021

Begin literature review on architecture design and data selection.
Summarise completed work and build a unified FL training
system via NAS.

LT 2022

Run our methods on real edge devices. Write up summary of all
completed projects. Begin thesis write-up

ET 2022

Thesis outline, complete outstanding experiments and thesis
write-up.

Summer 2022

Thesis write-up
Table 5.1: Timeline

33

34

Bibliography
[1] ai.google. Under the hood of the pixel 2: How ai is supercharging hardware.
https://support.google.com/messages/answer/9327902, 2019.
[2] Dario Amodei, Sundaram Ananthanarayanan, Rishita Anubhai, Jingliang Bai, Eric
Battenberg, Carl Case, Jared Casper, Bryan Catanzaro, Qiang Cheng, Guoliang
Chen, et al. Deep speech 2: End-to-end speech recognition in english and mandarin.
In International conference on machine learning, pages 173–182, 2016.
[3] Rosana Ardila, Megan Branson, Kelly Davis, Michael Henretty, Michael Kohler,
Josh Meyer, Reuben Morais, Lindsay Saunders, Francis M Tyers, and Gregor
Weber. Common voice: A massively-multilingual speech corpus. arXiv preprint
arXiv:1912.06670, 2019.
[4] Kartik Audhkhasi, Bhuvana Ramabhadran, George Saon, Michael Picheny, and
David Nahamoo. Direct acoustics-to-word models for english conversational speech
recognition. arXiv preprint arXiv:1703.07754, 2017.
[5] Kartik Audhkhasi, Brian Kingsbury, Bhuvana Ramabhadran, George Saon, and
Michael Picheny. Building competitive direct acoustics-to-word models for english
conversational speech recognition. In 2018 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP), pages 4759–4763. IEEE, 2018.
[6] Amittai Axelrod, Xiaodong He, and Jianfeng Gao. Domain adaptation via pseudo indomain data selection. In Proceedings of the 2011 Conference on Empirical Methods
in Natural Language Processing, pages 355–362, 2011.
[7] Alexei Baevski, Steffen Schneider, and Michael Auli. vq-wav2vec: Self-supervised
learning of discrete speech representations. arXiv preprint arXiv:1910.05453, 2019.
[8] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation
by jointly learning to align and translate. arXiv preprint arXiv:1409.0473, 2014.
[9] Dzmitry Bahdanau, Jan Chorowski, Dmitriy Serdyuk, Philemon Brakel, and Yoshua
Bengio. End-to-end attention-based large vocabulary speech recognition. In 2016

35

IEEE international conference on acoustics, speech and signal processing (ICASSP),
pages 4945–4949. IEEE, 2016.
[10] Bowen Baker, Otkrist Gupta, Nikhil Naik, and Ramesh Raskar. Designing neural
network architectures using reinforcement learning. arXiv preprint arXiv:1611.02167,
2016.
[11] Ahmed Baruwa, Mojeed Abisiga, Ibrahim Gbadegesin, and Afeez Fakunle. Leveraging end-to-end speech recognition with neural architecture search. arXiv preprint
arXiv:1912.05946, 2019.
[12] Yoshua Bengio. Markovian models for sequential data. Neural computing surveys, 2
(199):129–162, 1999.
[13] Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H Brendan
McMahan, Sarvar Patel, Daniel Ramage, Aaron Segal, and Karn Seth. Practical
secure aggregation for privacy-preserving machine learning. In Proceedings of the
2017 ACM SIGSAC Conference on Computer and Communications Security, pages
1175–1191, 2017.
[14] Andrew Brock, Theodore Lim, James M Ritchie, and Nick Weston. Smash: one-shot
model architecture search through hypernetworks. arXiv preprint arXiv:1708.05344,
2017.
[15] Han Cai, Ligeng Zhu, and Song Han. Proxylessnas: Direct neural architecture search
on target task and hardware. arXiv preprint arXiv:1812.00332, 2018.
[16] Han Cai, Chuang Gan, Tianzhe Wang, Zhekai Zhang, and Song Han. Once-forall: Train one network and specialize it for efficient deployment. arXiv preprint
arXiv:1908.09791, 2019.
[17] William Chan, Navdeep Jaitly, Quoc Le, and Oriol Vinyals. Listen, attend and
spell: A neural network for large vocabulary conversational speech recognition. In
2016 IEEE International Conference on Acoustics, Speech and Signal Processing
(ICASSP), pages 4960–4964. IEEE, 2016.
[18] Yevgen Chebotar and Austin Waters. Distilling knowledge from ensembles of neural
networks for speech recognition. In Interspeech, pages 3439–3443, 2016.
[19] Jan Chorowski, Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. End-toend continuous speech recognition using attention-based recurrent nn: First results.
arXiv preprint arXiv:1412.1602, 2014.

36

[20] Jan K Chorowski, Dzmitry Bahdanau, Dmitriy Serdyuk, Kyunghyun Cho, and
Yoshua Bengio. Attention-based models for speech recognition. Advances in neural
information processing systems, 28:577–585, 2015.
[21] Yu-An Chung, Wei-Ning Hsu, Hao Tang, and James Glass. An unsupervised autoregressive model for speech representation learning. arXiv preprint arXiv:1904.03240,
2019.
[22] Luca Corinzia and Joachim M Buhmann. Variational federated multi-task learning.
arXiv preprint arXiv:1906.06268, 2019.
[23] George E Dahl, Dong Yu, Li Deng, and Alex Acero. Context-dependent pre-trained
deep neural networks for large-vocabulary speech recognition. IEEE Transactions
on audio, speech, and language processing, 20(1):30–42, 2011.
[24] Walter de Brouwer. The federated future is ready for shipping, 2019.
[25] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pretraining of deep bidirectional transformers for language understanding. arXiv preprint
arXiv:1810.04805, 2018.
[26] Dimitrios Dimitriadis, Kenichi Kumatani, Robert Gmyr, Yashesh Gaur, and Sefik Emre Eskimez. A federated approach in training acoustic models. In Proc.
Interspeech, 2020.
[27] Haisong Ding, Kai Chen, and Qiang Huo. Compression of ctc-trained acoustic models
by dynamic frame-wise distillation or segment-wise n-best hypotheses imitation. In
INTERSPEECH, pages 3218–3222, 2019.
[28] Carl Doersch and Andrew Zisserman. Multi-task self-supervised visual learning.
In Proceedings of the IEEE International Conference on Computer Vision, pages
2051–2060, 2017.
[29] Linhao Dong, Shiyu Zhou, Wei Chen, and Bo Xu. Extending recurrent neural
aligner for streaming end-to-end speech recognition in mandarin. arXiv preprint
arXiv:1806.06342, 2018.
[30] Hubert Eichner, Tomer Koren, H Brendan McMahan, Nathan Srebro, and Kunal
Talwar. Semi-cyclic stochastic gradient descent. arXiv preprint arXiv:1904.10120,
2019.
[31] Florian Eyben, Martin Wöllmer, Björn Schuller, and Alex Graves. From speech to
letters-using a novel neural network architecture for grapheme based asr. In 2009

37

IEEE Workshop on Automatic Speech Recognition & Understanding, pages 376–380.
IEEE, 2009.
[32] George Foster, Cyril Goutte, and Roland Kuhn. Discriminative instance weighting
for domain adaptation in statistical machine translation. In Proceedings of the 2010
conference on empirical methods in natural language processing, pages 451–459, 2010.
[33] Takashi Fukuda, Masayuki Suzuki, Gakuto Kurata, Samuel Thomas, Jia Cui, and
Bhuvana Ramabhadran. Efficient knowledge distillation from an ensemble of teachers.
In Interspeech, pages 3697–3701, 2017.
[34] Yan Gao, Titouan Parcollet, and Nicholas Lane. Distilling knowledge from ensembles
of acoustic models for joint ctc-attention end-to-end speech recognition. arXiv
preprint arXiv:2005.09310, 2020.
[35] Yan Gao, Titouan Parcollet, Javier Fernandez-Marques, Pedro PB de Gusmao,
Daniel J Beutel, and Nicholas D Lane. End-to-end speech recognition from federated
acoustic models. arXiv preprint arXiv:2104.14297, 2021.
[36] Yang Gao, Hong Yang, Peng Zhang, Chuan Zhou, and Yue Hu. Graphnas: Graph neural architecture search with reinforcement learning. arXiv preprint arXiv:1904.09981,
2019.
[37] John S Garofolo, Lori F Lamel, William M Fisher, Jonathan G Fiscus, and David S
Pallett. Darpa timit acoustic-phonetic continous speech corpus cd-rom. nist speech
disc 1-1.1. STIN, 93:27403, 1993.
[38] Spyros Gidaris, Praveer Singh, and Nikos Komodakis. Unsupervised representation
learning by predicting image rotations. arXiv preprint arXiv:1803.07728, 2018.
[39] Filip Granqvist, Matt Seigel, Rogier van Dalen, Áine Cahill, Stephen Shum, and
Matthias Paulik. Improving on-device speaker verification using federated learning
with privacy. arXiv preprint arXiv:2008.02651, 2020.
[40] Alex Graves. Sequence transduction with recurrent neural networks. arXiv preprint
arXiv:1211.3711, 2012.
[41] Alex Graves and Navdeep Jaitly. Towards end-to-end speech recognition with
recurrent neural networks. In International conference on machine learning, pages
1764–1772, 2014.
[42] Alex Graves, Santiago Fernández, Faustino Gomez, and Jürgen Schmidhuber. Connectionist temporal classification: labelling unsegmented sequence data with recurrent

38

neural networks. In Proceedings of the 23rd international conference on Machine
learning, pages 369–376, 2006.
[43] Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. Speech recognition
with deep recurrent neural networks. In 2013 IEEE international conference on
acoustics, speech and signal processing, pages 6645–6649. IEEE, 2013.
[44] Alex Graves, Marc G Bellemare, Jacob Menick, Remi Munos, and Koray Kavukcuoglu.
Automated curriculum learning for neural networks. arXiv preprint arXiv:1704.03003,
2017.
[45] Michael Gutmann and Aapo Hyvärinen. Noise-contrastive estimation: A new
estimation principle for unnormalized statistical models. In Proceedings of the
Thirteenth International Conference on Artificial Intelligence and Statistics, pages
297–304, 2010.
[46] Awni Hannun, Carl Case, Jared Casper, Bryan Catanzaro, Greg Diamos, Erich
Elsen, Ryan Prenger, Sanjeev Satheesh, Shubho Sengupta, Adam Coates, et al. Deep
speech: Scaling up end-to-end speech recognition. arXiv preprint arXiv:1412.5567,
2014.
[47] Awni Y Hannun, Andrew L Maas, Daniel Jurafsky, and Andrew Y Ng. First-pass
large vocabulary continuous speech recognition using bi-directional recurrent dnns.
arXiv preprint arXiv:1408.2873, 2014.
[48] Andrew Hard, Kanishka Rao, Rajiv Mathews, Swaroop Ramaswamy, Françoise
Beaufays, Sean Augenstein, Hubert Eichner, Chloé Kiddon, and Daniel Ramage.
Federated learning for mobile keyboard prediction. arXiv preprint arXiv:1811.03604,
2018.
[49] Andrew Hard, Kurt Partridge, Cameron Nguyen, Niranjan Subrahmanya, Aishanee
Shah, Pai Zhu, Ignacio Lopez Moreno, and Rajiv Mathews. Training keyword spotting
models on non-iid data with federated learning. arXiv preprint arXiv:2005.10406,
2020.
[50] Chaoyang He, Murali Annavaram, and Salman Avestimehr. Fednas: Federated deep
learning via neural architecture search. arXiv preprint arXiv:2004.08546, 2020.
[51] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural
network. arXiv preprint arXiv:1503.02531, 2015.
[52] Shoukang Hu, Xurong Xie, Shansong Liu, Mengzhe Geng, Xunying Liu, and
Helen Meng. Neural architecture search for speech recognition. arXiv preprint
arXiv:2007.08818, 2020.
39

[53] Li Huang, Yifeng Yin, Zeng Fu, Shifa Zhang, Hao Deng, and Dianbo Liu. Loadaboost:
Loss-based adaboost federated machine learning on medical data. arXiv preprint
arXiv:1811.12629, 2018.
[54] Mingkun Huang, Yongbin You, Zhehuai Chen, Yanmin Qian, and Kai Yu. Knowledge
distillation for sequence model. In Interspeech, pages 3703–3707, 2018.
[55] Fumitada Itakura. A statistical method for estimation of speech spectral density
and formant frequencies. Electronics and Communications in Japan, A, 53(1):36–43,
1970.
[56] Eunjeong Jeong, Seungeun Oh, Hyesung Kim, Jihong Park, Mehdi Bennis, and
Seong-Lyun Kim. Communication-efficient on-device machine learning: Federated distillation and augmentation under non-iid private data. arXiv preprint
arXiv:1811.11479, 2018.
[57] Jing Jiang and ChengXiang Zhai. Instance weighting for domain adaptation in
nlp. In Proceedings of the 45th annual meeting of the association of computational
linguistics, pages 264–271, 2007.
[58] Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis,
Arjun Nitin Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode, Rachel
Cummings, et al. Advances and open problems in federated learning. arXiv preprint
arXiv:1912.04977, 2019.
[59] Naoyuki Kanda, Yusuke Fujita, and Kenji Nagamatsu. Sequence distillation for
purely sequence trained acoustic models. In 2018 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP), pages 1–5. IEEE, 2018.
[60] Mikhail Khodak, Maria-Florina F Balcan, and Ameet S Talwalkar. Adaptive gradientbased meta-learning methods. In Advances in Neural Information Processing Systems,
pages 5917–5928, 2019.
[61] Ho-Gyeong Kim, Hwidong Na, Hoshik Lee, Jihyun Lee, Tae Gyoon Kang, Min-Joong
Lee, and Young Sang Choi. Knowledge distillation using output errors for selfattention end-to-end models. In ICASSP 2019-2019 IEEE International Conference
on Acoustics, Speech and Signal Processing (ICASSP), pages 6181–6185. IEEE, 2019.
[62] Suyoun Kim, Takaaki Hori, and Shinji Watanabe. Joint ctc-attention based endto-end speech recognition using multi-task learning. In 2017 IEEE international
conference on acoustics, speech and signal processing (ICASSP), pages 4835–4839.
IEEE, 2017.

40

[63] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization.
arXiv preprint arXiv:1412.6980, 2014.
[64] Nikita Klyuchnikov, Ilya Trofimov, Ekaterina Artemova, Mikhail Salnikov, Maxim
Fedorov, and Evgeny Burnaev. Nas-bench-nlp: Neural architecture search benchmark
for natural language processing. arXiv preprint arXiv:2006.07116, 2020.
[65] M Kumar, Benjamin Packer, and Daphne Koller. Self-paced learning for latent
variable models. Advances in neural information processing systems, 23:1189–1197,
2010.
[66] Gakuto Kurata and Kartik Audhkhasi. Improved knowledge distillation from bidirectional to uni-directional lstm ctc for end-to-end speech recognition. In 2018
IEEE Spoken Language Technology Workshop (SLT), pages 411–417. IEEE, 2018.
[67] Hyeokhyen Kwon, Catherine Tong, Harish Haresamudram, Yan Gao, Gregory D
Abowd, Nicholas D Lane, and Thomas Ploetz. Imutube: Automatic extraction of
virtual on-body accelerometry from video for human activity recognition. arXiv
preprint arXiv:2006.05675, 2020.
[68] Kai-Fu Lee. On large-vocabulary speaker-independent continuous speech recognition.
Speech communication, 7(4):375–379, 1988.
[69] Yong Jae Lee and Kristen Grauman. Learning the easy things first: Self-paced visual
category discovery. In CVPR 2011, pages 1721–1728. IEEE, 2011.
[70] David Leroy, Alice Coucke, Thibaut Lavril, Thibault Gisselbrecht, and Joseph
Dureau. Federated learning for keyword spotting. In ICASSP 2019-2019 IEEE
International Conference on Acoustics, Speech and Signal Processing (ICASSP),
pages 6341–6345. IEEE, 2019.
[71] Jeffrey Li, Mikhail Khodak, Sebastian Caldas, and Ameet Talwalkar. Differentially
private meta-learning. arXiv preprint arXiv:1909.05830, 2019.
[72] Jie Li, Heng Zhang, Xinyuan Cai, and Bo Xu. Towards end-to-end speech recognition
for chinese mandarin using long short-term memory recurrent neural networks. In
Sixteenth annual conference of the international speech communication association,
2015.
[73] Jinyu Li, Guoli Ye, Rui Zhao, Jasha Droppo, and Yifan Gong. Acoustic-to-word
model without oov. In 2017 IEEE Automatic Speech Recognition and Understanding
Workshop (ASRU), pages 111–117. IEEE, 2017.

41

[74] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
Virginia Smith. Federated optimization in heterogeneous networks. arXiv preprint
arXiv:1812.06127, 2018.
[75] Tian Li, Maziar Sanjabi, Ahmad Beirami, and Virginia Smith. Fair resource allocation
in federated learning. arXiv preprint arXiv:1905.10497, 2019.
[76] Andy T Liu, Shu-wen Yang, Po-Han Chi, Po-chun Hsu, and Hung-yi Lee. Mockingjay:
Unsupervised speech representation learning with deep bidirectional transformer
encoders. In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech
and Signal Processing (ICASSP), pages 6419–6423. IEEE, 2020.
[77] Chenxi Liu, Barret Zoph, Maxim Neumann, Jonathon Shlens, Wei Hua, Li-Jia Li,
Li Fei-Fei, Alan Yuille, Jonathan Huang, and Kevin Murphy. Progressive neural
architecture search. In Proceedings of the European Conference on Computer Vision
(ECCV), pages 19–34, 2018.
[78] Hanxiao Liu, Karen Simonyan, and Yiming Yang. Darts: Differentiable architecture
search. arXiv preprint arXiv:1806.09055, 2018.
[79] Yu Liu, Xuhui Jia, Mingxing Tan, Raviteja Vemulapalli, Yukun Zhu, Bradley Green,
and Xiaogang Wang. Search to distill: Pearls are everywhere but not the eyes.
In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition, pages 7539–7548, 2020.
[80] Andrew Maas, Ziang Xie, Dan Jurafsky, and Andrew Y Ng. Lexicon-free conversational speech recognition with neural networks. In Proceedings of the 2015 Conference
of the North American Chapter of the Association for Computational Linguistics:
Human Language Technologies, pages 345–354, 2015.
[81] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera
y Arcas. Communication-efficient learning of deep networks from decentralized data.
In Artificial Intelligence and Statistics, pages 1273–1282. PMLR, 2017.
[82] H Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li Zhang. Learning
differentially private recurrent language models. arXiv preprint arXiv:1710.06963,
2017.
[83] Geoffrey F Miller, Peter M Todd, and Shailesh U Hegde. Designing neural networks
using genetic algorithms. In ICGA, volume 89, pages 379–384, 1989.
[84] Ishan Misra, C Lawrence Zitnick, and Martial Hebert. Shuffle and learn: unsupervised
learning using temporal order verification. In European Conference on Computer
Vision, pages 527–544. Springer, 2016.
42

[85] Mehryar Mohri, Gary Sivek, and Ananda Theertha Suresh. Agnostic federated
learning. arXiv preprint arXiv:1902.00146, 2019.
[86] Robert C Moore and Will Lewis. Intelligent selection of language model training
data. 2010.
[87] Raden Mu’az Mun’im, Nakamasa Inoue, and Koichi Shinoda. Sequence-level knowledge distillation for model compression of attention-based sequence-to-sequence
speech recognition. In ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 6151–6155. IEEE, 2019.
[88] Preetum Nakkiran, Raziel Alvarez, Rohit Prabhavalkar, and Carolina Parada. Compressing deep neural networks using a rank-constrained topology. 2015.
[89] Yurii E Nesterov. A method for solving the convex programming problem with
convergence rate o (1/kˆ 2). In Dokl. akad. nauk Sssr, volume 269, pages 543–547,
1983.
[90] Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur. Librispeech:
an asr corpus based on public domain audio books. In 2015 IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 5206–5210.
IEEE, 2015.
[91] Santiago Pascual, Mirco Ravanelli, Joan Serrà, Antonio Bonafonte, and Yoshua Bengio. Learning problem-agnostic speech representations from multiple self-supervised
tasks. arXiv preprint arXiv:1904.03416, 2019.
[92] Hieu Pham, Melody Y Guan, Barret Zoph, Quoc V Le, and Jeff Dean. Efficient
neural architecture search via parameter sharing. arXiv preprint arXiv:1802.03268,
2018.
[93] Minh Quang Pham, Josep M Crego, Jean Senellart, and François Yvon. Fixing
translation divergences in parallel corpora for neural mt. In Proceedings of the 2018
Conference on Empirical Methods in Natural Language Processing, pages 2967–2973,
2018.
[94] Sundar Pichai. Privacy should not be a luxury good. The New York Times, May, 7,
2019.
[95] Emmanouil Antonios Platanios, Otilia Stretcu, Graham Neubig, Barnabas Poczos,
and Tom M Mitchell. Competence-based curriculum learning for neural machine
translation. arXiv preprint arXiv:1903.09848, 2019.

43

[96] Rohit Prabhavalkar, Tara N Sainath, Yonghui Wu, Patrick Nguyen, Zhifeng Chen,
Chung-Cheng Chiu, and Anjuli Kannan. Minimum word error rate training for
attention-based sequence-to-sequence models. In 2018 IEEE International Conference
on Acoustics, Speech and Signal Processing (ICASSP), pages 4839–4843. IEEE, 2018.
[97] Ilija Radosavovic, Piotr Dollár, Ross Girshick, Georgia Gkioxari, and Kaiming He.
Data distillation: Towards omni-supervised learning. In Proceedings of the IEEE
conference on computer vision and pattern recognition, pages 4119–4128, 2018.
[98] Kanishka Rao, Haşim Sak, and Rohit Prabhavalkar. Exploring architectures, data
and units for streaming end-to-end speech recognition with rnn-transducer. In 2017
IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), pages
193–199. IEEE, 2017.
[99] Mirco Ravanelli and Yoshua Bengio. Learning speaker representations with mutual
information. arXiv preprint arXiv:1812.00271, 2018.
[100] Mirco Ravanelli, Jianyuan Zhong, Santiago Pascual, Pawel Swietojanski, Joao
Monteiro, Jan Trmal, and Yoshua Bengio. Multi-task self-supervised learning for
robust speech recognition. In ICASSP 2020-2020 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP), pages 6989–6993. IEEE, 2020.
[101] Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu,
Jie Tan, Quoc Le, and Alex Kurakin. Large-scale evolution of image classifiers. arXiv
preprint arXiv:1703.01041, 2017.
[102] Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc V Le. Aging evolution for
image classifier architecture search. In AAAI Conference on Artificial Intelligence,
2019.
[103] Amirhossein Reisizadeh, Aryan Mokhtari, Hamed Hassani, Ali Jadbabaie, and
Ramtin Pedarsani. Fedpaq: A communication-efficient federated learning method
with periodic averaging and quantization. In International Conference on Artificial
Intelligence and Statistics, pages 2021–2031. PMLR, 2020.
[104] Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun. Learning to reweight
examples for robust deep learning. arXiv preprint arXiv:1803.09050, 2018.
[105] Haşim Sak, Andrew Senior, Kanishka Rao, and Françoise Beaufays. Fast and accurate
recurrent neural network acoustic models for speech recognition. arXiv preprint
arXiv:1507.06947, 2015.

44

[106] Hasim Sak, Matt Shannon, Kanishka Rao, and Françoise Beaufays. Recurrent neural
aligner: An encoder-decoder neural network model for sequence to sequence mapping.
In Interspeech, volume 8, pages 1298–1302, 2017.
[107] Steffen Schneider, Alexei Baevski, Ronan Collobert, and Michael Auli. wav2vec:
Unsupervised pre-training for speech recognition. arXiv preprint arXiv:1904.05862,
2019.
[108] Sunit Sivasankaran, Emmanuel Vincent, and Irina Illina. Discriminative importance
weighting of augmented training data for acoustic model training. In 2017 IEEE
International Conference on Acoustics, Speech and Signal Processing (ICASSP),
pages 4885–4889. IEEE, 2017.
[109] Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet S Talwalkar. Federated
multi-task learning. Advances in neural information processing systems, 30:4424–
4434, 2017.
[110] Hagen Soltau, Hank Liao, and Hasim Sak. Neural speech recognizer: Acousticto-word lstm model for large vocabulary speech recognition. arXiv preprint
arXiv:1610.09975, 2016.
[111] William Song and Jim Cai. End-to-end deep neural network for automatic speech
recognition. Standford CS224D Reports, 2015.
[112] Dimitrios Stamoulis, Ruizhou Ding, Di Wang, Dimitrios Lymberopoulos, Bodhi
Priyantha, Jie Liu, and Diana Marculescu. Single-path nas: Designing hardwareefficient convnets in less than 4 hours. In Joint European Conference on Machine
Learning and Knowledge Discovery in Databases, pages 481–497. Springer, 2019.
[113] support.google. Your chats stay private while messages improves suggestions. https:
//www.intel.ai/federated-learning-for-medical-imaging/, 2019.
[114] Ryoichi Takashima, Sheng Li, and Hisashi Kawai. An investigation of a knowledge
distillation method for ctc acoustic models. In 2018 IEEE International Conference
on Acoustics, Speech and Signal Processing (ICASSP), pages 5809–5813. IEEE, 2018.
[115] Ryoichi Takashima, Li Sheng, and Hisashi Kawai. Investigation of sequence-level
knowledge distillation methods for ctc acoustic models. In ICASSP 2019-2019 IEEE
International Conference on Acoustics, Speech and Signal Processing (ICASSP),
pages 6156–6160. IEEE, 2019.
[116] Mingxing Tan and Quoc V Le. Efficientnet: Rethinking model scaling for convolutional neural networks. arXiv preprint arXiv:1905.11946, 2019.

45

[117] Taras K Vintsyuk. Speech discrimination by dynamic programming. Cybernetics, 4
(1):52–57, 1968.
[118] Yogarshi Vyas, Xing Niu, and Marine Carpuat. Identifying semantic divergences in
parallel text without annotations. arXiv preprint arXiv:1803.11112, 2018.
[119] Alvin Wan, Xiaoliang Dai, Peizhao Zhang, Zijian He, Yuandong Tian, Saining
Xie, Bichen Wu, Matthew Yu, Tao Xu, Kan Chen, et al. Fbnetv2: Differentiable
neural architecture search for spatial and channel dimensions. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages
12965–12974, 2020.
[120] Dong Wang, Xiaodong Wang, and Shaohe Lv. An overview of end-to-end automatic
speech recognition. Symmetry, 11(8):1018, 2019.
[121] Jianyu Wang and Gauri Joshi. Cooperative sgd: A unified framework for the
design and analysis of communication-efficient sgd algorithms. arXiv preprint
arXiv:1808.07576, 2018.
[122] Tongzhou Wang, Jun-Yan Zhu, Antonio Torralba, and Alexei A Efros. Dataset
distillation. arXiv preprint arXiv:1811.10959, 2018.
[123] Xinyi Wang, Hieu Pham, Paul Michel, Antonios Anastasopoulos, Jaime Carbonell,
and Graham Neubig. Optimizing data usage via differentiable rewards. In International Conference on Machine Learning, pages 9983–9995. PMLR, 2020.
[124] Shinji Watanabe, Takaaki Hori, Suyoun Kim, John R Hershey, and Tomoki Hayashi.
Hybrid ctc/attention architecture for end-to-end speech recognition. IEEE Journal
of Selected Topics in Signal Processing, 11(8):1240–1253, 2017.
[125] Mengwei Xu, Yuxin Zhao, Kaigui Bian, Gang Huang, Qiaozhu Mei, and Xuanzhe Liu.
Neural architecture search over decentralized data. arXiv preprint arXiv:2002.06352,
2020.
[126] Timothy Yang, Galen Andrew, Hubert Eichner, Haicheng Sun, Wei Li, Nicholas Kong,
Daniel Ramage, and Françoise Beaufays. Applied federated learning: Improving
google keyboard query suggestions. arXiv preprint arXiv:1812.02903, 2018.
[127] Manzil Zaheer, Sashank Reddi, Devendra Sachan, Satyen Kale, and Sanjiv Kumar.
Adaptive methods for nonconvex optimization. Advances in neural information
processing systems, 31:9793–9803, 2018.

46

[128] Arber Zela, Aaron Klein, Stefan Falkner, and Frank Hutter. Towards automated
deep learning: Efficient joint neural architecture and hyperparameter search. arXiv
preprint arXiv:1807.06906, 2018.
[129] Sixin Zhang, Anna E Choromanska, and Yann LeCun. Deep learning with elastic
averaging sgd. In Advances in neural information processing systems, pages 685–693,
2015.
[130] Xuan Zhang, Gaurav Kumar, Huda Khayrallah, Kenton Murray, Jeremy Gwinnup,
Marianna J Martindale, Paul McNamee, Kevin Duh, and Marine Carpuat. An
empirical exploration of curriculum learning for neural machine translation. arXiv
preprint arXiv:1811.00739, 2018.
[131] Ying Zhang, Mohammad Pezeshki, Philémon Brakel, Saizheng Zhang, Cesar Laurent Yoshua Bengio, and Aaron Courville. Towards end-to-end speech recognition
with deep convolutional neural networks. arXiv preprint arXiv:1701.02720, 2017.
[132] Yiren Zhao, Duo Wang, Xitong Gao, Robert Mullins, Pietro Lio, and Mateja
Jamnik. Probabilistic dual network architecture search on graphs. arXiv preprint
arXiv:2003.09676, 2020.
[133] Hangyu Zhu and Yaochu Jin. Multi-objective evolutionary federated learning. IEEE
transactions on neural networks and learning systems, 31(4):1310–1322, 2019.
[134] Hangyu Zhu and Yaochu Jin. Real-time federated evolutionary neural architecture
search. arXiv preprint arXiv:2003.02793, 2020.
[135] Barret Zoph and Quoc V Le. Neural architecture search with reinforcement learning.
arXiv preprint arXiv:1611.01578, 2016.

47

48

Appendix A
Attached papers
The following three papers are produced during my PhD so far.

Distilling Knowledge from Ensembles of Acoustic Models
for Joint CTC-Attention End-to-End Speech Recognition
Yan Gao1 , Titouan Parcollet2 , Nicholas D. Lane1,3
1

University of Cambridge, United Kingdom, 2 Avignon University, France
3
Samsung AI, Cambridge, United-Kingdom
yg381@cam.ac.uk, titouan.parcollet@univ-avignon.fr
ndl32@cam.ac.uk

arXiv:2005.09310v2 [cs.LG] 14 May 2021

Abstract
Knowledge distillation has been widely used to compress existing deep learning models while preserving the performance on
a wide range of applications. In the specific context of Automatic Speech Recognition (ASR), distillation from ensembles
of acoustic models has recently shown promising results in increasing recognition performance. In this paper, we propose an
extension of multi-teacher distillation methods to joint CTCattention end-to-end ASR systems. We also introduce three
novel distillation strategies. The core intuition behind them is to
integrate the error rate metric to the teacher selection rather than
solely focusing on the observed losses. This way, we directly
distillate and optimize the student toward the relevant metric for
speech recognition. We evaluated these strategies under a selection of training procedures on the TIMIT phoneme recognition
task and observed promising error rates for these strategies compared to common baselines. Indeed, the best obtained phoneme
error rate of 13.11% represents a state-of-the-art score.
Index Terms: End-to-end speech recognition, attention models, CTC, multi-teacher knowledge distillation.

1. Introduction
Knowledge distillation (KD) [1], also known as teacher-student
training, is commonly used to narrow the gap of performance
between a smaller model and a larger one [2, 3, 4, 5, 6]. A
typical KD training procedure consists of two stages. First, a
deep neural network referred as the teacher is trained in line
with standard supervised training rules based on numerous samples and their corresponding ground truth labels. Second, a
compressed network, the student model, is trained on a selection of original ground truths and soft targets labelled by the
teacher. These soft targets are the posterior probabilities obtained from the pre-trained teacher. Knowledge distillation has
been shown to be particularly efficient to reduce the student size
while matching its performance to that of the teacher. Common
applications include Computer Vision (CV) [4, 7, 8], Natural
Language Processing [9, 10, 11] (NLP) and Automatic Speech
Recognition (ASR) [12, 13, 14, 15].
An alternative approach to KD focuses solely on increasing
the performances of the student model without considering its
complexity. Distillation from ensembles of teachers has been
commonly conducted under this approach. This method is referred as the multi-teacher distillation [16, 17].
Modern deep learning based ASR systems have been shown
to strongly benefit from multi-teacher distillation strategies
[12, 17]. Empirically, ensembles of teacher models capture
complementary information by making different errors that can
be further distillate to a student model. A critical aspect of

multi-teacher distillation in the context of ASR is to find suitable strategies to maximize the distillation with respect to a specific set of teachers. For instance, [12] proposed to pre-assign
weights to teachers to control their impact on the distilled information. Another strategy is to sample the considered teachers randomly [17]. However, both strategies may give higher
weighting, and thus higher importance, to teachers that are performing worse than others in the teacher set when applied to
specific sentences.
End-to-End ASR models are particularly well suited for
KD as the whole pipeline is composed of neural networks only
[13, 15, 18]. One set of E2E ASR systems commonly rely either
on the Connectionist Temporal Classification (CTC) loss [19],
Sequence to Sequence models (Seq2Seq) [20], or a combination of the two [21]. While single teacher distillation to achieve
acoustic model compression have been widely investigated on
the CTC and Seq2Seq families of models [13, 3], works on ensembles of teachers to enhance the performances remain scarce.
Multi-teacher setup holds untapped potential as different
E2E ASR systems often lead to different transcriptions given
a fixed audio sample, which strongly increases the diversity of
the teachable distributions that could be distilled to the student.
Therefore, it is of crucial interest to explore the use of diverse
set of E2E teachers to increase both the robustness and the performance of the student acoustic model. Potential use-cases include: Federated Learning (FL) [22, 23] with hundreds of potential acoustic models being trained concurrently, thus needing
a proper aggregation or distillation strategy to further reduce
the error rate and training time. Production-oriented training
pipelines of ASR systems relying on strong hyper-parameters
tuning phases with multiple models that could be further used
rather than discarded to improve the quality of the final model.
In this paper, we first propose and investigate an extension of multi-teacher KD strategies to joint CTC-attention based
ASR models. Motivated by error-weighted ensemble methods
[24], we introduce three novel Error Rate-based (ER) multiteacher distillation strategies. Indeed, common distillation
strategies only consider the loss as an indicator to assess the
teacher quality, while a more relevant scheme for ASR is to optimise our student toward the transcription quality.
First, the weighted strategy enables the student to directly
assign weights to all the teachers in the course of training based
on the average observed ER on the training processed minibatch. The impact of the teachers is therefore dynamically
changed between mini-batches. Then, The strategy top-1 offers
the student an option to choose a single teacher with respect
to the best ER observed at the sentence level on the processed
mini-batch. Finally, The strategy top-k allows the student to
learn from the a set of best teachers that perform equally in
terms of error rate on the processed mini-batch.

Dataset

Mini-batch

Student

Teacher Set
x

Encoder
Softmax Layer

he
Attention
ct
yt-1

Decoding

CTC loss

Distillation
Strategies

Softmax Layer

he

Attention

yt-1

Decoder

ct

Decoding

“You can too”
“I have a tree”
“I don’t know ”

yt

he

…

ct

Decoder

yt-1
CE loss

Encoder
Softmax Layer

Attention

WER
Calculation

Decoder

Encoder
Softmax Layer

“You can too”

Ground Truth “I have a tree”

Softmax Layer

Softmax Layer

“You can too”
“I have a tree”
“I don’t know ”

“You can too”
“I have a tree”
“I don’t know ”

yt

yt

“I don’t know ”

Dataset

Figure 1: Illustration of the error rate multi-teacher distillation strategies connected to a Joint CTC-Attention E2E ASR system.
In short, our contributions are: a. Introduce multi-teacher
distillation for ER reduction on joint CTC-attention based E2E
systems (Sec. 2 & Sec. 3); b. Propose three novel distillation strategies focusing on the reduction of the ER (Sec. 3); c.
Compare all the models on the TIMIT dataset [25] and release
the code and the models within the SpeechBrain [26] 1 toolkit
(Sec. 4). Following these experiments, a Phoneme Error Rate
(PER) of 13.11% is reported on TIMIT, thus improving the performance over all previously investigated supervised-only E2E
ASR systems.

2. Distillation for Joint CTC-Attention
Speech Recognition
Joint CTC-Attention E2E systems [21] combine a seq-to-seq
attention-based model [20] with the CTC loss [19]. The CTC
is applied to facilitate the training of the attention decoder by
directing the attention toward the correct alignment.
A typical Seq2Seq model includes three modules: an encoder, a decoder and an attention module. The encoder processes an input sequence x = [x1 , ..., xTx ] with a length Tx ,
and creates an hidden latent representation he = [he1 , ..., heTx ].
Then the decoder attends he combined with an attention context vector ct obtained with the attention module to produce
the different decoder hidden states hd = [hd1 , ..., hdTy ], where
Ty corresponds to the length of the target y. Note that in a
speech recognition scenario, the length of the original signal Tx
is much longer than the utterance length Ty .
The standard supervised training procedure of the Joint
CTC-Attention ASR pipeline is based on two different losses.
First, the CTC loss is derived with respect to the prediction obtained from the encoder module of the Seq2Seq model:
X
LCT C = −
log p(y0 |he ),
(1)
S

with S denoting the training dataset and y0 = y∪{blank}. Note
that the blank token is added to enable the alignment between
Tx and Ty .
Second, the attention-based decoder is optimized following
the Cross Entropy (CE) loss.
1 https://speechbrain.github.io

LCE = −

X

log p(y|hd ).

(2)

S

Both losses are combined and controlled with a fixed hyperparameter α (0 ≤ α ≤ 1) as:
L = αLCE + (1 − α)LCT C .

(3)

In the context of knowledge distillation, we can enhance
both losses by considering the different posterior probabilities
obtained with a teacher for all their targets. For instance, the CE
loss applied in our distillation process for the attention decoded
can be rewritten as:
LCE−KD = −

XX
S

ptea (y|hd ) log pst (y|hd ),

(4)

y∈Y

with y being one of the target of the label set Y . Here,
ptea (y|hd ) represents the posterior probability given by the
teacher model with respect to the label y, and pst (y|hd ) the
one estimated by the student model.
These hypotheses are then used as new soft targets for the
student model as following:

LCT C−KD = −

N
XX
S

n=1

p0tea (Hn |he ) log pst (Hn |he ), (5)

with h the hidden vector representation of the encoder and Hn
the n-th hypothesis from the set of N -best hypothesis for the
teacher. p0tea (Hn |he ) is the normalised posterior probability of
the teacher:
e

ptea (Hn |he )
p0tea (Hn |he ) = PN
.
e
n=1 ptea (Hn |h )

(6)

Then, Eq. 3 is extended to knowledge distillation:
LKD = αLCE−KD + (1 − α)LCT C−KD .

(7)

Finally, the global loss is computed by combining knowledge distillation and the supervised training as:

(8)

Ltotal = βLKD + (1 − β)L,

with β ∈ (0, 1] an hyperparameter controlling the impact of KD
during the training.

3. Multi-teacher Error Rate Distillation
Different E2E ASR models make different mistakes while transcripting the same audio recording. Therefore, distillation from
multiple pre-trained teachers has potential to help the student
model to improve considerably. Finding a good teacher weight
assignment strategy, however, is not trivial.
An existing approach [12, 17] is to simply compute an average over the set of teachers:
X
Lmulti =
wm Lm ,
(9)
m

with wm ∈ [0, 1] the pre-assigned weight corresponding to the
m-th teacher model and equal to 1/M . M is the total number of
teachers composing the ensemble. However, this method gives
to a poor teacher the same importance as a good one while a
natural solution would be to associate well-performing teachers
with higher weights.
We propose to consider the error rate metric as a proxy to
determine which teacher loss to consider during distillation. Indeed, cross-entropy and CTC losses are not directly linked to error rates, and there is no evidence that a teacher with the lowest
global loss also provides the lowest error rate. Nonetheless, in
speech recognition applications, the standard metric to measure
performances remains error rate. The multi-teacher distillation
can, therefore, benefit from the introduction of this metric to the
training procedure.
More precisely, the sequence level distillation detailed in
[15] and Eq. 5 can easily be extended to multi-teacher distillation and ER by replacing the N best hypothesis with the number
of teachers M :

LCT C−KD = −

M
XX
S

m=1

p0tea (Hm |he ) log pst (Hm |he ),

with p0tea (Hm |he ) computed with respect to the ER:
exp (1 − erm )
p0tea (Hm |he ) = PM
,
m=1 exp (1 − erm )

(10)

(11)

and erm the average error rate (e.g. word, phonemes or concept
error rates) observed on the current training mini-batch for the
m-th teacher model. To complete the integration of the ER to
LKD , we propose to derive three different strategies to modify
LCE−KD .
Weighted Strategy: Similar to LCT C−KD , we benefit from all
the teachers by assigning them a weight w.r.t. their average error
rates of a mini-batch, such that the weights would dynamically
change adapting to different mini-batches. More precisely, wm
from Eq.9 is computed as the softmax distribution obtained from
the ER of the current training mini-batch:
exp (1 − erm )
.
wm = PM
m=1 exp (1 − erm )

(12)

However, this approach may exhibits two potential weaknesses: 1) the worst teacher would still impact negatively the

training, even though it has lowest weight; 2) the variation of
ERs in one mini-batch could be large and the average ER may
not reflect properly the quality of a teacher. To overcome these
issues, a sentence level distillation strategy is proposed.
Top-1 Strategy: Here, instead of computing an average over
the error rate in a mini-batch, we consider only the best
performing teacher at the sentence level, i.e. the posterior
probabilities of the best teacher for each sentence composing
the mini-batch are distilled. Note that a single teacher is
used for each sentence. Then, LCE−KD can dynamically be
computed following Eq. 4 during training. This approach
slightly reduces the computational complexity, but also suffers
from a lack of diversity. Indeed, the same teacher will always
be picked for a specific sentence from one epoch to an other
one. To mitigate this issue, a third strategy is introduced.
Top-K Strategy: this method proposes to consider all the teachers that obtain identical error rates at the sentence level as candidates for distillation. In particular, identical ER do not necessarily mean that posterior probabilities are also equivalent as
different word-level mistakes could be observed. Consequently,
Eq. 4 is extended to the K-best teachers as:

LCE−KD = −

K X
XX
1
S

k=1

K
y∈Y

ptea (y|hd ) log pst (y|hd ).

(13)
Finally, the global losses LKD and Ltotal are computed
with the new LCE−KD and LCT C−KD based on Eq. 7 and
Eq. 8 respectively.

4. Experiments
The multi-teacher knowledge distillation approach for joint
CTC-attention E2E ASR systems (Sec. 4.2) and the proposed
distillation strategies are investigated and discussed (Sec. 4.4)
under different training strategies (Sec. 4.3) on the TIMIT [25]
phoneme recognition task (Sec. 4.1).
4.1. The TIMIT phoneme recognition task
The TIMIT [25] dataset consists of the standard 462-speaker
training set, a 50-speakers development set and a core test set
of 192 sentences for a total of 5 hours of clean speech. During
the experiments, the SA records of the training set are removed
and the development set is used for tuning.
4.2. Model architectures
Table 1 shows the different teacher architectures and hyperparameters with their performance on validation and test sets. 80dimensional Mel filter banks energies are extracted from the raw
waveform and used as input features to the model. One CNN
encoder block is composed of two 2D CNN of 64 filters and a
kernel size equal to 3 with a stride of 1.
To increase the diversity in the set of teachers we also
changed the recurrent neural network employed from LSTM to
GRU with different numbers of layers (i.e. from 4 to 5) and
neurons (i.e. from 320 to 640). Attention dimensions have
also been changed across the teachers. Additionally, the models
were trained with different set of hyperparameters.
The output layer of the encoder consists of 40 classes corresponding to the 39 phonemes and 1 blank label, while the
decoder output size is 40 with an EOS token. All models were

Table 1: List of the different teacher models used to compose the ensemble. “RC” is the number of repeated convolutional blocks and
”data aug” represents whether data augmentation (Y) is applied or not (N).
RC

rnn type

n neurons

n layers

dropout

data aug

batch size

PER valid set

PER test set

2
2
2
2
2
2
1
2
2
2

GRU
GRU
GRU
LSTM
GRU
LSTM
LSTM
GRU
LSTM
GRU

512
512
512
512
512
320
320
640
512
512

4
4
4
5
4
4
4
4
5
4

0.15
0.3
0.3
0.2
0.3
0.3
0.3
0.15
0.3
0.15

Y
N
Y
N
N
N
N
N
N
N

8
16
16
8
8
8
8
8
8
8

12.38
13.51
13.36
12.64
12.87
14.56
15.31
13.44
12.65
13.27

13.94
14.61
14.17
14.31
14.32
15.61
16.81
15.15
14.36
15.20

Table 2: Results expressed in term of Phoneme Error Rate
(PER) % (i.e. lower is better) observed on the test set of the
TIMIT dataset for different distillation strategies. Models are
evaluated on the test with respect to the best validation performance. Original results give the PER obtained by the teacher
model selected to be the student architecture prior to distillation. Single represents single teacher distillation. Average is the
baseline multi-teacher KD strategy detailed in Eq. 9. Weighted
(global) is a variation of Weighted considering the validation
set PER rather than mini-batch-level PER to attribute weights.

Strategies

PER (%)

Original
Single
Average
Top-1
Top-k
Weighted (global)
Weighted

13.94
14.15
14.58
13.15
13.13
14.06
13.11

trained for 100 epochs including pre-training and knowledge
distillation. Training was performed with the Adam learning
rate optimizer with vanilla hyperparameters [27]. Data augmentation is performed with a variation of SpecAugment [28]
implemented within SpeechBrain.
4.3. Student selection
The student model architecture is based on the best performing teacher from the ensemble. Therefore, we propose to pick
the best teacher with respect to the best PER on the validation
set of TIMIT. Then, the selected model is trained with KD following the four training strategies detailed in Sec. 3 and compared to some other baselines (Sec. 4.4). For the initialization
scheme, we propose to start from the pre-trained teacher neural parameters except for the last layer that is re-initialized randomly. Then, we fine-tune the whole architecture.
4.4. Speech recognition results
Table 2 shows the Phoneme Error Rate (PER) of the tested
student-teacher strategies on the TIMIT test set. It is important to note that results are obtained w.r.t. the best validation
performance (i.e. not tuned on the TIMIT test set). We compare
our proposed strategies with several baselines, including singe
teacher distillation, averaging weights and a strategy with fixed
global weights based on ERs from the whole validation set. It
is worth emphasising that TIMIT is a challenging task for E2E

ASR systems due to the small amount of training samples (i.e.
less than 5 hours). Nevertheless, the very clean recording conditions alongside with the lack of language modalities allow for
a good benchmarking of pure acoustic models. Interestingly,
the original teacher offers a PER of 13.94% and three baselines
fail at matching this level of performance. In fact, the best reported PER of 13.11% is a state-of-the-art result on TIMIT for
both E2E ASR and HMM-DNN ASR systems trained on a supervised manner only. Indeed, the previously reported SOTA
with a deep CNN model and CTC is 17.7% [29] and 13.8% for
a HMM-DNN pipeline [30] excluding data augmentation.
First, compared to single teacher distillation, our weighted
multi-teacher KD strategy reaches the best performance (surpass single by 1.04 and original by 0.83). Note that in single
strategy, teacher and student models have the same architectures (i.e. self distillation), where the student could not gain
extra information during distillation, and thus would be tough
to achieve further improvement.
Second, the very good overall performance observed with
weighted strategy could be easily explained by the nature of the
strategy and the PER statistics obtained from the ensemble of
teachers. All teachers are exploited during training and the importance is determined by their PERs. Indeed, all the errors and
uncertainties are helpful to build more robust students. This
finding also supports the recent empirical research on the importance of the diversity in teacher ensembles [31].
Finally, top-k strategy offers slightly better performance
than top-1 strategy, mainly due to considering more well-quality
teachers into computing metric. Additionally, it is interesting
to note that the strategy relying on globally computed statistics (i.e. over the whole validation dataset) obtain worse performance compared to our dynamic approaches, thus highlighting
the importance of sentence and mini-batch level distillation.

5. Conclusion
This paper introduces multi-teacher distillation for joint ctcattention end-to-end ASR systems, and three novel distillation strategies relying on a combination of the error rate and
the losses of the teachers. The conducted experiments on the
TIMIT dataset have highlighted promising performance improvements achieved under these strategies with a state-of-theart phoneme error rate of 13.11%. For future work, some of our
results illustrated that teacher diversity is crucial for increasing the system performance. Nevertheless, it is not clear how
one would measure this relationship between diversity and error rate. Developing such a measure is of utmost importance
since it will allow for formulating ensemble forming strategies
that produce better-constructed teacher sets.

6. References
[1] G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in
a neural network,” arXiv preprint arXiv:1503.02531, 2015.
[2] A. A. Rusu, S. G. Colmenarejo, C. Gulcehre, G. Desjardins,
J. Kirkpatrick, R. Pascanu, V. Mnih, K. Kavukcuoglu, and R. Hadsell, “Policy distillation,” arXiv preprint arXiv:1511.06295, 2015.
[3] Y. Kim and A. M. Rush, “Sequence-level knowledge distillation,”
arXiv preprint arXiv:1606.07947, 2016.
[4] G. Chen, W. Choi, X. Yu, T. Han, and M. Chandraker, “Learning
efficient object detection models with knowledge distillation,” in
Advances in Neural Information Processing Systems, 2017, pp.
742–751.
[5] A. Mishra and D. Marr, “Apprentice: Using knowledge distillation techniques to improve low-precision network accuracy,”
arXiv preprint arXiv:1711.05852, 2017.
[6] J. Wang, W. Bao, L. Sun, X. Zhu, B. Cao, and S. Y. Philip, “Private
model compression via knowledge distillation,” in Proceedings of
the AAAI Conference on Artificial Intelligence, vol. 33, 2019, pp.
1190–1197.
[7] A. Polino, R. Pascanu, and D. Alistarh, “Model compression via
distillation and quantization,” arXiv preprint arXiv:1802.05668,
2018.
[8] Y. Liu, L. Sheng, J. Shao, J. Yan, S. Xiang, and C. Pan, “Multilabel image classification via knowledge distillation from weaklysupervised detection,” in Proceedings of the 26th ACM international conference on Multimedia, 2018, pp. 700–708.
[9] J. Cui, B. Kingsbury, B. Ramabhadran, G. Saon, T. Sercu,
K. Audhkhasi, A. Sethy, M. Nussbaum-Thom, and A. Rosenberg,
“Knowledge distillation across ensembles of multilingual models for low-resource languages,” in 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).
IEEE, 2017, pp. 4825–4829.
[10] X. Jiao, Y. Yin, L. Shang, X. Jiang, X. Chen, L. Li, F. Wang, and
Q. Liu, “Tinybert: Distilling bert for natural language understanding,” arXiv preprint arXiv:1909.10351, 2019.
[11] S. Sun, Y. Cheng, Z. Gan, and J. Liu, “Patient knowledge distillation for bert model compression,” arXiv preprint
arXiv:1908.09355, 2019.
[12] Y. Chebotar and A. Waters, “Distilling knowledge from ensembles
of neural networks for speech recognition.” in Interspeech, 2016,
pp. 3439–3443.
[13] G. Kurata and K. Audhkhasi, “Guiding ctc posterior spike timings
for improved posterior fusion and knowledge distillation,” arXiv
preprint arXiv:1904.08311, 2019.
[14] H.-G. Kim, H. Na, H. Lee, J. Lee, T. G. Kang, M.-J. Lee, and
Y. S. Choi, “Knowledge distillation using output errors for selfattention end-to-end models,” in ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing
(ICASSP). IEEE, 2019, pp. 6181–6185.
[15] R. Takashima, S. Li, and H. Kawai, “An investigation of a knowledge distillation method for ctc acoustic models,” in 2018 IEEE
International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2018, pp. 5809–5813.
[16] M. Freitag, Y. Al-Onaizan, and B. Sankaran, “Ensemble
distillation for neural machine translation,” arXiv preprint
arXiv:1702.01802, 2017.
[17] T. Fukuda, M. Suzuki, G. Kurata, S. Thomas, J. Cui, and B. Ramabhadran, “Efficient knowledge distillation from an ensemble of
teachers.” in Interspeech, 2017, pp. 3697–3701.
[18] M. Huang, Y. You, Z. Chen, Y. Qian, and K. Yu, “Knowledge
distillation for sequence model.” in Interspeech, 2018, pp. 3703–
3707.
[19] A. Graves and N. Jaitly, “Towards end-to-end speech recognition
with recurrent neural networks,” in International conference on
machine learning, 2014, pp. 1764–1772.

[20] D. Bahdanau, J. Chorowski, D. Serdyuk, P. Brakel, and Y. Bengio, “End-to-end attention-based large vocabulary speech recognition,” in 2016 IEEE international conference on acoustics,
speech and signal processing (ICASSP). IEEE, 2016, pp. 4945–
4949.
[21] S. Kim, T. Hori, and S. Watanabe, “Joint ctc-attention based
end-to-end speech recognition using multi-task learning,” in 2017
IEEE international conference on acoustics, speech and signal
processing (ICASSP). IEEE, 2017, pp. 4835–4839.
[22] D. Dimitriadis, K. Kumatani, R. Gmyr, Y. Gaur, and S. E. Eskimez, “A federated approach in training acoustic models,” in
Proc. Interspeech, 2020.
[23] T. Li, A. K. Sahu, A. Talwalkar, and V. Smith, “Federated learning: Challenges, methods, and future directions,” IEEE Signal
Processing Magazine, vol. 37, no. 3, pp. 50–60, 2020.
[24] L. I. Kuncheva, Combining pattern classifiers: methods and algorithms. John Wiley & Sons, 2014.
[25] J. S. Garofolo, L. F. Lamel, W. M. Fisher, J. G. Fiscus, and D. S.
Pallett, “Darpa timit acoustic-phonetic continous speech corpus
cd-rom. nist speech disc 1-1.1,” NASA STI/Recon technical report
n, vol. 93, 1993.
[26] M. Ravanelli, T. Parcollet, A. Rouhe, P. Plantinga, E. Rastorgueva,
L. Lugosch, N. Dawalatabad, C. Ju-Chieh, A. Heba, F. Grondin,
W. Aris, C.-F. Liao, S. Cornell, S.-L. Yeh, H. Na, Y. Gao, S.W. Fu, C. Subakan, R. De Mori, and Y. Bengio, “Speechbrain,”
https://github.com/speechbrain/speechbrain, 2021.
[27] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,” arXiv preprint arXiv:1412.6980, 2014.
[28] D. S. Park, W. Chan, Y. Zhang, C.-C. Chiu, B. Zoph, E. D.
Cubuk, and Q. V. Le, “Specaugment: A simple data augmentation method for automatic speech recognition,” arXiv preprint
arXiv:1904.08779, 2019.
[29] A. Graves, A.-r. Mohamed, and G. Hinton, “Speech recognition
with deep recurrent neural networks,” in 2013 IEEE international
conference on acoustics, speech and signal processing. IEEE,
2013, pp. 6645–6649.
[30] M. Ravanelli, T. Parcollet, and Y. Bengio, “The pytorch-kaldi
speech recognition toolkit,” in ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing
(ICASSP). IEEE, 2019, pp. 6465–6469.
[31] X. Zhu, S. Gong et al., “Knowledge distillation by on-the-fly native ensemble,” in Advances in neural information processing systems, 2018, pp. 7517–7527.

End-to-End Speech Recognition from Federated Acoustic Models
Yan Gao1 , Titouan Parcollet2 , Javier Fernandez-Marques3
Pedro P. B. de Gusmao1 , Daniel J. Beutel1,4 , Nicholas D. Lane1
1

University of Cambridge, 2 Avignon University, 3 University of Oxford, 4 Adap GmbH

yg381@cam.ac.uk, titouan.parcollet@univ-avignon.fr, javier.fernandezmarques@cs.ox.ac.uk
pp524@cam.ac.uk, daniel@adap.com, ndl32@cam.ac.uk

arXiv:2104.14297v1 [cs.SD] 29 Apr 2021

Abstract
Training Automatic Speech Recognition (ASR) models under
federated learning (FL) settings has recently attracted considerable attention. However, the FL scenarios often presented in
the literature are artificial and fail to capture the complexity
of real FL systems. In this paper, we construct a challenging
and realistic ASR federated experimental setup consisting of
clients with heterogeneous data distributions using the French
Common Voice dataset, a large heterogeneous dataset containing over 10k speakers. We present the first empirical study
on attention-based sequence-to-sequence E2E ASR model with
three aggregation weighting strategies – standard FedAvg, lossbased aggregation and a novel word error rate (WER)-based aggregation, are conducted in two realistic FL scenarios: crosssilo with 10-clients and cross-device with 2k-clients. In particular, the WER-based weighting method is proposed to better
adapt FL to the context of ASR by integrating the error rate
metric with the aggregation process. Our analysis on E2E ASR
from heterogeneous and realistic federated acoustic models provides the foundations for future research and development of
realistic FL-based ASR applications.
Index Terms: End-to-end ASR, federated learning

1. Introduction
Neural networks are now widely adopted in state-of-the-art automatic speech recognition (ASR) systems [1]. This success
mostly relies on centralised training of deep neural architectures
with large amounts of data and computational power [2, 3, 4].
But decentralized alternatives are becoming more practical due
to the proliferation of powerful mobile devices (e.g. phones,
tablets) and rapid developments of communication technologies (e.g. 5G). Such ingredients make federated and on-device
training of ASR a feasible and an attractive alternative to traditional centralised training [5]. Federated learning (FL) offers
new opportunities to advance ASR quality given the unprecedented amount of user data directly available on-device. For
example, such data could be leveraged to better adapt ASR to
the users’ usage, or to simply improve the robustness of models to realistic scenarios [6]. However, decentralized training
with users’ data require strong anonymity and privacy guarantees, this in turn limits how such training maybe performed and
presenting a series of significant challenges.
With FL, the training process leverages large and diverse
amounts of data collected locally by user devices, while also
offering the requisite privacy protection [7]. In practice, FL allows for the training of machine learning models, such as deep
neural networks, collaboratively between a number of devices
– assisted by a central server [7, 5, 6]. In a standard setup,
a global model is learned from aggregating updates obtained
from computation performed locally on the considered pool of

mobile devices (often referred to as clients). While the aggregation step is performed on a central server, users’ data is never
shared with it and remains local to the clients.
However, training E2E ASR models in a realistic FL setting comes with numerous challenges. First, it is notoriously
complicated to train a deep learning model with FL on non independent and identically distributed data (non-IID) [6, 8, 9].
Unfortunately, on-device speech data is, by its very nature, extremely non-IID (e.g. different acoustic environments, words
being spoken, languages, microphones, amount of available
speech, etc.). Second, state-of-the-art (SOTA) E2E ASR models are computationally intensive and potentially not suited to
on-device training phases of FL. Indeed, the latest ASR systems rely on large Transformers [10, 11], Transducers [12, 13]
or attention sequence-to-sequence (Seq2Seq) models [14, 15]
that process high-dimensional acoustic features. In addition,
E2E ASR training is difficult and very sensitive at early optimisation stages due to the complexity of learning a proper alignment between the latent speech representation and the transcription. Because of these three issues, training ASR models from
scratch on low-resources languages [16, 17, 18] is particularly
challenging.
Despite the growing number of studies applying FL on
speech-related tasks [19, 20, 21, 22, 23], very few of these
have investigated its use for end-to-end (E2E) ASR. To our best
knowledge, existing works on FL for ASR typically rely on
strong simplifying assumptions for many of these challenges –
and this results in their experimental settings being still far away
from the conditions in which a FL ASR would need to function.
In addition, some works are evaluated on the LibriSpeech [24]
dataset, further limiting the realism as recordings are from users
reading books in a controlled setting without background noise.
For instance, the work [22] introduces a novel FL client-based
adaptive training in a specific setup known as cross-silo (i.e.
reduced number of clients with high amount of homogeneous
data) to train a HMM-DNN based ASR system, thus relinquishing two of the constraints (i.e. non-IID and complexity of the
model with simplified HMM alignments). Then, [21] proposes
a federated transfer learning platform with improved performance using enhanced federated averaging and hierarchical optimization for E2E ASR. While the alignment issue is alleviated
with a careful centralised pre-training phase, the non-IID constraint remains mostly unconsidered as the FL training is performed on LibriSpeech.
In this paper, we investigate FL in a more realistic setting
with the French Common Voice (CV) dataset. It provides a
large set of speakers that used their own devices to record a
given set of sentences, naturally fitting to federated learning
with various speakers, acoustic conditions, microphones and
accents. We evaluate both a cross-silo and a cross-device (i.e.
large number of clients with few non-IID data) FL setups while

training a SOTA E2E ASR system. We conduct an empirical
study of three different weighting strategies during model aggregation to approach the difficulty of non-IID FL. In particular,
this work introduces a word error rate (WER) based strategy to
further adapt ASR training to federated learning. In short, our
contributions are:
1. Present the first study on attention-based Seq2Seq E2E
ASR model for realistic FL scenarios. Our setup approaches previously overlooked challenges such as extremely heterogeneous recording conditions.
2. Evaluate both cross-silo and cross-device FL with up to
2k clients on the naturally-partitioned and heterogeneous
French Common Voice dataset.
3. A new aggregation strategy based on WER to further integrate the specificity of ASR to FL.
4. Release the source code using Flower [25] and SpeechBrain [26] to facilitate replication and future research1 .

2. End-to-end Speech Recognizer
To ensure realistic conditions, the considered E2E ASR system
relies on the wide spread joint connectionist temporal classification (CTC) with attention paradigm [14]. This method combines a Seq2Seq attention-based model [27] with the CTC loss
[28].
A typical ASR Seq2Seq model includes three modules: an
encoder, a decoder and an attention module. Given a speech
input sequence (i.e. speech signal or acoustic features) x =
[x1 , ..., xTx ] with a length Tx , the encoder first converts it into
an hidden latent representation he = [he1 , ..., heTx ]. Then the
decoder attends to the encoded representation he combined
with an attention context vector ct obtained with the attention module, to produce the different decoder hidden states
hd = [hd1 , ..., hdTy ], with Ty corresponding to the length of the
target y. In a speech recognition scenario, the length of the original signal Tx is usually longer than the utterance length Ty .
The standard training procedure of the joint CTC-Attention
ASR pipeline is based on two different losses. First, the CTC
loss is derived with respect to the prediction obtained from the
encoder module of the Seq2Seq model:
LCT C = −

X
S

log p(y0 |he ),

(1)

with S denoting the training dataset and y0 = y ∪ {blank}.
The blank token enables the alignment between Tx and Ty .
Second, the attention-based decoder is optimised following the
cross entropy (CE) loss:
LCE = −

X

log p(y|hd ).

(2)

S

The losses are combined with a hyperparameter µ ∈ [0, 1] as:
L = µLCE + (1 − µ)LCT C .

(3)

In practice the CTC loss facilitates the early convergence
of the system due its monotonic behavior while the attentional
decoder needs to first figure out where to attend in the hidden
representation of the entire input sequence.
1 https://github.com/yan-gao-GY/
Flower-SpeechBrain

3. Federated Training of Acoustic Models
The process of training an end-to-end acoustic model using federated learning follows four steps: 1) Following [21], model
weights are initialised with a pre-training phase on a centralised
dataset; 2) The centralised server samples K clients from a pool
of M clients and uploads to these clients the weights of the
model. 3) The clients train the model for tlocal local epochs in
parallel based on their local user data and send back the new
weights or gradients to the server. 4) The server aggregates the
weights and restart at step 2. This procedure is executed for T
rounds until the model converges on a dedicated validation set.
3.1. Federated Optimisation
Federated Averaging (FedAvg) [7], as a typical aggregation
strategy based on averaging local stochastic gradient descent
(SGD) updates, has been widely applied in various FL tasks
[29]. At the beginning of a new round, the server sends to all
participating clients the global model, which contains the resulting model after the aggregation stage. During each training
round, each client k ∈ K, consisting of nk samples of audio
data, runs t ∈ [0, tlocal ] iterations with learning rate ηl to locally update the model based on the loss function Eq. 3,
(k)

(k)

− ηl g˜k .

(4)

gT = wT − wT −1 .

(5)

wt+1 = wt

where wk is the local model weights in client k, and g˜k denotes an average gradient over local samples. After training for
tlocal local epochs in the global round T , the updated weights
(k)
wT of the client k are sent back to the server. Then, the local
(k)
gradient gT can be approximated by computing the difference
between the latest updated model and the previous global model
wT −1 :
(k)

(k)

Then, the gradients from all clients are aggregated as follows:
∆T =

K
X

(k) (k)

(6)

αT gT ,

k=1
(k)

where αT denotes different weighting strategies described
in Section 3.2. The updated global model weights wT are computed with a server learning rate ηs according to:
(7)

wT = wT −1 − ηs ∆T ,

During FL training, especially with heterogeneous data, the
global model may deviates away from the original task or simply not converges [6, 8, 9], and therefore lead to performance
degradation. To alleviate this issue, and motivated by [21], we
propose an additional training iteration over a small batch of
held-out data on the server, after the standard model update procedure with Eq. 7. This way, the global model would be pulled
back to the direction of interest and the convergence would accelerate. Once the aggregated global model has been computed,
the server sends it back to the clients and re-iterates.
3.2. Weighting Strategies
(k)

In the original FedAvg algorithm, the weighting αT for the
aggregation step is based on the number of client samples each:
nk
(k)
αT = PK

k=1 nk

,

(8)

exp (−Lk )
(k)
αT = PK
.
k=1 exp (−Lk )

(9)

In the context of ASR, WER is commonly used as the final evaluation metric for the model instead of the training loss.
Intuitively, we propose a WER-based weighting strategy for aggregation. Similarly, this approach utilizes the values (1−wer)
(k)
obtained on the validation set as weighting coefficients αT , after passing them through a Softmax function:
exp (1 − werk )
(k)
αT = PK
.
k=1 exp (1 − werk )

(10)

In this way, we directly optimise the model towards the relevant metric for speech recognition.

4. Experimental Settings
In this section we present the model, the dataset used in our
experiments and describe our realistic FL experimental setup.
4.1. E2E Speech Recognizer
The experiments are based on an attention Seq2Seq model
trained with the joint CTC-attention objective [14]. The encoder is made of a 2D CNN block with 128 filters and a 5-layer
bidirectional LSTM with 1024 units. The decoder is a single
layered attentional GRU. The E2E acoustic model is trained to
predict subwords units. No language model fusion is performed
to properly assess the impact of the training procedure on the
acoustic models. Data is augmented in the time-domain during
training. The complete details of the architecture and hyperparameters can be found in our GitHub1 . The model has been implemented within SpeechBrain [26] and is therefore extremely
easy to manipulate, customise and retrain.
4.2. Common Voice French
In our experiments, we used the French set of the Common
Voice dataset (version 6.1) [30]. Common Voice (CV) allows us to simulate a realistic FL setup as it contains a total
of 328k utterances (475 hours in total) with diverse accents
which were recorded by more than 10K French-speaking participants. More precisely, the train set consists of 4190 speakers
(425.5 hours of speech), while the validation and test sets contain around 24 hours of speech from 2415 and 4247 speakers
respectively. Such recording, accent, and acoustic environment

600
Number of clients

400

200

+

0

30
0

0

30
0–

20

0

20
0–

15

00

0

15

0–

10

–1

60
–8

80

0

–6
0

40

0

–4

–2

20

10

10

0
0–

In realistic FL settings with heterogeneous client data distribution, however, the situation becomes challenging. First, some
clients may contain data that is skewed and not representative
of the global data distribution (e.g. audio samples with different languages or multiple speakers). As a result, the aggregated
model might simply not converge if such clients have proportionally more training samples than others. Second, clients containing low quality data would introduce unexpected noise into
the training process (e.g. extreme noise in the background). Either scenarios could lead to model deviation in the aggregation
step, which can not be solved via the standard FedAvg weighting method (Eq. 8). A potential solution, instead, is to use the
averaged training loss as a weighting coefficient, thus reflecting the quality of the locally trained model. Intuitively, higher
loss would indicate that the global model struggles to learn from
the client’ local data. More precisely, we compute the weighting with the Softmax distribution obtained from the the negative
training loss from Eq. 3. Eq. 8 can be modified as follows:

Number of samples in each client

Figure 1: Illustration of the sample distribution across the 2036
FL clients from the French Common Voice dataset.

diversity highly correlates with the requirements needed for
real-world FL. This level of realism, especially on the variety of
acoustic environments, is not possible with other datasets such
as LibriSpeech used in the closest works to our own [22, 21].
4.3. Realistic Federated Learning
Based on the natural partitioning on the CV dataset we propose
to conduct two sets of experiments reflecting real usages of FL:
Cross-silo FL. In this scenario, clients are generally few, with
high availability during all rounds, and are likely to have similar
data distribution for training [6], e.g. a consortium of hospitals,
each of which having large amounts of data from a large set
of users. In this context, shared data is often independent and
identically distributed. To achieve cross-silo FL, and following
[21], the dataset is split in 10 random partitions with no
overlapping speakers each containing roughly the same amount
of speech data. Each partition is assigned to one FL client.
Cross-device FL. On the other hand, a cross-device setup will
likely encompass thousands of clients having very different data
distributions (non-IID) participating in just a few rounds [6]. To
reproduce this scenario, we randomly divided the CV datasets
into 2036 partitions. This results in each client containing data
from two different speakers. In this way, we simulate the realistic scenario where two users use the same device (e.g personal
assistants or smart car). Figure 1 precisely depicts the sample
distribution over all considered clients.
4.4. Federated Learning for ASR: a hybrid approach
Training E2E ASR models in a federated learning manner is
challenging in many aspects. First, jointly learning the alignment and the latent speech representation is a difficult task that
commonly requires large datasets. Therefore, and as we experienced during our analysis, it is nearly impossible to train an
E2E ASR model from scratch in a realistic FL setup. This is
because most of the clients can only provide a few minutes of
speech, resulting in a slow model convergence or no convergence at all. To overcome this issue we first pre-train the global
model on half of the data samples. We do this by distinctly
partitioning the original dataset into a small subset of speakers
(with many samples) for centralized training (referred to sub-

5. Speech Recognition Results

Figure 2: Word error rate (WER) for 3 weighting strategies with
respect to global training rounds in the 2K-client setting.

Table 1: Speech recognition results on the test set of French
Common Voice for different scenarios and weighting strategies.
Training Scenario
Train on all data (lower bound)
Centralised
Train on 1st half (warm-up only)
Train on 2nd half (after warm-up)
Standard FedAvg
10-clients FL Loss-based aggregation
Cross-silo
WER-based aggregation
Standard FedAvg
2K-clients FL Loss-based aggregation
Cross-device
WER-based aggregation

WER (%)
20.18
25.26
20.94
21.26
21.10
20.99
22.83
22.67
22.42

sequently as the warm-up dataset) and a much larger subset of
speakers (having fewer samples each) for the FL experiment.
The small subset contains 117 speakers, leaving the remaining
4073 speakers to continue training the E2E ASR model in a federated fashion. We argue that this scenario remains realistic as,
in practice, centralised data is often available and can therefore
be used to pre-train models.
The number of clients that participate in each round influences the outcome of the experiment. More precisely, at the
beginning of each round, K clients are randomly selected from
the available set. Higher K lead to slight improvement of the
performance but also increase the communication overhead and
potential memory usage on the server side (i.e. more clients
to aggregate), while lower K induce an increased number of
rounds to converge. In addition to setting the number of global
rounds for the FL experiment, we must as well set the number of local epoch (i.e. on each client). This, however, is a
non-trivial task [7]. In practice, we found that increasing the
number of local epochs leads to instabilities as longer training
would cause over-fitting the local client data. Hence, clients are
locally trained for only 5 epochs.
For the cross-silo setup, all clients are selected at each
round (K = 10) while cross-device training relies on K = 100.
Indeed, we decided to follow the strategy investigated by previous large scale FL works [5].
For evaluation, we infer the trained models on the test set
of French Common Voice dataset with beam search. The results
are shows on Table 1. Note that the test set is smaller in number of speech hours but contains more speakers (4247 speakers)
than the training set, making this a challenging but realistic task.

When comparing results across the different training setups, we
may notice from Table 1 that training on the entire dataset in
a centralised way gives us the best WER with 20.18%. This
lower-bound is expected as the system has full visibility of the
data and can sample the inputs in an almost IID fashion. On the
other hand, when using only the warm-up dataset, we notice the
effect of having fewer data points for training as the WER increases to 25.26%. This is expected as the system has now less
data to learn from. This sheds some light on the inherent lowerbound limitations of FL, limited to partial data observations in
each round. The third centralised scenario trains the warmedup model on the 2nd half of data in an on-line training fashion.
This model provides a slightly lower WER compared to all FL
models. However, we should note that this is an unrealistic setting as training models in a centralised way would void all the
privacy guarantees that FL offers.
The effect of data visibility can indeed be seen in both
cross-silo and cross-device scenarios, which do not have uniform access to data. However, since this problem is less severe in the former setup, with the correct choice of aggregation
strategy we are still able to obtain a WER of 20.99%, which is
very close to the centralised lower bound of 20.18%. As for the
more challenging cross-device scenario, the effect of non-IID
data distribution among devices leads to its best WER being
22.43%. This value is larger than the worst cross-silo result,
showing the strong effects of the non-IID nature of the data partitioning and also suggesting that cross-silo results could offer
a more realistic lower-bound results for FL in general.
Compared to different weighting strategies, WER-based
and loss-based methods obtain a better performance and converge faster (Figure 2), which indicates that weakening the effects of low-quality clients can assist the aggregation process in
federated training with heterogeneous data distribution. Herein,
we have two types of indicators reflecting the quality of clients.
WER-based method exceeds loss-based strategy after 40 training rounds in 2k-client setting (Figure 2). The results in Table 1
show that WER-based strategy obtain the lowest WER in both
settings, surpassing the warm-up model in the cross-silo setting
by 4.3%. This could be easily explained by the nature of the
strategy which directly optimise the model toward the relevant
metric for speech recognition.

6. Conclusion
In this paper, we presented the first study on attention-based
Seq2Seq E2E ASR model with three aggregation weighting
strategies – standard FedAvg, loss-based aggregation and a
novel WER-based aggregation, for realistic FL scenarios. We
evaluated both cross-silo and cross-device FL on the French
Common Voice dataset which, unlike other datasets such as LibriSpeech, includes recordings from a large number of users in a
diverse set of scenarios. Our WER-based aggregation strategy,
aware of the data quality of clients with respect to the task, enables complex FL trained E2E ASR models to perform as well
as centralised trained ones. Our work sets the foundations for
future research and development of realistic FL-based ASR applications. For future work, we plan to investigate other ASR
model architectures and optimisers to better adapt to challenging FL environments.

7. References
[1] A. Kumar, S. Verma, and H. Mangla, “A survey of deep learning techniques in speech recognition,” in 2018 International Conference on Advances in Computing, Communication Control and
Networking (ICACCCN). IEEE, 2018, pp. 179–185.

[17] S. Bansal, H. Kamper, K. Livescu, A. Lopez, and S. Goldwater,
“Pre-training on high-resource speech recognition improves lowresource speech-to-text translation,” in Proceedings of the 2019
Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 2019, pp. 58–68.

[2] A. Hannun, C. Case, J. Casper, B. Catanzaro, G. Diamos,
E. Elsen, R. Prenger, S. Satheesh, S. Sengupta, A. Coates et al.,
“Deep speech: Scaling up end-to-end speech recognition,” arXiv
preprint arXiv:1412.5567, 2014.

[18] J.-Y. Hsu, Y.-J. Chen, and H.-y. Lee, “Meta learning for endto-end low-resource speech recognition,” in ICASSP 2020-2020
IEEE International Conference on Acoustics, Speech and Signal
Processing (ICASSP). IEEE, 2020, pp. 7844–7848.

[3] D. Amodei, S. Ananthanarayanan, R. Anubhai, J. Bai, E. Battenberg, C. Case, J. Casper, B. Catanzaro, Q. Cheng, G. Chen
et al., “Deep speech 2: End-to-end speech recognition in english
and mandarin,” in International conference on machine learning,
2016, pp. 173–182.

[19] A. Hard, K. Partridge, C. Nguyen, N. Subrahmanya, A. Shah,
P. Zhu, I. L. Moreno, and R. Mathews, “Training keyword spotting
models on non-iid data with federated learning,” arXiv preprint
arXiv:2005.10406, 2020.

[4] H. Soltau, H. Liao, and H. Sak, “Neural speech recognizer:
Acoustic-to-word lstm model for large vocabulary speech recognition,” arXiv preprint arXiv:1610.09975, 2016.

[20] D. Leroy, A. Coucke, T. Lavril, T. Gisselbrecht, and J. Dureau,
“Federated learning for keyword spotting,” in ICASSP 2019-2019
IEEE International Conference on Acoustics, Speech and Signal
Processing (ICASSP). IEEE, 2019, pp. 6341–6345.

[5] J. Konečnỳ, H. B. McMahan, F. X. Yu, P. Richtárik, A. T. Suresh,
and D. Bacon, “Federated learning: Strategies for improving communication efficiency,” arXiv preprint arXiv:1610.05492, 2016.

[21] D. Dimitriadis, K. Kumatani, R. Gmyr, Y. Gaur, and S. E. Eskimez, “A federated approach in training acoustic models,” in
Proc. Interspeech, 2020.

[6] P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N.
Bhagoji, K. Bonawitz, Z. Charles, G. Cormode, R. Cummings
et al., “Advances and open problems in federated learning,” arXiv
preprint arXiv:1912.04977, 2019.
[7] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A.
y Arcas, “Communication-efficient learning of deep networks
from decentralized data,” in Artificial Intelligence and Statistics.
PMLR, 2017, pp. 1273–1282.
[8] Y. Zhao, M. Li, L. Lai, N. Suda, D. Civin, and V. Chandra, “Federated learning with non-iid data,” arXiv preprint
arXiv:1806.00582, 2018.
[9] F. Sattler, S. Wiedemann, K.-R. Müller, and W. Samek, “Robust and communication-efficient federated learning from non-iid
data,” IEEE transactions on neural networks and learning systems, vol. 31, no. 9, pp. 3400–3413, 2019.
[10] A. Mohamed, D. Okhonko, and L. Zettlemoyer, “Transformers with convolutional context for asr,” arXiv preprint
arXiv:1904.11660, 2019.
[11] A. Zeyer, P. Bahar, K. Irie, R. Schlüter, and H. Ney, “A comparison of transformer and lstm encoder decoder models for asr,”
in 2019 IEEE Automatic Speech Recognition and Understanding
Workshop (ASRU). IEEE, 2019, pp. 8–15.
[12] M. Mohri, F. Pereira, and M. Riley, “Weighted finite-state transducers in speech recognition,” Computer Speech & Language,
vol. 16, no. 1, pp. 69–88, 2002.
[13] E. Battenberg, J. Chen, R. Child, A. Coates, Y. G. Y. Li, H. Liu,
S. Satheesh, A. Sriram, and Z. Zhu, “Exploring neural transducers for end-to-end speech recognition,” in 2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU).
IEEE, 2017, pp. 206–213.
[14] S. Kim, T. Hori, and S. Watanabe, “Joint ctc-attention based
end-to-end speech recognition using multi-task learning,” in 2017
IEEE international conference on acoustics, speech and signal
processing (ICASSP). IEEE, 2017, pp. 4835–4839.
[15] C.-C. Chiu, T. N. Sainath, Y. Wu, R. Prabhavalkar, P. Nguyen,
Z. Chen, A. Kannan, R. J. Weiss, K. Rao, E. Gonina et al., “Stateof-the-art speech recognition with sequence-to-sequence models,”
in 2018 IEEE International Conference on Acoustics, Speech and
Signal Processing (ICASSP). IEEE, 2018, pp. 4774–4778.
[16] A. Rosenberg, K. Audhkhasi, A. Sethy, B. Ramabhadran, and
M. Picheny, “End-to-end speech recognition and keyword search
on low-resource languages,” in 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).
IEEE, 2017, pp. 5280–5284.

[22] X. Cui, S. Lu, and B. Kingsbury, “Federated acoustic modeling for
automatic speech recognition,” arXiv preprint arXiv:2102.04429,
2021.
[23] F. Granqvist, M. Seigel, R. van Dalen, Á. Cahill, S. Shum, and
M. Paulik, “Improving on-device speaker verification using federated learning with privacy,” arXiv preprint arXiv:2008.02651,
2020.
[24] V. Panayotov, G. Chen, D. Povey, and S. Khudanpur, “Librispeech: An asr corpus based on public domain audio books,”
in 2015 IEEE International Conference on Acoustics, Speech and
Signal Processing (ICASSP), 2015, pp. 5206–5210.
[25] D. J. Beutel, T. Topal, A. Mathur, X. Qiu, T. Parcollet, and N. D.
Lane, “Flower: A friendly federated learning research framework,” arXiv preprint arXiv:2007.14390, 2020.
[26] M. Ravanelli, T. Parcollet, A. Rouhe, P. Plantinga, E. Rastorgueva,
L. Lugosch, N. Dawalatabad, C. Ju-Chieh, A. Heba, F. Grondin,
W. Aris, C.-F. Liao, S. Cornell, S.-L. Yeh, H. Na, Y. Gao, S.W. Fu, C. Subakan, R. De Mori, and Y. Bengio, “Speechbrain,”
https://github.com/speechbrain/speechbrain, 2021.
[27] D. Bahdanau, J. Chorowski, D. Serdyuk, P. Brakel, and Y. Bengio, “End-to-end attention-based large vocabulary speech recognition,” in 2016 IEEE international conference on acoustics,
speech and signal processing (ICASSP). IEEE, 2016, pp. 4945–
4949.
[28] A. Graves and N. Jaitly, “Towards end-to-end speech recognition
with recurrent neural networks,” in International conference on
machine learning, 2014, pp. 1764–1772.
[29] T. Li, A. K. Sahu, A. Talwalkar, and V. Smith, “Federated learning: Challenges, methods, and future directions,” IEEE Signal
Processing Magazine, vol. 37, no. 3, pp. 50–60, 2020.
[30] R. Ardila, M. Branson, K. Davis, M. Henretty, M. Kohler,
J. Meyer, R. Morais, L. Saunders, F. M. Tyers, and G. Weber,
“Common voice: A massively-multilingual speech corpus,” arXiv
preprint arXiv:1912.06670, 2019.

IMUTube: Automatic Extraction of Virtual on-body Accelerometry
from Video for Human Activity Recognition
HYEOKHYEN KWON∗ , School of Interactive Computing, Georgia Institute of Technology, USA
CATHERINE TONG∗ , Department of Computer Science, University of Oxford, UK
HARISH HARESAMUDRAM, School of Electrical and Computer Engineering, Georgia Institute of Tech-

arXiv:2006.05675v2 [cs.CV] 4 Aug 2020

nology, USA

YAN GAO, Department of Computer Science, University of Oxford, UK
GREGORY D. ABOWD, School of Interactive Computing, Georgia Institute of Technology, USA
NICHOLAS D. LANE, Department of Computer Science, University of Oxford, UK
THOMAS PLÖTZ, School of Interactive Computing, Georgia Institute of Technology, USA
The lack of large-scale, labeled data sets impedes progress in developing robust and generalized predictive models for on-body
sensor-based human activity recognition (HAR). Labeled data in human activity recognition is scarce and hard to come
by, as sensor data collection is expensive, and the annotation is time-consuming and error-prone. To address this problem,
we introduce IMUTube, an automated processing pipeline that integrates existing computer vision and signal processing
techniques to convert videos of human activity into virtual streams of IMU data. These virtual IMU streams represent
accelerometry at a wide variety of locations on the human body. We show how the virtually-generated IMU data improves the
performance of a variety of models on known HAR datasets. Our initial results are very promising, but the greater promise of
this work lies in a collective approach by the computer vision, signal processing, and activity recognition communities to
extend this work in ways that we outline. This should lead to on-body, sensor-based HAR becoming yet another success story
in large-dataset breakthroughs in recognition.
CCS Concepts: • Human-centered computing → Ubiquitous and mobile computing; • Computing methodologies
→ Artificial intelligence; Supervised learning by classification.

Additional Key Words and Phrases: Activity Recognition, Data Collection, Machine Learning

ACM Reference Format:
Hyeokhyen Kwon, Catherine Tong, Harish Haresamudram, Yan Gao, Gregory D. Abowd, Nicholas D. Lane, and Thomas Plötz.
2020. IMUTube: Automatic Extraction of Virtual on-body Accelerometry from Video for Human Activity Recognition. Proc.
ACM Interact. Mob. Wearable Ubiquitous Technol. 4, 3, Article 87 (September 2020), 29 pages. https://doi.org/10.1145/3411841
∗ Both authors contributed equally to this research.

Authors’ addresses: Hyeokhyen Kwon, hyeokhyen@gatech.edu, School of Interactive Computing, Georgia Institute of Technology, Atlanta,
GA, USA; Catherine Tong, eu.tong@cs.ox.ac.uk, Department of Computer Science, University of Oxford, UK; Harish Haresamudram,
harishkashyap@gatech.edu, School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Yan Gao,
yan.gao@keble.ox.ac.uk, Department of Computer Science, University of Oxford, UK; Gregory D. Abowd, abowd@gatech.edu, School of
Interactive Computing, Georgia Institute of Technology, Atlanta, GA, USA; Nicholas D. Lane, nicholas.lane@cs.ox.ac.uk, Department of
Computer Science, University of Oxford, UK; Thomas Plötz, thomas.ploetz@gatech.edu, School of Interactive Computing, Georgia Institute
of Technology, Atlanta, GA, USA.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that
copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.
Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy
otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from
permissions@acm.org.
© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.
2474-9567/2020/9-ART87 $15.00
https://doi.org/10.1145/3411841
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

87

87:2

•

Kwon and Tong, et al.

1 INTRODUCTION
On-body sensor-based human activity recognition (HAR) is widely utilized for behavioral analysis, such as user
authentication, healthcare, and tracking everyday activities [5, 14, 50, 78, 97]. Regardless of its utility, the HAR
field has yet to experience significant improvements in recognition accuracy, in contrast to the breakthroughs in
other fields, such as speech recognition [34], natural language processing [19], and computer vision [32]. In those
domains it is possible to collect huge amounts of labeled data, the key for deriving robust recognition models
that strongly generalize across application boundaries. In contrast, collecting large-scale, labeled data sets has
so far been limited in sensor-based human activity recognition. Labeled data in human activity recognition is
scarce and hard to come by, as sensor data collection is expensive, and the annotation is time-consuming and
sometimes even impossible for privacy or other practical reasons. A model derived from such a sparse dataset is
not likely to generalize well.
Despite the numerous efforts in improving human activity dataset collection, the scale of typical datasets
remains small, thereby only covering limited sets of activities [14, 35, 88, 97]. Even the largest sensor-based
activity dataset only spans a few dozen users and relatively short durations [5, 72], which is in stark contrast to
the massive datasets in other domains that are often several orders of magnitude larger. For example, Daphnet
freezing of gait dataset [5] has 5 hours of sensor data from 10 subjects, and PAMAP2 dataset [72] has 7.5 hours of
sensor data from 9 subjects. However, for reference, the ImageNet dataset [18] has approx. 14 million images, and
the "One billion words" benchmark [15] contains literally one billion words.
In this work, we develop a framework that can potentially alleviate the sparse data problem in sensor-based
human activity recognition. We aim at harvesting existing video data from large-scale repositories, such as
YouTube, and automatically generate data for virtual, body-worn movement sensors (IMUs) that will then be
used for deriving sensor-based human activity recognition systems that can be used in real-world settings. The
overarching idea is appealing due to the sheer size of common video repositories and the availability of labels
in the form of video titles and descriptions. Having access to such data repositories opens up possibilities for
more robust and potentially more complex activity recognition models that can be employed in entirely new
application scenarios, which so far could not have been targeted due to limited robustness of the learned models.
The challenges for making these vast amounts of existing data usable for sensor-based activity recognition are
manyfold, though: i) the datasets need to be curated and filtered towards the actual activities of interest; ii) even
though video data capture the same information about activities in principle, sophisticated preprocessing is
required to match the source and target sensing domains; iii) the opportunistic use of activity videos requires
adaptations to account for contextual factors such as multiple scene changes, rapid camera orientation changes
(landscape/portrait), the scale of the performer in the far sight, or multiple background people not involved in
the activity; and iv) new forms of features and activity recognition models will need to be designed to overcome
the short-comings of learning from video-sourced motion information for eventual IMU-based inference.
Our work is part of a growing number of exciting recent research results that explore the generation of crossmodality sensor data from "data-rich" sources such as video and motion capture in various domains [36, 74, 87, 92].
For example, in [36] IMU data was synthesized from high-fidelity motion capture data with high temporal and
spatial resolutions for computing human pose in real-time. On a similar vein, [87, 92] generate sensory data from
motion capture datasets and demonstrate their effectiveness for activity recognition. Most similar to our work,
[74] showed in principle that motion information can be extracted from video and utilized for sensor-based HAR.
In this paper, we present a method that allows us to effectively use video data for training sensor-based activity
recognizers, and as such demonstrates the first step towards larger-scale, and more complex deployment scenarios
than what is considered the state-of-the-art in the field. Our approach extracts motion information from arbitrary
human activity videos, and is thereby not limited to specific scenes or viewpoints. We have developed IMUTube,
an automated processing pipeline that: i) applies standard pose tracking and 3D scene understanding techniques
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

IMUTube: Automatic Extraction of Virtual on-body Accelerometry from Video for Human Activity Recognition •

87:3

to estimate full 3D human motion from a video segment that captures a target activity; ii) translates the visual
tracking information into virtual motion sensors (IMU) that are placed on dedicated body positions; iii) adapts the
virtual IMU data towards the target domain through distribution matching; and iv) derives activity recognizers
from the generated virtual sensor data, potentially enriched with small amounts of real sensor data. Our pipeline
integrates a number of off-the-shelf computer vision and graphics techniques, so that IMUTube is fully automated
and thus directly applicable to a rich variety of existing videos. One notable limitation from our current prototype
is that it still requires human curation of videos to select appropriate activity content. However, with advances in
computer vision the potential of our approach can be further increased towards complete automation.
The work presented in this paper is our first step towards the greater vision of automatically deriving robust
activity recognition systems for body-worn sensing systems. The key idea is to opportunistically utilize as much
existing data and information as possible thereby not being limited to the particular target sensing modalities. We
present the overall approach and relevant technical details and explore the potential of the approach on practical
recognition scenarios. Through a series of experiments on three benchmark datasets—RealWorld [86], PAMAP2
[72], and Opportunity [14]—we demonstrate the effectiveness of our approach. We discuss the overall potential
of models trained purely on virtual sensor data, which in certain cases can even reach recognition accuracies
that are comparable to models that are trained only on actual sensor data. Moreover, we show that when adding
only small portions of real sensor data during model training we are even able to outperform those models that
were trained on real sensor data alone. As such, our experiments show the potential of the proposed approach, a
paradigm shift for deriving sensor-based human activity recognition systems.
This work opens up the opportunity for the human activity recognition community to expand the general
focus towards more complex and more challenging recognition scenarios. We expect the proposed approach
to dramatically accelerate the progress of human activity recognition research. With the proposed method it
will also be possible to freely experiment with and optimize on-body sensor configurations, which will have a
substantial impact on real-world deployments. We discuss possible extensions to the presented approach, and
thus define a research agenda towards next-generation sensor-based human activity recognition.

2 EXTRACTING VIRTUAL IMU DATA FROM VIDEOS
The key idea of our work is to replace the conventional data collection procedure that is typically employed
for the development of sensor-based human activity recognition (HAR) systems. Our approach aims at making
existing, large-scale video repositories accessible for the HAR domain, leading to training datasets of sensor data,
such as IMUs, that are potentially multiple orders of magnitude larger than what is standard today. With such a
massively increased volume of real movement data—in contrast to simulated or generated samples, that often do
not exhibit the required quality nor variability—it will become possible to develop substantially more complex
and more robust activity recognition systems with a potentially much broader scope than the state-of-the-art
in the field. In what follows, we first give an overview of the general approach before we provide the technical
details of our procedure that converts videos into virtual IMU data.

2.1

IMUTube Overview

Figure 1 gives on overview of our framework for deriving sensor-based human activity recognition systems. The
top left part ("conventional") summarizes the currently predominant protocol. Study participants are recruited and
invited for data collection in a laboratory environment. There they wear sensing platforms, such as a wrist-worn
IMU, and engage in the activities of interest, typically in front of a camera. Human annotators provide ground
truth labeling either directly, i.e., while the activities are performed, or based on the video footage from the
recording session. This procedure is very labor-intensive and often error-prone, and, as such, labeled datasets of
only limited size can typically be recorded with reasonable efforts.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

,]ISO

IODWLFRQV
87:4

•

Kwon and Tong, et al.

][pI[jQ][<Y
$DhIgpI
Û[[]j<jI

/Z<YY <D
<j<hIj
.!]GIY
0g<Q[Q[O

<D

!10kDI

6QGI]
<j<

+g]EIhhQ[O
Ã+]hI
Ä+]hI
!1][]Q[jh

àgk[[Q[O

Zdg]pIG!1

.IdY]sZI[j
<gOI6Qgjk<Y
!1<j<hIj

Fig. 1. The proposed IMUTube system replaces the conventional data recording and annotation protocol (upper left) for
developing sensor-based human activity recognition (HAR) systems (upper right). We utilize existing, large-scale video
repositories from which we generate virtual IMU data that are then used for training the HAR system (bottom part).

In contrast, our approach aims at utilizing existing, large-scale repositories of videos that capture activities of
interest (bottom left part of Figure 1 labeled "IMUTube"). With the explosive growth of social media platforms, a
virtually unlimited supply of labeled video is available online that we aim to utilize for training sensor-based
HAR systems. In our envisioned application, a query for a specific activity delivers a (large) set of videos that
seemingly capture the target activity. These results (currently) need to be curated in order to eliminate obvious
outliers etc. such that the videos are actually relevant to the task (see discussion in Section 6). Our processing
pipeline then converts the video data into usable virtual sensor (IMU) data. The procedure is based on a computer
vision pipeline that first extracts 2D pose information, which is then lifted to 3D. Through tracking individual
joints of the extracted 3D poses, we are then able to generate sensor data, such as tri-axial acceleration values, at
many locations on the body. These values are then post-processed to match the target application domain.
Our work aims at replacing the data collection phase of HAR development. It is universal as it does not impose
constraints on model training (top center in Figure 1) nor deployment (right part of Figure 1). In what follows, we
describe the technical details of our processing pipeline that make videos usable for training IMU-based activity
recognition systems. This description assumes direct access to a video that captures a target activity, i.e., here we
do not focus on the logistics and practicalities of querying video repositories and curating the search results.

2.2

Motion Estimation for 3D Joints

On-body movement sensors capture local 3D joint motion, and, as such, our processing pipeline aims at reproducing this information but from 2D video. As shown in Figure 2 we employ a two-step approach. First, we estimate
2D pose skeletons for potentially multiple people in a scene using a state-of-the-art pose extractor, namely the
OpenPose model [10]. Then, each 2D pose is lifted to 3D by estimating the depth information that is missing in
2D videos. Without limiting the general applicability we assume here that all people in a scene are performing
the same activity. Although fast and accurate, the OpenPose model estimates 2D poses of people on a frame by
frame basis only, i.e., no tracking is included which requires post-processing to establish and maintain person
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

IMUTube: Automatic Extraction of Virtual on-body Accelerometry from Video for Human Activity Recognition •

87:5

Fig. 2. 3D joint orientation estimation and pose calibration. The multi-person 2D poses are estimated with OpenPose followed
by lifting to 3D through VideoPose3D. The camera intrinsic parameters are estimated using the DeepCalib model. Jointly
with the pose and camera related parameters, we calibrate the orientation and translation in the 3D scene for each frame.

correspondences across frames. In response, we apply the SORT tracking algorithm [7] to track each person across
the video sequence. SORT utilizes bipartite graph matching with the edge weights as the intersection-over-union
(IOU) distance between boundary boxes of people from consecutive frames. The boundary boxes are derived as
tight boxes including the 2D keypoints for each person.
To increase the reliability of the 2D pose detection and tracking, we remove 2D poses where over half of the
joints are missing, and also drop sequences that are shorter than one second. For each sequence of a tracked
person, we also interpolate and smooth missing or noisy keypoints in each frame using a Kalman filter, as poses
cannot be dramatically different between subsequent frames. Finally, each 2D pose sequence is lifted to 3D pose
by employing the VideoPose3D model [63]. Capturing the inherent smooth transition of 2D poses across the
frames encourages more natural 3D motion in the final estimated (lifted) 3D pose.

2.3

Global Body Tracking in 3D

Inertial measurement units capture the acceleration from global body movement in 3D, and additionally local
joint motion in 3D. Thus, we also have to extract global 3D scene information from the 2D video to track a
person’s movement in the whole scene. Typical 3D pose estimation models do not localize the global 3D position
and orientation of the pose in the scene. Tracking the 3D position of a person in 2D video requires two pieces of
information: i) 3D localization in each 2D frame; and ii) the camera viewpoint changes (ego-motion) between
subsequent 3D scenes. We map the 3D pose of a frame to the corresponding position within the whole 3D scene
in the video, compensating for the camera viewpoint of the frame. The sequence of the location and orientation
of 3D pose is the global body movement in the whole 3D space. For the virtual sensor, the global acceleration
from the tracked sequence will be extracted along with local joint acceleration.
2.3.1 3D Pose Calibration. First, we estimate the 3D rotation and translation of the 3D pose within a frame, as
shown in Figure 2. For each frame, we calibrate each 3D pose from a previously estimated 3D joint according
to the perspective projection between corresponding 3D and 2D keypoints. The perspective projection can be
estimated with the Perspective-n-Point (PnP) algorithm [38]. Additionally to 3D and 2D correspondences, the
PnP algorithm requires the camera intrinsic parameters for the projection, which include focal length, image
center, and the lens distortion parameters [11, 79]. Since arbitrary online videos typically do not come with
such metadata, the camera intrinsic parameters are estimated from the video with the DeepCalib model [8]. The
DeepCalib model is a frame-based model that considers a single image at a time so that the estimated intrinsic
parameter for each frame slightly differs across the frame according to its scene structure. Hence, we assume that
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

87:6

•

Kwon and Tong, et al.

a given video clip sequence is recorded with a single camera, and aggregate the intrinsic parameter predictions
by calculating the average from all frames:
c int =

1 Õ int
c
T t =1 t
T

(1)

where c int = [f , p, d] is the averaged camera intrinsic parameters from each frame, x t at time t, predictions,
c tint = DeepCalib(x t ). f = [f x , fy ] is the focal length and p = [px , py ] is the optical center for the x and y axis,
and d denotes the lense distortion. Once the camera intrinsic parameter is calculated, the PnP algorithm regresses
global pose rotation and translation by minimizing the following objective function:
{R calib ,T cal ib } = arg min
R,T

N
Õ

1
∥p2i − c int (Rp3i + T )∥
s
i=1

(2)

subject to R R = I 3 , det(R) = 1
T

where p2 ∈ R2 and p3 ∈ R3 are corresponding 2D and 3D keypoints. R calib ∈ R3×3 is the extrinsic rotation matrix,
T cal ib ∈ R3 is the extrinsic translation vector, and s ∈ R denotes the scaling factor [98, 101]. For the temporally
smooth rotation and translation of a 3D pose across frames, we initialize the extrinsic parameter, R, and T , with
the result from the previous frame. The 3D pose for each person, p3 ∈ R3×N , at each frame is calibrated (or
localized) with the estimated corresponding extrinsic parameter.
p3calib = R calib p3 + T calib

(3)

From the calibrated 3D poses, p3calib ∈ R3×N , we remove people considered as the background. For example,
in a rope jumping competition scene, a set of people may rope jump while others are sitting and watching.
Depending on the scene, not all people captured may partake in an activity (e.g., bystanders). To effectively collect
3D pose and motion that belongs to a target activity, we thus remove those people in the (estimated) background.
We first calculate the pose variation across the frames as the summation of the variance of each joint location
across time. Subsequently, we only keep those people with the pose variation larger than the median of all people.
2.3.2 Estimation of Camera Ego-motion. In an arbitrary video, the camera can move around the scene freely.
However, the pipeline should not confuse the camera motion with human motion. For example, a person who
does not move (much) may appear at a different location in subsequent frames due to the camera movement,
which is misleading for our purpose. Also, a moving person can always appear in the center of the frame, and
thus erroneously appear static, if the camera follows that person and therefore the movements are effectively
compensated for in the video. In these two cases, the virtual sensor should capture no motion (static), or the
global body acceleration only, respectively, independently from camera motion. Hence, before generating the
virtual sensor data, the 3D poses, which were previously calibrated per frame, need to be corrected for camera
ego-motion, i.e., potential viewpoint changes, across the frames.
Camera ego-motion estimation from one viewpoint to another requires 3D point clouds of both scenes [6, 66, 76].
Deriving a 3D point cloud of a scene requires two pieces of information: i) the depth map; and ii) camera intrinsic
parameters. For camera intrinsic parameters, we reuse the parameters previously estimated. The depth map
is the distances of pixels in the 2D scene from a given camera center, which we estimate with the DepthWild
model [25] for each frame. Once we have obtained the depth map and the camera intrinsic parameters, we can
geometrically inverse the mapping of each pixel in the image to the 3D point cloud of the original 3D scene. With
basic trigonometry, the point cloud can be derived from the depth map using the previously estimated camera
intrinsic parameter, c int = [f x , fy , px , py , d]. For a depth value Z at image position (x, y), the point cloud value,
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

IMUTube: Automatic Extraction of Virtual on-body Accelerometry from Video for Human Activity Recognition •

87:7

Fig. 3. 3D pose and motion tracking with compensation of the camera motion. The camera motion is estimated through the
iterative closest point (ICP) algorithm between subsequent point clouds. Then, calibrated 3D poses per frame are mapped to
the location in the entire 3D scene, compensating for camera motion. The calibrated 3D poses from both frames are initially
centered in the 3D world origin as the camera follows the cyclists. After incorporating ego-motion information, we can see
that two cyclists are moving from right to left, moving closer to each other as in the video (most right figure).

[X , Y , Z ], is:
[X , Y , Z ] =

h (x − p ) · Z (y − py ) · Z i
x
,
,Z
fx
fy

(4)

Once point clouds are calculated across frames, we can derive the camera ego-motion (rotation and translation)
parameters between two consecutive frame point clouds. A popular method for registering groups of point clouds
is the Iterative Closest Points (ICP) algorithm [6, 66, 76]. Fixing a point cloud as a reference, ICP iteratively finds
closest point pairs between two point clouds and estimates rotation and translation for the other point cloud that
minimizes the positional error between matched points [6]. Since we extract color point clouds from video frames,
we adopted Park et al.’s variant of the ICP algorithm [62], which considers color matching between matched
points in addition to the surface normals to enhance color consistency after registration. More specifically, we
utilize background point clouds instead of the entire point cloud from a scene because the observational changes
for the stationary background objects in the scene are more relevant to the camera movement. We consider
humans in the scene as foreground objects, and remove points that belong to human bounding boxes determined
from 2D pose detection. The reason for this step is that we noticed that including foreground objects, such as
humans, leads to the ICP algorithm confusing movements of moving objects, i.e., the humans, and of the camera.
With the background point clouds, we apply the color ICP algorithm between point clouds at time t − 1 and t,
qt −1 and qt respectively. As such, we iteratively solve:
Õ
eдo
eдo
(1 − δ )∥Cqt −1 (f (Rqt + T )) − C(qt −1 )∥ + δ ∥(Rqt + T − qt −1 ) · nqt −1 ∥
(5)
{R t ,Tt } = arg min
R,T

(q t −1,q t )∈K

where C(q) is the color of point q, nq is the normal of point q. K is the correspondence set between qt −1 and qt ,
eдo
eдo
and R t ∈ R3×3 and TT ∈ R3 are fitted rotation and translation vectors in the current iteration. δ ∈ [0, 1] is the
weight parameter that balances the emphasis given to positional or color matches.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

87:8

•

Kwon and Tong, et al.

The estimated sequence of translation and rotation of a point cloud represents the resulting ego-motion of the
camera. As the last step, we integrate the calibrated 3D pose and ego-motion across the video to fully track 3D
human motion. Previously calibrated 3D pose sequences, p3calib , are rotated and translated according to their
ego-motion at frame t:
eдo
eдo
p3t tr ack = R t p3calib
+ Tt
(6)
t

where p3t r ack ∈ RT ×N ×3 is the resulting 3D human pose and motion tracked in the scene for the video, T is
the number of frames, and N is the number of joint keypoints. The overall process of compensating camera
ego-motion is illustrated in Figure 3.

2.4

Generating Virtual Sensor Data

Once full 3D motion information has been extracted for each person in a video, we can extract virtual IMU
sensor streams from specific body locations. The estimated 3D motion only tracks the locations of joint keypoints,
i.e., those dedicated joints that are part of the 3D skeleton as it has been determined by the pose estimation
process. However, in order to track how a virtual IMU sensor that is attached to such joints rotates while the
person is moving, we also need to track the orientation change of that local joint. This tracking needs to be done
from the perspective of the body coordinates. The local joint orientation changes can be calculated through
forward kinematics based from the hip, i.e., the body center, to each joint. We utilize state-of-the-art 3D animation
software – Blender [16], to estimate and track these orientation changes. Using the orientation derived from
forward kinematics, the acceleration of joint movements in the world coordinate system is then transformed into
the local sensor coordinate system. The angular velocity of the virtual sensor (i.e., a gyroscope) is calculated by
tracking orientation changes.
We employ our video processing pipeline on raw 2D videos that can readily be retrieved by, for example,
querying public repositories such as YouTube, and combined with subsequent curation (not within the focus of
this paper). The pipeline produces virtual IMU, for example, tri-axial accelerometer data. This data effectively
captures the recorded activities, yet the characteristics of the generated sensor data will still differ from real
IMU data, for instance it will lack any MEMS noise. In order to compensate for this mismatch, we employ the
IMUSim [95] model to extract realistic sensor behavior for each on-body location. IMUSim estimates sensor output
considering mechanical and electronic components in the device, as well as the changes of a simulated magnetic
field in the environment. As such, this post-processing step leads to more realistic IMU data [4, 42, 64].

2.5

Distribution Mapping for Virtual Sensor Data

As the last step before using the virtual IMU dataset for HAR model training, we define a calibration operation to
account for any potential mismatch between the source (virtual) and target (real) domains [13]. We employ a
distribution mapping technique to fix such mismatch, where we transfer the distribution of the virtual sensor to
that of the target sensor. For computational efficiency, the rank transformation approach [17] is utilized:
x r = G −1 (F (X ≤ xv ))
(7)
∫x
where, G(X ≤ x r ) = − inf д(x)dx and F (X ≤ xv ) = −∞v f (x)dx are cumulative density functions for real, x r , and
virtual, xv , sensor samples, respectively. In our experiments (Section 4.2), we show that only a few seconds to
minutes of real sensor data is sufficient to calibrate the virtual sensor effectively for successful activity recognition.
∫ xr

3 TRAINING ACTIVITY RECOGNITION CLASSIFIERS WITH VIRTUAL IMU DATA
We now describe a series of experiments to examine the viability of using IMUTube to produce virtual IMU data
useful for HAR. Our first set of experiments consider the performance of virtual IMU data on a HAR dataset
providing both video and real IMU data, which enables a fair comparison between virtual and real IMU data. Here,
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

IMUTube: Automatic Extraction of Virtual on-body Accelerometry from Video for Human Activity Recognition •

87:9

we see promising results suggesting that training activity classifiers from virtual IMU data alone can perform
well on real IMU data. We then move on to show that activity classifiers trained using this virtual IMU data can
also perform well on real IMU data coming from common HAR datasets, namely Opportunity [14] and PAMAP2
[72]. Finally, we describe how we curate a video dataset comprising of online videos (e.g., YouTube) in order to
extract virtual IMU data for complex activities.
In each experiment, we compare the performances of models on real IMU data (i.e., the test data is from real
IMUs), when trained from real IMUs (R2R), trained from virtual IMUs (V2R), or trained from a mixture of virtual
and real (Mix2R) IMU data. Throughout our experiments, we consider the Random Forest classifier as our main
machine learning back-end for activity recognition, evaluated via leave-one-subject-out scheme. We supplement
this primary result by also demonstrating the feasibility to apply deep learning with a hold-out evaluation scheme;
in doing so we show our approach is agnostic to the choice of the learning algorithm.

3.1

Feasibility Experiment under Controlled Conditions

There are many potential sources of noise which may impact the activity recognition performance; therefore, in
our first experiment we hold constant as many factors as possible. We accomplish this by using the RealWorld
dataset [86], an activity recognition dataset that contains not only IMU data but also provides videos of the
subjects performing the activities.
Data. The Realworld dataset covers 15 subjects performing eight locomotion-style activities, namely climbing
up, climbing down, jumping, lying, running, sitting, standing, and walking. Each subject wears the sensors for
approximately ten minutes for each activity except for jumping (<2 minutes). The video and accelerometer data
are not time-synchronized, as each video starts some time (under one minute) before each activity begins. The
video is recorded using a hand-held device by the experiment’s administrator, who follows the subject as they
perform the activity (e.g., running through the city alongside the subject). The videos do not always present a
full-body view of the subject, and the video-taker sometimes makes arbitrary changes to the video scene (e.g.,
he/she might walk past the subject, or rotate the camera from landscape to portrait mode halfway). These factors
present extra difficulty in extracting virtual IMU for the full duration of the activities; nonetheless we are able to
extract 12 hours of virtual IMU data, this is compared to 20 hours of available real IMU data. As a preprocessing
step, we remove the first ten seconds of each video and divide the remainder into two-minute chunks for efficient
running of IMUTube. Virtual IMU data are extracted from 7 body locations, i.e. forearm, head, shin, thigh, upper
arm and waist/chest, corresponding to where real sensors are placed in Realworld. We assume all IMU data to
have a frequency of 30Hz and use sliding windows to generate training samples of duration 1 second and 50%
overlap. The resulting real and virtual IMU dataset contains 221k and 86k windows, respectively.
Method. Our primary evaluations are performed with the Random Forest classifier using ECDF features [28]
(15 components), trained using a leave-one-subject-out scheme. On Realworld, we use a train set of 13 subjects,
validation set of 1 subject and test set of 1 subject in each fold. This scheme is followed in R2R (where training
data is real IMU data), V2R (where training data is virtual, and distribution-mapped only using data from train
users), and Mix2R (which contains a mixture of both real and virtual IMU data). We calibrate hyperparameters on
the validation subjects by varying the number of trees from 3 to 50 and the minimum number of samples in leaf
node from 1 to 50. We report the mean F1-score of the test subjects computed after the completion of all folds.
Separate from this, we train DeepConvLSTM [61] on a hold-out evaluation scheme, where subject 15 is
randomly selected as validation, 14 as test, and the rest as the training set. DeepConvLSTM is trained on raw
data for a maximum of 100 epochs with an Adam optimizer [43] and early stopping on the validation set with a
patience of ten epochs; learning rate is searched from 10−6 to 10−3 , and weight decay from 10−4 to 10−3 via grid
search. We further regularize model training by employing augmentation techniques from [91] with a probability
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

87:10

•

Kwon and Tong, et al.

Table 1. Recognition results on the Realworld dataset (8 classes) when training models from real IMU data (R2R), from
virtual IMU data (V2R), and from a mixture of both (Mix2R). Wilson score confidence intervals are shown. For Random
Forest models, V2R achieves 98% of the R2R F1-score, while a Mix2R setup surpasses R2R by 12%.
(a) Random Forest (leave-one-subject-out)

R2R
0.5779±0.0025

V2R
0.5675±0.0025

Mix2R
0.6444±0.0024

(b) DeepConvLSTM (random single-subject hold-out)

R2R
0.7305±0.0073

V2R
0.5465±0.0082

Mix2R
0.7785±0.0068

of application set at either 0 and 0.5 depending on validation set result. We average over 3 runs initiated with
different random seeds and report the mean F1-score.
In both cases, we report the highest test F1-score achieved using any amount of training data, along with the
Wilson score interval with 95% confidence. We discuss the effect of training set size in Section 4.3. We reuse these
settings throughout the paper unless stated otherwise.
Results. In Table 1a, we see convincing evidence that human activity classifiers can learn from virtual IMU data
alone. When learning from virtual IMU data alone (V2R), the 8-class model achieves an F1-score of 0.57, which is
within 2% of that achieved by learning from real IMU data (R2R). This result is remarkable as the difference in
recognition performance of R2R and V2R is small notwithstanding the change in data source and the introduction
of noise while going through our pipeline.
Furthermore, when we use a mixture of virtual and real IMU data to train the model, it is even able to surpass
R2R performance with a significant relative performance gain of 12%, reaching an F1-score of 0.64. This showcases
an additional potential of IMUTube – we can build activity classifiers using both virtual and real IMU data to
push recognition capabilities beyond that achieved by either.
Our DeepConvLSTM results (evaluated on a random subject, Table 1b) offers another perspective into modeling
virtual IMU data when deep learning models are used. Although learning from virtual IMU data alone is seen
to pose more challenges (V2R achieves 75% of R2R), this is possibly related to the setup of learning directly
from raw data, in contrast to processed features in the Random Forest case. As a consequence, DeepConvLSTM
may be learning feature representations highly specific to the virtual IMU domain, which prevents immediate
generalization to real IMU data. This issue is diminished when using a mixture of virtual and real IMU data
for training, as Mix2R even outperforms R2R by 6.6%. We presume that the improvement is related to the
complementary benefits of both real and virtual data, as well as the feature learning capabilities of deep learning
models, which learn better when more data is available.
This set of results provide promising signs for IMUTube – we can learn capable activity classifiers with virtual
IMU data alone, despite having only so far considered relatively straightforward techniques in extracting and
modeling the virtual IMU data. We delve into these concerns about the quality of virtual IMU data in Section 4 to
provide a more complete view.

3.2

Performance on Common Activity Recognition Datasets

We have achieved promising results under the controlled conditions of Realworld, which simultaneously gathers
video and IMU together. We now seek to relax these conditions, and establish the viability of IMUTube when the
exact actions performed in the video data and the real IMU data do not completely align. Imagine a scenario
where we want to build a classifier for ‘standing’ vs. ‘sitting’. Instead of collecting simultaneous video and real
IMU data of people standing and sitting, we want to leverage existing videos of people standing and sitting and
train the classifier using the derived virtual data.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

IMUTube: Automatic Extraction of Virtual on-body Accelerometry from Video for Human Activity Recognition •

87:11

Table 2. Recognition results (mean F1-score) on Opportunity dataset (4 classes) and locomotion activities found in PAMAP2
(8 classes) when using different training data. For Random Forest models, V2R achieves 95% of R2R F1-scores on average,
while Mix2R outperforms R2R by 5% on average.
(a) Random Forest (leave-one-subject-out)

Dataset
Opportunity
PAMAP2 (8-class)

R2R
0.8271±0.0034
0.7029±0.0055

V2R
0.7757±0.0037
0.6728±0.0058

Mix2R
0.8820±0.0029
0.7284±0.0053

(b) DeepConvLSTM (random single-subject hold-out)

Dataset
Opportunity
PAMAP2 (8-class)

R2R
0.8871±0.0074
0.7002±0.0161

V2R
0.7882±0.0096
0.5524±0.0175

Mix2R
0.8838±0.0075
0.7020±0.0161

In the following, we test this scenario by re-using the video data from Realworld and learning models from its
virtual data to test on two common HAR datasets, Opportunity and PAMAP2. These datasets are considered as
they contain activity labels that roughly correspond to those in Realworld.
Data. We consider activities in Opportunity and PAMAP2 which are overlapping with those in Realworld, i.e.,
four classes (stand, walk, sit, lie) in Opportunity, and eight classes (ascending stairs, descending stairs, rope jumping,
lying, running, sitting, standing, walking) in PAMAP2. We use 1-second sliding windows with 50% overlap.
For Opportunity, we re-extracted virtual data from the Realworld videos in eleven body positions (left and
right feet, left shin and thigh, hip, back, left and right arms, left and right forearms), which resulted in 40k and
46k real and virtual IMU windows respectively. For DeepConvLSTM, we used random subject 3 for validation, 4
for test, and the rest for training.
For PAMAP2, the activities are slightly different from those in Realworld so we equated the labels with the
closest meaning (e.g., using jumping Realworld videos as the source for rope jumping virtual IMU in PAMAP2.
The PAMAP2 dataset specifies that sensors were placed in three locations (dominant wrist, dominant ankle,
chest), which gives rise to a total of four possible combinations for arm and chest location when we extract virtual
IMU data from a single video (i.e., left-left, right-right, left-right, right-left). We took advantage of this ambiguity
and extracted 4× as much virtual IMU per video, resulting in 24k and 152k windows for real and virtual IMU
respectively. For DeepConvLSTM, we followed the same setup as [29] and use subject 5 for validation, 6 for test,
and the rest for training.
Results. Table 2a shows the classification performance for R2R, V2R and Mix2R. We observe encouraging results,
where learning from virtual IMU data alone can recover high levels of R2R performance, despite data collection
conditions not being held constant. A Random Forest classifier trained from virtual IMU data achieves 94% and
96% of R2R performance on Opportunity and PAMAP2 respectively. While this good performance might be
related to the simplicity of the motions classified (mainly locomotive activities), we highlight that the conditions
of data collection in Realworld and Opportunity are very different–subjects could be walking through the forest
or city in Realworld, but all subjects perform activities inside a laboratory in Opportunity; Likewise for Realworld
and PAMAP2–subjects could also be climbing down the streets of a city (a mixture of pavement and stairs) in
Realworld whereas all subjects are climbing up the same building in PAMAP2. Thus, being able to utilize virtual
data from one scenario and test it on another is not a trivial task. These results suggest that, on these two tasks,
virtual IMU data can provide salient features that are generalizable and robust across testing scenarios.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

87:12

•

Kwon and Tong, et al.

Table 3. Recognition results (mean F1-score) on PAMAP2 (11-classes) when using different training data. The Random Forest
model trained with virtual IMU data including YouTube videos (for four complex activities) recovered 80% of R2R model
performance. For Mix2R, additional real IMU data helped the Random Forest model increase performance up to 98% of R2R
model performance.
(a) Random Forest (leave-one-subject-out)

R2R
0.7225±0.0044

V2R
0.5792±0.0049

Mix2R
0.7111±0.0044

(b) DeepConvLSTM (random single-subject hold-out)

R2R
0.6977±0.0129

V2R
0.5326±0.0140

Mix2R
0.7095±0.0128

We also observe performance gains when training with a mixture of real and virtual IMU data, which exceeds
R2R F1-scores by 5% on average. Not only does this observation solidify the argument that virtual and real IMU
data can bring complementary benefits to activity recognition, but such performance gains are also a positive
sign especially since the two types of data are collected under rather different circumstances. We argue that,
adding virtual IMU data – in this case, virtual data generated from a related different scenario – can help expand
the variety of motions seen by the classifier and as a result improve model generalization.
As before, we provide the performance by DeepConvLSTM on a random test subject as additional results in
Table 2b, where V2R recovers 84% of R2R F1-scores, while Mix2R and R2R scores are statistically comparable.
Overall, this set of results presents strong evidence supporting the usefulness of virtual IMU data, either used
standalone or in combination with real IMU data for activity recognition. Beyond this, these results also imply an
encouraging view that aligns well with our vision for IMUTube – that virtual data, even when collected under
vastly different settings, can be useful in building capable or even better models for activity recognition.

3.3

Virtual IMU Data for Complex Activity Recognition

Encouraged by the results so far, we now try to apply IMUTube onto activity recognition scenarios with even
more challenging conditions and test its ability in building classifiers for complex activities. Our ultimate vision
for IMUTube is to extract virtual data from any video, especially those freely available in large online repositories
such as YouTube. To test the feasibility of doing so, we first need to curate a dataset with activity videos originating
from the web. In the following, we attempt to source these videos for complex activities present in PAMAP2, and
train classifiers with the extracted virtual IMU data.
Data. We curated a dataset of virtual data covering four complex activities present in PAMAP2, namely vacuum
cleaning, ironing, rope jumping and cycling. To efficiently locate such videos, we extract annotated video segments from activity video datasets in the computer vision domain, including ActivityNet [9], Kinetics700 [12],
HMDB51 [44], MPIIHPD [3], UCF101 [84], Charades [83], AVA [26], MSRdailyactivity3D [49], and NTU RGBD [51]. The resulting video dataset consists of a mix of videos collected in experiment scenarios and in-the-wild
(e.g., from YouTube). In total, we collected ∼ 10 hours of virtual data from 7,255 videos. To extend our activity
recognition task to as many classes in PAMAP2 as possible, we also reuse the other seven videos from Realworld
(we do not use the jumping videos); this allows us to consider an 11-class activity recognition problem in PAMAP2.
As mentioned for the PAMAP2 (8-class) task, we face an ambiguity in sensor location which led us to extract 4×
virtual data per video. Using sliding windows of 1-second size and 50% overlap, resulted in 38k real and 390k
virtual IMU windows in total.
Results. For these challenging conditions (using in-the-wild videos, learning complex activities), Table 3a shows
that virtual IMU data can still be useful for training activity classifiers. With the Random Forest classifier, training
from virtual IMU data alone achieves a 0.58 F1-score under V2R, which is 80% of that achieved with R2R (0.72
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

IMUTube: Automatic Extraction of Virtual on-body Accelerometry from Video for Human Activity Recognition •

87:13

F1-score). This is a weaker result compared to those achieved on previous datasets (where V2R achieved 96% of
R2R on average). However, this is because there is an even more drastic difference in the data sources and activity
label interpretations between the real and virtual IMU data. Another likely factor causing the weaker performance
is the quality of virtual IMU data that IMUTube is currently able to produce, which might be amplified by the
complex activities introduced in this experiment. In Section 4.1 we will examine the fidelity of virtual IMU data,
and provide directions to improve its quality in Section 6.2. Finally, one must consider as a factor the greater
domain shift that is probably present between train and test scenarios, which we will discuss in Section 4.2.
When real IMU data is added to virtual IMU data for training, the Random Forest model gains 23% and achieves
a F1-score of 0.71 in Mix2R versus 0.58 in V2R, though Mix2R is still 2% worse than R2R performance. We believe
these results are related to the domain shift within the training data. To better cope with the scenario where we
want to make use of both real and virtual IMU data, we investigate the effect of mixing data in Section 4.3 and
investigate more sophisticated methods beyond simple mixing in Section 5. Our evaluation under DeepConvLSTM
is shown in Table 3b, and results align with those of the Random Forest.
Through this set of experiments, we have demonstrated that, despite very challenging conditions–in-the-wild
videos and complex activity recognition, it is still feasible to learn capable classifiers using virtual IMU data. The
results overwhelmingly support that virtual IMU data generated via IMUTube are useful for even real-world
instances of activity recognition. Demonstrated over a range of locomotion and more complex activities, virtual
IMU data is seen to effectively capture motion information, such that classifiers can be trained from them alone
and still perform well on real IMU data. In addition, mixing real and virtual IMU data for training is also shown
to be a potential source of performance gain.

4 UNDERSTANDING VIRTUAL IMU DATA
Across multiple datasets, the model trained on the virtual IMU dataset (V2R) performed well on the real IMU
test datasets. The V2R performance varies between 80% - 90% compared to R2R models, and only matches or
outperforms R2R when trained alongside real IMU data (Mix2R). Although notably, for the experiment on PAMAP2
(11-class), the V2R model could not outperform R2R even when trained with the larger virtual dataset extracted
from multiple video sources. Thus, in this section, we investigate the potential sources of such performance gaps
in detail. First, we analyze the extracted virtual IMU data by inspecting the sample-level similarity in IMU signals
using synced sequences of real and virtual IMU data. Then, at a distribution level, we investigate the effects of
domain shift, along with the impact of our distribution mapping technique (Section 2.5). Finally, we investigate
the mixing of real and virtual IMU data for model training (Mix2R), which was seen to give comparable, if not
superior, performance relative to R2R in Section 3. Through our analysis, we aim to provide key insights into the
IMUTube pipeline and the use of virtual IMU data for human activity recognition. All experiments presented in
this section are carried out using Random Forest in the leave-on-subject-out setting unless otherwise specified.

4.1

Comparing Virtual and Real IMU

We do not expect IMUTube to function flawlessly. Given the complexity of the process, the translation from video
to virtual IMU data will naturally contain errors. Despite this, we observe promising results of competitive V2R
performance in the prior section. This seems to suggest that perfect sample-level realism in the virtual IMU data
is not necessary to train capable human activity classifiers. In the following, we compare virtual and real IMU
samples to better understand the limits of IMUTube and argue that, the focus, during virtual IMU generation,
should be placed on capturing salient features useful for activity recognition.
Method. Sample-level comparison between the virtual and real IMU data requires a dataset with time-synchronized
video and IMU sensor data. Although the Realworld dataset contains both accelerometer and video data, these
modalities are not synchronized (as mentioned in Section 3.1). Therefore, in this experiment, we introduce the
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

87:14

•

Kwon and Tong, et al.
(a) Left wrist
−5

x_vir
x_real

−10
−15

Acceleration (m/s^2)

−20
0

1

2

3

4

5

6
y_vir
y_real

5
0
−5
0

1

2

3

4

5

6

4

z_vir
z_real

2
0
−2
0

1

2

3

4

5

6

Time (s)

(b) Left ankle
x_vir
x_real

0

Acceleration (m/s^2)

−50
0

1

2

3

4

5

6
y_vir
y_real

0
−50
0

1

2

3

4

5

6

40

z_vir
z_real

20
0
−20
0

1

2

3

4

5

6

Time (s)

Fig. 4. Comparison between virtual and real IMU on the TotalCapture dataset. Distribution mapping has been applied to the
virtual IMU data.

TotalCapture dataset [90] which contains time-synchronized (real) IMU data and video recordings (from which
the virtual IMU data are extracted). As TotalCapture contains various scripted motions but not labels that are
immediately useful for activity recognition-related tasks, we did not evaluate this dataset in Section 3.
Analysis. Figure 4 shows an example of the virtual and real IMU time-series data of a subject walking, with
sensors placed on their wrist and ankle. Along the x-axis, virtual IMU readings are seen to reflect large movement
changes also observed in the real IMU—one can almost see from the ‘wrist’ time-series (see Figure 4(a)) that
the person is walking with periodic hand movements. Along the z-axis, the virtual IMU is also seen to capture
any spikes in acceleration reasonably well, albeit with a noticeable time lag in the ‘ankle’ case. Virtual and real
IMU data differ the most along the y-axis. We postulate that this is related to a dimensionality issue—we are
trying to reconstruct 3-D information from a 2-D image time series. The y-axis here refers to the axis pointing
perpendicular to the visual plane, which means any acceleration measured along this dimension cannot be easily
deduced visually.
While generating realistic virtual IMU data is important, it is secondary to our main goal of producing virtual
IMU data that captures useful information for HAR tasks. To achieve this, what is vital is the ability of the virtual
IMU data to capture salient features of the activities that we need to recognize. We already see signs of this
happening with the current IMUTube (e.g., the x-axis of the ‘arm’ while walking in Figure 4). This also offers a
possible explanation for the better V2R performance seen in predicting locomotion-style activities in Section 3.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

IMUTube: Automatic Extraction of Virtual on-body Accelerometry from Video for Human Activity Recognition •

87:15

Table 4. Recognition results (mean F1-score, Random Forest) on the 4-class activity recognition task from Opportunity
when using training data from other data sources (top rows) and from Opportunity itself (last row, provided for reference).
Without distribution mapping, there is a significant drop in performance when using training data collected under different
circumstances than the test case, regardless of whether the IMU data is real (66%) or virtual (64%). This is resolved when
distribution mapping is applied.

Train data source
Virtual data
PAMAP2
Realworld
Opportunity

Without mapping
0.2949±0.0041
0.2770±0.0040
0.2828±0.0041
0.8272±0.0034

With mapping
0.7757±0.0037
0.6931±0.0041
0.6637±0.0043
-

Perhaps IMUTube, in its current form, is best suited to capture information about simple motions (i.e., ones
mostly characterized by movement in a 2D plane) of which there is still a wide variety, and to which existing
HAR methods still struggle to generalize [46] (for additional qualitative observations see Section 6.2). To apply
IMUTube to more complex activities, it may require improved techniques during virtual IMU data generation
(also discussed further in Section 6.2).

4.2

Coping with Domain Shift

The last step of our pipeline performs a distribution mapping post-processing step between virtual and real
data (Section 2.5). Applying some form of distribution mapping is necessary due to the presence of domain shift
between training and testing data. This domain shift is not exclusive to extracting virtual sensor data from videos,
but it is also present whenever data is taken from different tasks (or datasets) which result in dissimilar data
distributions between training and testing [13].
Method. Our first experiment is to compare the recognition performance on the Opportunity dataset with models
trained using data from sources other than Opportunity, with or without distribution mapping. Specifically, the
train data can be i) real IMU data from PAMAP2, ii) real IMU data from Realworld, or iii) virtual IMU data from
Realworld videos (Section 3.1). Without distribution mapping, we use all available data in the respective datasets
that fall under the 4 Opportunity classes (stand, walk, sit, lie) for training, and test using the entire Opportunity
dataset. With distribution mapping, we follow a leave-one-subject-out evaluation scheme; In each fold, we train
the model using data distribution-mapped with data only from the corresponding train subjects in Opportunity,
and evaluate on the remaining test subject.
In our second experiment, we focus on the virtual and real IMU used in the 4 datasets described in Section 3,
i.e., Realworld, Opportunity, PAMAP2 8-class and 11-class. We aim to understand how much real IMU data is
needed for distribution mapping on the virtual IMU data. To do so, we vary the amount of real IMU data used for
distribution mapping and evaluate at what point do the virtual and real IMU data distribution become sufficiently
similar. We report the similarity between each data distribution using the Frechet Inception Distance (FID), a
metric commonly used in generative modeling to compare the real and generated datasets [33, 53]; lower FID
scores indicate more similar data distributions. We also report the confidence interval as calculated by randomly
sampling real IMU data with 10 different random seeds for distribution mapping.
Analysis. In Table 4, the effects of domain shift are demonstrated by the significant drop in the performance seen
in the ‘without mapping’ column. When using training data not from Opportunity – despite having the same
activity labels – even models trained with real IMU data (from PAMAP2 and Realworld) suffer a 66% drop in
F1-scores. From this, it is clear that the domain shift issue is not exclusive to the shift present between virtual and
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

87:16

•

Kwon and Tong, et al.

Realworld (8-class)

Opportunity (4-class)

20.0
60

FID

17.5
15.0

50

12.5
40

10.0

30

7.5

PAMAP2 (8-class)

10

PAMAP2 (11-class)
8

FID

8
6
6
4

4
0

200
400
600
800
Real training data per class (s)

1000

0

200
400
600
800
Real training data per class (s)

1000

Fig. 5. Frechet Inception Distance (FID) and confidence interval (shaded area) between virtual IMU and real IMU data
distributions after performing distribution mapping of the virtual IMU data with increasing amounts of real IMU samples.
The dotted horizontal line is the FID score obtained when the entire real IMU dataset is used for distribution mapping.

real IMU domains. The drop in performance is resolved when we perform distribution mapping (Section 2.5); we
even observe that training from virtual data outperforms training using other real IMU datasets. This hints that
virtual data might have greater value than real IMU data in developing general HAR models. This conclusion was
also supported by the results seen when performing the same analysis on the PAMAP2 and Realworld datasets.
Figure 5 shows how the virtual/real FID score varies with the quantity of real IMU data used for distribution
mapping. In all four cases, an abrupt, significant drop in the FID score is seen with the use of under 100 seconds
of real IMU samples. When using 10 minutes of real IMU data per class for distribution mapping, the FID scores
are within 6% of the final FID score (when all real IMU is used for distribution mapping).

4.3

Varying the Mixture and Size of Training Data

Here, we inspect how varying the mixture and size of training data affects recognition performance on the four
datasets considered in Section 3.
Method. Our first experiment compares the F1-scores achieved by models trained with a mixture of real and
virtual IMU data (fixed at 1:1 ratio) as the amount of training data is varied. We repeat this on all 4 datasets
and plot the respective learning curves to inspect if the performance gain by Mix2R over R2R is consistent. Our
second experiment compares the F1-score achieved by models trained with a mixture of real and virtual IMU data,
where the real IMU data is fixed at 300 seconds per class, but real-to-virtual data ratio is varied from 1:1 to 1:10.
Analysis. Figure 6 shows the learning curves on each dataset as the amount of training data is varied. For 3 out of
4 datasets, Mix2R outperforms R2R consistently by a clear margin at every inspected point of the learning curves.
The greatest performance gain is observed throughout the Realworld learning curve, with an increase of at least
9% in F1-score by Mix2R over R2R. Similar trajectories are observed on Opportunity and PAMAP2 (8-class), with
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

IMUTube: Automatic Extraction of Virtual on-body Accelerometry from Video for Human Activity Recognition •

F1-score

Realworld (8-class)

Opportunity (4-class)

0.64

0.875

0.62

0.850

0.60

0.825

0.58

0.800

0.56

R2R
Mix2R
best R2R
best Mix2R
best V2R

0.775

0.54

PAMAP2 (8-class)

F1-score

87:17

PAMAP2 (11-class)

0.70

0.70

0.65

0.65

0.60

0.60
0

100
200
300
400
500
Real training data per class (s)

600

0

100
200
300
400
500
Real training data per class (s)

600

Fig. 6. Mix2R and R2R performance of a random forest model on 4 different HAR tasks when different amounts of real data
per class (in seconds) are used for training. The ratio of virtual data and real data is kept at 1:1 at all datapoints.

the most significant difference between Mix2R and R2R occurring when very limited training data are available
(under 100 seconds per class).
On PAMAP2 (11-class), Mix2R outperforms R2R when there are only 10 samples per class, and both Mix2R and
R2R curves plateau when there are more data available. Given that PAMAP2 (11-class) is also the case where we
predict complex activities under the most dissimilar settings, the plot highlights the difficulty of the classification
task for both real and virtual IMU data.
Although it may appear that the learning performance saturates with relatively small amount of data per class
(600 seconds per class, for instance) – we highlight that this has been commonly observed in the literature for
the HAR datasets we used (Opportunity, PAMAP2, e.g., [31, 73, 99]).
Next, we evaluate the performance achieved when varying virtual and real IMU data mixtures, as presented in
Table 5. When compared to the F1-scores of models only trained from real data, adding virtual data to training is
seen to give a better or comparable performance at all considered ratios on Realworld, Opportunity, and PAMAP2
(8-class). On Realworld, the greatest gain is seen at 1:5, where the F1-score is increased by 9% over that at 1:0; At
the ratio 1:1, both Opportunity and PAMAP2 (8-class) see improvements of 6%. The performance however does
not increase monotonically with the addition of more virtual data. This shows that the effect of mixing virtual
and real data is not straightforward. It is possible that as more virtual IMU data is used, the domain shift issue
becomes severe and the Random Forest classifier starts to overfit to the virtual IMU data. Adding virtual data
has a detrimental effect on PAMAP2 (11-class). This follows our observations in Figure 6 and can be similarly
explained by PAMAP2 (11-class) containing complex activities under the most dissimilar settings in comparison
to the virtual IMU data.
Hence, we suggest finding the right balance between the amount of real and virtual IMU data for a model to
learn the target activity pattern coexisting in both real and virtual IMU data, before overfitting to the virtual IMU
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

87:18

•

Kwon and Tong, et al.

Table 5. Recognition results (mean F1-score, Random Forest classifier) on all datasets. Different amounts of virtual data are
added to a constant amount of real data, given in seconds per class.

Real
Data
300
300
300
300
300

Virtual
Data
0
300
600
1500
3000

Real :
Virtual
1:0
1:1
1:2
1:5
1:10

RealWorld
0.5706±0.0025
0.6230±0.0025
0.6146±0.0025
0.6247±0.0024
0.6061±0.0025

Opportunity
0.8214±0.0034
0.8738±0.0029
0.8637±0.0030
0.8503±0.0032
0.8396±0.0031

PAMAP2
(8-class)
0.6869±0.0056
0.7284±0.0053
0.7006±0.0055
0.6926±0.0055
0.6792±0.0056

PAMAP2
(11-class)
0.7206±0.0044
0.6978±0.0045
0.7051±0.0045
0.6898±0.0045
0.6824±0.0046

data. We also anticipate that as the quality of virtual IMU improves in future versions of IMUTube, that larger
amounts of it will be able to be successfully integrated during HAR training.

5 TRANSFER LEARNING WITH VIRTUAL IMU DATA FOR HAR CLASSIFIERS
In the previous two sections, we have demonstrated that sensor-based human activity classifiers can learn from
virtual IMU data, although limitations still exist. So far, we have assumed that labeled virtual and real IMU
datasets for target activities are always available. In practice, such a scenario may not always be possible. For
example, curating video datasets for virtual IMU data could be challenging, as titles or descriptions of videos can
be arbitrarily ambiguous.
Here, we explore two additional cases for utilizing virtual IMU data: i) when the virtual IMU dataset contains a
subset of target activity labels; ii) when labels for virtual IMU are not available at all. To do so, we leverage two
transfer learning setups, supervised and unsupervised, respectively. The analysis in this section represents our
first attempts in utilizing more sophisticated modeling techniques from deep learning to extend the contribution
of IMUTube. Our results are a first step towards handling realistic issues in label collection, as we do not yet
incorporate any automated video labeling or search mechanisms. All experiments follow the same hold-out
evaluation protocol detailed in Section 3.

5.1

Supervised Transfer Learning

With supervised transfer learning, we pre-train a model using labeled virtual IMU data and fine-tune it using
labeled real IMU data. Importantly, the labels for pre-training and fine-tuning need not match. We first explore
the setup where virtual and real IMU data share the same set of activity labels – Imagine we have already curated
video and virtual IMU data for some targeted activities, and also collected a small amount of real IMU data; instead
of waiting until sufficient amounts of real IMU data is collected, we can first train a model on the virtual IMU
data and fine-tune on the small-scale real IMU data. By studying this scenario, we can also gauge if pre-training
with virtual data might provide any benefits to activity recognition performance.
Next, we consider a scenario where the virtual IMU data only contains a subset of the real IMU data activity
classes. To examine this, we pre-train a model on the virtual PAMAP locomotion (8-classes) task and fine-tune it
on the complex activities (11-classes) tasks.
Method. We compare the recognition performance of DeepConvLSTM models i) trained only with real data and ii)
pre-trained on virtual and fine-tuned on real IMU data. The former is the same as the R2R case in Section 3. For ii),
we randomly split the virtual IMU data into train/validation/test (80%/10%/10%) and pre-train the network using
the virtual IMU training data. During fine-tuning, all model weights are updated and we report the performance
on the real IMU test dataset; In the case where real and virtual IMU activity labels do not match, we replace the
last layer of the pre-trained model with the target number of classes (thereby going from 8 to 11 activity classes
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

IMUTube: Automatic Extraction of Virtual on-body Accelerometry from Video for Human Activity Recognition •

87:19

Table 6. Recognition results (mean F1-score) of transfer learning setups when evaluated on different HAR tasks. R2R is the
baseline trained on real data from scratch. Transfer learning (TL) results show the performance of the models fine-tuned on
real data.

Pre-training
Realworld
Opportunity
PAMAP2 (8-class)
PAMAP2 (11-class)
PAMAP2 (8-class)

Fine-tuning
Realworld
Opportunity
PAMAP2 (8-class)
PAMAP2 (11-class)
PAMAP2 (11-class)

DeepConvLSTM
Supervised R2R Supervised TL
0.7305±0.0073 0.8337±0.0061
0.8871±0.0074 0.9100±0.0067
0.7002±0.0161 0.7137±0.0159
0.6977±0.0129 0.7023±0.0129
0.7071±0.0129

Realworld (8-class)

Opportunity (4-class)

0.8
F1-score

CAE+RF
Unsupervised R2R Unsupervised TL
0.7923±0.0067
0.7718±0.0069
0.8896±0.0074
0.8477±0.0084
0.6471±0.0168
0.6809±0.0164
0.7004±0.0129
0.6989±0.0129
-

0.8

0.6
0.6
0.4
0.4
0.2
R2R
Supervised TL
best R2R
best Supervised TL
beset V2R

0.2
0.0

F1-score

PAMAP2 (8-class)

PAMAP2 (11-class)

0.7

0.7

0.6

0.6

0.5

0.5

0.4

0.4

0.3
0

1000
2000
3000
No. of real windows per class

4000

0.3

0

1000
2000
3000
No. of real widows per class

4000

Fig. 7. Transfer learning vs. amount of real data used for training.

for PAMAP2) and update all the network weights. We present results on all 4 datasets and follow the training
and evaluation protocols described in Section 3.
Results. The left of Table 6 shows the differences in F1-scores achieved by DeepConvLSTM models with (Supervised TL) and without pre-training (Supervised R2R) when evaluated on a random test subject. With pre-training,
statistically significant performance gains are observed on Realworld and Opportunity, at 14% and 3% respectively.
We further present the effects of using different amounts of real IMU data for fine-tuning the selected base model
in Figure 7. We see the most obvious difference in learning trajectories on the Realworld dataset, where only a
small amount of real data is needed to fine-tune the base model such that it surpasses R2R performance. In the
last row of Table 6, we also show results for transfer learning in the case where virtual and real IMU data labels
do not match (PAMAP2 8-class for pre-training, PAMAP2 11-class for fine-tuning). In this case, the model with
pre-training achieves an F1-score of 0.71 on PAMAP2 (11-class), which is statistically comparable to the result in
the R2R setting.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

87:20

•

Kwon and Tong, et al.

5.2

Unsupervised Transfer Learning

Unsupervised transfer learning considers the scenario where we extract the virtual IMU data from a large body
of videos without labels. Curating a collection of unlabeled videos is easier relative to obtaining labeled videos,
particularly in scenarios where the video descriptions/labels may be unreliable. Without a set of specific target
activities in mind, any videos with humans can be utilized. Validating the feasibility of this approach represents
a first step towards curating a large collection of virtual IMU data, consisting of very diverse movements and
activities from which a model can learn generic representations.
Method. Our unsupervised transfer learning setup consists of two stages. The first stage pre-trains a convolutional
autoencoder (CAE) to learn feature representations. The second stage extracts from real IMU data the learned
representations, which are then used to train a random forest classifier. We compare the recognition performance
achieved by the entire CAE-RF setup when: i) virtual IMU data is used for training the CAE (Unsupervised TL);
and ii) when real IMU data is used for training the CAE (Unsupervised R2R).
We use Haresamudram et al.’s architecture, where the encoder contains four convolutional blocks, leading
to the bottleneck layer [31]. Each block contains two 3x3 convolutional layers followed by 2x2 max-pooling.
Batch normalization is applied after each layer [37]. The output from the last convolutional block is flattened
before being connected to the bottleneck layer. The decoder inverts the encoder by performing convolution,
interpolation, and padding to match the sizes of the corresponding encoder blocks [58]. ReLU activation [57]
is used throughout, except the output, where the hyperbolic tangent function is used instead. We follow the
evaluation protocol used in the DeepConvLSTM case.
Results. The right part of Table 6, shows results for using virtual IMU for pre-training with varying performance
relative to models trained on real IMU data. On Realworld, Opportunity and PAMAP2 (11-class), unsupervised
TL using virtual IMU data reached up to 95% − 100% of R2R F1-scores. On PAMAP2 (8-class), we even see an
increase of 5% over the R2R protocol. These results demonstrate the feasibility in utilizing virtual IMU data even
in scenarios where video labels are completely absent.

6 DISCUSSION
In this section, we discuss the implications of the results presented, limitations in our approach, and highlight
opportunities which this work opens up.

6.1

Demonstrating Feasibility

We have presented a processing pipeline and a series of validation studies to support our thesis that an automated
pipeline from video to virtual IMU data can replace the labor-intensive practice of collecting labeled datasets
from real on-body IMU devices. IMUtube shows how a full three-axis virtual accelerometer sensor derived from
arbitrary videos can be utilized for human activity recognition. The automated pipeline provides the opportunity
to collect much larger labeled data sets, which in turn can improve classifiers for human activity recognition.
Our validation experiments explored ways to model virtual IMU data, either standalone or in conjunction with
real IMU data. On three different datasets (Realworld, Opportunity and PAMAP2 8-class), training from virtual
IMU alone led to competitive results compared to those from real IMU data (recovering up to 90%), and a simple
mixing of data from two sources brought considerable gains (4%-12% increase) to recognition performance.
PAMAP2 11-class is a special case as the activity recognition task extends to complex, non-locomotion human
activities, such as vacuum cleaning. It is also different because we have utilized a diverse range of video data
collected over multiple visual datasets. Our results show that we can indeed still learn from virtual data under
such settings, and our V2R results still reach at least 80% when compared to R2R (Table 3a). However, what
is still missing is that we have not seen an improvement over R2R results through mixing (2% decrease) or
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

IMUTube: Automatic Extraction of Virtual on-body Accelerometry from Video for Human Activity Recognition •

87:21

transfer learning (insignificant change). While this suggests that modeling complex activities and mixed data
sources remain issues, we believe that modelling complex activities, and by extension, the merit of using more
accelerometry data (be it virtual or real) still warrants further investigation. For example, is there simply an
upper bound to predicting these complex activities using motion-based data alone?

6.2

Limitations and Extensions of Current Approach

We have utilized a series of off-the-shelf techniques at every step of the proposed pipeline in Section 2. While this
supports reproducibility of our results, it does result in limitations that impact the overall quality of labeled data
for HAR. We discuss the known limitations of each step of the pipeline and present steps forward to advance this
line of research.
6.2.1 From Vision To Pose. Accurate recovery of the human skeleton pose from videos has known limitations
arising from the movement of both the subjects as well as the camera.
The 2D pose estimator used in IMUTube, OpenPose, has previously known failure scenarios including partial
detection of joints, swapping between left and right for rare poses, self-occlusion from the camera viewpoints,
and partially visible bodies [10]. Such errors in the estimated 2D pose propagate to the 3D pose estimation, which
itself is a challenging problem due to the inherent uncertainty of the added third dimension [63]. Erroneous
2D and 3D poses may distort corresponding perspective projections (PnP) between the poses leading to wrong
3D pose calibration [38]. Depth map or camera ego-motion estimation for a dynamic scene can be imprecise
when having occlusions or motion blur between foreground and background objects, or when light condition
changes [25]. Therefore, the current pipeline can result in distorted 3D motion due to the accumulated errors,
since these challenges are common for videos in the wild.
For the recovery of the human skeleton pose, we would expect improvements based on solutions that leverage
more sophisticated pose tracking techniques that are more robust to vigorous movement, a change of scenery, the
presence of multiple people, and occlusion. Also, camera movements relative to the people captured in the videos
could come from the instability of the camera (e.g., for hand-held cameras) as well as video filming techniques
(e.g., panning shots). Specialized video stabilization strategies or camera ego-motion techniques can address these
issues [80, 96, 100]. We believe that the application of these techniques (and others not yet mentioned or even
developed) will further improve pose extraction quality and expand the variety of videos that can be treated as
input to our pipeline.
6.2.2 From Pose To Accelerometry. Our current approach assumes an equivalence between acceleration measured
by a device on the wearer’s body with that measured at the nearest body joint. This view discounts any consideration of factors such as body mass, device movement and skin friction. To better model the on-body location of IMU
devices, utilizing techniques from body mesh modeling is a straightforward solution to increase realism to the
pipeline. We foresee that investigating the use of body mesh might also bring up the possibilities of synthesizing
credible accelerometry data from people of different body shapes from the movement of a single human skeleton
pose [39, 52, 68]. In addition, while we have only considered the generation of virtual accelerometry data in this
work, we can adapt most parts of the pipeline to generate the full set of IMU signals, including gyroscope and
magnetometer readings.
6.2.3 From Accelerometry to Virtual IMU. Real IMU data, which have been the basis of building HAR classifiers,
are not free of noise. Sensor noise may come from factors such as drift, hysteresis and device calibration. To carry
over such characteristic sensor noise on our virtual data, domain adaptation techniques can be deployed as well
as more sophisticated techniques like Generative Adversarial Networks. [24, 75]

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

87:22

•

Kwon and Tong, et al.

6.2.4 Learning from Virtual Data. A domain shift exists when a machine learning model is trained from virtual
data and tested on real IMU data. Again, domain adaptation strategies to the input of the machine learning model
is a solution. Alternatively, it will be promising to investigate domain-invariant features learned from virtual and
real data, which could potentially lead to performance gains in HAR.
6.2.5 Which Videos are Currently Suitable for IMUTube? Our qualitative inspection of the IMUTube output and
the per-class V2R results suggests that certain video features may contribute to poorer recognition performance
on virtual IMU data: large ego-motions, multiple moving objects and people, and occlusion.
Large ego-motions can be found in the Realworld ‘running’ videos in which the video-taker was also running,
leading to significant vertical shaking motion from the camera itself. It is possible that such vertical motions
end up producing features that are very similar to those from a ‘jumping’ motion, which may explain a higher
class confusion observed between ‘running’ and ‘jumping’ on the Realworld and PAMAP2 (8-class) tasks. An
additional factor might have come from the presence of multiple moving objects and people in the background
(e.g. pedestrians) in the ‘running’ videos.
We also found that V2R models struggle more in classifying activities with similar poses which have more
subtle differences in limb movements, e.g. ‘standing‘ vs. ‘vacuum cleaning‘, ‘sitting’ vs. ‘ironing’, as in PAMAP2
(11-class). In many ‘vacuum cleaning’ and ‘ironing’ videos, the subject’s arm movements are occluded by objects
in the scene, e.g. clothes or home furniture.
On the other hand, videos with fewer or without such motion artifacts tend to produce virtual IMU data
that are well-classified under V2R. Moreover, videos featuring activities with distinctive poses and motions, e.g.
cycling, are well-classified under the V2R setting. There are also many existing techniques that will allow us to
further tackle motion blur ([1, 81]) and occlusion ([23, 71]). It is also possible that the future curation of video
data can automatically rank videos by the presence of these undesirable features to arrive at a suitable dataset for
virtual IMU data extraction.

6.3

The Road Ahead

Our primary goal in this paper was to motivate the HAR community with a promising approach that overcomes
the main impediment to progress—lacking large labeled data sets of IMU data. While technical challenges remain,
we have validated this approach and provide a processing pipeline that the community can collectively develop.
Here we highlight the most compelling research opportunities.
6.3.1 Large-scale Data Collection. The ultimate goal, as suggested by the name of IMUTube for our initial tool,
is to develop a fully automated pipeline that begins with the retrieval of videos representing particular human
activities from readily available sources (e.g., YouTube) and converts that video data to labeled IMU data. Since
it is much more common to have video evidence of the wide variety of human behaviors, this is an obvious
advantage over past labor-intensive and small-scale efforts to produce such HAR datasets. We have shown great
promise with this direction, and above listed some known limitations that can be addressed by different vision,
signal processing, and machine learning techniques. The reader will note that the videos used for our validation
studies were also curated, meaning there was a significant effort in selecting appropriate video examples. The
hope is that this curation effort can also be reduced and ultimately eliminated because the sheer number of
relevant videos will overcome the deficiencies of less useful video data.
6.3.2 Deep Learning. Deep Neural Networks have transformed recognition rates in other fields [32, 60], but
HAR has lagged behind, again due to the lack of large corpora of labeled data. While we expect that IMUTube is
a significant advance towards that goal, having the data alone is not the end goal. We have not yet produced a
large-scale HAR dataset, and until we do so we can only hope that deep learning techniques will take over. We
then fully expect HAR to inform deep learning techniques.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

IMUTube: Automatic Extraction of Virtual on-body Accelerometry from Video for Human Activity Recognition •

87:23

6.3.3 Extending the Field of HAR. An important advantage to generating virtual IMU data is that we can place
the virtual sensor in a wide variety of places on the human body. While some of the standard datasets we used
in this work have subjects wearing multiple IMUs, there are limits to how many devices one can wear and still
perform activities naturally. IMUTube removes that limitation. Now, for any given activity, we can experimentally
determine where to place one IMU (or multiple IMUs) to best recognize that activity. For a set of activities, which
place optimizes the recognition of all of the activities in that set. We have never had the ability to contemplate that
kind of question. We also need not limit to IMUs placed directly on the body. Models of how clothing responds
on a body might be used to generate virtual IMU data for objects that are loosely connected to the body [2, 67].
HAR can now inform clothing manufacturers of where in the material for a shirt, for example, one would want
to integrate IMU data collection to predict the activities of the person wearing the shirt, or any other piece of
clothing for that matter [41, 56].
6.3.4 Real IMU as ‘Seeds’ to Our Pipeline. While IMUTube is about generating lots of virtual IMU data, our
results show the value for the more traditional curated datasets from real IMU data. The real IMU data provides a
seed that the virtual data grows into more sophisticated HAR models. Now the efforts in real IMU data collection
can be focused on producing very high quality labeled data from a wide enough variety of subjects performing
key activities. It may even be the case that this real IMU seed data is the treasured commodity that companies
can use to provide the best seeds for IMUTube-generated virtual IMU data and the models grown from them.

7 RELATED WORK
The proposed method details a pipeline towards opportunistically extracting virtual sensor data from a potentially
very large body of publicly available videos. This is in contrast to current wearable sensor data collection protocols,
which involve user studies and human participants, as well as other approaches that generate sensor data from
motion capture (mocap) settings. In what follows, we first discuss approaches to data collection for sensor-based
human activity recognition as well as mocap based techniques. These approaches represent the state-of-the-art
in the field that are based on dedicated data recording protocols. Subsequently, we detail prior work on training
classifiers with limited labeled data, thereby focusing on data augmentation techniques and transfer learning.

7.1

Sensor Data Collection in HAR

Sensor data collection for human activity recognition is often performed by conducting user studies [14, 72, 97].
Typically, the participants in a study are asked to perform activities in laboratory settings while wearing a sensing
platform. The advantage of data recording in a lab setting is that in addition to sensor data typically video data
is recorded that is subsequently used for manual data annotation. For this purpose, the sensor and video data
streams need to be synchronized [65], and human annotators need to be trained for consistency in annotation. The
laboratory is designed to resemble a real-world environment, and user activities are either scripted or naturalistic.
These include various gesture and locomotion level activities. However, designing a lab study to capture realistic
natural behaviors is difficult. The protocol of such studies makes it challenging to collect large scale datasets.
Furthermore, the annotation of activities is costly and error-prone and therefore prohibitive towards creating
large datasets as they are required for deriving complex machine learning models.
Recently, Ecological Momentary Assessment (EMA) based approaches have been employed to record and
especially annotate real-world activity data [35, 47, 88]. The sensing apparatus (containing sensors such as
accelerometers or full-fledged IMUs) is worn on-body, and users self-report the activity labels when they are
asked to do so through direct notification. Although these methods may lose sample-precise annotation of the
activities, they encourage the collection of larger-scale datasets. While limited to gesture-based activities, Laput
and Harrison [47] have shown that larger numbers (83) of fine-grained hand activities can be reliably recorded
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

87:24

•

Kwon and Tong, et al.

and annotated. Both in-lab and EMA based collection protocols directly involve human participants to collect
movement data using body-worn sensors.
Other approaches have explored alternative data collection methods that do not directly involve human
participants. Kang et al. render a 3D human model on computer graphics software and simulate human activities
[40]. The sensor data is extracted from the simulated human motion, and subsequently used to train the recognition
models. However, it is very difficult to realistically simulate and design complex human activities. Therefore, such
methods typically only explore simple gestures and locomotion activities. Alternatively, [87, 92] extract sensory
data from public, large-scale motion capture (mocap) datasets [45, 54, 59], which contain a variety of motions
and poses for human activity recognition. Although these datasets cover hundreds of subjects and thousands of
poses and motions, they rarely include everyday activities. The majority of such mocap datasets include dancing,
quick locomotion transitions, and martial arts, which are less relevant to recognizing daily human activities.
Most related to our work, Rey et al. [74] also proposed to collect virtual sensor data from online videos
and demonstrated the effectiveness of the virtual sensor data for recognizing fitness activities. Their approach
computes the 2D pose motion for a single person in the video with a fixed camera viewpoint. A regressor is
trained for a target real sensor with the synced video and accelerometer recordings, which transfers the changes
in joint locations from the 2D scene to the norm of the three-axis accelerometer. In contrast, our work can
generate data from the full IMU (three-axis accelerometer, gyroscope, and simulated magnetometer). Further, we
perform 3D motion estimation from videos with multiple people and scenes in the wild using camera motion
tracking. We do not require synced video and wearable recordings as the virtual sensor can be adapted to any
real sensor with our efficient distribution mapping method.
We leverage the availability of large scale video datasets that cover real-world activities to extract sensory
data. These videos are recorded in-the-wild and contain a wide range of activities, including everyday activities,
which makes them very attractive for deriving realistic and robust human activity recognition systems.

7.2 Tackling the Sparse Data Problem
Many publicly available datasets for human activity recognition contain imbalanced classes. For example, approximately 75% of the Opportunity dataset (which has 18 classes in total) [14] consists of the null class [27],
making it challenging to design classifiers. The activities being studied also impact the class imbalance to some
extent. In the PAMAP2 dataset, the skipping rope class constitutes approximately 2.5% of data, relative to other
activities which constitute around 9% on average [27]. This follows reason as, unless your name is Rocky Balboa,
it is harder for subjects to perform rope skipping for longer durations of time, in contrast to walking or lying
down. This resulting class imbalance poses a challenge for the design and training of classifiers, which may find
it easier to simply predict the majority class. Furthermore, the relatively small size of labeled datasets results in
models quickly overfitting and does not allow the application of complex model architectures. It is also difficult
to apply potentially alleviating techniques such as transfer learning, which rely on large datasets for knowledge
transfer. As a result, [89] have noticed that the adoption of deep learning methods in human activity recognition
has not yet translated to the pronounced accuracy gains seen in other domains.
As a way to overcome the problem of small, class-imbalanced datasets, data augmentation techniques have
been applied previously to prevent overfitting, improve generalizability and increase variability in the datasets.
They involve techniques that systematically transform the data during the training process in order to make
classifiers more robust to noise and other variations [55]. They artificially inflate the training data by utilizing
methods, which perform data warping, or oversampling [82]. Data warping includes geometric transformations
such as rotations, and cropping, as well as adversarial training. For time series classification, the data warping
techniques include window slicing, window warping, rotations, permutations and dynamic time warping [20, 48].
Several of these transformations can be combined to further improve the performance over a single method.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

IMUTube: Automatic Extraction of Virtual on-body Accelerometry from Video for Human Activity Recognition •

87:25

Um et al. demonstrate that combining three basic methods (permutation, rotation and time warping) yields
better performance than using a single method [91]. In [70], construction equipment activity recognition is also
improved by combining simple transformations.
Recently, data generation using either oversampling or generative adversarial networks (GANs [82]) have also
been successfully introduced to sensor-based human activity recognition [93]. However, in contrast to other
domains such as computer vision, performance improvements remain moderate, most likely due to non-trivial
challenges inherent to generating realistic yet novel timeseries data. Oversampling based methods include
synthetic minority oversampling technique (SMOTE) [22]. GANs have been used to, for example, augment
biosignals [30] or in IoT [93]. Extending the conventional GAN approach, in [69], a data augmentation technique
for time series data with irregular sampling is proposed utilizing conditional GANs. It is shown to outperform
data warping techniques such as window slicing and time warping. Augmentation for wearable sensor data has
been explored for monitoring Parkinson’s disease in [91]. In this paper, seven transformations, including jittering,
scaling, rotation and warping are detailed and their effects relative to no augmentation is studied. Further, the
authors observed that combining multiple transformations results in higher performance. In [85], augmentation
is performed on IMU spectrogram features to improve the activity recognition performance.
Another approach to deal with small labeled datasets includes transfer learning. Here, a base classifier (typically
a neural network) is first trained on a base dataset and task. Subsequently, the learned features are re-purposed,
or transferred, to a second target network to be trained on the target dataset and task. In particular, if the target
dataset is significantly smaller compared to the base dataset, transfer learning enables training a large target
network without overfitting [94], and typically results in improved performance. In [77], the authors propose
a self-supervision pretext task and demonstrate its effectiveness for unsupervised transfer learning on other
datasets with little labeled data. A more extreme example of having very small labeled datasets includes one-shot
and few-shot learning, which contain very few labeled samples per class [21].
While the data augmentation techniques do improve the classification performance, they, ultimately, produce
perturbed training samples. Therefore, they are unable to provide for the variety in human movements that is
obtained by collecting data from a large number of subjects. On the other hand, the GAN based techniques perform
augmentation by sampling from the dataset distribution. However, they require substantial amounts of data to
train, and may suffer from training instability and non-convergence [93]. Furthermore, there is limited prior
work studying data augmentation by GANs for wearable sensor data and their actual suitability for sensor-based
human activity recognition remains to be shown. This makes it challenging to readily apply these generative
networks to create more data.
We tackle the problem of having small labeled datasets with a different approach – by generating large quantities
of virtual IMU data from videos. As we can leverage a large body of videos, containing many individuals, we
generate datasets containing more diverse movements and potentially much larger datasets of realistic data,
which is in stark contrast to existing methods that try to combat the sparse data problem.

8

CONCLUSION

In this paper we developed a framework for generating virtual IMU data based on automated extraction from
video as a means to collect large-scale labeled datasets to support research in human activity recognition (HAR).
We designed and validated our framework, IMUTube, that integrates a collection of techniques from computer
vision, signal processing, and machine learning. Our initial findings show great promise for this technique to
extend the capabilities for HAR, at a minimum for simple activities whose main IMU characteristics are confined
to expression in 2D.
The greater promise of this work requires a collective approach by computer vision, signal processing, and
activity recognition communities (who have already been greatly united through the advances of deep learning)
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

87:26

•

Kwon and Tong, et al.

to advance the underlying agenda. Computer vision researchers can clearly build upon the IMUTube pipeline
to address a variety of current limitations, further automating the pipeline and reducing the need for human
curation of online videos. Signal processing advances can further manipulate the virtually-generated data to
better condition the virtual data and represent the features and distributions of real IMU data. Activity recognition
researchers can apply known modern learning techniques to this new class of labeled data for HAR and develop
more effective ways to model, both with and without a mixture of real IMU data. Within a few years, we expect
this collective effort to result in HAR as yet another success story for large-data-inspired learning techniques.

REFERENCES
[1] S. Alireza Golestaneh and L. Karam. 2017. Spatially-varying blur detection based on multiscale fused and sorted transform coefficients
of gradient magnitudes. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 5800–5809.
[2] T. Alldieck, M. Magnor, B. Bhatnagar, C. Theobalt, and G. Pons-Moll. 2019. Learning to reconstruct people in clothing from a single
RGB camera. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 1175–1186.
[3] M. Andriluka, L. Pishchulin, P. Gehler, and B. Schiele. 2014. 2D Human Pose Estimation: New Benchmark and State of the Art Analysis.
In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).
[4] P. Asare, R. Dickerson, X. Wu, J. Lach, and J. Stankovic. 2013. BodySim: A Multi-Domain Modeling and Simulation Framework for
Body Sensor Networks Research and Design. In International Conference on Body Area Networks (BODYNETS). ICST.
[5] M. Bächlin, M. Plotnik, and G. Tröster. 2010. Wearable assistant for Parkinson's disease patients with the freezing of gait symptom.
IEEE Trans. Inf. Technol. Biomed. 14, 2 (2010), 436–446.
[6] P.J. Besl and N. McKay. 1992. A method for registration of 3-D shapes. IEEE Transactions on Pattern Analysis and Machine Intelligence
14, 2 (February 1992), 239–256.
[7] A. Bewley, Z. Ge, L. Ott, F. Ramos, and B. Upcroft. 2016. Simple online and realtime tracking. In IEEE International Conference on Image
Processing (ICIP). 3464–3468.
[8] O. Bogdan, V. Eckstein, F. Rameau, and J. Bazin. 2018. DeepCalib: a deep learning approach for automatic intrinsic calibration of wide
field-of-view cameras. In Proceedings of the ACM SIGGRAPH European Conference on Visual Media Production. ACM, 6:1–6:10.
[9] F. Caba Heilbron, V. Escorcia, B. Ghanem, and J. Carlos Niebles. 2015. Activitynet: A large-scale video benchmark for human activity
understanding. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 961–970.
[10] Z. Cao, T. Simon, S. Wei, and Y. Sheikh. 2017. Realtime multi-person 2d pose estimation using part affinity fields. In The IEEE Conference
on Computer Vision and Pattern Recognition (CVPR). 7291–7299.
[11] B. Caprile and V. Torre. 1990. Using vanishing points for camera calibration. International Journal of Computer Vision 4, 2 (March 1990),
127–139.
[12] J. Carreira, E. Noland, C. Hillier, and A. Zisserman. 2019. A short note on the kinetics-700 human action dataset. arXiv preprint
arXiv:1907.06987 (2019).
[13] Y. Chang, A. Mathur, A. Isopoussu, J. Song, and F. Kawsar. 2020. A Systematic Study of Unsupervised Domain Adaptation for Robust
Human-Activity Recognition. 4, 1, Article 39 (March 2020), 30 pages.
[14] R. Chavarriaga, H. Sagha, and D. Roggen. 2013. The Opportunity challenge: A benchmark database for on-body sensor-based activity
recognition. Pattern Recognition Letter 34, 15 (2013), 2033–2042.
[15] C. Chelba, T. Mikolov, M. Schuster, Q. Ge, T. Brants, P. Koehn, and T. Robinson. 2013. One billion word benchmark for measuring
progress in statistical language modeling. arXiv preprint arXiv:1312.3005 (2013).
[16] Blender Online Community. 2018. Blender - a 3D modelling and rendering package. Blender Foundation, Stichting Blender Foundation,
Amsterdam. http://www.blender.org
[17] W. Conover and R. Iman. 1981. Rank transformations as a bridge between parametric and nonparametric statistics. The American
Statistician 35, 3 (1981), 124–129.
[18] J. Deng, W. Dong, R. Socher, L. Li, K. Li, and L. Fei-Fei. 2009. Imagenet: A large-scale hierarchical image database. In The IEEE Conference
on Computer Vision and Pattern Recognition (CVPR). IEEE, 248–255.
[19] J. Devlin, M. Chang, K. Lee, and K. Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language understanding.
Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language
Technologies 1 (2019), 4171–4186.
[20] H. Fawaz, G. Forestier, J. Weber, L. Idoumghar, and P. Muller. 2018. Data augmentation using synthetic data for time series classification
with deep residual networks. arXiv preprint arXiv:1808.02455 (2018).
[21] S. Feng and M. Duarte. 2019. Few-shot learning-based human activity recognition. Expert Systems with Applications 138 (2019), 112782.
[22] A. Fernández, S. Garcia, F. Herrera, and N. Chawla. 2018. SMOTE for learning from imbalanced data: progress and challenges, marking
the 15-year anniversary. Journal of artificial intelligence research 61 (2018), 863–905.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

IMUTube: Automatic Extraction of Virtual on-body Accelerometry from Video for Human Activity Recognition •

87:27

[23] R. Girshick. 2015. Fast r-cnn. In IEEE International Conference on Computer Vision (ICCV). 1440–1448.
[24] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. 2014. Generative adversarial
nets. 2672–2680.
[25] A. Gordon, H. Li, R. Jonschkowski, and A. Angelova. 2019. Depth From Videos in the Wild: Unsupervised Monocular Depth Learning
From Unknown Cameras. In IEEE International Conference on Computer Vision (ICCV). IEEE.
[26] C. Gu, C. Sun, D. Ross, C. Vondrick, C. Pantofaru, Y. Li, S. Vijayanarasimhan, G. Toderici, S. Ricco, R. Sukthankar, C. Schmid, and J.
Malik. 2018. Ava: A video dataset of spatio-temporally localized atomic visual actions. In The IEEE Conference on Computer Vision and
Pattern Recognition (CVPR). 6047–6056.
[27] Y. Guan and T. Plötz. 2017. Ensembles of deep lstm learners for activity recognition using wearables. Proceedings of the ACM on
interactive, mobile, wearable and ubiquitous technologies (IMWUT) 1, 2 (2017), 1–28.
[28] N. Hammerla, R. Kirkham, P. Andras, and T. Ploetz. 2013. On preserving statistical characteristics of accelerometry data using their
empirical cumulative distribution. In Proceedings of the ACM International Symposium on Wearable Computers. 65–68.
[29] N. Y. Hammerla, S. Halloran, and T. Plötz. 2016. Deep, convolutional, and recurrent models for human activity recognition using
wearables.. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI). AAAI Press, 1533–1540.
[30] S. Haradal, H. Hayashi, and S. Uchida. 2018. Biosignal data augmentation based on generative adversarial networks. In Annual
International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC). IEEE, 368–371.
[31] H. Haresamudram, D. Anderson, and T. Plötz. 2019. On the role of features in human activity recognition. In Proceedings of the ACM
International Symposium on Wearable Computers. 78–88.
[32] K. He, X. Zhang, S. Ren, and J. Sun. 2016. Deep residual learning for image recognition. In The IEEE Conference on Computer Vision and
Pattern Recognition (CVPR). 770–778.
[33] M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and S. Hochreiter. 2017. Gans trained by a two time-scale update rule converge to a
local nash equilibrium. In Advances in neural information processing systems. 6626–6637.
[34] G. Hinton, L. Deng, D. Yu, G. Dahl, A. Mohamed, N. Jaitly, A. Senior, V. Vanhoucke, P. Nguyen, T. Sainath, and B. Kingsbury. 2012.
Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. IEEE Signal processing
magazine 29, 6 (2012), 82–97.
[35] K. Hovsepian, M. Al’Absi, E. Ertin, T. Kamarck, M. Nakajima, and S. Kumar. 2015. cStress: towards a gold standard for continuous stress
assessment in the mobile environment. In Proceedings of the ACM international joint conference on pervasive and ubiquitous computing.
493–504.
[36] Y. Huang, M. Kaufmann, E. Aksan, M. Black, O. Hilliges, and G. Pons-Moll. 2018. Deep inertial poser: learning to reconstruct human
pose from sparse inertial measurements in real time. ACM Transactions on Graphics (TOG) 37, 6 (2018), 1–15.
[37] S. Ioffe and C. Szegedy. 2015. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv
preprint arXiv:1502.03167 (2015).
[38] I. Joel, A.and Stergios. 2011. A Direct Least-Squares (DLS) method for PnP. In IEEE International Conference on Computer Vision (ICCV).
IEEE.
[39] A. Kanazawa, M. Black, D. Jacobs, and J. Malik. 2018. End-to-end recovery of human shape and pose. In The IEEE Conference on
Computer Vision and Pattern Recognition (CVPR). 7122–7131.
[40] C. Kang, H. Jung, and Y. Lee. 2019. Towards Machine Learning with Zero Real-World Data. In The ACM Workshop on Wearable Systems
and Applications. 41–46.
[41] S. Kang, H. Choi, H. Park, B. Choi, H. Im, D. Shin, Y. Jung, J. Lee, H. Park, S. Park, and J. Roh. 2017. The development of an IMU
integrated clothes for postural monitoring using conductive yarn and interconnecting technology. Sensors 17, 11 (2017), 2560.
[42] P. Karlsson, B. Lo, and G. Z. Yang. 2014. Inertial sensing simulations using modified motion capture data. In Proceedings of the
International Conference on Wearable and Implantable Body Sensor Networks (BSN). 16–19.
[43] D. Kingma and J. Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).
[44] H. Kuehne, H. Jhuang, E. Garrote, T. Poggio, and T. Serre. 2011. HMDB: a large video database for human motion recognition. In IEEE
International Conference on Computer Vision (ICCV). IEEE, 2556–2563.
[45] Carnegie Mellon Graphics Lab. 2008. Carnegie Mellon Motion Capture Database. http://mocap.cs.cmu.edu/
[46] N. Lane, Y. Xu, H. Lu, S. Hu, T. Choudhury, A. Campbell, and F. Zhao. 2011. Enabling Large-Scale Human Activity Inference on
Smartphones Using Community Similarity Networks. In Proceedings of the International Conference on Ubiquitous Computing. ACM,
355–364.
[47] G. Laput and C. Harrison. 2019. Sensing Fine-Grained Hand Activity with Smartwatches. In Proceedings of the 2019 CHI Conference on
Human Factors in Computing Systems. 1–13.
[48] A. Le Guennec, S. Malinowski, and R. Tavenard. 2016. Data Augmentation for Time Series Classification using Convolutional Neural
Networks. In ECML/PKDD Workshop on Advanced Analytics and Learning on Temporal Data.
[49] W. Li, Z. Zhang, and Z. Liu. 2010. Action recognition based on a bag of 3D points. In The IEEE Conference on Computer Vision and
Pattern Recognition Workshops (CVPRW). 9–14.
Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

87:28

•

Kwon and Tong, et al.

[50] D. Liaqat, M. Abdalla, Pegah Abed-Esfahani, Moshe Gabel, Tatiana Son, Robert Wu, Andrea Gershon, Frank Rudzicz, and Eyal De Lara.
2019. WearBreathing: Real World Respiratory Rate Monitoring Using Smartwatches. Proceedings of the ACM on interactive, mobile,
wearable and ubiquitous technologies (IMWUT) 3, 2 (2019), 1–22.
[51] J. Liu, A. Shahroudy, M. Perez, G. Wang, L. Duan, and A. Kot. 2019. NTU RGB+D 120: A Large-Scale Benchmark for 3D Human Activity
Understanding. IEEE Transactions on Pattern Analysis and Machine Intelligence (2019).
[52] M. Loper, N. Mahmood, J. Romero, G. Pons-Moll, and M. Black. 2015. SMPL: A skinned multi-person linear model. ACM Transactions
on Graphics (TOG) 34, 6 (2015), 1–16.
[53] M. Lucic, K. Kurach, M. Michalski, S. Gelly, and O. Bousquet. 2018. Are gans created equal? a large-scale study. In Advances in neural
information processing systems. 700–709.
[54] N. Mahmood, N. Ghorbani, N. Troje, G. Pons-Moll, and M. Black. 2019. AMASS: Archive of motion capture as surface shapes. In IEEE
International Conference on Computer Vision (ICCV). 5442–5451.
[55] A. Mathur, T. Zhang, S. Bhattacharya, P. Velickovic, L. Joffe, N. Lane, F. Kawsar, and P. Lió. 2018. Using deep data augmentation training
to address software and hardware heterogeneities in wearable and smartphone sensing devices. In IEEE International Conference on
Information Processing in Sensor Networks (IPSN). IEEE, 200–211.
[56] A. Muhammad Sayem, S. Hon Teay, H. Shahariar, P. Fink, and A. Albarbar. 2020. Review on Smart Electro-Clothing Systems (SeCSs).
Sensors 20, 3 (2020), 587.
[57] V. Nair and G. Hinton. 2010. Rectified linear units improve restricted boltzmann machines. In Proceedings of the international conference
on machine learning (ICML). 807–814.
[58] A. Odena, V. Dumoulin, and C. Olah. 2016. Deconvolution and checkerboard artifacts. Distill 1, 10 (2016), e3.
[59] F. Ofli, R. Chaudhry, G. Kurillo, R. Vidal, and R. Bajcsy. 2013. Berkeley mhad: A comprehensive multimodal human action database. In
IEEE Workshop on Applications of Computer Vision (WACV). IEEE, 53–60.
[60] A. Oord, S. Dieleman, H. Zen, K. Simonyan, O. Vinyals, A. Graves, N. Kalchbrenner, A. Senior, and K. Kavukcuoglu. 2016. Wavenet: A
generative model for raw audio. arXiv preprint arXiv:1609.03499 (2016).
[61] F. J. Ordóñez and D. Roggen. 2016. Deep convolutional and lstm recurrent neural networks for multimodal wearable activity recognition.
Sensors 16, 1 (2016), 115.
[62] J. Park, Q. Zhou, and V. Koltun. 2017. Colored Point Cloud Registration Revisited. In IEEE International Conference on Computer Vision
(ICCV). 143–152.
[63] D. Pavllo, C. Feichtenhofer, D. Grangier, and M. Auli. 2019. 3D human pose estimation in video with temporal convolutions and
semi-supervised training. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 7753–7762.
[64] T. Phąm and Y. Suh. 2018. Spline Function Simulation Data Generation for Walking Motion Using Foot-Mounted Inertial Sensors. In
Sensors. MDPI, 199–210.
[65] T. Plötz, C. Chen, N. Hammerla, and G. Abowd. 2012. Automatic synchronization of wearable sensors and video-cameras for ground
truth annotation–a practical approach. In Proceedings of the ACM International Symposium on Wearable Computers. IEEE, 100–103.
[66] F. Pomerleau, F. Colas, and R. Siegwart. 2015. A Review of Point Cloud Registration Algorithms for Mobile Robotics. Found. Trends
Robot 4, 1 (May 2015), 1âĂŞ104.
[67] G. Pons-Moll, S. Pujades, S. Hu, and M. Black. 2017. ClothCap: Seamless 4D clothing capture and retargeting. ACM Transactions on
Graphics (TOG) 36, 4 (2017), 1–15.
[68] G. Pons-Moll, J. Romero, N. Mahmood, and M Black. 2015. Dyna: A model of dynamic human shape in motion. ACM Transactions on
Graphics (TOG) 34, 4 (2015), 1–14.
[69] G. Ramponi, P. Protopapas, M. Brambilla, and R. Janssen. 2018. T-cgan: Conditional generative adversarial network for data augmentation
in noisy time series with irregular sampling. arXiv preprint arXiv:1811.08295 (2018).
[70] K. Rashid and J. Louis. 2019. Times-series data augmentation and deep learning for construction equipment activity recognition.
Advanced Engineering Informatics 42 (2019), 100944.
[71] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi. 2016. You only look once: Unified, real-time object detection. In The IEEE Conference
on Computer Vision and Pattern Recognition (CVPR). 779–788.
[72] A. Reiss and D. Stricker. 2012. Introducing a new benchmarked dataset for activity monitoring. In Proceedings of the ACM International
Symposium on Wearable Computers. IEEE, 108–109.
[73] A. Reiss and D. Stricker. 2013. Personalized mobile physical activity recognition. In Proceedings of the ACM International Symposium on
Wearable Computers. 25–28.
[74] V. Rey, P. Hevesi, O. Kovalenko, and P. Lukowicz. 2019. Let there be IMU data: generating training data for wearable, motion sensor
based activity recognition from monocular RGB videos. In Adjunct Proceedings of the ACM International Joint Conference on Pervasive
and Ubiquitous Computing and Proceedings of the ACM International Symposium on Wearable Computers. 699–708.
[75] M. Rosca, B. Lakshminarayanan, and S. Mohamed. 2018. Distribution matching in variational inference. arXiv preprint arXiv:1802.06847
(2018).

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

IMUTube: Automatic Extraction of Virtual on-body Accelerometry from Video for Human Activity Recognition •

87:29

[76] S. Rusinkiewicz and M. Levoy. 2001. Efficient variants of the ICP algorithm. In Proceedings Third International Conference on 3-D Digital
Imaging and Modeling. IEEE.
[77] A. Saeed, T. Ozcelebi, and J. Lukkien. 2019. Multi-task Self-Supervised Learning for Human Activity Detection. Proceedings of the ACM
on interactive, mobile, wearable and ubiquitous technologies (IMWUT) 3, 2 (2019), 1–30.
[78] P. M. Scholl, M. Wille, and K. Van Laerhoven. 2015. Wearables in the wet lab: a laboratory system for capturing and guiding experiments.
In Proceedings of the International Conference on Ubiquitous Computing. ACM, 589–599.
[79] S. Shah and J.K. Aggarwal. 1996. Intrinsic parameter calibration procedure for a (high-distortion) fish-eye lens camera with distortion
model and accuracy estimation. Pattern Recognition 29, 11 (November 1996), 1775–1788.
[80] Z. Shen, W. Wang, X. Lu, J. Shen, H. Ling, T. Xu, and L. Shao. 2019. Human-Aware Motion Deblurring. In IEEE International Conference
on Computer Vision (ICCV). 5572–5581.
[81] J. Shi, L. Xu, and J. Jia. 2014. Discriminative blur detection features. In The IEEE Conference on Computer Vision and Pattern Recognition
(CVPR). 2965–2972.
[82] C. Shorten and T. Khoshgoftaar. 2019. A survey on image data augmentation for deep learning. Journal of Big Data 6, 1 (2019), 60.
[83] G. Sigurdsson, G. Varol, X. Wang, I. Laptev, A. Farhadi, and A. Gupta. 2016. Hollywood in Homes: Crowdsourcing Data Collection for
Activity Understanding. arXiv preprint arXiv:1604.01753 (2016).
[84] K. Soomro, A. Zamir, and M. Shah. 2012. UCF101: A dataset of 101 human actions classes from videos in the wild. arXiv preprint
arXiv:1212.0402 (2012).
[85] O. Steven Eyobu and D. Han. 2018. Feature representation and data augmentation for human activity classification based on wearable
IMU sensor data using a deep LSTM neural network. Sensors 18, 9 (2018), 2892.
[86] T. Sztyler and H. Stuckenschmidt. 2016. On-body localization of wearable devices: An investigation of position-aware activity
recognition. In IEEE International Conference on Pervasive Computing and Communications (PerCom). IEEE, 1–9.
[87] S. Takeda, T. Okita, P. Lago, and S. Inoue. 2018. A multi-sensor setting activity recognition simulation tool. In Proceedings of the
ACM International Joint Conference and International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers.
1444–1448.
[88] E. Thomaz, I. Essa, and G. Abowd. 2015. A practical approach for recognizing eating moments with wrist-mounted inertial sensing. In
Proceedings of the ACM International Joint Conference on Pervasive and Ubiquitous Computing. 1029–1040.
[89] C. Tong, S. Tailor, and N. Lane. 2020. Are Accelerometers for Activity Recognition a Dead-End?. In Proceedings of the International
Workshop on Mobile Computing Systems and Applications. ACM, 39–44.
[90] M. Trumble, A. Gilbert, C. Malleson, A. Hilton, and J. Collomosse. 2017. Total Capture: 3D Human Pose Estimation Fusing Video and
Inertial Sensors. In British Machine Vision Conference (BMVC).
[91] T. Um, F. Pfister, D. Pichler, S. Endo, M. Lang, S. Hirche, U. Fietzek, and D. Kulić. 2017. Data augmentation of wearable sensor data for
parkinson’s disease monitoring using convolutional neural networks. In Proceedings of the ACM International Conference on Multimodal
Interaction. 216–220.
[92] F. Xiao, L. Pei, L. Chu, D. Zou, W. Yu, Y. Zhu, and T. Li. 2020. A Deep Learning Method for Complex Human Activity Recognition Using
Virtual Wearable Sensors. arXiv preprint arXiv:2003.01874 (2020).
[93] S. Yao, Y. Zhao, H. Shao, C. Zhang, A. Zhang, S. Hu, D. Liu, S. Liu, Lu Su, and T. Abdelzaher. 2018. Sensegan: Enabling deep learning
for internet of things with a semi-supervised framework. Proceedings of the ACM on interactive, mobile, wearable and ubiquitous
technologies (IMWUT) 2, 3 (2018), 1–21.
[94] J. Yosinski, J. Clune, Y. Bengio, and H. Lipson. 2014. How transferable are features in deep neural networks?. In Advances in neural
information processing systems. 3320–3328.
[95] A. Young, M. Ling, and D. Arvind. 2011. IMUSim: A simulation environment for inertial sensing algorithm design and evaluation. In
Proceedings of the International Conference on Information Processing in Sensor Networks (IPSN). IEEE, 199–210.
[96] J. Yu and R. Ramamoorthi. 2019. Robust Video Stabilization by Optimization in CNN Weight Space. In The IEEE Conference on Computer
Vision and Pattern Recognition (CVPR). 3800–3808.
[97] M. Zhang and A. A. Sawchuk. 2012. USC-HAD: a daily activity dataset for ubiquitous activity recognition using wearable sensors. In
Proceedings of the International Conference on Ubiquitous Computing.
[98] Q. Zhang and R. Pless. 2004. Extrinsic calibration of a camera and laser range finder (improves camera calibration). In IEEE International
Conference on Intelligent Robots and Systems (IROS). IEEE.
[99] Z. Zhao, Y. Chen, J. Liu, Z. Shen, and M. Liu. 2011. Cross-people mobile-phone based activity recognition. In Proceedings of the
International Joint Conference on Artificial Intelligence (IJCAI).
[100] T. Zhou, M. Brown, Noah S., and D. Lowe. 2017. Unsupervised learning of depth and ego-motion from video. In The IEEE Conference on
Computer Vision and Pattern Recognition (CVPR). 1851–1858.
[101] H. Zhuang. 1995. A self-calibration approach to extrinsic parameter estimation of stereo cameras. Robotics and Autonomous Systems 15,
3 (August 1995), 189–197.

Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 4, No. 3, Article 87. Publication date: September 2020.

000
001
002
003
004
005
006
007
008
009
010
011
012
013
014
015
016
017
018
019
020
021
022
023
024
025
026
027
028
029
030
031
032
033
034
035
036
037
038
039
040
041
042
043
044
045
046
047
048
049
050
051
052
053
054

P RIVACY IN M ULTIMODAL F EDERATED H UMAN ACTIVITY R ECOGNITION
Anonymous Authors1

A BSTRACT
Human Activity Recognition (HAR) training data is often privacy-sensitive or held by non-cooperative entities.
Federated Learning (FL) addresses such concerns by training ML models on edge clients. This work studies the
impact of privacy in federated HAR at a user, environment, and sensor level. We show that the performance of
FL for HAR depends on the assumed privacy level of the FL system and primarily upon the colocation of data
from different sensors. By avoiding data sharing and assuming privacy at the human or environment level, as
prior works have done, the accuracy decreases by 5-7%. However, extending this to the modality level and strictly
separating sensor data between multiple clients may decrease the accuracy by 19-42%. As this form of privacy is
necessary for the ethical utilisation of passive sensing methods in HAR, we implement a system where clients
mutually train both a general FL model and a group-level one per modality. Our evaluation shows that this method
leads to only a 7-13% decrease in accuracy, making it possible to build HAR systems with diverse hardware.
1

I NTRODUCTION

Human Activity Recognition (HAR) involves classifying
human actions (Vrigkas et al., 2015; Jobanputra et al., 2019),
such as running or sitting, using data from personal devices
like smartphones or environmental sensors. However, practical and legal considerations limit learning from HAR data.
For example, using video cameras to simulate virtual bodilyworn movement sensors (Kwon et al., 2020) may generate
divergent features from Wi-Fi signals. Furthermore, privacy
requirements impose data collection limitations. In this
work, privacy requirements refer to constraints on collecting
or centralising data at three levels:

Traditional Machine Learning approaches tackle feature
heterogeneity by colocating data and by training with Multitask Learning techniques. However, the privacy constraints
above make centralisation unfeasible on a large scale in
HAR. Instead, they require a Federated Learning (FL) approach to keep data encapsulated in clients at the necessary
privacy level during training. Our work brings the following
contributions to Federated Human Activity Recognition:
1. First, we evaluate the performance of multiple models
trained in a federated fashion on a multimodal dataset
keeping data privately stored on clients at increasing
privacy levels. Unlike other works, we investigate the
additive effects of privacy up to the complete separation
of each user, environment, and modality combination.

User(Human subject)-level Privacy For gyroscope or accelerometer data from smartphones and wearables, endusers may be unwilling to share personal information.

2. Second, we show that privacy at the modality level
results in the highest accuracy cost, followed by the
environmental level and then the user level. To mitigate
this, we propose mutual learning of group-level models
alongside the standard FL model to cover modalities
that cannot be colocated in a single client. Our results indicate that this method can significantly reduce
accuracy degradation from 19-42% to just 7-13%.

Environment-level Privacy For locations such as hospitals
and internment facilities, sensitive information must often
remain private from third parties. This constraint may prove
challenging as data used for HAR is susceptible to environmental characteristics. For example, a sensor may produce
varying features based on object placement or room size.
Modality-level Privacy Data generated from different
groups of sensors may be owned by competing entities
or raise ethical concerns when collected in public spaces,
making it undesirable to store in a centralised fashion.
1

Anonymous Institution, Anonymous City, Anonymous Region,
Anonymous Country. Correspondence to: Anonymous Author
<anon.email@domain.com>.
Preliminary work. Under review by the Machine Learning and
Systems (MLSys) Conference. Do not distribute.

2

M ULTIMODALITY IN F EDERATED
H UMAN ACTIVITY R ECOGNITION

Federated Learning, proposed by McMahan et al. (2017),
trains ML models from distributed data on edge devices
using efficient communication techniques for maintaining
privacy. Although successful in training models from diverse users, such as keyboard prediction (Hard et al., 2018),
and diverse hardware, such as medical applications (Sheller

Privacy in Multimodal Federated Human Activity Recognition

055
056
057
058
059
060
061
062
063
064
065
066
067
068
069
070
071
072
073
074
075
076
077
078
079
080
081
082
083
084
085
086
087
088
089
090
091
092
093
094
095
096
097
098
099
100
101
102
103
104
105
106
107
108
109

et al., 2020), data heterogeneity remains a significant challenge (Kairouz et al., 2021, sec 3.1). Due to privacy constraints, approaches like Multi-task Learning and Continual
Learning, which handle feature heterogeneity, are limited in
a Federated Learning context. For instance, Elastic Weight
Consolidation (Kirkpatrick et al., 2017) estimates parameter
variance using past data, while Learning Without Forgetting
(Li & Hoiem, 2018) stores network outputs from past tasks.
Previous work on Federated Human Activity Recognition
has not fully explored the heterogeneity emerging from independent data collection systems. For instance, Sozinov
et al. (2018) considers skewed label distributions and noise
across smartphone users while colocating gyroscope and
accelerometer data. Similar partitioning schemes are investigated for feature extraction (Xiao et al., 2021) and clustering
methods (Ouyang et al., 2021). Furthermore, such works
may use artificially partitioned centralised datasets, as in
Zhao et al. (2020), or contain only one modality, as in some
datasets collected by Ouyang et al. (2021). To create adaptable HAR systems that can accommodate new clients with
different sensor types in the federation, investigating Federated HAR with modalities split across clients is necessary,
given the shifting hardware landscape of HAR sensors.

3

F EDERATING H UMAN ACTIVITY
R ECOGNITION

We construct multiple partitions of the OPERAnet dataset
published by Bocus et al. (2022) to assess Federated Human
Activity Recognition under privacy at user, environment,
and modality privacy levels. The dataset contains five different sensors; however, Bocus et al. (2022) indicate that only
Channel State Information (CSI) from a Network Card Interface (NIC) and Passive Wi-Fi Radar (PWR) should be used
for HAR. The data were collected synchronously, with the
multiple channels—three for CSI and two for PWR—of RF
data. They cover eight hours of surveying six participants
performing six activities spread across two rooms. Because
room activity distribution is non-uniform, separating clients
by environment also provides skewness at the label level.
We transform the time-series data into image data in keeping
with the original HAR preprocessing applied by Bocus et al.
(2022) and previous works (Bocus et al., 2021; Li et al.,
2020; 2022). We further increase the dataset’s size and
modality diversity by reusing the pipeline of Koupai et al.
(2022). Based on the underlying CSI and PWR data, Koupai
et al. (2022) construct spectrograms of the CSI and PWR
data. The complete image set contains five data views for
each underlying CSI or PWR channel. We use the three
most effective view types reported by Koupai et al. (2022).
Since different channels for CSI and PWR are physically
colocated on the device, it is assumed that fusing images
generated from separate channels would not be a violation

of privacy at the sensor level. Consequently, the complete
image types we shall refer to as modalities for the rest of
this work contain concatenated images generated from each
source channel. One such image type comes from CSI; two
come from PWR.
The work of Koupai et al. (2022) offers two centralised baselines to compare against, a ResNet34 (He et al., 2016) model
used for HAR and a Fusion Vision Transformer (FViT).
While CNNs have been successfully applied to HAR by
Bevilacqua et al. (2018); Ronald et al. (2021) and Tang et al.
(2023), the novel FViT addresses the issue of multimodal
HAR by adapting the Vision Transformer (ViT) architecture
developed by Dosovitskiy et al. (2021) to operate over fused
images. Crucially for our experiments, FViT has a parameter
count invariant to the number of images combined, making
the network capacity equivalent between fused and unfused
modalities. In addition to the transformer and ResNet34, we
use the smallest EfficientNetV2 constructed by Tan & Le
(2021) as the communication costs and compute concerns
in FL make the smaller network a practical choice.
3.1

Partitioning by Privacy Level

The partitions we construct correspond to increasing privacy
levels. For example, splitting by human subject implies that
each client in that partition only contains data corresponding
to one human participant and thus obeys Subject(User)-level
privacy. Likewise, the partition splitting by participant and
room implies that each participant and room combination
is treated as a separate client and offers both Subject(User)level and Environment-level privacy. The most heterogeneous partition we create treats each participant, room, and
modality combination as one client and offers the previous
two levels of privacy together with Modality-level privacy.
To create a meaningful test set for Federated HAR, we use
the data of the sixth client. Since OPERAnet has not been
used for FL before, our evaluation compares the accuracy
of FL partitioned by subject and environment to the State of
The Art centralised baselines using colocated fused modalities. Following this initial investigation, we explore privacy
interactions at a subject (user), environmental and modality
level when the modalities are never fused and not necessarily colocated. The separated-modality experiments are the
ones we use to report findings, as they can cover all levels of
privacy. Table 1 presents the constructed partitions and their
statistics. As we intended to use 30% of total clients each
round, we split the data of one participant into two clients
based on their room when federating by subject. For the centralised baseline, we follow Koupai et al. (2022) and train
for 100 local epochs, while FL trains for 10 rounds with 10
local epochs. The optimiser parameters are kept constant
and at parity with Koupai et al. (2022)—see Appendix A.

Privacy in Multimodal Federated Human Activity Recognition

110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164

Table 1. The partitions in our experimental setup. They include
the centralised baseline (Centralised), those partitioned by human
subject (Subj), by subject and environment (Subj+Env), or by
subject, environment, and modality (Subj+Env+Mod). A partition
can contain fused (F) or separated (S) modalities.
Partition

Avg Samples

#Samples Subj 6

#Train Clients

#Clients/R

Centralised (F)
Subj (F)
Subj + Env (F)

1947.0 ± 0.0
324.3 ± 32.3
194.6 ± 194.6

463
463
463

1
6
10

1
2
3

Centralised (S)
Subj (S)
Subj + Env (S)
Subj + Env + Mod (S)

5841.0 ± 0.0
973.0 ± 973.0
583.8 ± 583.8
194.6 ± 194.6

1389
1389
1389
1389

1
6
10
30

1
2
3
9

3.2

E VALUATION

Our evaluation reveals that Federated Human Activity
Recognition is sensitive to sensor heterogeneity but partially resilient to subject characteristics and room structure.
In Table 2, we present accuracy results of all partition and
model combinations using fused (F) or separated (S) modalities. Fused modality experiments establish a baseline of
comparison between federated and centralised training on
OPERAnet. Separated modality experiments allow us to
investigate more granular levels of privacy and will provide
most of the notable figures. Accuracy convergence curves
are available per model in Fig. 1; however, they only show
unfused modalities to emphasise results for modality-level
privacy. In the appendix, convergence curves for fused
modalities are presented in Fig. 2 and follow similar trends.
All experiments used the Flower (Beutel et al., 2020) FL
framework.
4.1

Partition
Centralised (Fused)
Subj (Fused)
Subj+Env (Fused)
Centralised (S)
Subj (S)
Subj+Env (S)
Subj+Env+Mod (S)

FViT
0.90±0.01
0.85±0.02
0.83±0.03
0.83±0.01
0.81±0.01
0.78±0.02
0.64±0.04

ResNet34
0.93±0.01
0.90±0.02
0.84±0.07
0.89±0.02
0.84±0.03
0.84±0.02
0.47±0.03

EffNetB0
0.91±0.01
0.88±0.01
0.79±0.04
0.87±0.01
0.85±0.01
0.80±0.01
0.55±0.05

Ensemble
0.76±0.02

Mutual Global and Group Model Learning

To handle separating modalities across clients in a federated
network, we propose a group FL structure utilising Deep
Mutual Learning (Zhang et al., 2018). Two models are
trained on each client and distil knowledge into each other.
One model is a globally federated model trained on all
clients. The other is a group-level one trained only on clients
with a specific modality. The server maintains one model
per modality group, providing flexibility for integrating new
sensors. We chose the FViT as the global federated model
because of its resilience to high heterogeneity in previous
experiments. Furthermore, we use the small EfficientNetV2
as the group-level model for future scalability. We present
the performance of an ensemble of group-level models, each
predicting the relevant modality. Hyperparameters were
optimised via Bayesian search, resulting in global and grouplevel distillation weights of 0.33 and 0.75, respectively.

4

Table 2. Accuracy results (mean and standard deviation) for model
and partition combinations on the test set of OPERAnet. Note
the impact of partitioning by modality compared to the subject or
environment and the smoother decline in the performance of FViT
compared to the CNNs. The “Ensemble” uses the three group
models to predict the data label belonging to their modality. The
results of F1-Score, shown in Table 3, follow the same trend.

Subject(User)-level Privacy

Experiments with user-level privacy showed that all three
models achieved results within 3-5% of the centralised base-

line, regardless of modality fusion. As shown in Fig. 1,
this small gap to the centralised unfused baseline was consistently observed across rounds. In addition, a study by
Sozinov et al. (2018) found a similar 4-6% accuracy gap
when treating each person as a separate partition, indicating
that body characteristics and slight movement differences
are not significant enough to generate highly divergent features. These findings suggest that FL is a practical solution
for accessing extensive private data from end users. However, unfused modalities reduced accuracy for centralised
and subject-level partitions nearly uniformly compared to
fused ones—showcasing the benefits of centralisation.
4.2

Environment-level Privacy

A further slight-to-medium accuracy degradation is perceptible in the experimental partitions applying subject-level
and environmental privacy in Table 2. It is worth noting
that data from OPERAnet may have reduced environmental
heterogeneity as the same hardware, procedure, and subjects were used in a controlled setting. However, this is a
common issue for all HAR systems (Vrigkas et al., 2015,
sec.6). Fused modalities saw an additional drop in accuracy
of 2-9%, while unfused modalities saw a less significant
impact, with the additional maximum drop never exceeding
5%. Notably, ResNet34 operating on unfused modalities
did not exhibit a significant accuracy drop when privacy was
increased. Fused modalities contain more information about
the environment per sample, aiding in distinguishing between rooms. However, the additional information becomes
less valuable after samples are split into clients. Figure 1
highlights that the small EfficientNetV2 suffers more from
not having examples from both rooms available.
4.3

Modality-level Privacy

The experimental results reveal an unexpected pattern when
applying privacy at the modality level. The previously topperforming ResNet34 experiences a 37% further drop in accuracy with a 42% total, while the EfficientNetV2 suffers a

Privacy in Multimodal Federated Human Activity Recognition

Network = FViT

1.0

Network = ResNet34

Network = EffNetB0

0.8

Accuracy

165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219

0.6
0.4

Centralised (S)
Subj (S)
Subj+Env (S)
Subj+Env+Mod (S)
Ensemble

0.2
0.0

0

2

4

Round

6

8

10

0

2

4

Round

6

8

10

0

2

4

Round

6

8

10

Figure 1. Model per-round accuracy on the sixth subject’s dataset at all privacy levels. For low-heterogeneity, CNNs generally outperform
FViT, but FViT gains a significant advantage when modality partitioning is introduced. Notably, FViT converges faster in the initial
rounds and reaches higher accuracy with fewer data in the first two rounds. The “Ensemble” results reverse the effects of modality-level
privacy and outperform all non-grouped federated models.

25% further drop in accuracy with a 32% total. By contrast,
the Fusion Vision Transformer (FViT), which produced
worse results in previous experiments, only experiences a
14% further drop in accuracy with 19% total and emerges as
the model with the most significant performance advantage
for a given privacy level. To better understand this outcome
and the interplay between different model types, we turn to
the plot in Fig. 1, which shows the convergence of models
for different partitions. The plot immediately reveals the
steeper slope of improvement that FViT obtains in the first
few rounds. Furthermore, this pattern of performance aligns
with the fine-tuning experiments reported in (Koupai et al.,
2022), where FViT outperformed ResNet when both were
trained on a small amount (1-20%) of data.
The increasing prevalence of IoT devices, surveillance cameras, personal smartphones, and passive RF sensors has led
to extensive human activity recognition (HAR) data collection. However, with no uniform regulation or competitive
environment, it is critical to prioritise privacy preservation
and address the afferent accuracy degradation.
4.4

Mutual Learning with Per-modality Group Models

We evaluate the effectiveness of our ensemble, which uses
mutual learning to handle the challenges of federated learning across modalities. As demonstrated in both Fig. 1 and
Table 2, the ensemble achieves near-equivalent accuracy to
FViT on the ”Subj+Env” partition with colocated modalities. However, training the federated learning and grouplevel models simultaneously is costly and difficult to optimise. Moreover, our hyperparameter search, which explored 79 combinations of distillation weights, revealed that

the ensemble’s performance is sensitive to hyperparameter
changes. Meanwhile, the federated model failed to surpass
the ”Subj+Env+Mod(S)” result in Table 2 through mutual
learning, primarily due to the inherent difficulty of multimodal training on the same network without employing
specific multi-task techniques.

5

C ONCLUSION

We investigated the performance of Multimodal Federated
Human Activity Recognition under privacy levels that may
arise in practice, such as the subject(user), environmental,
and modality levels. Our results show that performance
degrades with each additional privacy layer starting with
5-%7 for the subject and environmental levels. Remarkably,
we observed an overall accuracy drop of 32-42% for CNNs
when modality-level privacy is assumed. Nevertheless, our
experiments determined that a Fusion Vision Transformer
architecture performs well in extreme scenarios. Its fast initial convergence with few samples led to an additional drop
of only 14% with a 19% overall drop for modality-level privacy. Furthermore, constructing small group-level models
for each modality type trained in a mutual-learning fashion
with a global one can limit the overall degradation to 7-13%.
Such a system can adjust to shifting hardware conditions
by incorporating new group-level models and utilising the
global model’s knowledge for bootstrapping. Despite the
clear trends, this work is limited by the size of OPERAnet.
Besides larger datasets, other potential future research avenues include hierarchical FL with layered aggregation and
creating sparse models with task-based subnetworks.

Privacy in Multimodal Federated Human Activity Recognition

220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274

R EFERENCES
Beutel, D. J., Topal, T., Mathur, A., Qiu, X., Parcollet, T.,
and Lane, N. D. Flower: A friendly federated learning
research framework. CoRR, abs/2007.14390, 2020. URL
https://arxiv.org/abs/2007.14390.
Bevilacqua, A., MacDonald, K., Rangarej, A., Widjaya,
V., Caulfield, B., and Kechadi, M. T. Human activity recognition with convolutional neural networks.
In Brefeld, U., Curry, E., Daly, E., MacNamee, B.,
Marascu, A., Pinelli, F., Berlingerio, M., and Hurley, N.
(eds.), Machine Learning and Knowledge Discovery in
Databases - European Conference, ECML PKDD 2018,
Dublin, Ireland, September 10-14, 2018, Proceedings,
Part III, volume 11053 of Lecture Notes in Computer
Science, pp. 541–552. Springer, 2018. doi: 10.1007/
978-3-030-10997-4\ 33. URL https://doi.org/
10.1007/978-3-030-10997-4_33.
Bocus, M. J., Li, W., Paulavicius, J., McConville, R., SantosRodriguez, R., Chetty, K., and Piechocki, R. Translation
resilient opportunistic wifi sensing. In 2020 25th International Conference on Pattern Recognition (ICPR),
pp. 5627–5633, 2021. doi: 10.1109/ICPR48806.2021.
9412263.
Bocus, M. J., Li, W., Vishwakarma, S., Kou, R., Tang,
C., Woodbridge, K., Craddock, I., McConville, R.,
Santos-Rodriguez, R., Chetty, K., and Piechocki, R.
Operanet, a multimodal activity recognition dataset
acquired from radio frequency and vision-based sensors. Scientific Data, 9(1):474, 2022. doi: 10.1038/
s41597-022-01573-2. URL https://doi.org/10.
1038/s41597-022-01573-2.
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn,
D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer,
M., Heigold, G., Gelly, S., Uszkoreit, J., and Houlsby,
N. An image is worth 16x16 words: Transformers for
image recognition at scale. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net,
2021. URL https://openreview.net/forum?
id=YicbFdNTTy.

10.1109/CVPR.2016.90. URL https://doi.org/
10.1109/CVPR.2016.90.
Jobanputra, C., Bavishi, J., and Doshi, N. Human
activity recognition: A survey. Procedia Computer
Science, 155:698–703, 2019.
ISSN 1877-0509.
doi:
https://doi.org/10.1016/j.procs.2019.08.100.
URL
https://www.sciencedirect.com/
science/article/pii/S1877050919310166.
The 16th International Conference on Mobile Systems and Pervasive Computing (MobiSPC 2019),The
14th International Conference on Future Networks
and Communications (FNC-2019),The 9th International Conference on Sustainable Energy Information
Technology.
Kairouz, P., McMahan, H. B., Avent, B., Bellet, A., Bennis,
M., Bhagoji, A. N., Bonawitz, K. A., Charles, Z., Cormode, G., Cummings, R., D’Oliveira, R. G. L., Eichner,
H., Rouayheb, S. E., Evans, D., Gardner, J., Garrett, Z.,
Gascón, A., Ghazi, B., Gibbons, P. B., Gruteser, M., Harchaoui, Z., He, C., He, L., Huo, Z., Hutchinson, B., Hsu,
J., Jaggi, M., Javidi, T., Joshi, G., Khodak, M., Konečný,
J., Korolova, A., Koushanfar, F., Koyejo, S., Lepoint, T.,
Liu, Y., Mittal, P., Mohri, M., Nock, R., Özgür, A., Pagh,
R., Qi, H., Ramage, D., Raskar, R., Raykova, M., Song,
D., Song, W., Stich, S. U., Sun, Z., Suresh, A. T., Tramèr,
F., Vepakomma, P., Wang, J., Xiong, L., Xu, Z., Yang, Q.,
Yu, F. X., Yu, H., and Zhao, S. Advances and open problems in federated learning. Found. Trends Mach. Learn.,
14(1-2):1–210, 2021. doi: 10.1561/2200000083. URL
https://doi.org/10.1561/2200000083.
Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A. A., Milan, K., Quan, J., Ramalho, T.,
Grabska-Barwinska, A., Hassabis, D., Clopath, C., Kumaran, D., and Hadsell, R. Overcoming catastrophic forgetting in neural networks. Proceedings of the National
Academy of Sciences, 114(13):3521–3526, 2017. doi: 10.
1073/pnas.1611835114. URL https://www.pnas.
org/doi/abs/10.1073/pnas.1611835114.

Hard, A., Rao, K., Mathews, R., Beaufays, F., Augenstein,
S., Eichner, H., Kiddon, C., and Ramage, D. Federated learning for mobile keyboard prediction. CoRR,
abs/1811.03604, 2018. URL http://arxiv.org/
abs/1811.03604.

Koupai, A. K., Bocus, M. J., Santos-Rodriguez, R.,
Piechocki, R. J., and McConville, R. Self-supervised
multimodal fusion transformer for passive activity recognition. IET Wireless Sensor Systems, 12(5-6):149–
160, 2022. doi: https://doi.org/10.1049/wss2.12044.
URL https://ietresearch.onlinelibrary.
wiley.com/doi/abs/10.1049/wss2.12044.

He, K., Zhang, X., Ren, S., and Sun, J. Deep residual learning for image recognition. In 2016 IEEE
Conference on Computer Vision and Pattern Recognition, CVPR 2016, Las Vegas, NV, USA, June 27-30,
2016, pp. 770–778. IEEE Computer Society, 2016. doi:

Kwon, H., Tong, C., Haresamudram, H., Gao, Y., Abowd,
G. D., Lane, N. D., and Ploetz, T. Imutube: Automatic
extraction of virtual on-body accelerometry from video
for human activity recognition, 2020. URL https://
arxiv.org/abs/2006.05675.

Privacy in Multimodal Federated Human Activity Recognition

275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329

Li, W., Bocus, M. J., Tang, C., Vishwakarma, S., Piechocki,
R. J., Woodbridge, K., and Chetty, K. A taxonomy of
wifi sensing: Csi vs passive wifi radar. In 2020 IEEE
Globecom Workshops (GC Wkshps, pp. 1–6, 2020. doi:
10.1109/GCWkshps50303.2020.9367546.
Li, W., Bocus, M. J., Tang, C., Piechocki, R. J., Woodbridge,
K., and Chetty, K. On csi and passive wi-fi radar for opportunistic physical activity recognition. IEEE Transactions on Wireless Communications, 21(1):607–620, 2022.
doi: 10.1109/TWC.2021.3098526.
Li, Z. and Hoiem, D. Learning without forgetting. IEEE
Trans. Pattern Anal. Mach. Intell., 40(12):2935–2947,
2018. doi: 10.1109/TPAMI.2017.2773081. URL https:
//doi.org/10.1109/TPAMI.2017.2773081.
McMahan, B., Moore, E., Ramage, D., Hampson, S.,
and y Arcas, B. A. Communication-efficient learning of deep networks from decentralized data. In
Singh, A. and Zhu, X. J. (eds.), Proceedings of the
20th International Conference on Artificial Intelligence
and Statistics, AISTATS 2017, 20-22 April 2017, Fort
Lauderdale, FL, USA, volume 54 of Proceedings of
Machine Learning Research, pp. 1273–1282. PMLR,
2017. URL http://proceedings.mlr.press/
v54/mcmahan17a.html.
Ouyang, X., Xie, Z., Zhou, J., Huang, J., and Xing,
G. Clusterfl: a similarity-aware federated learning system for human activity recognition. In Banerjee, S.,
Mottola, L., and Zhou, X. (eds.), MobiSys ’21: The
19th Annual International Conference on Mobile Systems, Applications, and Services, Virtual Event, Wisconsin, USA, 24 June - 2 July, 2021, pp. 54–66. ACM,
2021. doi: 10.1145/3458864.3467681. URL https:
//doi.org/10.1145/3458864.3467681.
Ronald, M., Poulose, A., and Han, D. S. isplinception:
An inception-resnet deep learning architecture for human
activity recognition. IEEE Access, 9:68985–69001, 2021.
doi: 10.1109/ACCESS.2021.3078184.
Sheller, M. J., Edwards, B., Reina, G. A., Martin, J., Pati, S.,
Kotrotsou, A., Milchenko, M., Xu, W., Marcus, D., Colen,
R. R., and Bakas, S. Federated learning in medicine: facilitating multi-institutional collaborations without sharing
patient data. Scientific Reports, 10(1):12598, 2020. doi:
10.1038/s41598-020-69250-1. URL https://doi.
org/10.1038/s41598-020-69250-1.
Sozinov, K., Vlassov, V., and Girdzijauskas, S. Human activity recognition using federated learning. In
Chen, J. and Yang, L. T. (eds.), IEEE International
Conference on Parallel & Distributed Processing with

Applications, Ubiquitous Computing & Communications, Big Data & Cloud Computing, Social Computing & Networking, Sustainable Computing & Communications, ISPA/IUCC/BDCloud/SocialCom/SustainCom
2018, Melbourne, Australia, December 11-13, 2018,
pp. 1103–1111. IEEE, 2018. doi: 10.1109/BDCloud.
2018.00164. URL https://doi.org/10.1109/
BDCloud.2018.00164.
Tan, M. and Le, Q. V. Efficientnetv2: Smaller models and faster training. In Meila, M. and Zhang, T.
(eds.), Proceedings of the 38th International Conference
on Machine Learning, ICML 2021, 18-24 July 2021,
Virtual Event, volume 139 of Proceedings of Machine
Learning Research, pp. 10096–10106. PMLR, 2021.
URL http://proceedings.mlr.press/v139/
tan21a.html.
Tang, Y., Zhang, L., Min, F., and He, J. Multiscale deep feature learning for human activity recognition using wearable sensors. IEEE Transactions on Industrial Electronics, 70(2):2106–2116, 2023. doi: 10.1109/TIE.2022.
3161812.
Vrigkas, M., Nikou, C., and Kakadiaris, I. A. A review of human activity recognition methods. Frontiers Robotics AI, 2:28, 2015. doi: 10.3389/frobt.
2015.00028. URL https://doi.org/10.3389/
frobt.2015.00028.
Xiao, Z., Xu, X., Xing, H., Song, F., Wang, X., and Zhao,
B. A federated learning system with enhanced feature extraction for human activity recognition. Knowl.
Based Syst., 229:107338, 2021. doi: 10.1016/j.knosys.
2021.107338. URL https://doi.org/10.1016/
j.knosys.2021.107338.
Zhang, Y., Xiang, T., Hospedales, T. M., and Lu, H.
Deep mutual learning. In 2018 IEEE Conference on
Computer Vision and Pattern Recognition, CVPR 2018,
Salt Lake City, UT, USA, June 18-22, 2018, pp. 4320–
4328. Computer Vision Foundation / IEEE Computer
Society, 2018. doi: 10.1109/CVPR.2018.00454. URL
http://openaccess.thecvf.com/content_
cvpr_2018/html/Zhang_Deep_Mutual_
Learning_CVPR_2018_paper.html.
Zhao, Y., Liu, H., Li, H., Barnaghi, P. M., and Haddadi, H. Semi-supervised federated learning for activity recognition. CoRR, abs/2011.00851, 2020. URL
https://arxiv.org/abs/2011.00851.

Privacy in Multimodal Federated Human Activity Recognition

330
331
332
333
334
335
336
337
338
339
340
341
342
343
344
345
346
347
348
349
350
351
352
353
354
355
356
357
358
359
360
361
362
363
364
365
366
367
368
369
370
371
372
373
374
375
376
377
378
379
380
381
382
383
384

A

A PPENDIX

The preprocessing pipeline we use is precisely described in
Koupai et al. (2022); however, we shall offer a brief summary here. First, the CSI signal is denoised using a discrete
wavelet transform and median filtering before applying PCA
and generating a spectrogram through the STFT. Then, for
the PWR data, the authors apply the cross ambiguity function to the PWR data followed by the CLEAN algorithm
and the outputting of a Doppler spectrogram. We use three
of the image types they generate. First, we use the concatenated spectrograms generated from the three-receiver
surveillance channels of the PWR data. The combined images from the three channels have a dimension of 224 × 672.
Second, we use the spectrograms generated using STFT
on amplitude CSI data from two receivers with a concatenated size of 224 × 448. Third, we use the phase-difference
spectrograms generated via STFT from the phase-difference
CSI data from the two receivers with a concatenated size of
224 × 448. Combined in the fused partitions, they add up to
224 × 1568 images. Finally, we take the largest image type
(224 × 672) in unfused partitions and pad the rest.
Client data partitions are generated in order of person index
for split-subject modalities, person index and then room
index for subject and environment, and subject, room and
modality index for the final partitioning. Our indexing assumes the human subjects are ordered from one to six, the
rooms from one to two, and the modalities from one to
three in the above order. The subject and room indexes
are directly available in the dataset. Each model and partition combination was run using five distinct seeds generating the same client sequence across models. Thus
differences in performance between models are not due
to randomness in client selection. The seeds we use are
42, 1337, 3407, 8711, 9370, and the client sequence is generated by calling np.random.choice for the given number of clients per round out of the entire population for each
of the ten rounds at the start of the script right after the seed
has been set. The mean and standard deviation are reported
based on the five seeds in and Table 2 and Table 3. The
per-round values in Fig. 1 and Fig. 2 have their mean and
standard deviation calculated based on the accuracy of the
models on each of the five seeds at the specific round. The
same seeds are used to set the random, numpy and torch
modules in python before every experiment.
All models have been trained as in Koupai et al. (2022)
using AdamW with β1 = 0.9 and β2 = 0.999 with a weight
decay of 0.01 and batch size of 10 rather than 64 due to the
small size of the federated partitions. The computational
resources involved four Nvidia A40s and were extensively
used during parameter tuning.

Table 3. The F1-Score results of partition-model combinations.
The same trends from the accuracy comparisons repeat themselves
with higher privacy requirements leading to worse performance.
A similar strong decline can be observed when clients are partitioned by modality, with the FViT performing the best in the most
heterogeneous condition despite trailing behind the CNNs for all
other partitions. The ensemble group models also successfully
recovered performance near the FViT levels when the partitioning
was based only on subject and environment.
Partition

FViT

ResNet34

EffNetB0

Ensemble

Centralised (Fused)
Subj (Fused)
Subj+Env (Fused)

0.80± 0.03
0.73± 0.03
0.70± 0.05

0.86 ± 0.02
0.82 ± 0.05
0.74 ± 0.08

0.83± 0.02
0.78± 0.02
0.64± 0.04

-

Centralised (Split)
Subj (Split)
Subj+Env (Split)
Subj+Env+Mod (Split)

0.71± 0.01
0.68± 0.01
0.64± 0.03
0.50± 0.04

0.80± 0.03
0.72± 0.06
0.71± 0.04
0.35± 0.03

0.78± 0.02
0.73± 0.02
0.67± 0.02
0.39± 0.04

0.60± 0.03

Privacy in Multimodal Federated Human Activity Recognition

Network = FViT

1.0

Network = ResNet34

Network = EffNetB0

0.8

Accuracy

385
386
387
388
389
390
391
392
393
394
395
396
397
398
399
400
401
402
403
404
405
406
407
408
409
410
411
412
413
414
415
416
417
418
419
420
421
422
423
424
425
426
427
428
429
430
431
432
433
434
435
436
437
438
439

0.6
0.4
Centralised (F)
Subj (F)
Subj+Env (F)

0.2
0.0

0

2

4

Round

6

8

10

0

2

4

Round

6

8

10

0

2

4

Round

6

8

10

Figure 2. Model per-round accuracy on the fused-modality dataset. The trends observed resemble those for the split partitions with only a
uniform decrease in accuracy by comparison. The only major change in results is the sensitivity of ResNet34 to environmental privacy.

PREPRINT: Accepted at The 3rd Workshop on Machine Learning and Systems (EuroMLSys 20223)

Can Fair Federated Learning reduce the need for
Personalisation?
Alex Iacob, Pedro P. B. Gusmão, Nicholas D. Lane
University of Cambridge

Abstract
Federated Learning (FL) enables training ML models on edge
clients without sharing data. However, the federated model’s
performance on local data varies, disincentivising the participation of clients who benefit little from FL. Fair FL reduces
accuracy disparity by focusing on clients with higher losses
while personalisation locally fine-tunes the model. Personalisation provides a participation incentive when an FL model
underperforms relative to one trained locally. For situations
where the federated model provides a lower accuracy than
a model trained entirely locally by a client, personalisation
improves the accuracy of the pre-trained federated weights
to be similar to or exceed those of the local client model.
This paper evaluates two Fair FL (FFL) algorithms as starting
points for personalisation. Our results show that FFL provides no benefit to relative performance in a language task
and may double the number of underperforming clients for
an image task. Instead, we propose Personalisation-aware
Federated Learning (PaFL) as a paradigm that pre-emptively
uses personalisation losses during training. Our technique
shows a 50% reduction in the number of underperforming
clients for the language task while lowering the number of
underperforming clients in the image task instead of doubling it. Thus, evidence indicates that it may allow a broader
set of devices to benefit from FL and represents a promising
avenue for future experimentation and theoretical analysis.

1

Introduction

Edge devices provide computational power and data for
Machine Learning tasks; however, minimising communication costs while using them can be challenging. Federated
Learning (FL) was introduced by McMahan et al. [18] to enable model training on client devices without sharing data.
However, the FL model accuracy may be underwhelming on
clients with unusual data and even worse than a local model,
reducing the incentive for participation.
The existing body of research on balancing global and local performance has proposed several approaches. Two Fair
Federated Learning (FFL) techniques, q-Fair Federated Learning (q-FFL) and Tilted Empirical Risk Minimization (TERM),
proposed by Li et al. [15] and Li et al. [11] respectively, aim
to improve the accuracy of the worst-performing clients by
prioritising those with large losses during FL. Alternatively,
Yu et al. [23] and Mansour et al. [17] recommend using personalisation (local adaptation) methods such as Freezebase

(FB), Elastic Weight Consolidation (EWC), and Knowledge
Distillation (KD) for fine-tuning. In this work, relative accuracy refers to the difference in local client test set accuracy
between a federated and local model.
While the sets of potential use cases for fairness and personalisation are not identical—e.g., personalisation would
be inappropriate for clients with few samples—FFL could
construct a fairer relative accuracy distribution as a starting point. For FFL to reduce the need for personalisation, it
would have to lower the number of underperforming clients
or improve their average relative accuracy. However, in our
experiments, FFL had a neutral or negative effect on the
relative accuracy distribution. Our contribution is threefold:
1. We construct an initial empirical evaluation of the
relative accuracy distribution of models trained with
FFL on the Reddit, CIFAR-10, and FEMNIST datasets
for next-word prediction and image recognition tasks.
During our evaluation, we show that FFL does not
significantly reduce the number of underperforming
clients or improve the relative accuracy distribution
on Reddit and brings little benefit over FedAvg and
personalisation. We also show it doubles the number
of underperforming clients for FEMNIST.
2. We investigate potential synergies between FFL and
personalisation by adapting fair federated models. Results show that the adapted models do not significantly outperform those initially trained with FedAvg
in relative accuracy or the number of underperforming clients.
3. We propose Personalization-aware Federated Learning (PaFL) as a paradigm that uses local adaptation
techniques during FL training to pre-empt personalisation. Results on the language task show a significant reduction in underperforming clients over FFL
when applying KD without any downsides to subsequent personalisation. Moreover, PaFL can avoid
the increase in underperforming clients observed for
image recognition on FEMNIST when using EWC or
KD for our tested hyperparameters. However, given
that our results are based entirely on simulation, future work consisting of additional experimentation
and theoretical analysis is needed to determine the
exact relationship between the training loss, e.g., KD
or EWC, fairness, and local accuracy after personalisation.

PREPRINT: Accepted at The 3rd Workshop on Machine Learning and Systems (EuroMLSys 20223)

2

Background and Related Work

Li et al. [13] formulate the FL objective function as seen in
Eq. (1)
𝑚
∑︁
min 𝑓 (𝑤) =
𝑝𝑘 𝐹𝑘 (𝑤) ,
(1)
𝑤
𝑘=1

where 𝑓 is the federated loss, 𝑚 is the client count, 𝑤 is the
model, and 𝐹𝑘 is the loss of client 𝑘 weighted by 𝑝𝑘 . For a
total number of samples 𝑛, 𝑝𝑘 is defined as the proportion of
samples on the client 𝑛𝑛𝑘 . The Federated Averaging (FedAvg)
algorithm introduced by McMahan et al. [18] trains locally
on clients and for each round 𝑡 sums the parameters of each
model 𝐺𝑘𝑡 from client 𝑘 weighted by 𝑝𝑘 with the previous
model 𝐺 𝑡 using learning rate 𝜂, as seen in Eq. (2)
!
𝑚
∑︁
𝑡 +1
𝑡
𝑡
𝐺 =𝐺 +𝜂
𝑝𝑘 𝐺𝑘 .
(2)
𝑘=1

Data and Hardware heterogeneity. Data generation, network speed and computation naturally vary across devices
due to hardware, location, time, and behaviour. These factors
make the data distribution not Idendepentend and Identically
Distributed (IID), leading to feature label or quantity skew
as reported by Kairouz et al. [8, sec.3.1]. Non-IID data can
impact accuracy [6, 24] and convergence [16] while different
hardware results in stragglers and unreliability.
2.1

Fair Federated Learning

Li et al. [15] propose Fair FL (FFL), which defines a “fairer”
FL model as one that achieves a lower variance in its accuracy distribution over local client test sets while keeping
average accuracy similar. They propose a version of FFL, qFFL, to emphasise underperforming clients during federated
training as seen in Eq. (3)
𝑚
∑︁
𝑝𝑘 𝑞+1
min 𝑓 (𝑤) =
𝐹 (𝑤) ,
(3)
𝑤
𝑞+1 𝑘
𝑘=1

where 𝑞 controls the degree of fairness. A 𝑞 = 0 corresponds
to FedAvg, while larger values prioritise higher losses to
improve accuracy on clients for which the federated model
underperforms. Li et al. [11] develop Tilted Empirical Risk
Minimization (TERM), shown in Eq. (4), which behaves similarly to q-FFL. While the two objectives show comparable
improvements in the evaluations of Li et al. [11], their interactions with personalisation are unknown.
𝑚
∑︁
1
min 𝑓 (𝑤) = log(
𝑝𝑘 𝑒 𝑡 𝐹𝑘 (𝑤 ) ) ,
(4)
𝑤
𝑡
𝑘=1

The original publications of Li et al. [11, 15] used a weighted
sampling of devices based on their number of examples, followed by uniform averaging. However, the server must know
the dataset size of all clients a priori, which is potentially
unfeasible. Thus, we use uniform sampling and weighted
averaging in this work.

The most relevant recent FFL work is Ditto, published by
Li et al. [12], which constructs personalised models while
encouraging fairness for the global model. Ditto keeps a
persistent local model in sync with the federated one by
minimising the 𝐿2 distance to the federated model, similar
to the personalisation techniques discussed below. While Li
et al. [12] show this local regularisation to be superior to
TERM in promoting fairness, it requires more resources than
personalisation. Maintaining a persistent local model incurs
training costs on every single round, in addition to the increased storage demands during training, without the benefit
of a highly-trained federated model to provide pre-trained
weights. As such, we have chosen to opt against maintaining
persistent local models; however, we recommend them as a
promising avenue for future work.
2.2

Local Adaptation

The analysis of Yu et al. [23] established that the federated
model performs worse on heterogeneous clients, as previously noted by Kairouz et al. [8], Li et al. [15], and it may
offer inferior performance to local ones. They propose several techniques to address this.
Elastic-weight Consolidation (EWC). The task of the
global model is to maintain performance on all previous
clients while training locally. Equation (5) frames it as Multitask Learning (MTL) problem using the Elastic Weight Consolidation technique (EWC) introduced by Kirkpatrick et al.
[9] to avoid Catastrophic forgetting [3]
∑︁
2
𝜆
𝑙 (𝐶, 𝑥) = 𝐿(𝐶, 𝑥) +
(5)
2 𝑀 [𝑖] (𝐶 [𝑖] − 𝐺 [𝑖]) ,
𝑖

where L is the client loss, 𝜆 determines the weighting between the two tasks and 𝑀 is the Fisher information matrix.
Fine-tuning (FT) and Freezebase (FB). When a client
receives a global model after the FL process, it can apply
Fine-tuning [17, 19, 20] to retrain the model on its data. Furthermore, to avoid potential Catastrophic forgetting, Yu et al.
[23] also opt to apply Freezebase (FB) as a variant of FT
which retrains only the top layer.
Knowledge Distillation (KD). As an alternative to EWC
and FT, Knowledge Distillation [5] uses the global model as
a teacher for a client model. For the pure logit outputs of
the federated model 𝐺 (𝑥) and client model 𝐶 (𝑥), the client
minimises the loss in Eq. (6)
𝑙 (𝐶, 𝑥) = 𝛼𝑇 2 𝐿(𝐶, 𝑥) + (1 − 𝛼)𝐾𝐿 (𝜎 (𝐺 (𝑥) /𝑇 ), 𝜎 (𝐶 (𝑥) /𝑇 )) ,
(6)
where 𝐿 is the client loss, 𝐾𝐿 is the Kullback-Leibler divergence [10], 𝜎 is the softmax, 𝛼 is the weighting and 𝑇 is the
temperature.
FedProx. One relevant loss function not considered by
Yu et al. [23] is the constraint on the Euclidean distance of
model parameters employed by FedProx [14] to limit model

PREPRINT: Accepted at The 3rd Workshop on Machine Learning and Systems (EuroMLSys 20223)
divergence. The loss function shown in Eq. (7) is formulated
similarly to EWC in Eq. (5).

Rather than using it to create personalised models, the original work of Li et al. [14] employs this loss function between
the model parameters at the start of the round and the parameters being trained on the client, which serves as the
inspiration for our proposal.

where 𝑡 is the current round, 𝐿(𝐶, 𝑥) is the training loss
and 𝐷 (𝑡) returns a personalisation loss function for the current round—potentially dependent on the data point 𝑥. The
weight of each term is set per round through the weighting
function 𝜇 (𝑡). PaFL can be naturally extended to incorporate local adaptation if deemed beneficial by allowing clients
to keep their model received after the final training round.
However, for the rest of this work, PaFL shall refer only to
the federated training phase. Local adaptation happens after
federated training is complete to allow comparison against
combinations of FL algorithms and personalisation methods.

3

4

𝑙 (𝐶, 𝑥) = 𝐿(𝐶, 𝑥) +

∑︁

2
𝜆
2 (𝐶 [𝑖] − 𝐺 [𝑖]) ,

(7)

𝑖

Personalisation-aware Federated
Learning

As an alternative to FFL for reducing personalisation costs,
we consider modifying local client training in a manner
which pre-empts a later adaptation phase by using loss functions meant for personalisation. The procedure is roughly
analogous to quantisation-aware training [2]. This work uses
Personalisation-aware Federated Learning (PaFL) to refer to
such a paradigm. While Federated Learning and local adaptation have historically been regarded as separate, the FedProx
algorithm developed by Li et al. [14] may be considered prototypical to PaFL as it injects the 𝐿2 norm of the model weight
differences into the local loss.
The FedProx algorithm aims to mitigate model divergence
caused by data heterogeneity in a manner that may improve
the accuracy of the federated model on average across clients.
However, it only considers the contribution of the model parameters based on their magnitude rather than their importance to the output of the federated model. While this choice
is well-justified by Li et al. [14], we consider some modifications while maintaining the principle when adapting it to
pre-empt personalisation.
Personalisation-aware Federated Learning modifies FedProx to allow the loss function and the afferent weight to vary
across rounds. Beyond potentially improved convergence,
such a process may benefit final locally-trained models by
providing continuity in the local objective between FL training and the final adaptation stage if the same loss function
is used. Furthermore, loss-based weighted averaging as used
in q-FFL (Eq. (3)) and TERM (Eq. (4)) has no means of reconciling differences between models required by clients with
equally high losses and highly divergent data partitions. By
contrast, PaFL allows clients for whom the global model performance is underwhelming to diverge in a manner which
maintains accuracy on the whole federated distribution on
which the model was trained.
Formally, PaFL can be defined as a type of Federated Learning where each client has a loss function obeying the structure in Eq. (8):
𝑙 (𝐶, 𝑥, 𝑡) = 𝜇 (𝑡) 𝐿(𝐶, 𝑥) + (1 − 𝜇 (𝑡)) 𝐷 (𝑡) (𝐶, 𝐺, 𝑥) ,

(8)

Experimental Design

Following the lead of Yu et al. [23] and McMahan et al. [18],
we train models using FedAvg, q-FedAvg, TERM, or PaFL for
next-word prediction on a version of the Reddit [1] dataset
with 80 000 participants each having 150 − 500 posts treated
as sperate sentences. We also train on CIFAR-10 partitioned
into 100 participants and the naturally heterogeneous Federated Extended MNIST (FEMNIST) [1] for image recognition.
During local adaptation, we follow the parameters recommended by Yu et al. [23]. For EWC, we use a weighting of
𝜆 = 5000; for KD, we use a temperature 𝑇 = 6 and weighting
𝛼 = 0.95. Our hyperparameter choices attempt to replicate
those of Yu et al. [23] whenever possible.
Reddit. Reddit contains diverse sentences from its forum users, which makes it a valuable resource for Federated
Learning, as users’ total word counts and vocabulary size
vary across several orders of magnitude with a skewed distribution. We train a standard LSTM for next-word prediction
using 2 layers, 200 hidden units and 10 million parameters.
To construct tokens, we employ the dictionary of the 50, 000
most frequent words compiled by Yu et al. [23]; all other
words are replaced with placeholders. The first 90% of a
user’s posts, chronologically, is used as a training set, with
the final 10% reserved for local testing. A separate centralised
test set is maintained for evaluating global task performance
during the FL training process with ≈ 5% of it used to track
convergence. In contrast, the full test set is used for the final
evaluation. Federated models train for 1 000 rounds using
20 clients per round. On the client side, models train for 2
internal epochs with a batch size of 20 using SGD with a
learning rate of 40. For adaptation, we use a learning rate of
1 and batch size of 20 for 100 epochs of retraining.
FEMNIST. Federated Extended MNIST is an image dataset
comprised of 62 characters written in a 28𝑥28 format. It
is naturally divided into clients based on the author of a
character, with each client having 226 samples on average.
We use a similar experimental setup to Caldas et al. [1] with
a simple two-layer CNN. Rather than subsampling 5% of
the data from all clients as Caldas et al. [1] do, we keep 350
clients with more than 10 samples out of the total 3 597. We

PREPRINT: Accepted at The 3rd Workshop on Machine Learning and Systems (EuroMLSys 20223)

CIFAR-10. CIFAR-10 is an image dataset composed of
60, 000 images of 10 objects in a 32𝑥32 format. Since CIFAR10 is not a naturally federated dataset as it is not split into
clients, a Dirichlet distribution (𝛼 = 0.9) is used to simulate
a Non-IID partitioning similarly to Hsu et al. [7] and Yu et al.
[23]. A ResNet-18 [4] model is trained over 1, 000 rounds
with 10 clients per round. Clients are trained using a batch
size of 32 with 2 internal epochs and a learning rate of 0.1.
The test accuracy is computed by multiplying a client’s perclass accuracy on the CIFAR-10 test set with its proportion
of the local device data. For adaptation, we use a learning
rate of 10−3 and batch size of 32 for 200 epochs. Training
uses SGD with momentum 0.9 and weight decay 5 × 10−4 ,
4.1

Experiments

We train models for FedAvg, q-FedAvg, TERM and PaFL.
Specifically, FedAvg (i.e., q-FedAvg with 𝑞 = 0) is trained
using the abovementioned standard parameters and serves
as the baseline for all datasets and models. For q-FedAvg,
we test 𝑞 ∈ {0, 0.01, 0.1, 0.5, 1, 5} for Reddit and show evaluation results for the relevant values of 𝑞 ∈ {0, 0.1, 5} which
produce sufficiently distinguished results. Similarly, we test
𝑞 ∈ {0, 0.1, 1, 5, 10, 15} for FEMNIST and CIFAR-10, and
we report the evaluation results for 𝑞 ∈ {0, 10, 15} and
𝑞 ∈ {0, 5, 15} respectively as to showcase the overall trend
that increases in fairness create. For TERM on Reddit we use
𝑡 ∈ {0.1, 5} while on FEMNIST we do not tune the value of
𝑡 for TERM and instead reuse the 𝑡 = 1 value chosen by Li
et al. [12]. For PaFL we choose a simple proof-of-concept
training sequence where we apply KD or EWC with constant
weightings and parameters after the model has approached
convergence at the halfway point of training—denoted 𝐻𝐸𝑊 𝐶
and 𝐻𝐾𝐷 . We use the same parameters and weightings for
the losses after the halfway point as in local adaptation.
Centralised evaluation. The first experiment uses the
held-out centralised test set of each dataset defined above to
test federated models. It is also used to choose which models should be tested locally or adapted given our hardware
constraints from Section 4.2.
Local Accuracy Evaluation. The second experiment
evaluates federated models on each client’s local test set
and reports average accuracy and variance for the client
population. We also investigate accuracy and variance for
the best and worst 10% of clients in terms of test accuracy.
Finally, we report the average accuracy of locally trained

models using the same parameters as in the local adaptation
phase without the personalisation loss.
Local Adaptation and Relative Accuracy Evaluation.
The primary experimental setup entails comparing the accuracy of federated or adapted models with purely local models
on client data; the difference between the two is referred to
as relative accuracy. The effectiveness of federated models is
determined by two key factors: the number of clients with
positive relative accuracy and the average relative accuracy.
If a synergistic relationship exists between FFL or PaFL and
local adaptation methods, models trained using these techniques would significantly improve average relative accuracy
or have fewer underperforming clients after adaptation.
4.2

Hardware Limitations

Each node of the cluster that the experiments were run on
holds four Nvidia A100 GPUs. Given the quotas and service
levels of the cluster, the number of clients on which the
federated model could be tested locally for the language task
was limited to ∼ 65 500 to avoid incurring costs beyond the
allocated university funds. Similarly, the number that could
be adapted was limited to (∼ 18500). Therefore, all charts and
tables comparing local model or adaptation performance use
data from the client set common to all results.

5

Results

We begin by examining the convergence process for nextword prediction on Reddit and summarise our findings on the
centralised test-set accuracy and local accuracy. As shown in
Fig. 1 and Table 1, the impact of q-FFL on accuracy is neutral
to negative for our tested 𝑞-values, while that of TERM is
highly negative for all tested 𝑡. Although fairness reliably reduces the accuracy variance for 𝑞 ≥ 1, the performance cost
is too high for all values reported in Section 4.1. Meanwhile,
we found that TERM did not obtain acceptable performance
q=0

q = 0.1

q=5

t=5

t = 0.1

HEWC

HKD

20
18

Acccent (%) (Linear)

use 70% of a client’s data for training, 10% for local testing
and add the remaining 20% to the federated test set. For the
FL process, we use an aggregation learning rate of 𝜂 = 1.0
with 10 clients per round for 500 rounds. During training, we
use SGD for 2 internal epochs with a learning rate of 0.1 and
a batch size of 32 for each client, while during adaptation,
we lower the learning rate to 0.01.

16
14
12
10
8
6
4
2
0

0

200

400

600

800

1000

# Round

Figure 1. Language task test-set accuracy, TERM harms
performance for our tested values while q-FFL only does
so significantly for 𝑞 ≥ 1.0. Crucially, both 𝐻𝐸𝑊 𝐶 and 𝐻𝐾𝐷
approach the FedAvg baseline with 𝐻𝐾𝐷 exceeding it.

PREPRINT: Accepted at The 3rd Workshop on Machine Learning and Systems (EuroMLSys 20223)
q=0

q = 10

q = 15

t=1

HEWC

HKD

90

Acccent (%) (Linear)

75
60
45
30
15
0

0

100

200

300

400

500

# Round

Figure 2. FEMNIST centralised accuracy, q-FFL and PaFl
approach FedAvg for our tested hyperparameters while causing increased instability in the training process or outright
divergence past a certain round—for such models, we test
and adapt the last version before divergence. TERM merely
underperforms without divergence for the 𝑡 = 1 value.

for any (t) we explored and excluded it from future Reddit
experiments.
Moving on to the FEMNIST training results, Fig. 2 and
Table 2 show that q-FedAvg and PaFL both tend to cause
instability for our hyperparameters. However, both q-FedAvg
with 𝑞 = 10 and 𝐻𝐾𝐷 have a comparable centralised and
average local accuracy to FedAvg. Unlike Reddit, TERM is
well-behaved at a value of 𝑡 = 1 and thus included in future
experiments.
Table 3 indicates the CIFAR-10 image classification task
to be more resilient to fairness than previous tasks, with a
noticeable accuracy decrease only observable for 𝑞 ≥ 10. The
lower sensitivity of this task to FFL is consistent with Yu et al.
[23] who find CIFAR-10 highly resilient to robust [22] FL and
differential privacy [21]. Due to the similarity across fairness
levels, the convergence graph for CIFAR-10 is not shown.
Given this lesser sensitivity for our tested values, we chose
not to expand the CIFAR-10 experiments past q-FedAvg and
𝐻𝐾𝐷 . These findings indicate that the dataset heterogeneity
may need to be meaningful rather than artificially imposed
for significant effects to emerge.
Implications: The loss-based averaging mechanism of qFedAvg and TERM is not guaranteed to improve the final
accuracy distribution proportionally to the fairness parameter and may fail to do so under our specific experimental
conditions. This calls for further inquiry into the viability of
such methods.
5.1

FFL fails to improve relative accuracy

Having established baselines of accuracy for fair models, we
can now evaluate the relative accuracy of FFL, PaFL and their
interactions with local adaptation. Unfortunately, the CIFAR10 data is uninformative as the federated model outperforms

Objective 𝐴𝑐𝑐𝑐𝑒𝑛𝑡 (%)

𝐴𝑣𝑔𝑙𝑜𝑐 (%)

𝐵𝑙𝑜𝑐 (%) 𝑊𝑙𝑜𝑐 (%)

(𝑉 𝑎𝑟 𝐴𝑣𝑔 )

(𝑉 𝑎𝑟 𝐵 )

(𝑉 𝑎𝑟𝑊 )

𝑞=0
𝑞 = 0.1
𝑞=5

17.826
17.789
14.056

18.645
18.66
14.819

24.572
24.843
20.208

14.815
14.728
11.66

9.177
9.81
7.983

22.114
22.914
26.769

1.072
1.036
0.69

𝑡 = 0.1
𝑡 =5

14.299
14.373

16.476
16.438

28.985
28.981

11.806
11.766

39.584
39.642

176.42
175.96

0.369
0.382

𝐻𝐸𝑊 𝐶
𝐻𝐾𝐷

17.322
18.177

18.255
19.179

24.653
26.406

14.226
14.887

10.277
12.438

23.059
25.85

1.185
1.039

Local

NaN

4.456

10.227

1.204

8.777

31.11

0.893

Table 1. Results showing the centralised and local accuracy
on Reddit. The 𝐴𝑐𝑐𝑐𝑒𝑛𝑡 (%) value refers to the accuracy of
the federated model on the centralised test set. In contrast,
𝐴𝑣𝑔𝑙𝑜𝑐 (%), 𝐵𝑙𝑜𝑐 (%), and𝑊𝑙𝑜𝑐 (%) refer to the average accuracy
of the model on the local test sets of the whole population,
the top 10% of clients in terms of local accuracy and the worst
10% respectively. The (𝑉 𝑎𝑟 𝐴𝑣𝑔 ), (𝑉 𝑎𝑟 𝐵 ), and (𝑉 𝑎𝑟𝑊 ) values
refer to the variance in accuracy seen by the populations
above. While fairness does decrease variance at 𝑞 ≥ 1.0,
the harm to accuracy is too great compared to 𝑞 = 0.1. The
proposed 𝐻𝐾𝐷 model improves accuracy across clients but
increases variance for everyone except the worst performers.

𝐴𝑣𝑔𝑙𝑜𝑐 (%)

𝐵𝑙𝑜𝑐 (%) 𝑊𝑙𝑜𝑐 (%)

(𝑉 𝑎𝑟 𝐴𝑣𝑔 )

(𝑉 𝑎𝑟 𝐵 )

(𝑉 𝑎𝑟𝑊 )

𝑞=0
𝑞 = 10
𝑞 = 15
𝑡 =1

Objective 𝐴𝑐𝑐𝑐𝑒𝑛𝑡 (%)
84.739
84.19
78.634
77.706

75.341
76.591
69.749
69.134

99.435
99.013
96.681
98.628

35.717
42.055
34.988
33.478

432.507
320.385
374.637
417.448

1.151
1.714
5.177
2.771

73.747
64.049
47.761
56.543

𝐻𝐸𝑊 𝐶
𝐻𝐾𝐷

82.825
84.51

73.964
75.243

99.321
99.491

33.457
34.34

465.605
443.015

1.376
1.07

71.481
62.91

Local

NaN

46.322

92.848

0.0

1006.77

18.144

0.0

Table 2. Results for FEMNIST. Unlike Reddit, there did not
seem to be a clear proportional relation between accuracy
and fairness level for our tested parameters; as such, we
chose to report the best and “fairest” value. Furthermore,
using KD helps the best performers primarily; however, both
𝐻𝐾𝐷 and 𝐻𝐸𝑊 𝐶 do well.

Objective 𝐴𝑐𝑐𝑐𝑒𝑛𝑡 (%)

𝐴𝑣𝑔𝑙𝑜𝑐 (%)

𝐵𝑙𝑜𝑐 (%) 𝑊𝑙𝑜𝑐 (%)

(𝑉 𝑎𝑟 𝐴𝑣𝑔 )

(𝑉 𝑎𝑟 𝐵 )

(𝑉 𝑎𝑟𝑊 )

𝑞=0
𝑞=5
𝑞 = 15

81.28
81.86
78.16

81.37
81.221
79.935

82.255
82.011
81.178

79.864
79.794
77.885

0.568
0.446
0.945

0.022
0.004
0.02

1.067
0.643
1.267

Local

NaN

31.718

38.297

24.649

16.3

1.543

0.906

Table 3. Results for CIFAR-10. Unlike the language task,
𝑞 = 5 represents an optimum across all our tested values in
terms of variance while maintaining performance; however,
differences are small.

the local one for all clients, consistent with the findings of
Yu et al. [23].
For q-FFL, the results for the language task showcased in
Table 4 are less than satisfactory as fair models fail to provide
benefits in terms of the number of underperforming clients,
relative accuracy, or variance. Furthermore, fair models do

PREPRINT: Accepted at The 3rd Workshop on Machine Learning and Systems (EuroMLSys 20223)
% <0 𝐵𝑙𝑜𝑐 (%) 𝑊𝑙𝑜𝑐 (%)

(𝑉 𝑎𝑟 𝐴𝑣𝑔 )

(𝑉 𝑎𝑟 𝐵 )

𝑞=0
14.185
A_FB
15.87
A_EWC 16.046
A_KD
15.538

53
0
0
0

20.715
25.849
27.558
24.376

9.392
11.311
11.304
11.209

13.323
29.216
36.067
23.112

34.379 20.201
149.736 3.246
178.387 3.337
115.016 3.183

𝑞 = 0.1

𝑞 = 0.1
A_FB
A_EWC
A_KD

14.208
15.827
15.839
15.546

50
0
0
0

20.907
25.964
27.692
24.614

9.359
11.261
11.024
11.19

13.742
29.505
37.108
23.95

35.005 20.733
149.011 3.212
179.066 3.336
118.471 3.166

𝐻𝐸𝑊 𝐶

𝐻𝐸𝑊 𝐶
A_FB
A_EWC
A_KD

13.807
15.423
15.561
15.157

108
0
0
0

20.723
25.709
27.482
24.336

8.681
10.88
10.762
10.823

14.994
29.795
37.251
23.996

38.119 24.938
149.308 3.02
179.528 3.266
117.427 3.041

𝐻𝐾𝐷

𝐻𝐾𝐷
14.729
A_FB
15.772
A_EWC 15.824
A_KD
15.698

27
0
2
0

22.038
26.533
28.217
25.358

9.971
11.154
10.966
11.214

14.969
31.068
38.439
25.367

41.225 18.409
150.552 3.156
178.543 3.469
119.418 3.241

Objective

Adapt

𝑞=0

𝐴𝑣𝑔𝑙𝑜𝑐 (%)

(𝑉 𝑎𝑟𝑊 )

Table 4. Results showing the relative accuracy of FFL and PaFL models on Reddit, % < 0 refers to the number of clients with
negative relative accuracy. The best value in a column is bold, while the best in a group is underlined. The chosen optimal fair
model does not significantly reduce the number of underperforming clients in our experiments. Alternatively, 𝐻𝐾𝐷 lowers it
to half. Local adaptation always provides similar results for the chosen hyperparameters.

not offer an improvement over FedAvg once adapted—this is
directly visible in the Fig. 3a scatter plot of relative accuracy
against local model accuracy.
The results for image recognition on FEMNIST are more
unusual yet similarly discouraging for both q-FFL and TERM.
Table 5 makes it clear that the fair model achieves a higher
relative accuracy on average and amongst the top 10% of
clients at the cost of obtaining a negative relative accuracy
on the worst 10%. Additionally, it has over twice as many
underperforming clients with negative relative accuracies.
We speculate that focusing on clients with high losses harms
the accuracy of fair models on those capable of training highquality local models. This result is corroborated by the final
distribution shown in Fig. 3b, as all the underperforming
clients have high local model accuracy. Another factor to
consider is the atypical personalisation behaviour of FEMNIST. Models trained with FedAvg and then adapted tend to
converge to nearly the same relative accuracy regardless of
adaptation technique.
Implications: For our tested hyperparameters, Fair FL training algorithms may harm the relative accuracy distribution
for datasets where clients can train high-quality local models
by themselves. Therefore, we explore a training methodology
intended not to sacrifice accuracy for such clients.
5.2

PaFL as an Alternative

Having shown the inability of FFL to replace or enhance local
adaptation, we argue that it is not the right approach for

this application. In principle, for an FL algorithm to provide
benefits in terms of relative accuracy, it must achieve two
goals. First, it must ensure that the worst-performing clients
receive sufficient accuracy to match or exceed local models.
Second, for the clients with the best local models, it must
provide disproportionately high accuracy. While FFL may
help fulfil the first requirement, its inability to raise the floor
of the worst performers without hurting the ceiling of those
that might have an excellent local model makes it incapable
of fulfilling the second in our simulations.
Personalisation-aware Federated Learning, in the most
general case, offers an alternative where models can be kept
closer to one another during training and only allowed to
diverge in ways which hurt federated performance the least.
Unlike regularisation based on the norm of the distance
between model parameters (e.g., FedProx), EWC and KD offer
the distinct advantage of determining how a parameter may
diverge based on its importance to federated performance.
Thus, the model can learn from highly heterogeneous data
and raise its accuracy floor for the worst performers without
hurting the accuracy ceiling of the best or even improving it.
Preliminary results for the language task are promising
in the case of 𝐻𝐾𝐷 as Figure 1 and Table 1 indicate that it
performs better than FedAvg and FFL models in every metric
except variance and best-performer variance. Notably, variance is not increased for the worst performers. On the other
hand, while 𝐻𝐸𝑊 𝐶 is not far below the FedAvg baseline, it
fails to provide any noticeable improvements. In terms of

PREPRINT: Accepted at The 3rd Workshop on Machine Learning and Systems (EuroMLSys 20223)
Objective

Adapt

𝐴𝑣𝑔𝑙𝑜𝑐 (%)

% <0 𝐵𝑙𝑜𝑐 (%) 𝑊𝑙𝑜𝑐 (%)

(𝑉 𝑎𝑟 𝐴𝑣𝑔 )

(𝑉 𝑎𝑟 𝐵 )

(𝑉 𝑎𝑟𝑊 )

𝑞=0

𝑞=0
A_FB
A_EWC
A_KD

29.02
28.954
28.994
28.986

16
17
16
16

65.768
65.463
65.672
65.684

2.729
2.72
2.802
2.788

338.387
334.754
336.25
337.14

137.366
134.824
137.507
137.796

12.33
11.853
11.325
11.594

𝑞 = 10

𝑞 = 10
A_FB
A_EWC
A_KD

30.269
28.613
28.612
28.563

39
12
14
14

79.687
64.818
64.818
64.645

-14.844
2.699
2.516
2.52

673.351
320.729
321.3
320.957

111.144
123.679
123.679
127.618

206.995
15.552
15.869
15.934

𝑡 =1

𝑡 =1
A_FB
A_EWC
A_KD

22.812
21.261
21.362
21.202

56
15
15
15

73.593
50.057
50.218
50.1

-17.069
0.806
0.765
0.706

627.167
201.35
201.703
202.488

215.261
127.802
123.192
125.153

91.294
8.417
8.102
7.71

𝐻𝐸𝑊 𝐶

𝐻𝐸𝑊 𝐶
A_FB
A_EWC
A_KD

27.642
27.558
27.603
27.611

13
14
13
13

62.157
62.431
62.588
62.588

1.522
1.404
1.349
1.542

315.388
316.622
315.619
314.112

123.438
124.092
122.717
122.717

19.225
18.888
20.502
19.176

𝐻𝐾𝐷

𝐻𝐾𝐷
A_FB
A_EWC
A_KD

28.921
28.916
28.871
28.967

16
17
16
15

66.178
66.605
66.605
66.329

1.65
1.644
1.719
1.869

353.698
350.631
350.742
351.991

154.217
152.111
152.111
150.583

16.231
16.922
16.865
17.124

Table 5. FEMNIST performance of the best fair model and our proposed alternative. Despite providing the highest average
relative accuracy and the highest amongst the best 10%, the model trained using 𝑞 = 10 has more than double the number of
underperforming clients of FedAvg (𝑞 = 0). This is also true for TERM with 𝑡 = 1. For PaFL, 𝐻𝐾𝐷 is close to FedAvg while
𝐻𝐸𝑊 𝐶 improves the number of underperforming clients for both baseline and adapted models.

relative accuracy, Table 4 shows that 𝐻𝐾𝐷 halves the number
of underperforming clients and provides the best average
relative accuracy. However, this higher baseline does not
translate to improved relative accuracy for adapted models.
Overall, lowering the number of clients which require adaptation in order to receive an incentive to participate 𝐻𝐾𝐷
successfully reduces the need for personalisation on Reddit.
On the other hand, 𝐻𝐸𝑊 𝐶 seems to double the number of
underperforming clients for the fixed chosen 𝜆, although a
different value may change results.
For image recognition on FEMNIST, 𝐻𝐾𝐷 and 𝐻𝐸𝑊 𝐶 are
satisfactory in terms of centralised and average accuracy
according to Fig. 2 and Table 2. On the other hand, relative
accuracy results in Table 5 are mixed. While both avoid the
doubling in underperforming clients that fair models suffer,
locally adapted models starting from 𝐻𝐾𝐷 as a baseline do
not seem to outperform those adapted from FedAvg. Perhaps
surprisingly, given its failure on the language task, 𝐻𝐸𝑊 𝐶
reduced the number of underperforming clients for baseline
and adapted models despite a lower starting average relative
accuracy than q-FedAvg and 𝐻𝐾𝐷 . While more experiments
are needed, it indicates potential synergy between PaFL and
local adaptation.

Implications: Personalisation-aware Federated Learning
may successfully improve the relative accuracy distribution
across all clients. By constraining divergence from the federated model in a manner meaningful to performance, PaFL
may learn from clients with “harder” datasets without harming the accuracy of those capable of training high-quality
local models.

6

Conclusion

This paper set out to incentivise FL participation for clients
whose local model outperforms a federated one while lowering the need for costly personalisation. Such a reduction
would be relevant for federated networks containing devices
with limited capabilities for retraining or little data. Our
results indicate that FFL is unlikely to provide the desired
properties as it did not reduce the number of underperforming clients on Reddit while doubling it on FEMNIST. We
hypothesise that Fair FL harms clients on whom the federated model performs well but could train an excellent local
model alone. Personalisation-aware Federated Learning offers an alternative approach, allowing loss functions used
for local adaptation to be applied during FL and vary across
rounds. After partial convergence, we applied EWC or KD

PREPRINT: Accepted at The 3rd Workshop on Machine Learning and Systems (EuroMLSys 20223)
(a) Reddit relative accuracy, fairness shows no benefit while 𝐻𝐾𝐷 reduces the number of underperforming clients without adaptation.

(b) FEMNIST results, clients with highly accurate local models are underserved by federated models trained using 𝑞 = 10 as many become
underperformers. Alternatively, those trained using 𝐻𝐸𝑊 𝐶 receive a slight improvement over FedAvg even when adapted.

Figure 3. Federated or adapted model relative accuracy on a client plotted against local client model accuracy. The horizontal
lines represent either the threshold for underperformance (0) or the average accuracy of a group of clients.
to enable learning from worst-performing data without sacrificing performance on the federated distribution. While
our chosen EWC configuration did not significantly improve
over FedAvg on Reddit, KD showed promising results by reducing the number of underperforming clients by up to 50%.
Furthermore, both avoided increasing the number of underperforming clients on FEMNIST while EWC slightly lowered
it even for adapted models. Unlike more complex systems,
which simultaneously train local and federated models, this
approach does not require storing an additional model nor
keeping it synchronised to the federated one. For KD, the
computational overhead is smaller than a local model as it
does not require training two separate networks, thus avoiding one of the two backward passes required by systems employing local models requir. For EWC, the advantage is even
more apparent as computation scales only in the number
of network parameters and requires no additional forward
or backward passes to be performed. Consequently, we recommend using it to incentivise participation even when an
explicit final local adaptation stage is not applied. In terms of
future work, more extensive simulations and the addition of
theoretical analyses would allow for greater insight into the
relation between fairness and the loss function used during
training and adaptation.

PREPRINT: Accepted at The 3rd Workshop on Machine Learning and Systems (EuroMLSys 20223)

References
[1] Sebastian Caldas, Peter Wu, Tian Li, Jakub Konečný, H. Brendan
McMahan, Virginia Smith, and Ameet Talwalkar. 2018. LEAF: A
Benchmark for Federated Settings. CoRR abs/1812.01097 (2018).
arXiv:1812.01097 http://arxiv.org/abs/1812.01097
[2] Amir Gholami, Sehoon Kim, Zhen Dong, Zhewei Yao, Michael W.
Mahoney, and Kurt Keutzer. 2021. A Survey of Quantization Methods
for Efficient Neural Network Inference. CoRR abs/2103.13630 (2021).
arXiv:2103.13630 https://arxiv.org/abs/2103.13630
[3] Ian J. Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, and Yoshua
Bengio. 2013. An Empirical Investigation of Catastrophic Forgetting
in Gradient-Based Neural Networks. https://doi.org/10.48550/ARXIV.
1312.6211
[4] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep
Residual Learning for Image Recognition. In 2016 IEEE Conference
on Computer Vision and Pattern Recognition, CVPR 2016, Las Vegas,
NV, USA, June 27-30, 2016. IEEE Computer Society, 770–778. https:
//doi.org/10.1109/CVPR.2016.90
[5] Geoffrey E. Hinton, Oriol Vinyals, and Jeffrey Dean. 2015. Distilling
the Knowledge in a Neural Network. CoRR abs/1503.02531 (2015).
arXiv:1503.02531 http://arxiv.org/abs/1503.02531
[6] Kevin Hsieh, Amar Phanishayee, Onur Mutlu, and Phillip Gibbons.
2020. The Non-IID Data Quagmire of Decentralized Machine Learning.
In Proceedings of the 37th International Conference on Machine Learning
(Proceedings of Machine Learning Research, Vol. 119), Hal Daumé III
and Aarti Singh (Eds.). PMLR, 4387–4398. https://proceedings.mlr.
press/v119/hsieh20a.html
[7] Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown. 2019. Measuring
the Effects of Non-Identical Data Distribution for Federated Visual
Classification. CoRR abs/1909.06335 (2019). arXiv:1909.06335 http:
//arxiv.org/abs/1909.06335
[8] Peter Kairouz, H. Brendan McMahan, Brendan Avent, Aurélien Bellet,
Mehdi Bennis, Arjun Nitin Bhagoji, Kallista A. Bonawitz, Zachary
Charles, Graham Cormode, Rachel Cummings, Rafael G. L. D’Oliveira,
Hubert Eichner, Salim El Rouayheb, David Evans, Josh Gardner,
Zachary Garrett, Adrià Gascón, Badih Ghazi, Phillip B. Gibbons, Marco
Gruteser, Zaïd Harchaoui, Chaoyang He, Lie He, Zhouyuan Huo, Ben
Hutchinson, Justin Hsu, Martin Jaggi, Tara Javidi, Gauri Joshi, Mikhail
Khodak, Jakub Konečný, Aleksandra Korolova, Farinaz Koushanfar,
Sanmi Koyejo, Tancrède Lepoint, Yang Liu, Prateek Mittal, Mehryar
Mohri, Richard Nock, Ayfer Özgür, Rasmus Pagh, Hang Qi, Daniel
Ramage, Ramesh Raskar, Mariana Raykova, Dawn Song, Weikang
Song, Sebastian U. Stich, Ziteng Sun, Ananda Theertha Suresh, Florian
Tramèr, Praneeth Vepakomma, Jianyu Wang, Li Xiong, Zheng Xu,
Qiang Yang, Felix X. Yu, Han Yu, and Sen Zhao. 2021. Advances and
Open Problems in Federated Learning. Found. Trends Mach. Learn. 14,
1-2 (2021), 1–210. https://doi.org/10.1561/2200000083
[9] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness,
Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago
Ramalho, Agnieszka Grabska-Barwinska, et al. 2017. Overcoming
catastrophic forgetting in neural networks. Proceedings of the national
academy of sciences 114, 13 (2017), 3521–3526.
[10] S. Kullback and R. A. Leibler. 1951. On Information and Sufficiency.
The Annals of Mathematical Statistics 22, 1 (1951), 79 – 86. https:
//doi.org/10.1214/aoms/1177729694
[11] Tian Li, Ahmad Beirami, Maziar Sanjabi, and Virginia Smith. 2021.
Tilted Empirical Risk Minimization. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria,
May 3-7, 2021. OpenReview.net. https://openreview.net/forum?id=
K5YasWXZT3O
[12] Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith. 2021.
Ditto: Fair and Robust Federated Learning Through Personalization.
In Proceedings of the 38th International Conference on Machine Learning
(Proceedings of Machine Learning Research, Vol. 139), Marina Meila and

Tong Zhang (Eds.). PMLR, 6357–6368. https://proceedings.mlr.press/
v139/li21h.html
[13] Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. 2020.
Federated Learning: Challenges, Methods, and Future Directions. IEEE
Signal Process. Mag. 37, 3 (2020), 50–60. https://doi.org/10.1109/MSP.
2020.2975749
[14] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet
Talwalkar, and Virginia Smith. 2020. Federated Optimization in Heterogeneous Networks. In Proceedings of Machine Learning and Systems 2020, MLSys 2020, Austin, TX, USA, March 2-4, 2020, Inderjit S.
Dhillon, Dimitris S. Papailiopoulos, and Vivienne Sze (Eds.). mlsys.org.
https://proceedings.mlsys.org/book/316.pdf
[15] Tian Li, Maziar Sanjabi, Ahmad Beirami, and Virginia Smith. 2020. Fair
Resource Allocation in Federated Learning. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia,
April 26-30, 2020. OpenReview.net. https://openreview.net/forum?id=
ByexElSYDr
[16] Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua
Zhang. 2020. On the Convergence of FedAvg on Non-IID Data. In
8th International Conference on Learning Representations, ICLR 2020,
Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net. https:
//openreview.net/forum?id=HJxNAnVtDS
[17] Yishay Mansour, Mehryar Mohri, Jae Ro, and Ananda Theertha Suresh.
2020. Three Approaches for Personalization with Applications to
Federated Learning. CoRR abs/2002.10619 (2020). arXiv:2002.10619
https://arxiv.org/abs/2002.10619
[18] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
Blaise Agüera y Arcas. 2017. Communication-Efficient Learning of
Deep Networks from Decentralized Data. In Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, AISTATS
2017, 20-22 April 2017, Fort Lauderdale, FL, USA (Proceedings of Machine
Learning Research, Vol. 54), Aarti Singh and Xiaojin (Jerry) Zhu (Eds.).
PMLR, 1273–1282. http://proceedings.mlr.press/v54/mcmahan17a.
html
[19] Matthias Paulik, Matt Seigel, Henry Mason, Dominic Telaar, Joris
Kluivers, Rogier C. van Dalen, Chi Wai Lau, Luke Carlson, Filip
Granqvist, Chris Vandevelde, Sudeep Agarwal, Julien Freudiger, Andrew Byde, Abhishek Bhowmick, Gaurav Kapoor, Si Beaumont, Áine
Cahill, Dominic Hughes, Omid Javidbakht, Fei Dong, Rehan Rishi, and
Stanley Hung. 2021. Federated Evaluation and Tuning for On-Device
Personalization: System Design & Applications. CoRR abs/2102.08503
(2021). arXiv:2102.08503 https://arxiv.org/abs/2102.08503
[20] Kangkang Wang, Rajiv Mathews, Chloé Kiddon, Hubert Eichner,
Françoise Beaufays, and Daniel Ramage. 2019. Federated Evaluation of On-device Personalization. CoRR abs/1910.10252 (2019).
arXiv:1910.10252 http://arxiv.org/abs/1910.10252
[21] Kang Wei, Jun Li, Ming Ding, Chuan Ma, Howard H. Yang, Farhad
Farokhi, Shi Jin, Tony Q. S. Quek, and H. Vincent Poor. 2020. Federated Learning With Differential Privacy: Algorithms and Performance
Analysis. IEEE Transactions on Information Forensics and Security 15
(2020), 3454–3469. https://doi.org/10.1109/TIFS.2020.2988575
[22] Dong Yin, Yudong Chen, Ramchandran Kannan, and Peter Bartlett.
2018. Byzantine-robust distributed learning: Towards optimal statistical rates. In International Conference on Machine Learning. PMLR,
5650–5659.
[23] Tao Yu, Eugene Bagdasaryan, and Vitaly Shmatikov. 2020. Salvaging
Federated Learning by Local Adaptation. CoRR abs/2002.04758 (2020).
arXiv:2002.04758 https://arxiv.org/abs/2002.04758
[24] Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and
Vikas Chandra. 2018. Federated Learning with Non-IID Data. CoRR
abs/1806.00582 (2018). arXiv:1806.00582 http://arxiv.org/abs/1806.
00582

Federated Learning (FL) enables training ML models on edge clients without sharing data. However, the federated model's performance on local data varies, disincentivising the participation of clients who benefit less from FL. Fair FL reduces accuracy disparity by focusing on clients with higher losses while personalisation locally fine-tunes the model. Personalisation provides a participation incentive when an FL model underperforms \emph{relative} to one trained locally. This paper evaluates two Fair FL (FFL) algorithms as starting points for personalisation. Our results show that FFL provides no benefit to relative performance in a language task and may double the number of underperforming clients for an image task. Instead, we propose Personalisation-aware Federated Learning (PaFL) as a paradigm that pre-emptively uses personalisation losses during training. Our technique shows a $50\%$ reduction in the number of underperforming clients for the language task while slightly lowering the number of underperforming clients in the image task instead of doubling it. Thus, it allows a broader range of devices to benefit from FL.

