Învățarea Federată (referită ca FL din termenul englez ``Federated Learning'') este o paradigmă de Învățare Automată Distribuită (referită ca ML din termenul englez ``Machine Learning'')  care permite mai multor clienți să antreneze un model colaborativ comun fără a comunica date private. Aceasta a fost introdusa de \citet{FedAvg} ca un mijloc de reducere a costurilor de comunicare și de diminuare a problemelor de confidențialitate legate de stocarea datelor sensibile într-o locație centralizată. Aceste proprietăți au condus la aplicații FL utilizând grupuri mari de dispozitive de dimensiuni mici, cum ar fi predicția tastaturii mobile~\citep{GoogleKeyboard} pentru telefoanele Android și aplicații cu entități mai mari supuse cerințelor de confidențialitate, cum ar fi spitalele~\citep{FLmedicine}. Aceste două tipuri de Învățare Federată sunt distinse de \citet{AdvancedAndOpenProblems} ca FL cross-device și cross-silo. Pentru restul acestei lucrări un ``client'' se referă la o entitate deținătoare de date private ce efectuează antrenament federat (e.g., telefoane/spitale).

Creșterea preponderenței FL de la publicarea \citet{FedAvg} poate fi atribuită către două trenduri. În primul rând, o creștere a cerințelor de confidențialitate ale consumatorilor și ale cadrului juridic a pus presiune pe companiile de tehnologie. Această presiune a condus la interesul pentru ML care protejează confidențialitatea în cadrul corporațiilor majore precum Google~\citep{FedAvg,GoogleKeyboard,ScaleSystemDesign}, Microsoft~\citep{FLINT} și  Meta~\citep{PAPAYA,FedBuff}. În al doilea rând, ML s-a extins către domenii cu cerințe stricte de confidențialitate precum sănătatea~\citep{FLmedicine}, Recunoașterea Activităților Umane~\citep{HARusingFL_2018,ClusterFL} sau colaborările între corporații~\citep{SustainableIncentive}. Mai mult, apariția Modelelor de Limbaj Mari (referită ca LLM din termenul englez ``Large Language Model'')~\citep{OpportunitiesAndRisksLLM} a făcut accesarea colecțiilor private de limbaj natural avantajoasă, conducând la dezvoltarea FL pentru Procesare a Limbajului Natural~\citep{FedNLP}. În mod similar, lansarea de ponderi~(weights) open pre-antrenate~\citep{LLaMA} permite colaborarea între entități cu resurse computaționale reduse, utilizând framework-uri de FL~\citep{Flower}.

Deși domeniul s-a bucurat de o atenție științifică și industrială sporită, beneficiile pe care le oferă confidențialitatea și comunicarea cauzează provocări semnificative în ceea ce privește creșterea eficienței și evoluția sistemelor federate. În mod crucial, compromisul de a antrena un singur model global nu este potrivit atunci când clienții eterogeni necesită personalizarea parțială sau completă a modelului pentru distribuția lor locală de date.

Această lucrare propune abordarea provocărilor menționate prin construirea de structuri de rețea federate ierarhice de tip arbore, care permit flux de date bidirecțional, unde fiecare frunză este un client, iar fiecare nod intern este un server capabil de antrenament pe date proxy. În consecință, nodurile apropiate de frunze sunt personalizate pentru populația specifică de clienți a subarborelui, iar cele apropiate de rădăcină oferă modele generalizate. Această abordare este denumită Învățare Federată Ierarhică Bidirecțională (referită ca B-HFL din termenul englez ``Bidirectional Hierarchical Federated Learning''). Mai mult, clienții pot executa antrenare asincronă cu modele persistente pentru a aborda shitful în distribuțiile lor de date.
\subsection{Motivație}

În forma sa standard, FL operează direct pe clienți, folosind un server centralizat pentru a distribui parametrii modelului și, apoi, pentru a-i agrega după antrenarea clientului. Acest proces este repetat pentru mai multe runde. Cu toate acestea, datele în FL sunt supuse atributelor precum: locația geografică a clientului, specificațiile senzorului și comportamentul clientului. Datorită acestor factori, distribuția federată încalcă ipoteza Independenței și Identității Distribuției (IID). O astfel de \emph{eterogenitate a datelor}~\citep[sec. 3.1]{AdvancedAndOpenProblems} este împletită cu \emph{eterogenitatea sistemelor}~\citep[sec. 7.2]{AdvancedAndOpenProblems} deoarece clienții au abilități de calcul și viteze diferite de rețea. În plus, costurile de comunicare ale modelului între servere și clienți sunt semnificative. Deoarece eterogenitatea datelor face construirea unui singur model global eficient pentru datele tuturor clienților să fie imposibilă, este propusă crearea unor niveluri arbitrare de personalizare sub forma Învățării Federate Ierarhice într-un mod ce îmbunătățește eficiența și permite evoluția sistemelor.
\subsubsection{Eficiență}

Eficiența și scalabilitatea au fost în centrul cercetării FL de la momentul în care \citet{GoogleKeyboard} a aplicat FL pentru predicția tastaturii mobile de la Google. Pe baza lucrării \citet{GoogleKeyboard}, \citet{ScaleSystemDesign} a demonstrat că FL poate fi folosit pentru a antrena modele în zeci de milioane de smartphone-uri. Cu toate acestea, în ciuda prognozelor optimiste de un miliard de dispozitive ale \citet{ScaleSystemDesign}, au apărut multiple limitări ale eficienței FL. Aceste limitări sunt de trei feluri: (a) FL sincron poate folosi eficient doar sute de dispozitive din miloane în fiecare rundă, (b) antrenarea federată este considerabil mai lentă decât antrenarea centralizată, (c) dispozitivele utilizatorilor sunt nesigure, ceea ce duce la deconectarea acestora. Aceste limitări au primit o atenție suplimentară în evaluarea empirică a \citet{LargeCohorts}.

\citet{LargeCohorts} arată că performanța FL nu se îmbunătățește precum era de așteptat când numărul de clienți antrenați într-o rundă crește, în ciuda lucrărilor teoretice contrare~\citep{TighterTheory}. Rezultatele lor experimentale arată că principala limitare a creșterii dimensiunii grupurilor în setări Non-IID este diferența dintre actualizările de model ale clienților, indicată printr-un cosinus aproape zero între acestea. Această diferență limitează impactul fiecărei runde, provoacă randamente diminuate la creșterea dimensiunii grupurilor și rezultă în incapacitatea de a învăța eficient din datele clienților. Astfel, având în vedere că algoritmii FL sunt intrinsec paraleli, scalabilitatea lor este limitată de capacitatea de a învăța eficient pe baza fiecărui exemplu de antrenament al clienților. În plus, în timp ce investigațiile originale ale \citet{ScaleSystemDesign,LargeCohorts} erau cross-device, problema învățării eficiente de la clienți se aplică și situațiilor cross-silo.


\subsubsection{Evoluție}
Seturile de date ale clienților care formează o rețea federată nu sunt în general statice. Clienții pot șterge datele imediat după generare, periodic sau ad-hoc, în funcție de necesitățile de memorie sau de cererile proprietarului. În plus, caracteristicile datelor nou adăugate se pot modifica în timp într-un mod gradat sau imediat. De exemplu, în sarcinile de recunoaștere a imaginilor, tranzițiile sezoniere pot modifica încet imaginile capturate, în timp ce schimbarea locațiilor sau actualizarea hardware-ului camerei poate duce la schimbări discrete. Această problemă este cunoscută sub numele de ``shift'' al setului de date~\citep[sec. 3.1]{AdvancedAndOpenProblems} și reprezintă eterogenitatea \emph{în-client} mai degrabă decât eterogenitatea \emph{între-clienți}, mai comună. Algoritmii sincroni de Învățare Federată~\citep{FedAvg,FedOPT,QFedAvg} presupun că antrenarea clienților se realizează doar pe modelul federat primit la începutul unei runde. Chiar și sistemele ce mențin modele locale persistente~\citep{Ditto}, presupun că acest model persistent este folosit doar în timpul rundelor FL. Prin urmare, abordările actuale nu pot capta schimbările în distribuția datelor unui client. Sistemele asincrone de FL~\citep{AsynchronousFLonHetDevicesSurvey,FedBuff}, precum PAPAYA de la Meta~\citep{PAPAYA}, permit clienților să fie utilizați în afara limitelor unei runde. Cu toate acestea, ele consideră antrenarea clienților doar pe cea mai recentă versiune accesibila a modelului federat.

\subsection{Rezumatul propunerii}

Această propunere extinde lucrările realizate de \citet{EuroMLSysWorkshop} și \citet{OperaWorkshop} pe subiectele de Învățare Federată personalizată, respectiv ierarhică. Sistemul propus comunică datele într-o structură de tip arbore, așa cum este ilustrat în \cref{fig:TreeStructure}. În mod crucial, parametrii modelelor pot circula în ambele sensuri, iar nodurile pot aplica actualizări parțiale de la părinții lor prin agregare. În plus, fiecare nod poate asocia o pondere diferită parametrilor copiilor și părinților în timp ce folosește metode precum optimizatori adaptivi de server~\citep{FedOPT} sau cele bazate pe antrenare~\citep{Ditto,EWC,DeepMutualLearning}. Algoritmii adaptivi sunt relevanți deoarece permit fiecărui nod din arbore să se distingă în funcție de starea sa anterioară, fără a necesita ajustarea suplimentară a parametrilor. În final, în cazul în care grupurile de clienți sunt construite în mod semantic, această structură poate permite o creștere drastică a eficienței sistemului, deoarece fiecare cluster decide cum să optimizeze între generalizare și personalizare~\citep{PersonalisationGeneralisationTradeoff}. Contribuțiile potențiale ale propunerii includ:
\begin{enumerate}
    \item O familie de algoritmi FL ierarhici și scalabili care permit un control fin asupra personalizării și generalizării de la rădăcina globală până la frunzele complet personalizate.
    \item Investigarea a trei tehnici complementare permise de aceste structuri ierarhice: (a) permiterea frunzelor (clienților) să mențină modele locale persistente care se antrenează asincron pentru a aborda shiftul temporal al setului de date, (b) capabilitatea ca orice nod din arbore să se antreneze cu un set de date proxy pentru a injecta o perspectivă generală modelului, (c) construirea de conexiuni verticale suplimentare în arbore similare cu conexiunile reziduale~\citep{ResNet} pentru a permite un flux de date modificabil fără a schimba infrastructura de comunicare.
    \item Evaluări empirice extinse care iau în considerare scenarii cu sau fără clustere semnificative de clienți în sarcini de recunoaștere a limbajului sau, dacă timpul permite, a vorbirii umane.
    \item O lucrare științifică care este menită publicării la conferința \href{https://iclr.cc/}{ICLR} sau \href{https://mlsys.org/}{MLSys}. Această publicație va fi urmată de o lucrare destinată pentru conferința \href{https://sigmobile.org/mobicom/2023/}{MobiCom} ce investighează antrenamentul asincron pe dispozitive cu resurse limitate, cu shift de set de date, folosind clusterul Raspberry Pi FL din laboratorul Cambridge ML Systems.
\end{enumerate}
