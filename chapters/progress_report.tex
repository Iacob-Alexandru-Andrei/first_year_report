The proposal in this document emerged as a natural consequence of research on Personalised Federated Learning and Hierarchical Federated Learning I began during my MPhil in Advanced Computer Science and the first year of my PhD. All the mentioned works are available as appendices to this proposal.

\section{Fairness and Personalisation}

\citet{EuroMLSysWorkshop} investigated the trade-off between generalisation and personalisation, which is at the heart of this work, from the perspectives of Fair Federated Learning and its interactions with local adaptation~(fine-tuning) of the federated model post-training. Since Fair Federated Learning attempts to construct a more uniform accuracy distribution for the federated model over the local test sets of clients, the expectation was to either reduce the need for personalization or to provide a better starting point from which to carry it out. The experimental results showed that Fair FL brings no benefits and potential downsides towards later personalization and led to the proposal of a Personalisation-aware FL algorithm that attempts to anticipate the common regularises used during fine-tuning throughout the FL process.

Personalisation-aware FL functions in two phases, first it allows standard FL training to progress unimpeded. After near-convergence, it injects common personalisation regularises such as Knowledge Distillation~\citep{DistillingKnowledgeInNeuralNetworks,DeepMutualLearning} or Elastic-weight Consolidation~\citep{EWC} into the local client loss function where the reference model is taken to be the federated model from the start of the round. This allows the model to learn from the distributions of highly heterogeneous clients without harming performance on the overall federated network which enables a better distribution of accuracy over clients without the harm to average performance that Fair FL is known to bring~\citep{QFedAvg,TERM}. While more effective than Fair FL, this regularisation-based approach is still limited by the goal of training a single global model without any intermediary level of personalisation between the federated model and fine-tuned local models.

\section{Hierarchical multimodal Federated Human Activity Recognition}
\citet{OperaWorkshop} evaluated the performance of Federated Human Activity Recognition~\citep{HARusingFL_2018} when trained using multimodal data gathered from different sensor types at increasing levels of privacy. It showed that grouping clients based on the type of sensor that produced their training set effectively mitigated the impacts of privacy being required at a human subject, environment, and sensor level simultaneously. It was a direct precursor to Bidirectional Hierarchical Federated Learning as it relied on a two-tiered model structure where each client trained both a group-level model and the global federated model using a mutual learning approach~\citep{DeepMutualLearning}. This work was later extended to consider the adaptability of such two-tiered systems to the addition of a new sensor type~(group) into the federation; the extension was submitted to the \href{https://mobiuk.org/2023}{MobiUK} symposium. Mutual learning was chosen to relate the group-level and global models since it allowed divergent architectures that only shared the output layer. However, despite its success, this training method requires clients to have a high amount of data and local epochs to train both models. The expensive nature of the procedure prompted a move towards the more flexible and potentially data-free methods (such as FedOPT with persistent models) considered in this proposal.

\section{Simulation efficiency}
Both of the previous works were implemented in the Flower~\citep{Flower} FL framework; however, the scale of experimentation required for fully validating B-HFL would be unfeasible on the publicly available simulation engine in the case of cross-device scenarios. The previous Virtual Client Engine (VCE) of Flower used the Ray~\citep{RAY} distributed execution engine for simulation, which is designed for few long-running ML tasks rather than the numerous and short-running client training of FL\@. Furthermore, Ray does not have a means of forcefully freeing GPU-memory allocated by an ML framework like PyTorch without killing a process. This resulted in slow training times, instability and frequent disk spillage.

To correct these issues, I have contributed to research on a new engine that doubles Flower simulations' throughput by intelligent ML-based client placement on GPUs. Since clients in FL are heterogeneous in terms of workloads, pre-processing pipelines and dataset size this required more than mere load-balancing based on sample count. The system functions by actively placing clients to workers on specific GPUs based on a log-linear model which estimates client training time on a given piece of hardware based on historic data. The workers then perform local averaging in order to minimise communication. This system results in up-to $400\%$ improvements in FL training time compared to other FL frameworks like FedScale~\citep{FedScale}, original Flower~\citep{Flower}, and Flute~\citep{Flute}. The paper ``High-throughput Simulation of Federated Learning via Resource-Aware Client Placement'' will be submitted to \href{https://mlsys.org/}{MLSys}.

