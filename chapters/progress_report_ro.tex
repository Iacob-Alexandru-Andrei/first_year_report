Propunerea din acest document a apărut drept consecință naturală a cercetărilor privind Învățarea Federată Personalizată și Învățarea Federată Ierarhică efectuate în timpul Masterului meu în Informatică Avansată și în primul an al doctoratului meu în laboratorul Cambridge ML Systems, condus de Dr. Nicholas Lane.

\citet{EuroMLSysWorkshop} a investigat compromisul dintre generalizare și personalizare, care este în centrul acestui studiu, din perspectiva ``Fair'' FL~(FFL) și a interacțiunilor sale cu adaptarea locală~(fine-tuning) a modelului federat post-antrenament. Deoarece FFL încearcă să construiască o distribuție mai uniformă a acurateții pentru modelul federat pe seturile de date de testare locale ale clienților, așteptarea era fie reducerea necesității personalizării, fie oferirea unui punct de plecare mai avantajos din care să fie efectuată adaptarea locală. Rezultatele experimentale au arătat că FFL nu aduce beneficii. În schimb, are potențiale dezavantaje pentru aplicarea ulterioară a adaptării. Aceste dezavantaje au dus la propunerea unui algoritm FL conștient de personalizarea ulterioară (``Personalisation-aware Federated Learning'') care încearcă să anticipeze funcțiile de cost comune, utilizate în timpul fine-tuning-ului pe parcursul procesului FL.

\citet{OperaWorkshop} a evaluat performanța Recunoașterii Activităților Umane Federate~\citep{HARusingFL_2018} folosind date multimodale adunate de la diferite tipuri de senzori. Scopul era evaluarea efectului menținerii datelor în cadrul stocării private, cu un nivel crescător de confidențialitate. Studiul a demonstrat că gruparea clienților în funcție de tipul de senzor care a produs setul lor de antrenament atenuează eficient impactul necesității de confidențialitate la nivel de subiect uman, de mediu și de senzor. Această lucrare a fost un precursor direct al B-HFL, deoarece se baza pe o structură de model în două niveluri în care fiecare client antrenează atât un model la nivel de grup, cât și modelul federat global, folosind o abordare de învățare mutuală~\citep{DeepMutualLearning}. Această lucrare a fost ulterior extinsă pentru a lua în considerare adaptabilitatea unor astfel de sisteme la adăugarea unui nou tip de senzor~(grup) în federație; extinderea a fost trimisă simpozionului \href{https://mobiuk.org/2023}{MobiUK}. Învățarea mutuală a fost aleasă pentru a relaționa modelele la nivel de grup cu cel global, deoarece permite utilizarea de arhitecturi divergente ce împart doar stratul final. In ciuda succesului său, această metodă de antrenament necesită ca potențialii clienți să aibă o cantitate mare de date și resurse pentru a antrena modele. Natura costisitoare a procedurii a impus o mișcare spre o abordare bazată pe agregarea modelelor.

Ambele lucrări anterioare au fost implementate în cadrul framework-ului Flower~\citep{Flower}. Cu toate acestea, scara experimentării necesare pentru validarea completă a B-HFL ar fi nerealizabilă pe motorul de simulare public. Prin urmare, am contribuit la construirea unui nou motor ce dublează debitul simulărilor FL prin plasarea bazată pe ML a clienților pe GPU-uri. Lucrarea ce prezintă tehnicile noastre, pentru care împărtășesc un credit egal de contribuție ca autor principal, ``High-throughput Simulation of Federated Learning via Resource-Aware Client Placement'' a fost trimisă la conferința \href{https://sigmobile.org/mobicom/2023/}{Mobicom} și așteaptă răspunsul.