The presented family of Bidirectional Hierarchical Federated Learning algorithms will be developed during the PhD period and will form part of the final PhD thesis. In addition, before the final thesis, it offers opportunities for conference publications that significantly contribute to Federated Learning. Given the novelty of FL in general and hierarchical FL in particular, there is ample room for further developments in the structure of B-HFL as the fields mature.

The summer period of the end of my first year of the PhD shall be dedicated to implementing the example version of B-HFL in the Flower~\citep{Flower} FL framework affiliated with our research group. The framework is currently tuned to standard FL settings and would require heavy API modifications to execute and simulate hierarchical FL effectively. However, the previous work on group-level models for Federated Human Activity Recognition of \citet{OperaWorkshop} and the effective FL simulation engine I contributed to can be the basis for implementing and streamlining the process.

The autumn Michaelmas Term of my second year will have as a main objective the publication of a conference paper based on the example system proposed in \cref{sec:example_system}. \href{https://iclr.cc/}{ICLR} and \href{https://mlsys.org/}{MLSys} would be appropriate venues. Given the growing importance of LLMs, and the trade-offs recently discovered by \citet{PersonalisationGeneralisationTradeoff} in terms of their generalization and personalization abilities with or without pre-trained weights, they represent a natural application for the proposed hierarchical system. Moreover, multi-language text prediction provides a naturally clustered FL application corresponding to real-world scenarios where countries have independent edge servers for FL and must collaborate at a continental and global level. The study would use a large multi-lingual BERT model~\citep{RoBERTA} together with two multi-language datasets~\citep[e.g., ][]{XGLUE,mC4} for training. One dataset will be partitioned by language, and the other will be kept as a proxy dataset at the central server in \cref{fig:TreeStructure}. The study's goals would be to compare the final accuracy of each model at every level of the hierarchy on the client test sets and the centralised test set created from the proxy dataset. The expectation would be for the model performance on the data of a specific client to be proportional to their proximity to that client in the tree. Alternatively, for the proxy test set and the union of all client test sets, accuracy should be proportional to the proximity to the central server. In addition, ablation studies on the ``residual'' connections, adaptive optimization, or persistent local models will also be performed with efficiency comparisons between node-execution asynchronicity at different levels of the tree.   Finally, if time allows, the paper could include other naturally-clustered tasks, such as speech recognition for multilingual data or algorithmic clustering of a standard dataset.

Following the publication of this work, a natural extension during Lent and Easter terms would be to tackle a setting where clients continuously generate and delete data with limited local storage. The example system would be extended to allow asynchronous training on all nodes, including the leaves, which run parallel to the actual FL component. Each client would generate a data stream while having a fixed internal memory to operate on during training. Real resource constraints and asynchronicity can be modelled using the Raspberry Pi FL cluster at Cambridge ML Systems. This work would likely be intended for \href{https://sigmobile.org/mobicom/2023/}{MobiCom}, the same venue we submitted the Flower simulation engine to, or another systems-oriented conference.

If successful, the second year of my PhD would bring a valuable contribution to the field of Federated Learning, result in one or more conference publication with a potential workshop work along the way, and allow me to proceed through the rest of the PhD program with a substantial amount of progress towards my final thesis. It would also result in a major extensenion to the Flower~\citep{Flower} FL framework with potential for future colaborations or employment with the  \href{https://flower.dev/blog/2023-03-08-flower-labs/}{Flower Labs} startup funded by \href{https://www.ycombinator.com/}{Y Combinator}.