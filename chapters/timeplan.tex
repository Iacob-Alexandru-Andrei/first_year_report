
The presented family of Bidirectional Hierarchical Federated Learning algorithms will be developed during the PhD period and will form part of the final PhD thesis. In addition, before the final thesis, it offers opportunities for conference publications that significantly contribute to Federated Learning. Given the novelty of FL in general and hierarchical FL in particular, there is ample room for further developments in the structure of B-HFL as the fields mature.

\section{Second-year Plan}\label{sec:timeplan:secondYear}

The summer period of the end of my first year of the PhD shall be dedicated to implementing the example version of B-HFL in the Flower~\citep{Flower} FL framework affiliated with our research group. The framework is currently tuned to standard FL settings and would require heavy API modifications to execute and simulate hierarchical FL effectively. However, the previous work on group-level models for Federated Human Activity Recognition of \citet{OperaWorkshop} and the effective FL simulation engine I contributed to can be the basis for implementing and streamlining the process.

The autumn Michaelmas Term of my second year will have as a main objective the publication of a conference paper based on the example system proposed in \cref{sec:example_system}. \href{https://iclr.cc/}{ICLR} and \href{https://mlsys.org/}{MLSys} would be appropriate venues. Given the growing importance of LLMs, and the trade-offs recently discovered by \citet{PersonalisationGeneralisationTradeoff} in terms of their generalisation and personalisation abilities with or without pre-trained weights, they represent a natural application for the proposed hierarchical system. Moreover, multilingual text prediction provides a naturally clustered FL application corresponding to real-world scenarios where countries have independent edge servers for FL and must collaborate at a continental and global level. The study would use a large multilingual BERT model~\citep{RoBERTA} together with two multilingual datasets~\citep[e.g., ][]{XGLUE,mC4} for training. One dataset will be partitioned by language, and the other will be kept as a proxy dataset at the central server in \cref{fig:TreeStructure}. The study's goals would be to compare the final accuracy of each model at every level of the hierarchy on the client test sets and the centralised test set created from the proxy dataset. The expectation would be for the model performance on the data of a specific client to be proportional to their proximity to that client in the tree. Alternatively, for the proxy test set and the union of all client test sets, accuracy should be proportional to the proximity to the central server. In addition, ablation studies on the ``residual'' connections, adaptive optimisation, or persistent local models will also be performed with efficiency comparisons between node-execution asynchronicity at different levels of the tree. Finally, if time allows, the paper could include other naturally-clustered tasks, such as speech recognition for multilingual data or algorithmic clustering of a standard dataset.

Following the publication of this work, a natural extension during Lent and Easter terms would be to tackle a setting where clients continuously generate and delete data with limited local storage. The example system would be extended to allow asynchronous training on all nodes, including the leaves, which run parallel to the actual FL component. Each client would generate a data stream while having a fixed internal memory to operate on during training. Real resource constraints and asynchronicity can be modelled using the Raspberry Pi FL cluster at Cambridge ML Systems. This work would be intended for \href{https://sigmobile.org/mobicom/2023/}{MobiCom} or another systems conference. The summer term would include buffer time to account for any new projects spawned from previous ones. This would then be followed up by a further literature review on clustering and model aggregation, an inspection of the code of Auxo~\citep{Auxo}, and the implementation of early prototypes for automatic clustering in B-HFL\@.
\section{Third-year Plan}
During Michaelmas, I would finalise the thesis's literature review and implement an automatic hierarchical clustering system in the vein of Auxo. If successful, this would be intended for a potential publication at ICLR or a later conference.

The beginning of lent term will represent the beginning of the thesis write-up considering all work done up to that point. Lent term would then involve exploring different residual selection criteria and complex aggregation procedures based on the hierarchical structure of the model, assuming that the B-HFL system contains natural or automatically constructed clusters. The findings would be written up for a conference or workshop if successful. Otherwise, they would only get incorporated into the thesis.

Easter term would be devoted to finishing any work leftover from Michaelmas or Lent. It would be otherwise devoted to constructing a complete thesis outline and continuing the write-up started in the Lent term. The summer term would be dedicated entirely to finishing the thesis.

